TY  - JOUR
T1  - Gamifying information security: Adversarial risk exploration for IT/OT infrastructures
AU  - Luh, Robert
AU  - Eresheim, Sebastian
AU  - Tavolato, Paul
AU  - Petelin, Thomas
AU  - Gmeiner, Simon
AU  - Holzinger, Andreas
AU  - Schrittwieser, Sebastian
JO  - Computers & Security
VL  - 151
SP  - 104287
PY  - 2025
DA  - 2025/04/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104287
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824005935
KW  - Hacking
KW  - Security game
KW  - Model
KW  - Gamification
AB  - Today’s interconnected IT and OT infrastructure faces an array of cyber threats from diverse actors with varying motivations and capabilities. The increasing complexity of exposed systems, coupled with adversaries’ sophisticated technical arsenals, poses significant challenges for organizations seeking to defend against these attacks. Understanding the relationship between specific attack techniques and effective technical, organizational and human-centric mitigation measures remains elusive, as does grasping the underlying principles of information security and how they may be applied to cyber defense. In response to these challenges, we propose a gamified metamodel that combines well-established frameworks, including MITRE ATT&CK, D3FEND, CAPEC, and the NIST SP 800-53 security standard. The programmatic implementation of the model, “PenQuest”, combines elements of game theory with cybersecurity concepts to enhance risk assessment and training for IT practitioners and security engineers. In PenQuest, participants engage in a digital battle — attackers attempt to compromise an abstracted IT infrastructure, while defenders work to prevent or mitigate the threat. Bot opponents and the technical foundation for reinforcement learning enable future automated strategy inference. This paper provides an in-depth exploration of the metamodel, the game’s components and features built to translate cybersecurity principles into strategy game rules, and the technical implementation of a mature, ready-to-use education and risk exploration solution. Future work will focus on further improving the attack likelihood and detection chance algorithms for seamless risk assessment.
ER  - 

TY  - JOUR
T1  - Explainable DNN for smart contract vulnerability detection in the Metaverse
AU  - Nkoro, Ebuka Chinaechetam
AU  - Ahakonye, Love Allen Chijioke
AU  - Kim, Dong-Seong
JO  - High-Confidence Computing
SP  - 100374
PY  - 2025
DA  - 2025/11/11/
SN  - 2667-2952
DO  - https://doi.org/10.1016/j.hcc.2025.100374
UR  - https://www.sciencedirect.com/science/article/pii/S2667295225000789
KW  - Blockchain
KW  - Metaverse
KW  - Cybersecurity
KW  - Deep learning
KW  - Explainable AI
KW  - Smart contract
KW  - Machine learning
KW  - Vulnerability detection
KW  - Smart contract analysis
KW  - Ethereum smart contract
KW  - Blockchain vulnerabilities
KW  - LLMs
AB  - Smart Contracts (SCs), which are the backbone of automated transactions and digital assets within the Metaverse, ironically suffer from their own share of security vulnerabilities. While detecting these SC vulnerabilities using Artificial Intelligence (AI) and Deep Neural Networks (DNNs) has demonstrated remarkable performance and gained wide adoption, a critical limitation remains: the lack of explainability in these black box models. To facilitate meaningful progress in this field, our study addresses this gap by introducing a model-agnostic explanation framework that is both visual and quantitative, with human stakeholders actively involved to govern, verify, and interpret SC model predictions. The explainable SC outputs can be utilized for reward issuance and digital assets governance in the Metaverse. The effectiveness of our proposed Explainable AI (XAI) approach is validated using benchmark datasets, BCCC SCsVul 2024 and BCCC SCsVul 2023, comprising Ethereum SC entropy source codes, where it achieves an optimal detection accuracy of 97.13% alongside comprehensive explainability. To the best of our knowledge, this represents the first attempt at making Ethereum SC vulnerability detection within the Metaverse explainable, offering a valuable foundation for blockchain researchers, Metaverse security experts, and practitioners seeking verifiable, trustworthy, and auditable Ethereum SC vulnerability detection.
ER  - 

TY  - JOUR
T1  - Enhancing Cyber-Physical-Social Systems through Decentralized Governance and Blockchain-based Digital Twins
AU  - Hosseini Bamakan, Seyed Mojtaba
AU  - Dehghan, Farnaz
AU  - Far, Saeed Banaeian
AU  - Zareravasan, Ahad
JO  - Procedia Computer Science
VL  - 266
SP  - 971
EP  - 978
PY  - 2025
DA  - 2025/01/01/
T2  - The 12th International Conference on Information Technology and Quantitative Management (ITQM 2025)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2025.08.120
UR  - https://www.sciencedirect.com/science/article/pii/S1877050925024317
KW  - Cyber-Physical-Social Systems
KW  - Digital Twins
KW  - DAOs
KW  - Decentralized Governance
KW  - Blockchain Technology
AB  - Cyber-Physical-Social Systems (CPSS), as emerging paradigms, are evolving to address the growing need for intelligent, adaptive, and transparent decision-making in complex environments such as smart cities and industrial systems. However, the advancements enabled by Digital Twins (DTs), centralized governance models, and opaque analytics limit scalability and resilience. In this study, we propose a decentralized governance framework that integrates Decentralized Autonomous Organizations (DAOs) and blockchain-based predictive analytics to enhance trust, interoperability, and ethical decision-making for CPSS. The proposed framework utilizes immutable ledgers, automated smart contracts, and community-driven governance to improve real-time collaboration, thereby ensuring system resilience and facilitating adaptive optimization. The remarkable innovation of the CPSS framework lies in combining digital tokens (DTs) within a blockchain application. We believe that our approach provides a scalable mechanism for autonomous decision-making and secure data sharing across multi-stakeholder ecosystems. In this regard, using theoretical analysis and comparative evaluations, we have demonstrated how our framework mitigates conventional challenges in CPSS governance, including security vulnerabilities, algorithmic fairness, and data integrity. Moreover, this research makes a significant contribution to the advancement of decentralized digital twin (DT) infrastructures, paving the way for more robust, ethically aligned, and resilient cyber-physical systems.
ER  - 

TY  - JOUR
T1  - Mining user privacy concern topics from app reviews
AU  - Zhang, Jianzhang
AU  - Zhou, Jialong
AU  - Hua, Jinping
AU  - Niu, Nan
AU  - Liu, Chuang
JO  - Journal of Systems and Software
VL  - 222
SP  - 112355
PY  - 2025
DA  - 2025/04/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2025.112355
UR  - https://www.sciencedirect.com/science/article/pii/S0164121225000238
KW  - Privacy concerns
KW  - Topic modeling
KW  - App reviews mining
KW  - Privacy requirements
KW  - Requirements engineering
AB  - Context:
As mobile applications (apps) widely spread throughout our society and daily life, various personal information is constantly demanded by apps in exchange for more intelligent and customized functionality. An increasing number of users are voicing their privacy concerns through app reviews on app stores.
Objective:
The main challenge of effectively mining privacy concerns from user reviews lies in that reviews expressing privacy concerns are overridden by a large number of reviews expressing more generic themes and noisy content. In this work, we propose a novel automated approach to overcome that challenge.
Method:
Our approach first employs information retrieval and document embeddings to extract candidate privacy reviews in an unsupervised manner, which are further labeled to prepare the annotation dataset. Then, supervised classifiers are trained to automatically identify privacy reviews. Finally, an interpretable topic mining algorithm is designed to detect privacy concern topics contained in the privacy reviews.
Results:
Experimental results show that the best performing document embedding achieves an average precision of 96.80% in the top 100 retrieved candidate privacy reviews, outperforming the taxonomy-based baseline, which achieves 73.87%. All trained privacy review classifiers achieve an F1 score above 91%, surpassing the keyword-matching baseline by as much as 7.5% and the large language model baseline by up to 2.74%. For detecting privacy concern topics from privacy reviews, our proposed algorithm achieves both better topic coherence and topic diversity than three strong topic modeling baselines, including LDA.
Conclusion:
Empirical evaluation results demonstrate the effectiveness of our approach in identifying privacy reviews and detecting user privacy concerns in app reviews.
ER  - 

TY  - JOUR
T1  - An LLM-Based Virtual Assistant for Tele-operation of Industrial Electrical Systems
AU  - da Luz Sanchez, Ary H.
AU  - Figueiró, Iuri C.
AU  - Pohren, Daniel H.
AU  - de Freitas, Edison P.
AU  - Roque, Alexandre dos S.
JO  - IFAC-PapersOnLine
VL  - 59
IS  - 27
SP  - 184
EP  - 189
PY  - 2025
DA  - 2025/01/01/
T2  - 7th IFAC Symposium on Telematics Applications TA 2025
SN  - 2405-8963
DO  - https://doi.org/10.1016/j.ifacol.2025.12.100
UR  - https://www.sciencedirect.com/science/article/pii/S240589632502782X
KW  - Industrial Internet of Things
KW  - Tele-operation
KW  - LLM AI assistant
KW  - Maintenance
AB  - Industrial Internet of Things (IIoT) and Artificial Intelligence (AI) approaches, when combined, represent an innovative way of remote asset operation and maintenance. This paper proposes a novel virtual assistant based on an AI agent for interaction between humans and industrial machines. The system can understand natural human language as input values for tasks such as controlling and monitoring electrical systems, based on a system that allows the parametrization of commands via standardized communication protocols, such as CANopen and Modbus. A generative artificial intelligence model is applied, and refined with persona characteristics and specific settings for standardizing responses to trigger the desired electrical system commands. The evaluation is performed by integrating the AI assistant with an IoT device connected to the CFW-11 frequency inverter, as a case study. The preliminary results show the effectiveness of sending control commands and also the conversion and communication with the device, in test scenarios of control and data acquisition.
ER  - 

TY  - JOUR
T1  - Zero day malware detection with Alpha: Fast DBI with Transformer models for real world application
AU  - Gaber, Matthew
AU  - Ahmed, Mohiuddin
AU  - Janicke, Helge
JO  - Computers and Electrical Engineering
VL  - 128
SP  - 110751
PY  - 2025
DA  - 2025/12/01/
SN  - 0045-7906
DO  - https://doi.org/10.1016/j.compeleceng.2025.110751
UR  - https://www.sciencedirect.com/science/article/pii/S0045790625006949
KW  - Dynamic binary instrumentation
KW  - Malware analysis
KW  - Feature extraction
KW  - Ransomware
KW  - Transformers
KW  - LLM
KW  - AI
KW  - Assembly
AB  - The effectiveness of an AI model in accurately classifying novel malware hinges on the quality of the features it is trained on, which in turn depends on the effectiveness of the analysis tool used. Peekaboo, a Dynamic Binary Instrumentation (DBI) tool, defeats malware evasion techniques to capture authentic behavior at the Assembly (ASM) instruction level. This behavior exhibits patterns consistent with Zipf’s law, a distribution commonly seen in natural languages, making Transformer models particularly effective for binary classification tasks. We introduce Alpha, a framework for zero-day malware detection that leverages Transformer models, Support Vector Machines (SVMs) and ASM language features. Alpha is trained on malware and benign software data extracted at the ASM level, enabling it to detect entirely new malware samples with exceptional accuracy. Alpha eliminates any common functions from the test samples that are in the training dataset. This forces the model to rely on contextual patterns and novel ASM instruction combinations to detect malicious behavior, rather than memorizing familiar features. By combining the strengths of DBI, ASM analysis, and Transformer architectures, Alpha offers a powerful approach to proactively addressing the evolving threat of malware. Alpha demonstrates excellent accuracy for Ransomware, Worms and APTs with flawless classification for both malicious and benign samples. The results highlight the model’s exceptional performance in detecting truly new malware samples.
ER  - 

TY  - JOUR
T1  - MMEF-SSCT: A novel multidimensional and multi-level comprehensive evaluation framework for software supply chain threats
AU  - Wang, Maoyang
AU  - Luo, Qin
AU  - Wu, Peng
AU  - Zheng, Hongdi
JO  - Expert Systems with Applications
VL  - 296
SP  - 128924
PY  - 2026
DA  - 2026/01/15/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2025.128924
UR  - https://www.sciencedirect.com/science/article/pii/S0957417425025412
KW  - Software supply chain
KW  - Threat evaluation framework
KW  - Threat indicator system
KW  - Threat quantification
AB  - The software supply chain is currently facing a significant security challenge due to the rapid development of the software industry and the frequent occurrence of supply chain threat events, and the complex supply chain has led to an infinite expansion of the attack surface. However, existing research lacks a comprehensive quantitative assessment of potential threats. We propose a multi-dimensional and multi-level comprehensive assessment method for the first time, based on an indicator matrix and a large number of event texts, an assessment framework of “Technique and Impact” is constructed. The Analytic Hierarchy Process (AHP) method is also adjusted to quantify the weights of the multilevel indicators and accurately score the threats. The proposed framework has been validated through an in-depth analysis of real software supply chain events. It has been found to be effective in 81.67 % of real software supply chain events. Compared to classical qualitative and quantitative methods, the proposed method demonstrates an improvement of 15 %.
ER  - 

TY  - JOUR
T1  - TextJosher: A transfer-based black-box attack method Against text classifiers
AU  - Wang, Peishuai
AU  - Zhang, Sicong
AU  - Xu, Yang
AU  - He, Xinlong
AU  - Xu, Weida
JO  - Information Sciences
VL  - 731
SP  - 122888
PY  - 2026
DA  - 2026/04/05/
SN  - 0020-0255
DO  - https://doi.org/10.1016/j.ins.2025.122888
UR  - https://www.sciencedirect.com/science/article/pii/S0020025525010242
KW  - Natural language processing
KW  - Surrogate model
KW  - Adversarial attack
KW  - Textual adversarial examples
KW  - Semantic similarity
AB  - Although deep neural networks have achieved significant success in various domains, they remain susceptible to attacks from carefully crafted adversarial examples in the field of text. Existing text classification adversarial attack methods often suffer from low attack success rates and poor quality of generated samples, mainly due to two challenges: (1) accurately identifying salient tokens that significantly influence model decisions; (2) misleading classifiers with minimal text modifications while preserving semantic meaning and grammaticality. To address these issues, we propose TextJosher, a text adversarial example generation framework for text classification based on transfer-based black-box attacks. To overcome the non-differentiability of discrete text, TextJosher employs a local surrogate model to estimate gradients and computes embedding-level saliency to identify critical tokens. Furthermore, to improve the quality and stealthiness of adversarial samples, we design a decoding mechanism that integrates a masked language model head with a multi-constraint loss, incorporating both semantic similarity and grammatical fluency. Extensive experiments on text classification demonstrate that TextJosher outperforms baselines in terms of success rate, semantic similarity, and fluency. Its adversarial examples also transfer to LLaMA-2-7B-Chat and Mistral-7B-Instruct under decision-only, zero-shot evaluation, achieving high attack success rates on these large language models.
ER  - 

TY  - JOUR
T1  - Taxonomy of digital twins for power grids
AU  - Pavleska, Tanja
JO  - Advanced Engineering Informatics
VL  - 70
SP  - 104124
PY  - 2026
DA  - 2026/03/01/
SN  - 1474-0346
DO  - https://doi.org/10.1016/j.aei.2025.104124
UR  - https://www.sciencedirect.com/science/article/pii/S1474034625010171
KW  - Taxonomy
KW  - Power grids
KW  - Smart grids
KW  - Digital Twin
KW  - Co-occurrence analysis
KW  - Interactive tool
KW  - Maturity assessment
AB  - Digital twins (DTs) are increasingly adopted in the energy sector, yet existing conceptual frameworks and maturity models remain largely generic, limiting their usefulness for power grid applications with stringent requirements for resilience, security, and lifecycle integration. This paper proposes an upgraded taxonomy of DTs tailored to power grid systems, extending earlier generic frameworks and aligning them with the ISO/IEC30186:2025 maturity model. The taxonomy introduces domain-specific dimensions, including cyber-physical security integration, intelligence level, and multi-layered data architectures, while ensuring compatibility with internationally standardized maturity aspects. A comprehensive literature analysis and co-occurrence study underpin the revisions, ensuring both methodological rigor and relevance to current research and practice. The taxonomy’s analytical and practical value is demonstrated through its application to three real-world DT use cases: KOEN (generation-focused), Elvia (distribution-focused), and Bentley OpenUtilities (lifecycle-integrated). Comparative benchmarking across these cases highlights both commonalities and context-dependent maturity profiles, confirming that DT maturity is not absolute but shaped by organizational objectives, technical architectures, and sectoral priorities. The taxonomy also enables scenario-based reasoning and role-specific insights, supporting cybersecurity analysis, operational decision-making, and business risk evaluation. By combining academic rigor, sector-specific focus, and alignment with international standards, the proposed taxonomy offers a replicable framework for assessing and improving DT maturity in power grids. An interactive tool, openly available on GitHub, further supports its practical application by enabling benchmarking, visualization, and recommendations. In this way, the work contributes both to scholarly discourse on DT conceptualization and to the practical adoption of maturity frameworks by utilities, regulators, and technology providers.
ER  - 

TY  - JOUR
T1  - Digital Twins-enabled Zero Touch Network: A smart contract and explainable AI integrated cybersecurity framework
AU  - Kumar, Randhir
AU  - Aljuhani, Ahamed
AU  - Javeed, Danish
AU  - Kumar, Prabhat
AU  - Islam, Shareeful
AU  - Islam, A.K.M. Najmul
JO  - Future Generation Computer Systems
VL  - 156
SP  - 191
EP  - 205
PY  - 2024
DA  - 2024/07/01/
SN  - 0167-739X
DO  - https://doi.org/10.1016/j.future.2024.02.015
UR  - https://www.sciencedirect.com/science/article/pii/S0167739X24000608
KW  - Blockchain
KW  - Digital Twins
KW  - Explainable AI
KW  - Intrusion Detection System
KW  - Zero Touch Network
AB  - Data-driven modeling using Artificial Intelligence (AI) is envisioned as a key enabling technology for Zero Touch Network (ZTN) management. Specifically, AI has shown huge potential for automating and modeling the threat detection mechanism of complicated wireless systems. The current data-driven AI systems, however, lack transparency and accountability in their decisions, and assuring the reliability and trustworthiness of the data collected from participating entities is an important obstacle to threat detection and decision-making. To this end, we integrate smart contracts with eXplainable AI (XAI) to design a robust cybersecurity framework for ZTN. The proposed framework uses a blockchain and smart contract-enabled access control and authentication mechanism to ensure trust among the participating entities. Additionally, with the collected data, we designed Digital Twins (DTs) for simulating the attack detection operation in the ZTN environment. Specifically, to provide a platform for analysis and the development of an Intrusion Detection System (IDS), the DTs are equipped with a variety of process-aware attack scenarios. A Self Attention-based Long Short Term Memory (SALSTM) network is used to evaluate the attack detection capabilities of the proposed framework. Furthermore, the explainability of the proposed AI-based IDS is achieved using the SHapley Additive exPlanations (SHAP) tool. The experimental results using N-BaIoT and a self-generated DTs dataset confirm the superiority of the proposed framework over some baseline and state-of-the-art techniques.
ER  - 

TY  - JOUR
T1  - PWAGAT: Potential Web attacker detection based on graph attention network
AU  - Xu, Yijia
AU  - Fang, Yong
AU  - Liu, Zhonglin
AU  - Zhang, Qiang
JO  - Neurocomputing
VL  - 557
SP  - 126725
PY  - 2023
DA  - 2023/11/07/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2023.126725
UR  - https://www.sciencedirect.com/science/article/pii/S0925231223008482
KW  - Probing behavior
KW  - Potential attacker
KW  - Bert
KW  - Graph Attention Network
KW  - Deep forest
AB  - Attacker probing behavior detection is a notch in the current security defense system. Most cyber-attack detection research focuses on real-time payload interception and attack source tracing. However, the defense system cannot predict the attack behavior before the attack launches and cannot provide sufficient reaction and preparation time for the network administrators. Therefore, the current security system urgently needs to be improved by detecting cyber-attack precursors. We propose a potential Web attacker identification method based on a graph attention network (PWAGAT) by studying the features of the attacker’s behavior pattern before launching a Web attack. The core of PWAGAT is to identify the probing behavior of attackers and find those suspicious users with a high probability of carrying out Web attacks. The PWAGAT trains the embedding learning representation of each behavioral node from the Web attack behavior graph (WABG) through GAT and then uses the deep forest algorithm to train a classification model that recognizes probing behaviors. On the WAB-dataset provided by the Institute of Information Security of Sichuan University, the experiment proved that PWAGAT performed better than other graph learning methods in performing node embedding and classification of hacking behaviors. The results showed that identifying hacker probing behavior could help discover potential Web attackers, alerting defenders to assist in subsequent attack detection.
ER  - 

TY  - JOUR
T1  - Experiences and challenges from a software ecosystem for cyber–physical systems development: An empirical study on industry-academia collaboration
AU  - Muttillo, Vittoriano
AU  - Eramo, Romina
AU  - Cederbladh, Johan
AU  - Strandberg, Per Erik
AU  - Ashraf, Adnan
JO  - Journal of Systems and Software
VL  - 231
SP  - 112579
PY  - 2026
DA  - 2026/01/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2025.112579
UR  - https://www.sciencedirect.com/science/article/pii/S0164121225002481
KW  - Software ecosystem
KW  - Cyber–physical systems
KW  - Industry-academia collaboration
KW  - Challenges
AB  - Software Ecosystem (SECO) has emerged as a crucial concept, which represents a collaborative and interconnected environment in which a variety of actors engage in developing software systems. SECOs play a key role in the development of Cyber–Physical Systems (CPSs), that present a myriad of challenges, primarily due to the need for real-time responsiveness, reliability, security, and interoperability. The implications of leveraging SECOs for developing CPSs are profound in both research and practice. This paper aims to understand the collaboration between industry and academia within SECOs for the development of CPSs, identifying potential challenges and providing insights and guidelines for the proper management of these collaborations. We conducted a systematic literature review (SLR), complemented by empirical evidence collected through an opinion survey administered to the partners of the European collaborative project AIDOaRt, a concrete example of a SECO, which worked on the development of CPSs. From these findings we discuss the identified challenges, and potential effects on collaboration, in addition to our lessons learned in the AIDOaRt project and SECO.
ER  - 

TY  - JOUR
T1  - Temporal transaction network anomaly detection for Industrial Internet of Things with federated graph neural networks
AU  - Wang, Qingyong
AU  - Han, Beibei
JO  - Computers & Industrial Engineering
VL  - 205
SP  - 111122
PY  - 2025
DA  - 2025/07/01/
SN  - 0360-8352
DO  - https://doi.org/10.1016/j.cie.2025.111122
UR  - https://www.sciencedirect.com/science/article/pii/S0360835225002682
KW  - Anomaly detection
KW  - Temporal transaction network
KW  - Industrial Internet of Things
KW  - Federated graph neural networks
AB  - The Industrial Internet of Things (IIoT) has experienced significant advancements in recent years, resulting in a considerable increase in the volume of data generated by interconnected devices. This surge in data has created new opportunities to enhance the quality of service in machine learning applications within the IIoT through data sharing. Among these applications, anomaly detection in transaction networks utilizing graph neural networks (GNNs) has emerged as a prominent research topic. However, most current anomaly detection methods either focus exclusively on single-faceted transaction information or assume that multiple types of transaction network data are centrally stored or shared. In the field of IIoT scenario, privacy concerns and legal restrictions frequently hinder data centralization, resulting in data islands, which refer to decentralized multisource transaction information. Therefore, we propose a novel federated GNNs framework for the temporal transaction network anomaly detection, designated as FedGT2AD. Specifically, the training process is bifurcated: client-side privacy temporal transaction network feature extraction is conducted locally at its corresponding client, while privacy-protected feature aggregation from all clients occurs on a trusted server. To facilitate more effective anomaly detection, each client initially models edge features and temporal transaction information as node attributes, along with network snapshots for subsequent graph feature computation with GNNs. During the integration process, the server integrates the node-level embedding and computes multisource transaction network features from all clients following a differential privacy mechanism to ensure client-side data security. The experimental results on three decentralized multisource transaction networks demonstrated that FedGT2AD outperforms baseline methods by 0.9% to 2.7% in accuracy. Overall, FedGT2AD offers a promising approach for mining decentralized multisource transaction networks while preserving privacy in anomaly detection tasks.
ER  - 

TY  - JOUR
T1  - Leveraging federated learning for DoS attack detection in IoT networks based on ensemble feature selection and deep learning models
AU  - Al-Ghadi, Tasneem Qasem
AU  - Manickam, Selvakumar
AU  - Widia, I. Dewa Made
AU  - Wulandari, Eka Ratri Noor
AU  - Karuppayah, Shankar
JO  - Cyber Security and Applications
VL  - 3
SP  - 100098
PY  - 2025
DA  - 2025/12/01/
SN  - 2772-9184
DO  - https://doi.org/10.1016/j.csa.2025.100098
UR  - https://www.sciencedirect.com/science/article/pii/S2772918425000153
KW  - Federated learning
KW  - DoS attack
KW  - Centralized learning
KW  - Intrusion detection system
KW  - Internet of Things
AB  - The Internet of Things (IoT) seamlessly integrates into daily life, enhancing decision-making and simplifying everyday tasks across various domains, including organizations, healthcare, the military, and industry. However, IoT systems face numerous security threats, making data protection against cyberattacks essential. While deploying an Intrusion Detection System (IDS) in a centralized framework can lead to data leakage, Federated Learning (FL) offers a privacy-preserving alternative by training models locally and transmitting only the updated model weights to a central server for aggregation. Detecting Denial-of-Service (DoS) attacks in IoT networks is critical for ensuring cybersecurity. This study compares the performance of centralized and federated learning (FL) approaches in detecting DoS attacks using four deep learning models: Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), and Convolutional Neural Network (CNN). To enhance model efficiency, we apply filter-based feature selection techniques, including Variance Threshold, Mutual Information, Chi-square, ANOVA, and L1-based methods, and employ an ensemble feature selection approach by combining them through a union operation. Additionally, a wrapper-based Recursive Feature Elimination (RFE) method is used to refine feature selection by removing redundant and irrelevant features. Experiments were conducted using the IoT Intrusion Dataset (IoTID20), and model performance was evaluated based on accuracy, precision, recall, F1-score, and ROC-AUC metrics. In the centralized learning scenario, the highest accuracy was achieved with GRU using Mutual Information (MI) at 99.91 %, followed by RNN with MI at 99.90 %. In the FL scenario, the highest accuracy was achieved with CNN using the ANOVA method at 99.73 %, followed by GRU with Chi2 at 99.61 %. These findings underscore the significant impact of feature selection on learning performance and provide valuable insights into optimizing deep learning-based DoS detection in IoT networks.
ER  - 

TY  - JOUR
T1  - MAGNet: A multimodal knowledge-augmented graph network for early-stage misinformation detection
AU  - Wang, Jinghong
AU  - Yang, Hongbo
AU  - Wang, Xizhao
AU  - Wang, Wei
AU  - Li, Yanan
JO  - Neurocomputing
VL  - 658
SP  - 131533
PY  - 2025
DA  - 2025/12/28/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2025.131533
UR  - https://www.sciencedirect.com/science/article/pii/S0925231225022052
KW  - Misinformation detection
KW  - Knowledge-augmented learning
KW  - Sentiment graph network
KW  - Multimodal representation
AB  - With the rapid proliferation of multimodal misinformation on social media, detecting such content has become increasingly challenging. Existing approaches often rely on flat or shallow fusion strategies, which fail to capture structured semantic interactions across modalities. Moreover, most methods lack controllable, task-relevant mechanisms for integrating external knowledge, limiting their adaptability to emerging misinformation. In this paper, we present MAGNet, a Multimodal Augmented Graph Network that models fine-grained features with LLM-enhanced contextual knowledge through a hierarchical graph attention framework. MAGNet constructs heterogeneous graphs with modality- and context-specific edge weights based on semantic and affective alignment, enabling progressive reasoning from local features to global representations. Extensive experiments on three real-world datasets demonstrate that MAGNet consistently outperforms strong baselines across multiple evaluation metrics. The results underscore the effectiveness of combining graph-based modeling, fine-grained fusion, and structured knowledge integration in developing scalable and robust solutions for multimodal misinformation detection.
ER  - 

TY  - JOUR
T1  - Enhancing usability in face privacy protection via vision-language guided diffusion model
AU  - Xu, Zhifeng
AU  - Yuan, Peiyao
AU  - Zhao, Yiru
AU  - Zhao, Lei
JO  - Information Sciences
VL  - 725
SP  - 122736
PY  - 2026
DA  - 2026/01/01/
SN  - 0020-0255
DO  - https://doi.org/10.1016/j.ins.2025.122736
UR  - https://www.sciencedirect.com/science/article/pii/S0020025525008722
KW  - Privacy protection
KW  - Face de-identification
KW  - Generative model
KW  - Diffusion model
KW  - Vision-language model
AB  - With the development of the Internet, a large number of images containing faces are widely shared on social media, leading to increased risks of face-based identity tracking and privacy breaches. Face de-identification serves as a privacy protection technique that conceals identifiable personal information in images. Recent advancements in generative model-based face de-identification methods have made progress in ensuring privacy while preserving image usability. However, challenges remain in enhancing the usability. Specifically, current methods often generate images with noticeable artifacts or struggle to preserve the original semantic information, which can hinder the practical applications in various computer vision tasks. In this paper, we propose a vision-language understanding-guided diffusion model for face de-identification. Our method incorporates a semantic preservation module and an identity protection module to guide the diffusion model in generating de-identified images. The semantic preservation module leverages a vision-language model to retain the sentence-level semantic information of the original image. The identity protection module perturbs the identity representation to ensure privacy. We train and evaluate our method on different datasets, and the experimental results demonstrate that, while ensuring privacy protection, our method not only surpasses existing methods in image quality but also outperforms them across multiple fine-grained utility tasks.
ER  - 

TY  - JOUR
T1  - Structure-Aware Malicious Behavior Detection through 2D Spatio-Temporal Modeling of Process Hierarchies
AU  - Yoon, Seong-Su
AU  - Shin, Dong-Hyuk
AU  - Euom, Ieck-Chae
JO  - CMES - Computer Modeling in Engineering and Sciences
VL  - 145
IS  - 2
SP  - 2683
EP  - 2706
PY  - 2025
DA  - 2025/11/26/
SN  - 1526-1492
DO  - https://doi.org/10.32604/cmes.2025.071577
UR  - https://www.sciencedirect.com/science/article/pii/S1526149225004266
KW  - System security
KW  - anomaly detection
KW  - host-based log analysis
KW  - hierarchical process structure
KW  - machine learning
KW  - deep learning
KW  - malicious behavior
AB  - With the continuous expansion of digital infrastructures, malicious behaviors in host systems have become increasingly sophisticated, often spanning multiple processes and employing obfuscation techniques to evade detection. Audit logs, such as Sysmon, offer valuable insights; however, existing approaches typically flatten event sequences or rely on generic graph models, thereby discarding the natural parent-child process hierarchy that is critical for analyzing multiprocess attacks. This paper proposes a structure-aware threat detection framework that transforms audit logs into a unified two-dimensional (2D) spatio-temporal representation, where process hierarchy is modeled as the spatial axis and event chronology as the temporal axis. In addition, entropy-based features are incorporated to robustly capture obfuscated and non-linguistic strings, overcoming the limitations of semantic embeddings. The model’s performance was evaluated on publicly available datasets, achieving competitive results with an accuracy exceeding 95% and an F1-score of at least 0.94. The proposed approach provides a promising and reproducible solution for detecting attacks with unknown indicators of compromise (IoCs) by analyzing the relationships and behaviors of processes recorded in large-scale audit logs.
ER  - 

TY  - JOUR
T1  - A novel cross-domain adaptation framework for unsupervised criminal jargon detection via pre-trained contextual embedding of darknet corpus
AU  - Ke, Liang
AU  - Xiao, Peng
AU  - Chen, Xinyu
AU  - Yu, Shui
AU  - Chen, Xingshu
AU  - Wang, Haizhou
JO  - Expert Systems with Applications
VL  - 242
SP  - 122715
PY  - 2024
DA  - 2024/05/15/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2023.122715
UR  - https://www.sciencedirect.com/science/article/pii/S0957417423032177
KW  - Jargon detection
KW  - Underground economy
KW  - Darknet markets
KW  - Unsupervised learning
KW  - Language model
AB  - As the regulation on the surface web becomes more stringent, criminals are gradually turning to the darknet markets for illicit operations. Moderating and studying the content on the marketplaces contribute to the combat of criminal forces in the darknet. Nevertheless, to evade the surveillance of law enforcement, jargons are widely used in criminal conversations as a disguise. These jargons misinterpret the meaning of seemingly innocuous words in cryptic ways, creating a huge challenge for criminal investigation. Current research on Chinese jargon detection focuses on keyword matching. However, this approach cannot keep up with the rapid update of new jargons from various domains. To the best of our knowledge, we are the first to conduct Chinese jargons detection research in the darknet markets. Specifically, we design an unsupervised cross-domain adaptation Chinese jargon detection framework (CJD-Framework) integrated with the pre-trained language model. Firstly, six underground markets in Chinese are crawled to build the first dataset of darknet corpus (DC-dataset). Next, a pre-training model based on Chinese word is proposed to extract contextual embeddings for darknet words. Finally, relying on semantic similarity analysis, a cross-corpus framework is constructed to effectively identify Chinese jargons in the darknet. Comprehensive experiments demonstrate the effectiveness and generalizability of the CJD-framework over the state-of-the-art models, with a detection accuracy of 91.5%. The darknet corpus dataset and innovative framework proposed in this research can provide sources and ideas for future analysis of underground crimes in the darknet markets.
ER  - 

TY  - JOUR
T1  - DR-RAG: Domain-Rule-based Retrieval-Augmented Generation for aviation digital model design
AU  - Xiong, Xirui
AU  - Cai, Hongming
AU  - Yu, Han
AU  - Shen, Bingqing
AU  - Hu, Pan
JO  - Advanced Engineering Informatics
VL  - 68
SP  - 103688
PY  - 2025
DA  - 2025/11/01/
SN  - 1474-0346
DO  - https://doi.org/10.1016/j.aei.2025.103688
UR  - https://www.sciencedirect.com/science/article/pii/S1474034625005816
KW  - Aviation design
KW  - Product design & manufacturing
KW  - Large language model
KW  - Knowledge graph
KW  - Retrieval-Augmented Generation
AB  - In the rapidly evolving landscape of aviation manufacturing, the increasing complexity of aircraft design demands advanced tools for knowledge integration and reasoning. This paper presents DR-RAG (Domain-Rule-based Retrieval-Augmented Generation), a novel framework that synergizes domain knowledge graphs, rule-based reasoning and digital twin technology to address design challenges. DR-RAG constructs a dynamic knowledge graph by extracting entities from multi-source data using a hybrid R2D-LLM approach. We create a rule base via fusion rules mining algorithms. These rules are integrated into a retrieval-augmented generation pipeline with a binary classifier guides rule selection and prompt templates enhance LLM reasoning. A digital twin model visualizes design outcomes and feeds simulation feedback into the knowledge graph, creating a closed-loop system for continuous improvement. Experimental results demonstrate that DR-RAG outperforms other methods in knowledge retrieval tasks related to aircraft design, providing an efficient and reliable solution for knowledge processing in this domain. This research not only offers a new decision-support tool for aviation manufacturing design but also contributes to the application of large language models in complex engineering fields.
ER  - 

TY  - JOUR
T1  - From automated to autonomous process operations
AU  - Baldea, Michael
AU  - Georgiou, Apostolos T.
AU  - Gopaluni, Bhushan
AU  - Mercangöz, Mehmet
AU  - Pantelides, Constantinos C.
AU  - Sheth, Kiran
AU  - Zavala, Victor M.
AU  - Georgakis, Christos
JO  - Computers & Chemical Engineering
VL  - 196
SP  - 109064
PY  - 2025
DA  - 2025/05/01/
SN  - 0098-1354
DO  - https://doi.org/10.1016/j.compchemeng.2025.109064
UR  - https://www.sciencedirect.com/science/article/pii/S0098135425000687
KW  - Process operations
KW  - Autonomous operations
KW  - Process sensors
KW  - Reinforcement Learning
KW  - Large-Language models
AB  - This paper considers current trends towards a higher degree of automation of process operations. Often referred to as “autonomous” process operations, these developments involve cyber-physical systems that can automate tasks that have hitherto relied extensively on human plant operators and, in particular, on their accurate assessment of the current plant situation based on a multitude of information sources, and on their ability to devise and implement plans of actions for dealing with often novel situations. The paper analyses the main drivers behind the need for a higher level of automation in process operations, and reviews the industrial applications that have been described in the public domain to date. It also presents a review of advances and potential impact of some of the enabling technologies for autonomy; these include sensors, mathematical modelling abstractions, reinforcement learning, knowledge graphs, and large language models.
ER  - 

TY  - JOUR
T1  - Enhanced phishing detection using multimodal data
AU  - Bustio-Martínez, Lázaro
AU  - Herrera-Semenets, Vitali
AU  - González-Ordiano, Jorge A.
AU  - Pérez-Guadarrama, Yamel
AU  - Zúñiga-Morales, Luis N.
AU  - Montoya-Godínez, Daniela
AU  - Álvarez-Carmona, Miguel A.
AU  - van den Berg, Jan
JO  - Knowledge-Based Systems
VL  - 334
SP  - 115105
PY  - 2026
DA  - 2026/02/15/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2025.115105
UR  - https://www.sciencedirect.com/science/article/pii/S0950705125021434
KW  - Phishing detection
KW  - Multimodal learning
KW  - Explainable artificial intelligence
KW  - Principles of Persuasion
KW  - Human-centered cybersecurity
AB  - Phishing remains one of the most persistent cybersecurity threats, increasingly exploiting not only technical vulnerabilities but also human cognitive biases. Existing detection systems often rely on single-modality features and black-box models, which restrict both generalization and interpretability. This study presents an explainable multimodal framework that combines textual and technical cues, including message content, URL structure, and Principles of Persuasion, to capture both objective and subjective aspects of phishing. Several classifiers were evaluated using 10-fold stratified cross-validation, with Random Forest achieving the best balance between performance and transparency (ROC-AUC = 0.9840), supported by SHAP explanations that identify the most influential linguistic and structural features. Comparative analysis shows that the proposed framework outperforms unimodal baselines while preserving interpretability, enabling a clear rationale for classification outcomes. These results indicate that integrating multimodal representation with explainable learning strengthens phishing detection accuracy, improves user trust, and supports reliable deployment in real-world environments.
ER  - 

TY  - JOUR
T1  - Spam email classification based on cybersecurity potential risk using natural language processing
AU  - Jáñez-Martino, Francisco
AU  - Alaiz-Rodríguez, Rocío
AU  - González-Castro, Víctor
AU  - Fidalgo, Eduardo
AU  - Alegre, Enrique
JO  - Knowledge-Based Systems
VL  - 310
SP  - 112939
PY  - 2025
DA  - 2025/02/15/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2024.112939
UR  - https://www.sciencedirect.com/science/article/pii/S0950705124015739
KW  - Malicious spam email detection
KW  - Feature extraction
KW  - NLP
KW  - Security awareness
KW  - Cybersecurity
AB  - Spam emails go beyond being merely annoying messages, they have become one of the most used vectors for cyberattacks such as stealing personal information or spreading malware. These breaches in cybersecurity lead to financial and data loss for individuals and organisations. Thus, the ability to differentiate potentially risky emails is crucial to launch earlier warnings and gain relevant information for cybersecurity experts. Recent works have proposed models to detect phishing, fraudulent or critical spam emails. However, their focus is often restricted to a particular email type or only evaluated on spam emails received by organisations. In this work, we propose a new set of 56 features extracted using Natural Language Processing (NLP) techniques and grouped into five categories: Headers, Text, Attachments, URLs, and Protocols. We build a dataset, Spam Email Risk Classification (SERC), divided into two sub-datasets: one collected from a private source and another from Bruce Guenter’s public corpus. To assess the potential risk of spam emails for users, we follow two strategies: a binary classification using low and high risk and a regression approach to predict the level of risk from 1 to 10. We evaluated three Machine Learning classifiers and three regression models. Random Forest obtains the highest classification performance with 0.914 of F1-Score on SERC and Random Forest Regressor achieves the lowest Mean Square Error (MSE) of 0.781 for regression. We also conduct an analysis of the feature importance in terms of each feature and group where those from the Headers and Text groups become more relevant.
ER  - 

TY  - JOUR
T1  - CSTSINR: improving temporal continuity via convolutional structured implicit neural representations for time series anomaly detection
AU  - Liu, Ke
AU  - Li, Mengxuan
AU  - Bu, Jiajun
AU  - Wang, Hongwei
AU  - Wang, Haishuai
JO  - Neural Networks
VL  - 194
SP  - 108129
PY  - 2026
DA  - 2026/02/01/
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2025.108129
UR  - https://www.sciencedirect.com/science/article/pii/S0893608025010093
KW  - Time series
KW  - Anomaly detection
KW  - Implicit neural representation
KW  - Deep learning
AB  - Time series anomaly detection plays a crucial role in identifying significant deviations from expected behavior. Implicit Neural Representation (INR) has been explored for time series modeling due to its ability to learn continuous functions. The inherent spectral bias of INRs, which prioritizes low-frequency signal fitting, further enables the detection of high-frequency anomalies. However, current INR-based approaches demonstrate limited capability in representing complex temporal patterns, particularly when the normal data itself contains significant high-frequency components. To address these challenges, we propose CSTSINR, a novel anomaly detection model that integrates the structured feature map and convolutional mechanisms with the INR continuous function. By leveraging a structured feature map and convolutional layers, CSTSINR addresses the limitations of directive prediction of all parameters and point-wise query processing, providing improved modeling of temporal continuity and enhanced anomaly detection. Our extensive experiments demonstrate that CSTSINR outperforms existing state-of-the-art methods across ten benchmark datasets, highlighting its superior ability to detect anomalies, particularly in high-frequency or complex time series data.
ER  - 

TY  - JOUR
T1  - Real-time taxi spatial anomaly detection based on vehicle trajectory prediction
AU  - Hu, Wenyan
AU  - Li, Mengya
AU  - Kwan, Mei-Po
AU  - Luo, Haifeng
AU  - Chen, Bingkun
JO  - Travel Behaviour and Society
VL  - 34
SP  - 100698
PY  - 2024
DA  - 2024/01/01/
SN  - 2214-367X
DO  - https://doi.org/10.1016/j.tbs.2023.100698
UR  - https://www.sciencedirect.com/science/article/pii/S2214367X23001497
KW  - Anomaly detection
KW  - Trajectory prediction
KW  - Deep learning
KW  - Taxi service
KW  - GIS
AB  - Taxi services have long faced difficulties with unethical taxi drivers taking detours, especially when passengers are unfamiliar with their surroundings. Therefore, it is important to monitor taxis’ operation to enhance the quality of taxi services. In this paper, we mainly study the anomaly detection of taxi trajectories in the spatial dimension with a novel taxi anomaly detection framework based on real-time vehicle trajectory prediction. The framework is termed as TAPS and consists of two stages: the offline training stage and the online anomaly detection stage. In the first stage, a vehicle prediction model is established by training recommended routes provided by a navigation platform to predict a taxi’s next locations. The second step is to detect the taxi’s anomalous trajectories by measuring the consistency between its current and predicted positions as well as the relationship between these two positions and the origin. The effectiveness and timeliness of TAPS are evaluated in a real-world case study. The experiment results show that compared with two baselines, TAPS achieves greater Accuracy, Precision and F1 score to detect anomalous trajectories. This proposed framework can serve as a fundamental tool to detect anomalous trajectories for taxi passengers and companies.
ER  - 

TY  - JOUR
T1  - A comparative study of machine learning and deep learning models in binary and multiclass classification for intrusion detection systems
AU  - Alharthi, Ayesha
AU  - Alaryani, Meera
AU  - Kaddoura, Sanaa
JO  - Array
VL  - 26
SP  - 100406
PY  - 2025
DA  - 2025/07/01/
SN  - 2590-0056
DO  - https://doi.org/10.1016/j.array.2025.100406
UR  - https://www.sciencedirect.com/science/article/pii/S2590005625000335
KW  - Intrusion detection systems
KW  - Defensive security
KW  - Deep learning
KW  - Machine learning
AB  - Network infrastructure evolution has significantly expanded the attack surface, leading to increasingly complex and sophisticated cybersecurity threats. Traditional rule-based intrusion detection systems (IDS) often fail to detect emerging attack vectors, prompting the need for intelligent, data-driven approaches. This study evaluates and compares the performance of machine learning (ML) and deep learning (DL) models for network intrusion detection. Two publicly available datasets were utilized: a binary-labeled software-defined networking (SDN) dataset and a multiclass industrial control system dataset based on the IEC 60870-5-104 protocol. Preprocessing steps included normalization, label encoding, and a 70:10:20 train-validation-test split. Seven models, Random Forest, Decision Tree, K-Nearest Neighbors, XGBoost, Convolutional Neural Network, Gated Recurrent Unit, and Long Short-Term Memory, were trained and evaluated using precision, recall, and F1-score. The Random Forest model achieved the highest F1-score of 93.57 % on the IEC 60870-5-104 dataset, while XGBoost attained a near-perfect F1-score of 99.97 % on the SDN dataset. These results outperform comparable models in the literature and offer practical insights for selecting effective IDS solutions based on classification type and dataset structure.
ER  - 

TY  - JOUR
T1  - TFKAN: Transformer based on Kolmogorov–Arnold Networks for Intrusion Detection in IoT environment
AU  - Fares, Ibrahim A.
AU  - Abd Elaziz, Mohamed
AU  - Aseeri, Ahmad O.
AU  - Zied, Hamed Shawky
AU  - Abdellatif, Ahmed G.
JO  - Egyptian Informatics Journal
VL  - 30
SP  - 100666
PY  - 2025
DA  - 2025/06/01/
SN  - 1110-8665
DO  - https://doi.org/10.1016/j.eij.2025.100666
UR  - https://www.sciencedirect.com/science/article/pii/S1110866525000593
KW  - Kolmogorov–Arnold Networks (KANs)
KW  - Transformers
KW  - Intrusion detection
KW  - Cybersecurity
KW  - Multi-Layer Perceptrons (MLPs)
AB  - This work proposes a novel Transformer based on the Kolmogorov–Arnold Network (TFKAN) model for Intrusion Detection Systems (IDS) in the IoT environment. The TFKAN Transformer is developed by implementing the Kolmogorov–Arnold Networks (KANs) layers instead of the Multi-Layer Perceptrons (MLP) layers. Unlike the MLPs feed-forward layer, KAN layers have no fixed weights but use learnable univariate function components, enabling a more compact representation. This means a KAN can achieve comparable performance with fewer trainable parameters than a larger MLP. The RT-IoT2022, IoT23, and CICIoT2023 datasets were used in the evaluation process. The proposed TFKAN Transformer outperforms and obtains higher accuracy scores of 99.96%, 98.43%, and 99.27% on the RT-IoT2022, IoT23, and CICIoT2023 datasets, respectively. The results indicate that the developed Transformer using KAN shows promising performance in IDS within IoT environments compared to MLP layers.Transformers based on KANs are on average 78% lighter, in parameter count, than Transformers using MLPs. This makes KANs promising to be a replacement for MLPs.
ER  - 

TY  - JOUR
T1  - Towards a robust android malware detection model using explainable deep learning
AU  - Najibi, Masumeh
AU  - Bidgoly, Amir Jalaly
JO  - Journal of Information Security and Applications
VL  - 93
SP  - 104191
PY  - 2025
DA  - 2025/09/01/
SN  - 2214-2126
DO  - https://doi.org/10.1016/j.jisa.2025.104191
UR  - https://www.sciencedirect.com/science/article/pii/S2214212625002285
KW  - Explainable AI
KW  - Deep learning
KW  - Model robustness
KW  - Android malware detection
KW  - Android malware classification
KW  - LIME
KW  - SHAP
AB  - The growing threat of Android malware demands effective and trustworthy detection mechanisms. This paper investigates the robustness of explainable deep learning models for Android malware detection and classification using network flow features. Three deep learning architectures — DNN, 1D-CNN, and BiLSTM — were evaluated on the CICAndMal2017 dataset, with BiLSTM achieving the best performance on unseen samples. Model decisions were analyzed using LIME and SHAP to identify influential and potentially manipulable features. Using domain knowledge, features were categorized based on their resistance to evasion, with emphasis on robust indicators such as TCP flags and initial window sizes. Retraining models using only these robust features resulted in minimal performance degradation while significantly improving explainability and resilience to evasion. On the unseen dataset, the BiLSTM model achieved a 70.90% F1-score for malware detection and 62.84% for classification, with AUC scores of 73.39% and 79.96%, respectively. After removing weak features, the retrained detection model maintained a 71% F1-score, and the classification model achieved 57%, demonstrating that robustness can be improved without major loss in performance. These results highlight the potential for transparent and dependable AI-driven cybersecurity solutions, particularly in adversarial settings where evasion is common. By emphasizing explainability and robustness, this work contributes towards models that balance performance with trust in evolving threat landscapes.
ER  - 

TY  - JOUR
T1  - Perspectives for artificial intelligence in sustainable energy systems
AU  - Chen, Dongyu
AU  - Lin, Xiaojie
AU  - Qiao, Yiyuan
JO  - Energy
VL  - 318
SP  - 134711
PY  - 2025
DA  - 2025/03/01/
SN  - 0360-5442
DO  - https://doi.org/10.1016/j.energy.2025.134711
UR  - https://www.sciencedirect.com/science/article/pii/S0360544225003536
KW  - Machine learning
KW  - Multi-energy system
KW  - Data augmentation
KW  - Physics-informed model prediction
KW  - Interdisciplinary energy planning
KW  - Cybersecurity
AB  - This forward-looking perspective introduces the current applications of AI in sustainable energy systems, focusing on machine learning (ML) in three key areas: (i) system modeling and prediction, (ii) energy operation and management, and (iii) anomaly detection and diagnostics. For future low-carbon, decentralized and multi-energy systems, increasing complexity and communication pose challenges for system forecasting, operational control, grid planning, and energy security. AI offers revolutionary solutions by enhancing renewable energy integration, optimizing energy storage, and improving fault detection and cybersecurity. However, AI methods face limitations, including dependence on extensive data, lack of physical interpretability, and issues of transferability and robustness, hindering broader adoption in the energy sector. Therefore, perspectives are offered on four aspects: (1) developing generative AI to provide synthetic energy data, (2) adopting physics-informed AI to mitigate inherent AI limitations, (3) utilizing AI-based control and energy planning to address multi-energy complexities, and (4) implementing layered AI-based cybersecurity measures to defend smart energy systems. Overall, this perspective provides insights into the evolving role of AI in future energy systems.
ER  - 

TY  - JOUR
T1  - A novel framework for assessing determinant risk factors on cyber (dis)trust behaviors of netizens in deepfakes
AU  - Taleby Ahvanooey, Milad
AU  - Mazurczyk, Wojciech
AU  - Wang, Zefan
AU  - Zhao, Jun
JO  - Engineering Applications of Artificial Intelligence
VL  - 159
SP  - 111319
PY  - 2025
DA  - 2025/11/08/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2025.111319
UR  - https://www.sciencedirect.com/science/article/pii/S0952197625013211
KW  - Multi-criteria-multi-decision makers
KW  - Spherical fuzzy sets
KW  - Strategic information management
KW  - Socio-economic risks of deepfakes
KW  - Generative artificial intelligence risks
KW  - Game-theoretic framework
AB  - Nowadays, Generative Artificial Intelligence (GenAI) tools or trainable agents can craft synthetic media (hereafter referred to as deepfakes) in the form of realistic texts, images, videos, and audios, incorporating events or things that never occurred in real life. These GenAI tools empower marketers and malicious actors to create deepfakes, both authorized and weaponized multimedia, which allows them to include celebrities without appearing in front of cameras or creating seductive phishing scams. Although GenAI tools can reduce the cost of content construction, they enable new risky opportunities (e.g., deepfake phishing and cyberbullying) that negatively impact netizens’ learning and (dis)trust behaviors in cyberspace. To address such risks, this study proposes a Multi-Criteria-Multi-Decision-Makers (MCMDM)-based Deepfake Risk Assessment Framework (DeepFakeR-MF) to evaluate determinant factors that impact the cyber (dis)trust behaviors of netizens in deepfakes. Moreover, DeepFakeR-MF deploys a combination of a novel optimized spherical fuzzy analytic hierarchy process method and a game theory-based MCMDM approach to prioritize and recommend alternative strategies that can be taken by five management sectors (e.g., industrial enterprises, governmental organizations, media outlets, social non-profit, and educational institutes) to mitigate GenAI-associated risks. Then, we collect 100 experts’ judgments by analyzing their responses to our questionnaire and prioritize the importance of determinant factors considering their preferences. To validate the prioritized factors on the performance of DeepFakeR-MF, we conduct a sensitivity analysis applying Monte Carlo statistical modeling. Finally, our results confirm that DeepFakeR-MF provides effective strategic alternatives for policymakers, educators, media professionals, engineers, and netizens, hopefully reducing the socio-economic risks of deepfakes.
ER  - 

TY  - JOUR
T1  - Advancing autonomous driving system testing: Demands, challenges, and future directions
AU  - Liao, Yihan
AU  - Zhang, Jingyu
AU  - Keung, Jacky
AU  - Xiao, Yan
AU  - Dai, Yurou
JO  - Information and Software Technology
VL  - 187
SP  - 107859
PY  - 2025
DA  - 2025/11/01/
SN  - 0950-5849
DO  - https://doi.org/10.1016/j.infsof.2025.107859
UR  - https://www.sciencedirect.com/science/article/pii/S0950584925001983
KW  - Autonomous driving systems
KW  - Software testing
KW  - Vehicle-to-Everything
KW  - Foundation models
AB  - Context:
Autonomous driving systems (ADSs) promise enhanced transportation efficiency but face critical challenges in ensuring reliability across complex driving environments. Effective testing is essential to validate ADS performance and mitigate real-world risks.
Objective:
This study investigates current ADS testing practices for both modular and end-to-end systems, identifies key demands (needs required by practitioners and researchers), and examines gaps between research and real-world demands. We review critical testing techniques and extend to involve Vehicle-to-Everything (V2X) communication and Foundation Models (FMs), including large language models and vision foundation models, in enhancing ADS testing performance. We provide literature reviews and outline future directions for each demand of industry practitioners and academic researchers.
Methods:
A large-scale survey was conducted with 100 participants, including industry practitioners and academic researchers. We first discuss survey questions with professionals, distribute them to industry practitioners and academic researchers, and conduct follow-ups. Quantitative and qualitative analyses uncover key trends and challenges.
Results:
Findings reveal that existing ADS testing techniques struggle to evaluate real-world performance comprehensively, including the diversity of corner cases, the gap between simulation and real-world testing, the lack of comprehensive testing criteria, potential attacks, practical deployment for V2X, and the computational costs for FMs. By analyzing participants’ responses and 105 relevant papers, we summarize the future research directions.
Conclusion:
Our study highlights critical research gaps in ADS testing and underscores the demands of industry practitioners and academic researchers. We provide future directions for ADS: comprehensive testing criteria, cross-model collaboration in V2X, enhancing cross-modality (e.g., text and image) adaptation in FM testing, and scalable ADS validation frameworks. These insights contribute to advancing software engineering practices for ADS development, ensuring safer and more reliable autonomous systems.
ER  - 

TY  - JOUR
T1  - Toward human-centric coal mine auxiliary operations in Industry 5.0: An XR-based approach for human-robot hybrid decision-making
AU  - Liu, Shuguang
AU  - Xie, Jiacheng
AU  - Wang, Xuewen
AU  - Qin, Lang
JO  - Advanced Engineering Informatics
VL  - 69
SP  - 103965
PY  - 2026
DA  - 2026/01/01/
SN  - 1474-0346
DO  - https://doi.org/10.1016/j.aei.2025.103965
UR  - https://www.sciencedirect.com/science/article/pii/S1474034625008584
KW  - Human-robot hybrid decision-making
KW  - Coal mine auxiliary operations
KW  - Extended reality
KW  - LLMs
KW  - Human-centric
KW  - Industry 5.0
AB  - The explosive growth of large language models (LLMs) has not only significantly accelerated the advancement of embodied intelligence but also imbued robots with heightened expectations regarding their capabilities. However, in certain industrial scenarios, the openness and complexity of environments and tasks determine that robots cannot independently complete all work, and deep human involvement remains indispensable. Coal mine auxiliary operations are a typical representative of such scenarios. Industry 5.0 emphasizes combining the respective strengths of humans and robots. In this context, how to optimize the decision-making process in coal mine auxiliary operations through the full integration of human intelligence and machine intelligence warrants in-depth exploration. First, building upon the human–machine hybrid augmented intelligence paradigm of human-in-the-loop, a human-robot hybrid decision-making framework for coal mine auxiliary operations based on extended reality (XR) is proposed. Then, critical technologies required for operationalizing the framework are systematically investigated, with particular emphasis on introducing LLM assistance into the corresponding solutions. Finally, a case study on coal mining equipment maintenance, a representative coal mine auxiliary operation, is conducted to validate the feasibility and effectiveness of the proposed approach. The results demonstrate that the proposed scheme, through ingenious transformation and transmission of heterogeneous information flows, enables rational integration of decision-making between coal mine operators and auxiliary operation robots. This enables a decision-making paradigm characterized by virtual-real fusion and human-robot co-intelligence, exhibiting its superiority in coal mine auxiliary operations and application potential in analogous industrial scenarios.
ER  - 

TY  - JOUR
T1  - Anomaly Detection Using System Logs:
AU  - Sinha, Rohit
AU  - Sur, Rittika
AU  - Sharma, Ruchi
AU  - Shrivastava, Avinash K.
JO  - International Journal of Information Security and Privacy
VL  - 16
IS  - 1
PY  - 2022
DA  - 2022/01/01/
SN  - 1930-1650
DO  - https://doi.org/10.4018/IJISP.285584
UR  - https://www.sciencedirect.com/science/article/pii/S1930165022000255
KW  - Anomaly Detection
KW  - Convolution Neural Network (CNN)
KW  - Feed-Forward Neural Network
KW  - Log Analysis
KW  - Log Files
AB  - ABSTRACT
In this paper, the authors proposed an approach that leverages the pattern matching capabilities of convolution neural network (CNN) for anomaly detection in system logs. The model learns the variation in log pattern for normal execution and in abnormal execution that is giving rise to anomalous behavior. In the approach, features from log files are extracted using a windowing technique. Based on this feature, a one-dimensional image (1×n dimension) is generated where the pixel values of an image correlate with the features of the logs. On these generated images, the 1D convolution operation is applied followed by max pooling. Followed by these convolution layers, a multi-layer feed-forward neural network is used as a classifier that learns to classify the logs as normal or abnormal from the representation created by the convolution layers. The proposed approach uses the pattern recognition capabilities of CNN, and hence, it can be integrated in the data processing pipeline, thereby enabling quick response to the threat or malicious activity. From the experiment, it was seen that the approach achieved an accuracy of 0.995 (F1 measure) which is substantially high as compared to existing approaches that are using long short-term memory (LSTM) and multilayer perceptron (MLP) for anomaly detection in Hadoop distributed file system (HDFS) logs.
ER  - 

TY  - JOUR
T1  - Generation and deployment of honeytokens in relational databases for cyber deception
AU  - Prabhaker, Nilin
AU  - Bopche, Ghanshyam S.
AU  - Arock, Michael
JO  - Computers & Security
VL  - 146
SP  - 104032
PY  - 2024
DA  - 2024/11/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104032
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824003377
KW  - Data breaches
KW  - Identity theft
KW  - Database security
KW  - Cyber deception
KW  - Honeytoken
KW  - Data synthesis
KW  - Hierarchical modeling algorithms
AB  - Despite considerable investments in database security, global statistics indicate an exponential increase in data breaches. Organizations are often unaware of data breaches for weeks, months, or even years. Sufficient for adversaries to compromise and ex-filtrate business or mission-critical data. Recent research suggests using honeytokens for early detection of data breaches in organizations. Existing honeytoken generation methods rely on regular expressions, rule mining, constraint satisfaction, or representation learning, which are complex and limited to a few attributes. We created a framework for generating and deploying honeytokens in relational databases that actively monitor sensitive records and quickly detect data breaches and their misuse. To generate the honeytoken we have used the hierarchical machine learning algorithm which uses a recursive technique to model the parent–child relationships of multi-table databases. The proposed method enables the organization to take remedial action to reduce the impact of data breaches and complement existing database security solutions.
ER  - 

TY  - JOUR
T1  - LinguTimeX a Framework for Multilingual CTC Detection Using Explainable AI and Natural Language Processing
AU  - Darwish, Omar
AU  - Al-Eidi, Shorouq
AU  - Al-Shorman, Abdallah
AU  - Maabreh, Majdi
AU  - Alsobeh, Anas
AU  - Zahariev, Plamen
AU  - Tashtoush, Yahya
JO  - Computers, Materials and Continua
VL  - 86
IS  - 1
SP  - 1
EP  - 21
PY  - 2025
DA  - 2025/11/10/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2025.068266
UR  - https://www.sciencedirect.com/science/article/pii/S1546221825010574
KW  - Arabic language
KW  - Chinese language
KW  - covert timing channel
KW  - cybersecurity
KW  - deep learning
KW  - English language
KW  - language processing
KW  - machine learning
AB  - Covert timing channels (CTC) exploit network resources to establish hidden communication pathways, posing significant risks to data security and policy compliance. Therefore, detecting such hidden and dangerous threats remains one of the security challenges. This paper proposes LinguTimeX, a new framework that combines natural language processing with artificial intelligence, along with explainable Artificial Intelligence (AI) not only to detect CTC but also to provide insights into the decision process. LinguTimeX performs multidimensional feature extraction by fusing linguistic attributes with temporal network patterns to identify covert channels precisely. LinguTimeX demonstrates strong effectiveness in detecting CTC across multiple languages; namely English, Arabic, and Chinese. Specifically, the LSTM and RNN models achieved F1 scores of 90% on the English dataset, 89% on the Arabic dataset, and 88% on the Chinese dataset, showcasing their superior performance and ability to generalize across multiple languages. This highlights their robustness in detecting CTCs within security systems, regardless of the language or cultural context of the data. In contrast, the DeepForest model produced F1-scores ranging from 86% to 87% across the same datasets, further confirming its effectiveness in CTC detection. Although other algorithms also showed reasonable accuracy, the LSTM and RNN models consistently outperformed them in multilingual settings, suggesting that deep learning models might be better suited for this particular problem.
ER  - 

TY  - JOUR
T1  - Threat intelligence ATT&CK extraction based on the attention transformer hierarchical recurrent neural network
AU  - Liu, Chenjing
AU  - Wang, Junfeng
AU  - Chen, Xiangru
JO  - Applied Soft Computing
VL  - 122
SP  - 108826
PY  - 2022
DA  - 2022/06/01/
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2022.108826
UR  - https://www.sciencedirect.com/science/article/pii/S1568494622002289
KW  - ATT&CK
KW  - Cybersecurity
KW  - Cyber threat intelligence
KW  - Threat report analysis
KW  - Multi-label classification
KW  - Transformer
AB  - With the rapid growth of cyberattacks in the world wide, Tactics, Techniques & Procedures (TTPs) has become the most prevalent advanced indicator for a particular attack in cybersecurity community. However, extracting TTPs from unstructured cyber threat intelligence (CTI) can be arduous due to the large volume of the intelligence database. Although recent efforts on automatically extracting the structured TTPs from the unstructured intelligence have achieved promising results, they only employ simple statistical methods for TTP extraction and neglect the dependences among the hierarchical structure of TTPs. To solve those limitations, we proposed a novel attention-based method called Attention-based Transformer Hierarchical Recurrent Neural Network (ATHRNN) to extract the TTPs from the unstructured CTI. First of all, a Transformer Embedding Architecture (TEA) is designed to obtain high-level semantic representations of CTI and that of taxonomy of ATT&CK. Subsequently, an Attention Recurrent Structure (ARS) is developed to model the dependences between the tactical and technical labels in ATT&CK. Finally, a joint Hierarchical Classification (HC) module is developed to predict the final TTPs. Experiments of our approach on the collected dataset prove to be encouraging. The accuracies of TTPs extraction achieve 6.5% and 8.2% improvement in terms of Macro-F score and Micro-F score respectively.
ER  - 

TY  - JOUR
T1  - Studying SATD in drone systems with Human-AI collaboration
AU  - Rantala, Leevi
AU  - Shar, Lwin Khin
AU  - Mäntylä, Mika V.
AU  - Minn, Wei
AU  - Tun, Yan Naing
JO  - Journal of Systems and Software
VL  - 231
SP  - 112625
PY  - 2026
DA  - 2026/01/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2025.112625
UR  - https://www.sciencedirect.com/science/article/pii/S0164121225002948
KW  - Self-Admitted Technical Debt
KW  - Technical debt
KW  - Drones
KW  - Large-language models
KW  - Sample study
AB  - Background:
Self-Admitted Technical Debt (SATD) refers to sub-optimal solutions that developers acknowledge within the source code. SATD research originated on Java projects but is expanding to other domains. We focus on SATD in drones, which are used for various critical tasks.
Aims:
The primary objective is to investigate SATD in drone systems. The second aim is to explore the integration of AI and human collaboration for SATD labelling and classification.
Method:
Method: We conducted a sample study of SATD comments in drone systems (14 open source, 4 SDKs) to analyse the quantity and types of SATD comments present. Our study incorporates collaboration between AI and humans by utilising LLM for SATD classification. Additionally, we classified a sample of 385 SATD comments as either drone-specific or non-drone-specific.
Results:
The most prevalent SATD categories in drone software are Code Debt (35%), Unclassifiable Debt (16%), and Design Debt (15%). We found that 22% of SATD is specific to drones. Drone-specific SATD is proportionally more focused on Requirements and Design Debt compared to non-drone-specific SATD. We found that using both human and LLM for SATD classification can improve accuracy, as both LLM and human revised their initial ratings. After two rounds, a “near-perfect agreement” (Fleiss’ kappa 0.83) was achieved.
Conclusions:
Future studies should investigate whether our observation that domain-specific (drone) SATD comments relate more to Requirement Debt holds true in other domains. We propose a workflow that integrates AI into classification tasks, enhancing the accuracy of both human and AI classifications.
ER  - 

TY  - JOUR
T1  - Characterizing generative artificial intelligence applications: Text-mining-enabled technology roadmapping
AU  - Singh, Shiwangi
AU  - Singh, Surabhi
AU  - Kraus, Sascha
AU  - Sharma, Anuj
AU  - Dhir, Sanjay
JO  - Journal of Innovation & Knowledge
VL  - 9
IS  - 3
SP  - 100531
PY  - 2024
DA  - 2024/07/01/
SN  - 2444-569X
DO  - https://doi.org/10.1016/j.jik.2024.100531
UR  - https://www.sciencedirect.com/science/article/pii/S2444569X24000702
KW  - Generative AI
KW  - Technology roadmapping
KW  - Patents
KW  - Text-mining
KW  - Structural topic modeling
KW  - Patent data mining
AB  - This study aims to identify generative AI (GenAI) applications and develop a roadmap for the near, mid, and far future. Structural topic modeling (STM) is used to discover latent semantic patterns and identify the key application areas from a text corpus comprising 2,398 patents published between 2017 and 2023. The study identifies six latent topics of GenAI application, including object detection and identification; medical applications; intelligent conversational agents; image generation and processing; financial and information security applications; and cyber-physical systems. Emergent topic terms are listed for each topic, and inter-topic correlations are explored to understand the thematic structures and summarize the semantic relationships among GenAI application areas. Finally, a technology roadmap is developed for each identified application area for the near, mid, and far future. This study provides valuable insights into the evolving GenAI landscape and helps practitioners make strategic business decisions based on the GenAI roadmap.
ER  - 

TY  - JOUR
T1  - HyVAW: A hybrid vulnerability analysis workflow threat model methodology for complex systems based on distributed components
AU  - Bezerra, Wesley dos Reis
AU  - de Souza, Cristiano Antonio
AU  - Westphall, Carla Merkle
AU  - Westphall, Carlos Becker
JO  - Journal of Open Innovation: Technology, Market, and Complexity
VL  - 11
IS  - 4
SP  - 100654
PY  - 2025
DA  - 2025/12/01/
SN  - 2199-8531
DO  - https://doi.org/10.1016/j.joitmc.2025.100654
UR  - https://www.sciencedirect.com/science/article/pii/S2199853125001891
KW  - Threat model
KW  - Threat model methodology
KW  - Distributed system
KW  - Complex system
KW  - Security
AB  - Threat modeling is an essential tool for the quality of produced software artifacts, bringing maturity to the design process. However, even though several threat modeling methodologies are used, the evolution of the complexity of new technologies, such as microservices, APIs, and other distributed components, demands new challenges. Our methodology provides a comprehensive workflow aggregating existing methodologies such as STRIDE, CVSS, and ADT in a hybrid format and distinct modeling phases. With this approach, through easy traceability and maintenance, it was possible to visualize each component’s global and specific threats and the relationship between the components and countermeasures for each threat. As a result, HyVAW proved to be suitable for analyzing the different threats in each part of the proposed system and mainly for communication between the parts of the security mechanism through exemplification using a distributed project and through a comparison with other related works.
ER  - 

TY  - JOUR
T1  - Advanced BERT and CNN-Based Computational Model for Phishing Detection in Enterprise Systems
AU  - Gupta, Brij B.
AU  - Gaurav, Akshat
AU  - Arya, Varsha
AU  - Attar, Razaz Waheeb
AU  - Bansal, Shavi
AU  - Alhomoud, Ahmed
AU  - Chui, Kwok Tai
JO  - CMES - Computer Modeling in Engineering and Sciences
VL  - 141
IS  - 3
SP  - 2165
EP  - 2183
PY  - 2024
DA  - 2024/10/31/
SN  - 1526-1492
DO  - https://doi.org/10.32604/cmes.2024.056473
UR  - https://www.sciencedirect.com/science/article/pii/S1526149224003163
KW  - Phishing
KW  - BERT
KW  - convolutional neural networks
KW  - email security
KW  - deep learning
AB  - Phishing attacks present a serious threat to enterprise systems, requiring advanced detection techniques to protect sensitive data. This study introduces a phishing email detection framework that combines Bidirectional Encoder Representations from Transformers (BERT) for feature extraction and CNN for classification, specifically designed for enterprise information systems. BERT’s linguistic capabilities are used to extract key features from email content, which are then processed by a convolutional neural network (CNN) model optimized for phishing detection. Achieving an accuracy of 97.5%, our proposed model demonstrates strong proficiency in identifying phishing emails. This approach represents a significant advancement in applying deep learning to cybersecurity, setting a new benchmark for email security by effectively addressing the increasing complexity of phishing attacks.
ER  - 

TY  - JOUR
T1  - Energy-Efficient and Secure Digital Learning Using the GAIA Green AI Analytics Framework
AU  - Wen, Xin
AU  - Lv, Yang
JO  - Results in Engineering
SP  - 108746
PY  - 2025
DA  - 2025/12/15/
SN  - 2590-1230
DO  - https://doi.org/10.1016/j.rineng.2025.108746
UR  - https://www.sciencedirect.com/science/article/pii/S2590123025047899
KW  - Sustainable Digital Learning
KW  - Energy-Efficient Computing
KW  - Green Cybersecurity
KW  - GAIA
KW  - Secure Learning
AB  - Digital learning platforms' rapid growth has transformed education through virtual access, customized training, and flexible teaching methods. This rise threatens data security and sustainability due to cybersecurity and energy consumption issues. Traditional infrastructure has high carbon footprints and inadequate data systems, owing to energy-intensive servers and computers. To address these issues, this article suggests Green AI Analytics (GAIA), a groundbreaking architecture that combines energy-efficient AI models with green cybersecurity. GAIA balances energy, system performance, and security through green encryption, server optimization powered by renewable energy, and low-energy machine learning. Real-time analytics provide adaptive resource management for efficiency and learning. An experimental prototype digital learning platform showed a 30% reduction in energy use (saving 80 kWh), 40% improvement in performance efficiency (80%), and 25% improvement in cybersecurity resilience (above 75%) compared to CC-SRW, LLMs, and MUGuard while maintaining real-time latency between 410 ms and 650 ms. This shows GAIA's ability to provide scalable, sustainable, and safe digital education. Green computing and cutting-edge cybersecurity help GAIA develop a sustainable route for future digital learning technologies that meet international environmental and security goals.
ER  - 

TY  - JOUR
T1  - MDDB-AETB: Malicious domain detection boosting based on alignment with encrypted traffic behavior in restricted scenarios
AU  - Cao, Mengrui
AU  - Gou, Gaopeng
AU  - Shi, Junzheng
AU  - Xiong, Gang
AU  - Li, Zhen
AU  - Li, Jiayu
JO  - Computers & Security
VL  - 162
SP  - 104785
PY  - 2026
DA  - 2026/03/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104785
UR  - https://www.sciencedirect.com/science/article/pii/S0167404825004742
KW  - Malicious domain detection
KW  - Encrypted traffic analysis
KW  - Self-supervised learning
KW  - Domain embeddings
KW  - Embedding fine-tuning,
AB  - Malicious domain detection is a key challenge in network security. Traditional methods cannot achieve effective malicious domain detection in real-world limited scenarios with limited labeled data and insufficient domain relationships, which we focus on in this paper. Based on the insight that domains with similar encrypted traffic behavior are expected to share similar representations in the embedding space, we propose MDDB-AETB, boosting malicious domain detection based on alignment with encrypted traffic behavior. We extract text and behavior features from TLS messages of encrypted traffic. For behavior features, we measure the similarity of statistical features as self-supervised learning labels. With these labels, we fine-tune the pre-trained model whose input is domain text, getting an optimized embedding representation model. The loss function for fine-tuning combines mean square error (MSE) loss and contrastive loss to capture the subtle behavior of encrypted traffic, enhancing its detection capability. We evaluate MDDB-AETB against three state-of-the-art baselines, the results show that MDDB-AETB consistently achieves the best performance across all test set proportions, reaching up to 99 % F1-score while maintaining stable advantages even under limited training data.
ER  - 

TY  - JOUR
T1  - Explained anomaly detection in text reviews: Can subjective scenarios be correctly evaluated?
AU  - Novoa-Paradela, David
AU  - Fontenla-Romero, Oscar
AU  - Guijarro-Berdiñas, Bertha
JO  - Engineering Applications of Artificial Intelligence
VL  - 133
SP  - 108065
PY  - 2024
DA  - 2024/07/01/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2024.108065
UR  - https://www.sciencedirect.com/science/article/pii/S0952197624002239
KW  - Anomaly detection
KW  - Text reviews
KW  - Transformers
KW  - Explainability
AB  - In the current landscape, user opinions exert an unprecedented influence on the trajectory of companies. In the field of online review platforms, these opinions, transmitted through text reviews and numerical ratings, significantly shape the credibility of products and services. For this reason, detecting inappropriate reviews becomes crucial. This paper addresses the problem of automatic anomalous review detection using a novel approach based on Anomaly Detection in the field of Natural Language Processing (NLP). Unlike other NLP tasks, anomaly detection in texts is a relatively emerging area. In this paper, we present a pipeline for opinion filtering that poses the problem of discerning between normal opinions containing relevant information about an item and anomalous opinions with unrelated content. Its key functionalities include: Classifying the reviews, assigning normality scores, and generating explanations for each classification, indispensable for the human who normally moderates these platforms. To evaluate the model, several Amazon datasets were used to demonstrate that the performance obtained is robust, obtaining an average F1 score of 91.4 detecting anomalies in the most complex scenario. In addition, a comparative study of three explainability techniques was conducted with 241 participants to measure the impact on understanding the classifications of the model and to rank their perceived usefulness of explanations. As a result, we obtained a system with great potential to automate tasks related to online review platforms, offering insights into anomaly detection applications in textual data and showing the difficulties that arise when the task to be explained presents a subjectivity component.
ER  - 

TY  - JOUR
T1  - Vulnerability detection through machine learning-based fuzzing: A systematic review
AU  - Bamohabbat Chafjiri, Sadegh
AU  - Legg, Phil
AU  - Hong, Jun
AU  - Tsompanas, Michail-Antisthenis
JO  - Computers & Security
VL  - 143
SP  - 103903
PY  - 2024
DA  - 2024/08/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.103903
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824002050
KW  - ML fuzzing
KW  - TML fuzzing
KW  - DNN fuzzing
KW  - RL fuzzing
KW  - DRL fuzzing
AB  - Modern software and networks underpin our digital society, yet the rapid growth of vulnerabilities that are uncovered within these threaten our cyber security posture. Addressing these issues at scale requires automated proactive approaches that can identify and mitigate these vulnerabilities in a suitable time frame. Fuzzing techniques have emerged as crucial methods to preemptively tackle these risks. However, traditional fuzzing methods encounter various challenges, such as a lack of strategy for deep bug identification, time-intensive bug analysis, quality of inputs, seed scheduling and others. To overcome these challenges, diverse Machine Learning (ML) models and optimisation techniques have been employed, including advanced feature engineering, optimised seed selection, refined predictive/fitness models, and Gradient-based optimisation. Furthermore, the use of ML architectures such as Long Short-Term Memory (LSTM), Generative Adversarial Network (GAN), Sequence-to-Sequence (Seq2Seq), and Generative Randomised Unit (GRU), have demonstrated greater effectiveness within ML-based fuzzing. In this paper, we delve into this paradigm shift, aiming to address fundamental challenges across different ML categories. We survey popular ML categories such as Traditional Machine Learning (TML), Deep Learning (DL), Reinforcement Learning (RL), and Deep Reinforcement Learning (DRL), to investigate their potential for enhancing traditional fuzzing approaches. We explore the respective advantages in each category of ML-based fuzzing, while also analysing the challenges unique to each category. Our work provides a comprehensive survey across the fuzzing domain and how machine learning techniques have been utilised, that we believe will be of use to future researchers in this domain.
ER  - 

TY  - JOUR
T1  - Development of major process accident indicators based on Industrial Internet
AU  - Ni, Zi-jian
AU  - Wang, Xiao
AU  - Zhang, Zhi-cheng
AU  - Wang, Lei
JO  - Journal of Loss Prevention in the Process Industries
VL  - 92
SP  - 105418
PY  - 2024
DA  - 2024/12/01/
SN  - 0950-4230
DO  - https://doi.org/10.1016/j.jlp.2024.105418
UR  - https://www.sciencedirect.com/science/article/pii/S0950423024001761
KW  - STAMP
KW  - Large language model
KW  - SMART criteria
KW  - Accidents retrospective analysis
KW  - Accident factors
AB  - In recent years, Chinese-produced bulk chemical products have consistently ranked among the world’s leading suppliers. The scale of individual petrochemical plants and chemical parks has grown significantly, resulting in increased complexity that can contribute to higher levels of uncertainty surrounding potential losses. MA (major accident) indicators can provide a comprehensive assessment of a plant’s safety performance. This study focuses on three primary objectives: Firstly, utilizing process safety management software powered by Industrial Internet technology, we develop MA indicators. Secondly, applying the Systems-Theoretic Accident Model and Processes (STAMP) theory, this work analyzes the logical relationship between MA indicators and accidents. STAMP provides a more comprehensive understanding of indicators involving multiple barriers. Lastly, drawing upon a large language model, this paper retrospectively analyzes 212 accident reports to verify the connection between the index and actual accidents. It is noteworthy that the MA indicators adhere to SMART criteria for effective measurement.
ER  - 

TY  - JOUR
T1  - Semi-supervised graph anomaly detection via dual-channel reconstruction
AU  - Chen, Yujia
AU  - Li, Jian
AU  - Sun, Linfei
AU  - Liu, Tongcun
AU  - Liu, Guanjun
JO  - Neurocomputing
VL  - 668
SP  - 132401
PY  - 2026
DA  - 2026/03/01/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2025.132401
UR  - https://www.sciencedirect.com/science/article/pii/S0925231225030735
KW  - Graph Anomaly Detection
KW  - Semi-supervised learning
KW  - Contrastive learning
KW  - Dual-channel reconstruction
AB  - Graph Anomaly Detection (GAD) is a critical task for identifying deviant nodes in graphs. Despite progress in unsupervised methods, existing approaches face two key challenges: (1) Anomaly Overfitting, stemming from the contamination of training data by unlabeled anomalies in the traditional unsupervised manner; and (2) Homophily Trap, where traditional low-pass graph neural networks (GNNs) and contrastive learning frameworks fail to capture high-frequency signals essential for detecting anomalies. In this work, we propose Semi-Supervised Graph Anomaly Detection via Dual-Channel Reconstruction (SGAD-DCR). The proposed approach leverages three key modules: (1) the Dual-Filter Attention Encoder constructs dual aggregation channels for low-frequency and high-frequency signals. This preserves anomalous information in high-frequency signals and alleviates the homophily trap. (2) The Label-Guided Contrastive Learning module leverages limited supervision to pull and push embeddings at semantic-level. This effectively mitigates the homophily trap that obscures the distinction between normal and anomalous embeddings. (3) The Anomaly-Aware Reconstruction decoder leverages limited supervisory signals to model normal and anomalous patterns. It reconstructs nodes through low-frequency and high-frequency embeddings in semi-supervised manner, thereby mitigating overfitting anomalies. Extensive experiments demonstrate that SGAD-DCR outperforms state-of-the-art methods on most benchmark datasets, achieving superior robustness to various labeled ratios.
ER  - 

TY  - JOUR
T1  - Detecting duplicate vulnerability records across databases
AU  - Zhu, Kangliang
AU  - Yang, Wenhua
AU  - Pan, Minxue
AU  - Zhou, Yu
JO  - Science of Computer Programming
VL  - 247
SP  - 103357
PY  - 2026
DA  - 2026/01/01/
SN  - 0167-6423
DO  - https://doi.org/10.1016/j.scico.2025.103357
UR  - https://www.sciencedirect.com/science/article/pii/S0167642325000966
KW  - Duplicate vulnerability
KW  - Cosine similarity
KW  - BERT
KW  - Fine-tuning
KW  - Dataset
AB  - Vulnerability databases are critical repositories that aggregate information about known security vulnerabilities across various software products. However, the existence of multiple, heterogeneous databases often leads to duplicate vulnerability records, necessitating significant manual effort by maintainers to identify and consolidate these duplicates. This study addresses the challenge of detecting duplicate vulnerabilities across different databases by proposing a combined method that integrates cosine similarity measures with a fine-tuned BERT-based language model. We constructed a comprehensive duplicate vulnerability dataset by analyzing records from prominent databases such as CVE, OSV, and the GitHub Advisory Database. Our method was evaluated against several baseline techniques, including similarity-based and deep learning-based approaches, demonstrating superior performance across multiple metrics, including Hit Rate@N, Mean Reciprocal Rank (MRR), Mean Rank, and Median Rank. Additionally, our method proved effective in practical scenarios involving ongoing database maintenance, showcasing its ability to generalize to unseen data. The findings highlight the potential of integrating traditional similarity measures with advanced language models to enhance the accuracy and efficiency of duplicate vulnerability detection, thereby facilitating more reliable vulnerability management.
ER  - 

TY  - JOUR
T1  - Explainable Anomaly Detection Using Vision Transformer Based SVDD
AU  - Baek, Ji-Won
AU  - Chung, Kyungyong
JO  - Computers, Materials and Continua
VL  - 74
IS  - 3
SP  - 6573
EP  - 6586
PY  - 2022
DA  - 2022/12/15/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2023.035246
UR  - https://www.sciencedirect.com/science/article/pii/S1546221822003186
KW  - Explainable AI
KW  - anomaly detection
KW  - vision transformer
KW  - SVDD
KW  - health care
KW  - deep learning
KW  - classification
AB  - Explainable AI extracts a variety of patterns of data in the learning process and draws hidden information through the discovery of semantic relationships. It is possible to offer the explainable basis of decision-making for inference results. Through the causality of risk factors that have an ambiguous association in big medical data, it is possible to increase transparency and reliability of explainable decision-making that helps to diagnose disease status. In addition, the technique makes it possible to accurately predict disease risk for anomaly detection. Vision transformer for anomaly detection from image data makes classification through MLP. Unfortunately, in MLP, a vector value depends on patch sequence information, and thus a weight changes. This should solve the problem that there is a difference in the result value according to the change in the weight. In addition, since the deep learning model is a black box model, there is a problem that it is difficult to interpret the results determined by the model. Therefore, there is a need for an explainable method for the part where the disease exists. To solve the problem, this study proposes explainable anomaly detection using vision transformer-based Deep Support Vector Data Description (SVDD). The proposed method applies the SVDD to solve the problem of MLP in which a result value is different depending on a weight change that is influenced by patch sequence information used in the vision transformer. In order to draw the explain-ability of model results, it visualizes normal parts through Grad-CAM. In health data, both medical staff and patients are able to identify abnormal parts easily. In addition, it is possible to improve the reliability of models and medical staff. For performance evaluation normal/abnormal classification accuracy and f-measure are evaluated, according to whether to apply SVDD. Evaluation Results The results of classification by applying the proposed SVDD are evaluated excellently. Therefore, through the proposed method, it is possible to improve the reliability of decision-making by identifying the location of the disease and deriving consistent results.
ER  - 

TY  - JOUR
T1  - An integrated model based on deep learning classifiers and pre-trained transformer for phishing URL detection
AU  - Do, Nguyet Quang
AU  - Selamat, Ali
AU  - Fujita, Hamido
AU  - Krejcar, Ondrej
JO  - Future Generation Computer Systems
VL  - 161
SP  - 269
EP  - 285
PY  - 2024
DA  - 2024/12/01/
SN  - 0167-739X
DO  - https://doi.org/10.1016/j.future.2024.06.031
UR  - https://www.sciencedirect.com/science/article/pii/S0167739X24003315
KW  - Phishing detection
KW  - Transformer model
KW  - Residual network
KW  - Temporal convolutional network
KW  - Attention mechanism
AB  - The unique nature of website URLs has made phishing detection a challenging task. Unlike natural language, URLs have an unstructured nature with non-linear and sophisticated correlations. Therefore, they should be handled as both natural language and unstructured data sequences. However, the current solutions for phishing URL detection only focused on a single aspect of web page URLs. In this concern, this paper proposes an integrated model based on DL classifiers and pre-trained transformer to examine both the unique nature and the natural language structure of URL sequences simultaneously. The proposed model consists of three modules: RasNet (Keras-ResNet), TCMA (TCN-MHSA), and MPNet (Masked and Permuted Pre-training for Language Understanding). Considering the unique nature of the input data, RasNet combines two Keras embedding techniques to obtain the feature representations of URLs and then fuses them using a Residual Network (ResNet) to balance the weight distribution among the character-level and word-level information. Additionally, TCMA integrates the Temporal Convolutional Network (TCN) with the Multi-Head Self-Attention (MHSA) mechanism to optimize feature extraction and improve classification accuracy. Concurrently, MPNet joins the advantages and eliminates the drawbacks of Masked Language Modelling and Permuted Language Modelling to examine the nature language structure of web page URLs. The proposed model was trained and tested on four different datasets, including Ebbu2017, PhishCrawl, 420K-PD, and 1M-PD. The experimental results indicated that the proposed solution outperformed other models in classifying malicious URLs with the highest detection rate of 99.71% on the 1M-PD dataset, improving the performance accuracy of the state-of-the-art approaches by 1.37% to 2.01%.
ER  - 

TY  - JOUR
T1  - An empirical investigation into the capabilities of anomaly detection approaches for test smell detection
AU  - Pontillo, Valeria
AU  - Martins, Luana
AU  - Machado, Ivan
AU  - Palomba, Fabio
AU  - Ferrucci, Filomena
JO  - Journal of Systems and Software
VL  - 222
SP  - 112320
PY  - 2025
DA  - 2025/04/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2024.112320
UR  - https://www.sciencedirect.com/science/article/pii/S0164121224003649
KW  - Test smells
KW  - Anomaly detection
KW  - Empirical software engineering
AB  - Test smells are symptoms of sub-optimal design choices adopted when developing test cases. Previous research has demonstrated their harmfulness for test code maintainability and effectiveness, showing their impact on test code quality. As such, the quality of test cases affected by test smells is likely to deviate significantly from the quality of test cases not affected by any smell and might be classified as anomalies. In this paper, we challenge this observation by experimenting with three anomaly detection approaches based on machine learning, cluster analysis, and statistics to understand their effectiveness for the detection of four test smells, i.e., Eager Test, Mystery Guest, Resource Optimism, and Test Redundancy on 66 open-source Java projects. In addition, we compare our results with state-of-the-art heuristic-based and machine learning-based baselines. Our ultimate goal is not to prove that anomaly detection methods are better than existing approaches, but to objectively assess their effectiveness in this domain. The key findings of the study show that the F-Measure of anomaly detectors never exceeds 47%, obtained in the Eager Test detection using the statistical approach, while the Recall is generally higher for the statistical and clustering approaches. Nevertheless, the anomaly detection approaches have a higher Recall than the heuristic and machine learning-based techniques for all test smells. The low F-Measure values we observed for anomaly detectors provide valuable insights into the current limitations of anomaly detection in this context. We conclude our study by elaborating on and discussing the reasons behind these negative results through qualitative investigations. Our analysis shows that the detection of test smells could depend on the approach exploited, suggesting the feasibility of developing a meta-approach.
ER  - 

TY  - JOUR
T1  - Temporal-enhanced transformer for anomaly detection in spacecraft irregular-interval telemetry
AU  - Dai, Aixin
AU  - Xiao, Yancai
AU  - Ren, Fangyi
AU  - Shen, Haikuo
AU  - Zhi, Shaodan
AU  - Ma, Biao
JO  - Advances in Space Research
VL  - 77
IS  - 2
SP  - 2356
EP  - 2371
PY  - 2026
DA  - 2026/01/15/
SN  - 0273-1177
DO  - https://doi.org/10.1016/j.asr.2025.10.088
UR  - https://www.sciencedirect.com/science/article/pii/S0273117725012359
KW  - Spacecraft
KW  - Anomaly detection
KW  - Irregular-interval telemetry time series
KW  - Transformer
KW  - Temporal enhancement
AB  - Ensuring operational safety through spacecraft health monitoring critically relies on effective anomaly detection. However, the task is significantly complicated by irregular time intervals in real-world telemetry data. To address this pressing issue, we propose TETAD, a novel end-to-end Temporal-Enhanced Transformer model specifically designed for such data. TETAD integrates a unique Temporal-Enhanced Transformer (TET) architecture featuring our key innovation: the Temporal Enhancement Encoding Module (TEEM). TEEM effectively captures complex irregular-interval temporal features by encoding time interval information alongside learnable positional embeddings. Furthermore, a contrastive learning strategy boosts the model’s discriminative capability between normal and anomalous patterns. Evaluated extensively on real-world spacecraft telemetry and public datasets, TETAD demonstrates substantial improvements in anomaly detection precision and robustness compared to state-of-the-art methods. Extensive experimental analysis validates the effectiveness of our proposed mechanisms and the overall advantages of TETAD. Our work provides a robust and practical solution for enhancing spacecraft health monitoring reliability and introduces a novel deep architecture for sophisticated temporal feature extraction.
ER  - 

TY  - JOUR
T1  - Improving critical infrastructure security through hybrid embeddings for vulnerability classification
AU  - Ben Yahya, Aissa
AU  - El Akhal, Hicham
AU  - El Alaoui, Abdelbaki El Belrhiti
JO  - Journal of Information Security and Applications
VL  - 93
SP  - 104185
PY  - 2025
DA  - 2025/09/01/
SN  - 2214-2126
DO  - https://doi.org/10.1016/j.jisa.2025.104185
UR  - https://www.sciencedirect.com/science/article/pii/S2214212625002224
KW  - Embedded systems
KW  - Feature fusion
KW  - Deep learning
KW  - Vulnerabilities analysis
KW  - Vulnerability classification
KW  - Text classification
AB  - The growing prevalence of vulnerabilities in embedded devices poses a significant risk to critical infrastructure. While deep learning has advanced vulnerability classification, its effectiveness is often hindered by limitations in word representation. Traditional word embeddings struggle with out-of-vocabulary (OOV) words common in domain-specific reports, while pre-trained language models (PLMs), despite their contextual power, may lack specialized domain knowledge. To address these challenges, we propose a novel Two-Stream hybrid embedding architecture that combines Vuln2Vec, a custom domain-specific word embedding, with a large pre-trained language model (PLM) using a learnable weighted feature fusion. Our approach leverages the rich domain-specific vocabulary of Vuln2Vec to understand specialized terminology, while the PLM captures broader contextual relationships and effectively handles OOV words. We validate our method through rigorous experiments, including ablation studies and comparative analyses on vulnerability databases such as the National Vulnerability Database (NVD), the Chinese Vulnerability Database (CNNVD), and a challenging manually collected dataset. Our experiments demonstrate that the proposed hybrid embedding method achieves a state-of-the-art F1-score of 94.25% and an accuracy of 94.88% on the challenging test dataset, validating the superiority of fusing specialized and general-purpose knowledge for this critical task.
ER  - 

TY  - JOUR
T1  - Exploring the directions of artificial intelligence in good health and well-being (SDG3) using big data and LDA topic modeling
AU  - Madzík, Peter
AU  - Falát, Lukáš
AU  - Jayaraman, Raja
AU  - Sony, Michael
AU  - Antony, Jiju
AU  - Zimon, Dominik
AU  - Skýpalová, Renata
JO  - Technovation
VL  - 151
SP  - 103404
PY  - 2026
DA  - 2026/03/01/
SN  - 0166-4972
DO  - https://doi.org/10.1016/j.technovation.2025.103404
UR  - https://www.sciencedirect.com/science/article/pii/S0166497225002366
KW  - Artificial intelligence
KW  - Sustainable development goals (SDG3)
KW  - Healthcare automation
KW  - Global health trends
KW  - Latent Dirichlet allocation (LDA)
KW  - Topic modeling
AB  - Artificial Intelligence (AI) holds significant potential for advancing Sustainable Development Goal 3 (SDG3)—Good Health and Well-being—yet the field remains fragmented across numerous topics and disciplines. In this study, we apply Latent Dirichlet Allocation (LDA) to a final corpus of 60,010 Scopus abstracts after filtering, extracting k = 160 latent topics (selected via metric-based tuning; see Appendix A) and organizing them into a process-oriented, Health Technology Assessment–inspired framework that links Drivers, AI Infrastructure and Methods, Implementation, and Results. Key findings include dominant research streams in disease diagnostics (e.g., breast cancer, cardiovascular disease), personalized treatment, and automation, alongside the emergence of large language models (LLMs) like ChatGPT. Geographical mapping highlights Asia, North America, and Europe as research hubs, while underexplored areas such as AI in social media and student education are identified. We also introduce a quadrant-based trend analysis to distinguish “niche excellence” from “leading research areas” and chart short-versus medium-term dynamics. This methodological contribution not only offers a comprehensive “scientific map” of AI–SDG3 research but also provides a scalable blueprint for mapping AI's role across other SDGs and guiding future theory-driven and policy-relevant investigations.
ER  - 

TY  - JOUR
T1  - An end-to-end learning approach for enhancing intrusion detection in Industrial-Internet of Things
AU  - Hassini, Karima
AU  - Khalis, Safae
AU  - Habibi, Omar
AU  - Chemmakha, Mohammed
AU  - Lazaar, Mohamed
JO  - Knowledge-Based Systems
VL  - 294
SP  - 111785
PY  - 2024
DA  - 2024/06/21/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2024.111785
UR  - https://www.sciencedirect.com/science/article/pii/S0950705124004192
KW  - Internet of things (IoT)
KW  - Industrial-internet of things (I-IoT)
KW  - Industry 4.0
KW  - CyberSecurity
KW  - Intrusion detection system (IDS)
KW  - End-to-end model
KW  - Deep learning (DL)
KW  - One-dimensional convolutional neural network (CNN1D)
AB  - The Industrial-Internet of Things (I-IoT) stands out as one of the most dynamically evolving subfields within the expansive realm of the Internet of Things (IoT). Its exponential growth is reshaping industrial landscapes, bringing forth transformative innovations and advancements at an unprecedented pace, as the core of Industry 4.0. Among the formidable challenges faced by the Industrial-Internet of Things, cybersecurity stands out as a critical concern. Deep learning-based Intrusion Detection System (IDS) solutions showcase their steadfast ability to secure resource-limited, investigation-demanding, and complex I-IoT environments. However, their effectiveness hinges not only on the model but also on the dataset on which they are trained. While numerous literature studies delve into this field, existing proposed models often grapple with challenges. They are frequently trained on outdated, non-diverse datasets or lack specific features crucial for I-IoT networks. Recent efforts, thankfully, introduce more adequate datasets like Edge-IIoTset. Researchers leverage this extensive dataset to train models, focusing on detecting the 14 sophisticated attacks. These attacks predominantly target real I-IoT networks. Despite these efforts, none of the existing models proves entirely efficient. A review of literature solutions reveals that many models cannot detect all 15 classes in the dataset. Some are multi-staged or overly complex. In response to these challenges, this paper presents an End-to-End learning , non-complex CNN1D model tailored to the specific problem of detecting 14 sophisticated threats targeting I-IoT environments. Our proposed model demonstrated remarkable efficiency with an accuracy of 99.96%, successfully detecting all 15 classes in the Edge-IIoTset dataset with a minimal loss of 0.0011. Not only that, but our model was validated with k-fold cross-validation, demonstrating its efficiency in preserving the same performance on unseen data and its ability to be generalized for real-world I-IoT environments.
ER  - 

TY  - JOUR
T1  - Identification of cyber harassment and intention of target users on social media platforms
AU  - Abarna, S.
AU  - Sheeba, J.I.
AU  - Jayasrilakshmi, S.
AU  - Devaneyan, S. Pradeep
JO  - Engineering Applications of Artificial Intelligence
VL  - 115
SP  - 105283
PY  - 2022
DA  - 2022/10/01/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2022.105283
UR  - https://www.sciencedirect.com/science/article/pii/S0952197622003359
KW  - Cyberbullying
KW  - Fast text
KW  - Word2vec
KW  - Natural language processing
KW  - Insulting vocabulary
KW  - Intention detection
KW  - Buzzwords
AB  - Due to Coronavirus diseases in 2020, all the countries departed into lockdown to combat the spread of the pandemic situation. Schools and institutions remain closed and students’ screen time surged. The classes for the students are moved to the digital platform which leads to an increase in social media usage. Many children had become sufferers of cyber harassment which includes threatening comments on young students, sexual torture through a digital platform, people insulting one another, and the use of fake accounts to harass others. The rising effort on automated cyber harassment detection utilizes many AI-related components Natural language processing techniques and machine learning approaches. Though machine learning models using different algorithms fail to converge with higher accuracy, it is much more important to use significant natural language processes and efficient classifiers to detect cyberbullying comments on social media. In this proposed work, the lexical meaning of the text is analysed by the conventional scheme and the word order of the text is performed by the Fast Text model to improve the computational efficacy of the model. The intention of the text is analysed by various feature extraction methods. The score for intention detection is calculated using the frequency of words with a bully-victim participation score. Finally, the proposed model’s performance is measured by different evaluation metrics which illustrate that the accuracy of the model is higher than many other existing classification methods. The error rate is lesser for the detection model.
ER  - 

TY  - JOUR
T1  - Classification and application of deep learning in construction engineering and management – A systematic literature review and future innovations
AU  - Li, Qingze
AU  - Yang, Yang
AU  - Yao, Gang
AU  - Wei, Fujia
AU  - Li, Rui
AU  - Zhu, Mingtao
AU  - Hou, Huiwen
JO  - Case Studies in Construction Materials
VL  - 21
SP  - e04051
PY  - 2024
DA  - 2024/12/01/
SN  - 2214-5095
DO  - https://doi.org/10.1016/j.cscm.2024.e04051
UR  - https://www.sciencedirect.com/science/article/pii/S2214509524012038
KW  - Deep learning(DL)
KW  - Construction engineering management(CEM)
KW  - Condition monitoring
KW  - Damage detection
KW  - Large language models (LLM)
AB  - In the ever-evolving landscape of construction engineering and management (CEM), the dynamic and unique characteristics of construction project environments constantly present multifaceted challenges. These challenges are characterized by the extensive volume of project-specific information and intricate engineering data. Deep learning (DL), with its advanced analytical capabilities, has been emerging as a robust solution to these complexities. While the application of DL in CEM is on an upward trajectory, a systematic review of its implementation is conspicuously lacking. This paper, therefore, embarks on a scientometric and qualitative analysis of 296 DL-based studies related to CEM from 2014 to 2024 in the renowned data science repositories Scopus, Science Direct and Web of Science to explore the characteristics of journals, keywords and clusters. It is found that six research topics have fully utilized the advantages of DL in CEM in the last decade, including construction equipment management, structural health monitoring, construction site safety management, construction schedule management, worker health management and workforce assessment and intelligent design. Then, the studies under each research topic are summarized separately and a searchable taxonomy is proposed that secondarily categorizes each study according to the specific CEM task and DL method used to facilitate understanding and access. Finally, the primary obstacles encountered in DL itself and in its practical application in CEM are discussed. It further articulates five critical future research directions that are evolving in tandem with advances in CEM, multimodal construction site management, real-time structural health monitoring and prediction, project progress visualization and management, intelligent design with data sharing and the incorporating large language models (LLM) for text data analysis. The three goals of this study are providing CEM researchers and practitioners with an in-depth and nuanced understanding of DL, elucidating the diverse nature of CEM activities and the resulting benefits of applying DL, and identifying future opportunities for applying DL in CEM to inform subsequent ongoing academic inquiry and pragmatic applications.
ER  - 

TY  - JOUR
T1  - PSC-BERT: A spam identification and classification algorithm via prompt learning and spell check
AU  - Gui, Jiayi
AU  - Zhou, Yuhao
AU  - Yu, Ke
AU  - Wu, Xiaofei
JO  - Knowledge-Based Systems
VL  - 301
SP  - 112266
PY  - 2024
DA  - 2024/10/09/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2024.112266
UR  - https://www.sciencedirect.com/science/article/pii/S0950705124009006
KW  - Chinese spam detection
KW  - Prompt learning
KW  - Spell check
KW  - BERT
AB  - The rapid growth of the Internet has led to an increase in spam activities, posing significant security threats. Spammers use various tactics, such as intentional misspellings, to evade detection systems. Current spam detection mostly relies on semantic analysis, which is inadequate given these sophisticated evasion techniques. This paper addresses the problem by constructing a Chinese Camouflage Spam dataset (CCS) and proposing a novel detection and recognition model: Prompt and Spelling Checking-based BERT (PSC-BERT). BERT, a state-of-the-art language model, has been successful in many NLP tasks but faces limitations in handling misspelled text. PSC-BERT extends BERT by integrating semantic, phonetic, and glyph information from spam texts and employs a novel hard template prompt learning method that unifies text classification and spell-check tasks. In experiments, PSC-BERT outperformed baseline models, showing a 0.81% improvement over Semorph and a 2.01% improvement over LR in binary classification. For multi-class classification, it achieved a 0.95% increase in Macro-F1 and 0.49% in Weighed-F1 over the best baseline. Two sub-datasets from Chinese Camouflage Spam dataset were created for detection and recognition, and extensive analysis confirmed the model’s efficacy, especially in few-shot learning scenarios. Additionally, a case study illustrates the attention mechanism in BERT, providing deeper insights into token in the sequences. In summary, PSC-BERT demonstrates a significant advancement in spam detection capabilities against intentional misspellings problem.
ER  - 

TY  - JOUR
T1  - Semi-supervised log anomaly detection based on bidirectional temporal convolution network
AU  - Yin, Zhichao
AU  - Kong, Xian
AU  - Yin, Chunyong
JO  - Computers & Security
VL  - 140
SP  - 103808
PY  - 2024
DA  - 2024/05/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.103808
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824001093
KW  - Log parsing
KW  - Anomaly detection
KW  - Semi-supervised learning
KW  - Bidirectional temporal convolution network
KW  - Contextual correlation
AB  - System logs record system operation status and important event information. They are the important basis for debugging system failures and cause analysis. Due to the low accuracy of log parsing and insufficient labeled samples, anomaly detection precision is low. Therefore, we propose a new log-based semi-supervised anomaly detection method named BTCNLog. Firstly, the improved log parsing method with the dictionary keeps part of the parameter information in the log event. So, it can improve the utilization rate of log information and the accuracy of log parsing. Then, BERT is used to encode the semantic information to obtain the semantic vector of the log for the template. What's more, the clustering method is applied to estimate the tag to deal with insufficient data tagging problems. Therefore, it can improve the ability to detect unstable data for the model. Finally, a bidirectional temporal convolution network (Bi-TCN) with residual blocks is introduced to capture contextual information from two directions to improve the accuracy and efficiency of anomaly detection. To evaluate the performance of the proposed method, BTCNLog is compared with six baselines on two datasets. The final experimental results show that, compared with the latest three benchmark models, LogBERT, PLELog, and LogEncoder, the proposed method showed an average improvement of 7%, 14.1%, and 8.04% in F1 values.
ER  - 

TY  - JOUR
T1  - Improving intrusion detection in O-RAN with synthetic data generation: A GAN and SMOTE approach
AU  - Amachaghi, Emmanuel N.
AU  - Abdulkareem, Sulyman Age
AU  - Foh, Chuan Heng
AU  - Mi, De
AU  - Shojafar, Mohammad
JO  - Telematics and Informatics Reports
VL  - 20
SP  - 100269
PY  - 2025
DA  - 2025/12/01/
SN  - 2772-5030
DO  - https://doi.org/10.1016/j.teler.2025.100269
UR  - https://www.sciencedirect.com/science/article/pii/S2772503025000830
KW  - Open Radio Access Network
KW  - Machine learning
KW  - SMOTE
KW  - GenAI
KW  - GAN
KW  - Ensemble learning
KW  - Intrusion detection system
AB  - In network security, the issue of imbalanced data, where certain classes are under-represented, poses a significant challenge for intrusion detection systems (IDS). Machine learning algorithms often prioritise the majority class, resulting in poor detection of minority classes and reduced overall model accuracy. Accurately identifying these rare intrusions is essential for predicting and mitigating emerging threats. This paper presents an advanced IDS designed for Open Radio Access Networks (O-RAN) to address class imbalance by employing Synthetic Minority Over-sampling Technique (SMOTE) variants and Generative Adversarial Networks (GANs). The system was evaluated on the CICEVSE2024 dataset and a real-world O-RAN dataset. Results show that SMOTE improved the accuracy of weaker classifiers such as Naive Bayes by up to 10% (from 53.9% to 64.0%), with corresponding increases in recall and F1-score. Ensemble methods like Random Forest and XGBoost maintained high accuracy (≈ 81%–89%) and benefited from balanced recall when synthetic data was applied. However, GAN-generated data (CTGAN) showed little to no improvement over baseline models, and in some cases, SMOTE reduced accuracy for classifiers such as Logistic Regression and Random Forest on the O-RAN dataset (by up to 30%). These results highlight that while SMOTE variants can significantly enhance minority class detection, especially for weaker classifiers, the utility of GANs remains limited in this context. Future work should therefore focus on improving GAN-based data quality, exploring hybrid deep learning approaches, and extending IDS to real-time and multi-class scenarios.
ER  - 

TY  - JOUR
T1  - GraphShield: Advanced dynamic graph-based malware detection using graph neural networks
AU  - Amer, Eslam
AU  - El-Sappagh, Shaker
AU  - Abuhamad, Tamer
AU  - Al-Rimy, Bander Ali Saleh
AU  - Mohasseb, Alaa
JO  - Expert Systems with Applications
VL  - 298
SP  - 129812
PY  - 2026
DA  - 2026/03/01/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2025.129812
UR  - https://www.sciencedirect.com/science/article/pii/S095741742503427X
KW  - Malware detection
KW  - Graph neural networks (GNNs)
KW  - API Call analysis
KW  - Behavioral graph representation
KW  - Dynamic malware analysis
KW  - GNN Explainer
KW  - Zero-day threat detection
KW  - Temporal graph modeling
KW  - Deep learning for cybersecurity
AB  - The rising complexity of modern malware-such as polymorphic, fileless, and sandbox-aware variants-has severely diminished the reliability of conventional detection techniques. Models based on sequential data frequently miss intricate behavioral patterns and long-range dependencies, resulting in poor accuracy and limited adaptability to new threats. This paper introduces GraphShield, a graph-centric behavioral detection framework that identifies malware with high precision by analyzing dynamic API call sequences. GraphShield converts raw API calls into temporal graphs, applies semantic vectorization, and leverages attention mechanisms to extract both localized activity and extended behavioral correlations, directly addressing the weaknesses of earlier systems. We design and assess multiple Graph Neural Network (GNN) variants, including Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs), Graph Isomorphism Networks (GINs), and Transformer-based architectures combining convolutional, recurrent, and autoencoding layers. These models capture structural and temporal traits of execution traces using both classification-only and combined classification-reconstruction strategies. To enhance transparency, we incorporate GNN interpretation tools that isolate key API call subgraphs and critical decision pathways, making detection outcomes explainable for analysts. GraphShield is trained on 300,000 balanced instances and tested on a separate 200,000-sample holdout set, achieving over 58 % improvement in accuracy over advanced sequence-driven deep learning models while maintaining a false positive rate under 1 %. Key features include BERT-based API call grouping for reducing dimensionality and a Markov-inspired graph stabilization method for managing graphs of variable length. Our top models attain a 99.5 % F1-score on the test set. GraphShield aligns recent graph learning techniques with operational cybersecurity needs, delivering accurate detection and clear, interpretable results.
ER  - 

TY  - JOUR
T1  - Artificial Intelligence (AI): Foundations, trends and future directions
AU  - Golec, Muhammed
AU  - Hatay, Emir Sahin
AU  - Gill, Sukhpal Singh
AU  - Buyya, Rajkumar
JO  - Telematics and Informatics Reports
VL  - 20
SP  - 100265
PY  - 2025
DA  - 2025/12/01/
SN  - 2772-5030
DO  - https://doi.org/10.1016/j.teler.2025.100265
UR  - https://www.sciencedirect.com/science/article/pii/S2772503025000799
KW  - AI
KW  - Computing
KW  - Quantum computing
KW  - Artificial intelligence
KW  - Machine learning
AB  - Developments in artificial intelligence (AI) technology have revolutionized many areas, from health to education, and from defense to commercial applications, both civilian and military. This article provides a comprehensive overview of the foundations, theoretical, and technological developments of AI, and the application areas it has enabled. It also examines the industrial impact of AI, including recent trending applications such as DeepSeek, ChatGPT, Google Lens, Face ID, and Tesla, as well as the areas of Natural Language Processing, Autonomous Vehicles, and Computer Vision. Beyond these, it highlights on future aspects of AI, such as next-generation Large Language Models (LLMs) and Artificial General Intelligence (AGI), and explores its impact on social ethics. The investigation of all these aspects aims to equip the reader with a comprehensive understanding of the current impact and potential future directions of AI.
ER  - 

TY  - JOUR
T1  - Proactive Disentangled Modeling of Trigger–Object Pairings for Backdoor Defense
AU  - Stein, Kyle
AU  - Mahyari, Andrew A.
AU  - Francia III, Guillermo
AU  - El-Sheikh, Eman
JO  - Computers, Materials and Continua
VL  - 85
IS  - 1
SP  - 1001
EP  - 1018
PY  - 2025
DA  - 2025/08/29/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2025.068201
UR  - https://www.sciencedirect.com/science/article/pii/S1546221825008367
KW  - Backdoor attacks
KW  - generative AI
KW  - disentanglement
AB  - Deep neural networks (DNNs) and generative AI (GenAI) are increasingly vulnerable to backdoor attacks, where adversaries embed triggers into inputs to cause models to misclassify or misinterpret target labels. Beyond traditional single-trigger scenarios, attackers may inject multiple triggers across various object classes, forming unseen backdoor-object configurations that evade standard detection pipelines. In this paper, we introduce DBOM (Disentangled Backdoor-Object Modeling), a proactive framework that leverages structured disentanglement to identify and neutralize both seen and unseen backdoor threats at the dataset level. Specifically, DBOM factorizes input image representations by modeling triggers and objects as independent primitives in the embedding space through the use of Vision-Language Models (VLMs). By leveraging the frozen, pre-trained encoders of VLMs, our approach decomposes the latent representations into distinct components through a learnable visual prompt repository and prompt prefix tuning, ensuring that the relationships between triggers and objects are explicitly captured. To separate trigger and object representations in the visual prompt repository, we introduce the trigger–object separation and diversity losses that aids in disentangling trigger and object visual features. Next, by aligning image features with feature decomposition and fusion, as well as learned contextual prompt tokens in a shared multimodal space, DBOM enables zero-shot generalization to novel trigger-object pairings that were unseen during training, thereby offering deeper insights into adversarial attack patterns. Experimental results on CIFAR-10 and GTSRB demonstrate that DBOM robustly detects poisoned images prior to downstream training, significantly enhancing the security of DNN training pipelines.
ER  - 

TY  - JOUR
T1  - Enhancing Log Anomaly Detection with Semantic Embedding and Integrated Neural Network Innovations
AU  - Xu, Zhanyang
AU  - Wang, Zhe
AU  - Xu, Jian
AU  - Shi, Hongyan
AU  - Zhao, Hong
JO  - Computers, Materials and Continua
VL  - 80
IS  - 3
SP  - 3991
EP  - 4015
PY  - 2024
DA  - 2024/09/12/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2024.051620
UR  - https://www.sciencedirect.com/science/article/pii/S1546221824006131
KW  - Deep learning
KW  - log analysis
KW  - anomaly detection
KW  - natural language processing
AB  - System logs, serving as a pivotal data source for performance monitoring and anomaly detection, play an indispensable role in assuring service stability and reliability. Despite this, the majority of existing log-based anomaly detection methodologies predominantly depend on the sequence or quantity attributes of logs, utilizing solely a single Recurrent Neural Network (RNN) and its variant sequence models for detection. These approaches have not thoroughly exploited the semantic information embedded in logs, exhibit limited adaptability to novel logs, and a single model struggles to fully unearth the potential features within the log sequence. Addressing these challenges, this article proposes a hybrid architecture based on a multiscale convolutional neural network, efficient channel attention and mogrifier gated recurrent unit networks (LogCEM), which amalgamates multiple neural network technologies. Capitalizing on the superior performance of robustly optimized BERT approach (RoBERTa) in the realm of natural language processing, we employ RoBERTa to extract the original word vectors from each word in the log template. In conjunction with the enhanced Smooth Inverse Frequency (SIF) algorithm, we generate more precise log sentence vectors, thereby achieving an in-depth representation of log semantics. Subsequently, these log vector sequences are fed into a hybrid neural network, which fuses 1D Multi-Scale Convolutional Neural Network (MSCNN), Efficient Channel Attention Mechanism (ECA), and Mogrifier Gated Recurrent Unit (GRU). This amalgamation enables the model to concurrently capture the local and global dependencies of the log sequence and autonomously learn the significance of different log sequences, thereby markedly enhancing the efficacy of log anomaly detection. To validate the effectiveness of the LogCEM model, we conducted evaluations on two authoritative open-source datasets. The experimental results demonstrate that LogCEM not only exhibits excellent accuracy and robustness, but also outperforms the current mainstream log anomaly detection methods.
ER  - 

TY  - JOUR
T1  - CDA.AI for OpenCDA: AI pathways for cooperative driving automation research
AU  - Han, Xu
AU  - Zheng, Zhaoliang
AU  - Zhou, Zewei
AU  - Zhang, Yun
AU  - Cai, Tiahui
AU  - Liu, Yifan
AU  - Xiang, Hao
AU  - Correa-Jullian, Camila
AU  - Meng, Zonglin
AU  - Huang, Zhiyu
AU  - Gao, Letian
AU  - Xia, Xin
AU  - Ma, Jiaqi
JO  - Artificial Intelligence for Transportation
VL  - 1
SP  - 100002
PY  - 2025
DA  - 2025/07/01/
SN  - 3050-8606
DO  - https://doi.org/10.1016/j.ait.2025.100002
UR  - https://www.sciencedirect.com/science/article/pii/S305086062500002X
KW  - Cooperative driving automation (CDA)
KW  - Intelligent transportation systems (ITS)
KW  - Automated driving system (ADS)
KW  - Artificial intelligence (AI)
KW  - Reinforcement learning (RL)
KW  - End-to-end
KW  - Semi-end-to-end
KW  - Vision-language models (VLM)
KW  - Vision-language-action (VLA)
KW  - Cooperative perception
KW  - Cooperative detection and tracking
KW  - Cooperative localization
KW  - Decision making
KW  - Traffic control
KW  - Infrastructure sensing and perception
KW  - Infrastructure sensor placement
AB  - This position paper presents CDA.AI, a comprehensive artificial intelligence framework for Cooperative Driving Automation (CDA) that builds upon established ADAS and ADS technologies by integrating connectivity into a unified system. CDA.AI leverages both semi-end-to-end and end-to-end AI paradigms to enable scalable, interpretable, and adaptive multi-agent traffic systems. By facilitating real-time communication among connected vehicles and smart infrastructure, the framework supports system-level cooperative perception—employing diverse fusion strategies such as early, intermediate, and late fusion—along with coordinated planning and control. Moreover, CDA.AI incorporates closed-loop integration with large-scale vision-language models (VLM) and Vision-Language-Action (VLA) systems, directly enhancing reasoning capabilities and infusing higher-level intelligence into the perception and decision-making processes of CDA. This dual-pathway approach not only ensures high-performance end-to-end learning for complex decision-making but also retains the modular transparency needed for safety-critical applications and seamless human-CDA interaction. Use cases including multi-lane platooning, cooperative merging, and multi-modality sensing demonstrate how the framework improves both individual vehicle behavior and overall traffic system performance. Built upon the open-source OpenCDA ecosystem, this framework provides essential tools, datasets, and benchmark scenarios to accelerate research and facilitate the deployment of cooperative automated systems across diverse environments, while emphasizing a system-level perspective that supports both connected ADAS and ADS.
ER  - 

TY  - JOUR
T1  - NN2ViT: Neural Networks and Vision Transformers based approach for Visual Anomaly Detection in Industrial Images
AU  - Wahid, Junaid Abdul
AU  - Ayoub, Muhammad
AU  - Xu, Mingliang
AU  - Jiang, Xiaoheng
AU  - Shi, Lei
AU  - Hussain, Shabir
JO  - Neurocomputing
VL  - 615
SP  - 128845
PY  - 2025
DA  - 2025/01/28/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2024.128845
UR  - https://www.sciencedirect.com/science/article/pii/S0925231224016163
KW  - Anomaly detection
KW  - Anomaly segmentation
KW  - Industrial data
KW  - Neural network
KW  - Vision transformers
AB  - Ensuring product quality through automated anomaly detection is crucial in manufacturing. Traditional methods often struggle to capture both local and global features effectively, relying heavily on predefined templates that limit their adaptability and accuracy. To address these challenges, this study propose NN2ViT, a novel approach that integrates a Single Shot Detector (SSD) for local feature detection and the Segment Anything Model (SAM) for global feature segmentation. This integration allows for a comprehensive analysis of anomalies in industrial images. Our method improves anomaly segmentation performance by fine-tuning SAM for precise segmentation in industrial product images. Experiments on the MVTec benchmark dataset demonstrate that NN2ViT outperforms traditional models and achieved the highest 95.54% and 96.23% Image AUROC and AP scores, respectively thus enhancing interpretability and adaptability to various anomaly patterns. This research presents a significant advancement in manufacturing quality control, contributing to improved product quality and operational efficiency.
ER  - 

TY  - JOUR
T1  - SoK: An empirical investigation of malware techniques in advanced persistent threat attacks
AU  - Rahman, Md Rayhanur
AU  - Basak, Setu Kumar
AU  - Mahdavi Hezaveh, Rezvan
AU  - Williams, Laurie
JO  - Computers & Security
VL  - 157
SP  - 104618
PY  - 2025
DA  - 2025/10/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104618
UR  - https://www.sciencedirect.com/science/article/pii/S0167404825003074
KW  - Adversarial techniques
KW  - ATT&CK
KW  - TTPs
KW  - Advanced persistent threats
KW  - Malware
AB  - Context:
Adversaries launch advanced persistent threat (APT) attacks, where adversaries design their attack for a specific target and aim to remain undetected for a prolonged time. The attackers deploy a plethora of techniques for delivering and operating multiple malware in manual or automated manners. Cybersecurity vendors publish technical reports, known as cyberthreat intelligence reports, on past APT attacks, a rich information source on malware techniques. To defend organizations, prevalent techniques observed across malware in APT attacks and their association need to be identified.
Objective:
The goal of this research is to aid cybersecurity practitioners in defending against APT attacks by analyzing malware techniques documented in cyberthreat intelligence reports.
Methodology:
We construct a curated set of 798 cyberthreat intelligence reports and then analyze the reported malware techniques using MITRE ATT&CK, a well-known terminology of cyberattack techniques, cybercriminal groups, and campaigns in APT attacks. We analyze the frequency and trend of techniques, followed by a qualitative analysis. Next, we perform association rule mining to identify co-occurring techniques, followed by a qualitative analysis.
Findings:
We identify that obtaining information on the operating and network system of the victim environment is the most prevalent technique and appears in the highest number of co-occurring pairs. We identify that spear-phishing is the most prevalent way of initial infection. We also identify three prevalent misuses of system functionalities: Macros in Office documents, the Registry in Windows, and the Task scheduler. We advocate that organizations prioritize their defense against the identified prevalent techniques and actively hunt for potential malicious intrusions based on the identified association among malware techniques.
ER  - 

TY  - JOUR
T1  - Preparing for an agentic era of human-machine transportation systems: Opportunities, challenges, and policy recommendations
AU  - Yu, Jiangbo
JO  - Transport Policy
VL  - 171
SP  - 78
EP  - 97
PY  - 2025
DA  - 2025/09/01/
SN  - 0967-070X
DO  - https://doi.org/10.1016/j.tranpol.2025.05.030
UR  - https://www.sciencedirect.com/science/article/pii/S0967070X2500215X
KW  - AI agents
KW  - Human-AI
KW  - Machine learning
KW  - Autonomous vehicle
KW  - Smart cities
KW  - Automated construction
KW  - Participatory decision-making
KW  - Large language model
AB  - Human-Machine Transportation Systems (HMTS) refer to transportation systems where humans and machines interact to enable mobility. The history of humans creating and utilizing machines for transportation purposes dates back from the invention of the wheel to more recent innovations such as bicycles, automobiles, traffic signals, handheld navigation devices, asphalt pavers, and computer-aided design and management tools. In recent years, technological advancements have transformed machines from passive tools into more active participants, with humans increasingly delegating complex tasks and responsibilities to them. While these advancements have revolutionized mobility, their siloed, uncoordinated implementation has also introduced critical challenges, including urban sprawl, high fatalities, environmental degradation, and worsened societal disparity. The recent advancements in machine learning, robotics, communication, and computing technologies prompt the emergence of agentic transportation systems (ATS) to potentially address these chronic issues and transform how people access resources and opportunities. In ATS, intelligent machines serve as autonomous intermediaries, facilitating the interactions among humans and between humans and infrastructure. From this new standpoint, early-stage ATS—such as autonomous vehicles, on-demand ridesharing platforms, generative design tools, construction robots, and anomaly detection equipment—have already begun to enter society, calling for an understanding about whether the current research and practice in transportation planning and engineering are ready for ATS. A review of recent literature reveals four main categories of research: (1) co-visioning, co-planning, and co-design; (2) co-construction and co-maintenance; (3) co-control, co-operation, and co-management; and (4) co-usage and co-consumption. The review suggests a significant lack of studies on the proactive integration of agentic machines within and across individual lifecycle phases, risking severe and irreversible consequences. Accordingly, the paper proposes a framework to guide the development of ATS to be justifiable, inclusive, and adaptable (JIA) and ensure the intelligence in and of the next-generation HMTS to be genuinely human-centered and societally beneficial.
ER  - 

TY  - JOUR
T1  - Unveiling the multifaceted concept of cognitive security: Trends, perspectives, and future challenges
AU  - Casino, Fran
JO  - Technology in Society
VL  - 83
SP  - 102956
PY  - 2025
DA  - 2025/12/01/
SN  - 0160-791X
DO  - https://doi.org/10.1016/j.techsoc.2025.102956
UR  - https://www.sciencedirect.com/science/article/pii/S0160791X25001460
KW  - Cybersecurity
KW  - Cognitive security
KW  - Artificial intelligence
KW  - Human–computer interaction
KW  - Information systems
AB  - As a transversal concept tied to human evolution, security has increased its relevance at the same pace as development and digitisation. With the advancement of artificial intelligence (AI) and the sophistication of advanced persistent threats, the emerging paradigm of cognitive security (i.e., defined by some authors as the use of self-aware and adaptable AI with learning capabilities to detect and mitigate security threats) gains momentum. Nevertheless, cognitive security is a complex concept that requires a more granular description. In this article, we redefine cognitive security by first analysing the state of the art to derive the current state of practice and the definitions of cognitive security. Next, we expand the concept of cognitive security by analysing its multiple pillars, including learning theories, AI technologies, human–computer interactions, and the ethical and legal aspects impacting its development and implementation. The latter is crucial towards understanding cognitive security, providing insight into its potential and prerequisites towards its realisation while emphasising its multidisciplinary nature. In addition to such a description, we analyse the current challenges in three closely interconnected fields, namely cybersecurity, digital forensics, and digital investigations, to provide a taxonomy that can be used to assess the current challenges and limitations of cognitive security and understand its potential better. Finally, we propose future research directions, aiming to develop cognitive systems capable of continuous learning, adaptation, and ethical compliance in dynamic cybersecurity environments. Our findings highlight the role of cognitive computing systems in enhancing cybersecurity, discussing the integration of human cognition and AI for proactive and resilient security solutions.
ER  - 

TY  - JOUR
T1  - Unveiling security, privacy, and ethical concerns of ChatGPT
AU  - Wu, Xiaodong
AU  - Duan, Ran
AU  - Ni, Jianbing
JO  - Journal of Information and Intelligence
VL  - 2
IS  - 2
SP  - 102
EP  - 115
PY  - 2024
DA  - 2024/03/01/
SN  - 2949-7159
DO  - https://doi.org/10.1016/j.jiixd.2023.10.007
UR  - https://www.sciencedirect.com/science/article/pii/S2949715923000707
KW  - ChatGPT
KW  - Large language model (LLM)
KW  - Security
KW  - Privacy
KW  - Ethics
AB  - This paper delves into the realm of ChatGPT, an AI-powered chatbot that utilizes topic modeling and reinforcement learning to generate natural responses. Although ChatGPT holds immense promise across various industries, such as customer service, education, mental health treatment, personal productivity, and content creation, it is essential to address its security, privacy, and ethical implications. By exploring the upgrade path from GPT-1 to GPT-4, discussing the model's features, limitations, and potential applications, this study aims to shed light on the potential risks of integrating ChatGPT into our daily lives. Focusing on security, privacy, and ethics issues, we highlight the challenges these concerns pose for widespread adoption. Finally, we analyze the open problems in these areas, calling for concerted efforts to ensure the development of secure and ethically sound large language models.
ER  - 

TY  - JOUR
T1  - SCL-CVD: Supervised contrastive learning for code vulnerability detection via GraphCodeBERT
AU  - Wang, Rongcun
AU  - Xu, Senlei
AU  - Tian, Yuan
AU  - Ji, Xingyu
AU  - Sun, Xiaobing
AU  - Jiang, Shujuang
JO  - Computers & Security
VL  - 145
SP  - 103994
PY  - 2024
DA  - 2024/10/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.103994
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824002992
KW  - Contrastive learning
KW  - Vulnerability detection
KW  - Pre-trained models
KW  - LoRA
AB  - Detecting vulnerabilities in source code is crucial for protecting software systems from cyberattacks. Pre-trained language models such as CodeBERT and GraphCodeBERT have been applied in multiple code-related downstream tasks such as code search and code translation and have achieved notable success. Recently, this pre-trained and fine-tuned paradigm has also been applied to detect code vulnerabilities. However, fine-tuning pre-trained language models using cross-entropy loss has several limitations, such as poor generalization performance and lack of robustness to noisy labels. In particular, when the vulnerable code and the benign code are very similar, it is difficult for deep learning methods to differentiate them accurately. In this context, we introduce a novel approach for code vulnerability detection using supervised contrastive learning, namely SCL-CVD, which leverages GraphCodeBERT. This method aims to enhance the effectiveness of existing vulnerable code detection approaches. SCL-CVD represents the source code as data flow graphs. These graphs are then processed by GraphCodeBERT, which has been fine-tuned using a supervised contrastive loss function combined with R-Drop. This fine-tuning process is designed to generate more resilient and representative code embedding. Additionally, we incorporate LoRA (Low-Rank Adaptation) to streamline the fine-tuning process, significantly reducing the time required for model training. Finally, a Multilayer Perceptron (MLP) is employed to detect vulnerable code leveraging the learned representation of code. We designed and conducted experiments on three public benchmark datasets, i.e., Devign, Reveal, Big-Vul, and a combined dataset created by merging these sources. The experimental results demonstrate that SCL-CVD can effectively improve the performance of code vulnerability detection. Compared with the baselines, the proposed approach has a relative improvement of 0.48%∼3.42% for accuracy, 0.93%∼45.99% for precision, 35.68%∼67.48% for recall, and 16.31%∼49.67% for F1-score, respectively. Furthermore, compared to baselines, the model fine-tuning time of the proposed approach is reduced by 16.67%∼93.03%. In conclusion, our approach SCL-CVD offers significantly greater cost-effectiveness over existing approaches.
ER  - 

TY  - JOUR
T1  - Multi-Head Attention Enhanced Parallel Dilated Convolution and Residual Learning for Network Traffic Anomaly Detection
AU  - Qi, Guorong
AU  - Mao, Jian
AU  - Huang, Kai
AU  - You, Zhengxian
AU  - Lin, Jinliang
JO  - Computers, Materials and Continua
VL  - 82
IS  - 2
SP  - 2159
EP  - 2176
PY  - 2025
DA  - 2025/02/17/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2024.058396
UR  - https://www.sciencedirect.com/science/article/pii/S1546221825001213
KW  - Network traffic
KW  - anomaly detection
KW  - multi-head attention
KW  - parallel dilated convolution
KW  - residual learning
AB  - Abnormal network traffic, as a frequent security risk, requires a series of techniques to categorize and detect it. Existing network traffic anomaly detection still faces challenges: the inability to fully extract local and global features, as well as the lack of effective mechanisms to capture complex interactions between features; Additionally, when increasing the receptive field to obtain deeper feature representations, the reliance on increasing network depth leads to a significant increase in computational resource consumption, affecting the efficiency and performance of detection. Based on these issues, firstly, this paper proposes a network traffic anomaly detection model based on parallel dilated convolution and residual learning (Res-PDC). To better explore the interactive relationships between features, the traffic samples are converted into two-dimensional matrix. A module combining parallel dilated convolutions and residual learning (res-pdc) was designed to extract local and global features of traffic at different scales. By utilizing res-pdc modules with different dilation rates, we can effectively capture spatial features at different scales and explore feature dependencies spanning wider regions without increasing computational resources. Secondly, to focus and integrate the information in different feature subspaces, further enhance and extract the interactions among the features, multi-head attention is added to Res-PDC, resulting in the final model: multi-head attention enhanced parallel dilated convolution and residual learning (MHA-Res-PDC) for network traffic anomaly detection. Finally, comparisons with other machine learning and deep learning algorithms are conducted on the NSL-KDD and CIC-IDS-2018 datasets. The experimental results demonstrate that the proposed method in this paper can effectively improve the detection performance.
ER  - 

TY  - JOUR
T1  - Cerebrum twin: A 6D semantic digital twin of multi-lobe digital brain functions for human-centric Industry 5.0
AU  - Teng, Hanwei
AU  - Chen, Shuo
AU  - Li, Changping
AU  - Li, Shujian
AU  - Kurniawan, Rendi
AU  - Xu, Moran
AU  - Chen, Jielin
AU  - Ko, Tae Jo
JO  - Journal of Manufacturing Systems
VL  - 82
SP  - 1125
EP  - 1144
PY  - 2025
DA  - 2025/10/01/
SN  - 0278-6125
DO  - https://doi.org/10.1016/j.jmsy.2025.08.009
UR  - https://www.sciencedirect.com/science/article/pii/S0278612525002079
KW  - Semantic digital twin
KW  - CNC system
KW  - Information fusion
KW  - Remote/Real-time Control and Inspection
KW  - Multi-Lobe digital brain
KW  - Cerebrum twin
AB  - Industry 5.0 highlights the need for human-centric and adaptive intelligence in smart manufacturing. This paper proposes the Cerebrum Twin (CT), a brain-inspired, six-dimensional semantic digital twin (SDT) system that unifies five human-like senses, including listening, speaking, reading, writing, and looking, within a cohesive multi-lobe digital brain framework. CT integrates real-time physical signals from force, vibration, and vision sensors by leveraging a synergistic ensemble of advanced artificial intelligence (AI) modules, such as Extreme Gradient Boosting (XGBoost), ConvNeXt V2, Efficient Sub-Pixel Convolutional Networks (ESPCN), stacked sparse autoencoder with supervision (SSAES), large language models (LLM), and reinforcement learning (RL). Uniquely, CT establishes a closed-loop semantic feedback mechanism, enabling dynamic perception, multimodal semantic abstraction, signal-driven prediction, adaptive parameter optimization, and intuitive voice-based human interaction. This holistic integration bridges the physical, semantic, and cognitive layers of CNC machining, supporting robust, transparent, and operator-oriented decision-making. The proposed system was validated through ultrasonic vibration-assisted blade dicing (UVABD) experiments. CT reduced dicing force prediction error by 39.86 %, improved tool wear prediction accuracy by 29.59 %, and decreased edge chipping severity by 60.47 % compared to the baseline model. These results demonstrate that a semantically empowered, multisensory digital twin (DT), enabled by real-time physical–semantic–AI fusion and human-in-the-loop optimization, can significantly enhance intelligent manufacturing performance and fulfill the vision of Industry 5.0.
ER  - 

TY  - JOUR
T1  - SecureCPS: Cognitive inspired framework for detection of cyber attacks in cyber–physical systems
AU  - Makkar, Aaisha
AU  - Park, Jong Hyuk
JO  - Information Processing & Management
VL  - 59
IS  - 3
SP  - 102914
PY  - 2022
DA  - 2022/05/01/
SN  - 0306-4573
DO  - https://doi.org/10.1016/j.ipm.2022.102914
UR  - https://www.sciencedirect.com/science/article/pii/S0306457322000401
KW  - Cognitive-inspired
KW  - Cognitive sciences
KW  - Artificial intelligence
KW  - Machine learning
KW  - Cyber physical systems
AB  - In the era of autonomous systems, the security is indispensable module for flexible computing environment. Due to increased computer power and network speed, a new computing paradigm, such as cognitive inspired computing, will emerge. Such a paradigm provides human-centered services that are convenient and enjoyable at any time, anywhere, and on any device. On the foundation of smart city environment, human computer interaction, intelligent services, and universal device connectivity, Cyber Physical Computing for Cyber Physical systems has recently been investigated. However, in this proposal, a cognitive inspired framework for securing CPS is scrutinized. The cognitive ability is conceded to the search engines by updating the PageRank ranking methodology. The proposed framework, named SecureCPS is trained with real time collective dataset for marking the relevancy of web page with the support the facial expressions. The eye regions are marked using Focal Point Detector algorithm. The framework is validated with machine learning models and resulted in achieving 98.51% accuracy and its outperforms the existing frameworks.
ER  - 

TY  - JOUR
T1  - Towards reproducible machine learning-based process monitoring and quality prediction research for additive manufacturing
AU  - Xie, Jiarui
AU  - Safdar, Mutahar
AU  - Mircea, Andrei
AU  - Zhao, Bi Cheng
AU  - Lu, Yan
AU  - Ko, Hyunwoong
AU  - Yang, Zhuo
AU  - Zhao, Yaoyao Fiona
JO  - Engineering Applications of Artificial Intelligence
VL  - 161
SP  - 112223
PY  - 2025
DA  - 2025/12/12/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2025.112223
UR  - https://www.sciencedirect.com/science/article/pii/S0952197625022316
KW  - Additive manufacturing
KW  - Cyber-physical systems
KW  - Machine learning
KW  - Reproducibility
KW  - Process monitoring
KW  - Quality prediction
AB  - Additive manufacturing (AM) is increasingly adopted across industries for its ability to support design flexibility, rapid prototyping, and mass customization. Machine learning (ML)-based cyber-physical systems (CPSs) have been extensively developed to improve the print quality of AM. However, the reproducibility of these systems has not been thoroughly investigated due to a lack of formal evaluation methods. Reproducibility, a critical component of trustworthy artificial intelligence, is achieved when an independent team can replicate the findings or artifacts of a study using a different experimental setup and achieve comparable performance. In many publications, critical information necessary for reproduction is often missing due to a lack of comprehensive AM and ML domain knowledge, resulting in systems that fail to replicate the reported performance. Integrating AM and ML domain knowledge, this paper proposes a reproducibility investigation pipeline and a reproducibility checklist for ML-based AM process monitoring and quality prediction systems. Based on the CRoss Industry Standard Process (CRISP) methodology, the pipeline guides researchers through the key steps required to reproduce a study, while the checklist systematically extracts information relevant to reproducibility from the publication. We validated the proposed approach through two case studies: reproducing a fused filament fabrication warping detection system and a laser powder bed fusion melt pool area prediction model. Both case studies confirmed that the pipeline and checklist successfully identified missing information, improved reproducibility, and enhanced the performance of reproduced systems. Based on the proposed checklist and leveraging large language models, a reproducibility survey was conducted to assess the current reproducibility status within this research domain.
ER  - 

TY  - JOUR
T1  - APT-ATT: An efficient APT attribution model based on heterogeneous threat intelligence representation and CTGAN
AU  - Cai, Saihua
AU  - Wang, Gang
AU  - Chen, Jinfu
AU  - Wang, Shengran
AU  - Wang, Kun
JO  - Computer Networks
VL  - 270
SP  - 111511
PY  - 2025
DA  - 2025/10/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2025.111511
UR  - https://www.sciencedirect.com/science/article/pii/S1389128625004785
KW  - Advanced persistent threat
KW  - Attack attribution
KW  - Cyber threat intelligence
KW  - Data augmentation
KW  - Ensemble learning
AB  - With the rapid development of computer network, network security issues become increasingly severe. Due to the nature of highly organized, covert and persistent, advanced persistent threat (APT) has become a major security challenge. Accurately attributing APT attacks is crucial to effectively counter this threat, which not only quickly identifies the source of threats, but also provides the critical support for developing targeted defense strategies and reducing potential losses. However, existing APT attribution models still have significant shortcomings in terms of low efficiency in embedding heterogeneous threat intelligence, class imbalance and insufficient model stability. This paper proposes a novel lightweight APT attribution model called APT-ATT to effectively improve the accuracy and stability of APT attribution by combining the heterogeneous threat intelligence representation and conditional tabular generation adversarial network (CTGAN). Firstly, in response to the embedding requirements of heterogeneous long threat intelligence, a feature representation method combining N-Gram and TF-IDF is designed to quickly extract the local semantic features and use the chi-square statistics for feature selection. Secondly, the CTGAN is introduced to generate the realistic feature vectors to effectively alleviate the class imbalance problem. Finally, an ensemble learning framework is constructed based on the stacking strategy, with KNN, RF and XGBoost as the base learners and optimized logistic regression as the meta learner to further improve the attribution performance and model stability. Experiments on two cyber threat intelligence datasets show that the proposed APT-ATT method achieves an accuracy of 94.91%, along with excellent real-time performance and stronger stability.
ER  - 

TY  - JOUR
T1  - The prince of insiders: a multiple pathway approach to understanding IP theft insider attacks
AU  - Whitty, Monica Therese
AU  - Ruddy, Christopher
AU  - Keatley, David
AU  - Butavicius, Marcus
AU  - Grobler, Marthie
JO  - Information and Computer Security
VL  - 32
IS  - 4
SP  - 509
EP  - 522
PY  - 2024
DA  - 2024/04/26/
SN  - 2056-4961
DO  - https://doi.org/10.1108/ICS-11-2023-0210
UR  - https://www.sciencedirect.com/science/article/pii/S2056496124000126
KW  - Insider threat
KW  - IP theft
KW  - Machiavellianism
KW  - Behaviour sequence analysis
KW  - Socio-technical
KW  - Multiple critical pathways
KW  - Multidisciplinary
KW  - Situational crime prevention
KW  - Cybersecurity
AB  - Purpose
Intellectual property (IP) theft is an increasing threat that can lead to large financial losses and reputational harm. These attacks are typically noticed only after the IP is stolen, which is usually too late. This paper aims to investigate the psychological profile and the socio-technical events that statistically predict the likelihood of an IP threat.
Design/methodology/approach
This paper analyses 86 IP theft cases found in court documents. Two novel analyses are conducted. The research uses LLMs to analyse the personality of these insiders, which is followed by an investigation of the pathways to the attack using behaviour sequence analysis (BSA).
Findings
These IP theft insiders scored significantly higher on measures of Machiavellianism compared to the normal population. Socio-technical variables, including IP theft via photographs, travelling overseas, approaching multiple organisations and delivering presentations, were identified. Contrary to previous assumptions that there is a single pathway to an attack, the authors found that multiple, complex pathways lead to an attack (sometimes multiple attacks). This work, therefore, provides a new framework for considering critical pathways to insider attacks.
Practical implications
These findings reveal that IP theft insiders may come across as charming, star employees rather than the stereotype of disgruntled employees. Moreover, organisations’ policies may need to consider that IP theft occurs via non-linear and multiple pathways. This means that sequences of events need to be considered in detecting these attacks instead of anomalies outright. The authors also argue that there may be a case for “continuous evaluation” to detect insider activity.
Originality/value
This paper offers a new framework for understanding and studying insider threats. Instead of a single critical pathway, this work demonstrates the need to consider multiple interconnected pathways. It elucidates the importance of a multidisciplinary approach and provides opportunities to reconsider current practices in detection and prevention.
ER  - 

TY  - JOUR
T1  - RAF-AG: Report analysis framework for attack path generation
AU  - Mai, Khang
AU  - Lee, Jongmin
AU  - Beuran, Razvan
AU  - Hotchi, Ryosuke
AU  - Ooi, Sian En
AU  - Kuroda, Takayuki
AU  - Tan, Yasuo
JO  - Computers & Security
VL  - 148
SP  - 104125
PY  - 2025
DA  - 2025/01/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104125
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824004309
KW  - Automated report analysis
KW  - Attack path generation
KW  - Graph alignment
KW  - Weak supervision
KW  - MITRE ATT&CK
KW  - Cybersecurity
AB  - Information sharing is a key practice in cybersecurity for coping with the ever-changing cyberattacks that are targeting computer systems. Thus, when cyber incidents happen, cyber threat intelligence (CTI) reports are prepared and shared among cybersecurity practitioners to help them get up-to-date information about those incidents. However, reading and analyzing the report text to comprehend the included information is a cumbersome process. Although techniques based on deep learning were proposed to speed up report analysis in order to obtain the enclosed essential information, such as attack path, training data insufficiency makes these methods inefficient in practical circumstances. This paper presents RAF-AG, a report analysis framework for attack path generation. To analyze CTI reports, RAF-AG utilizes the sentence dependency tree for entity and relation extraction, and a weak supervision approach for entity labeling. This is followed by graph building and graph alignment for generating the attack paths. Our approach resolves the data insufficiency problem in the cybersecurity domain by lowering the need for expert involvement. We evaluated RAF-AG by comparing the generated attack paths with those produced by AttacKG, a state-of-the-art automatic report analysis framework. RAF-AG was able to identify cyberattack steps by matching their appearance order inside the report, and link them with techniques from the MITRE ATT&CK knowledge base with an improved F1 score compared to AttacKG (0.708 versus 0.393).
ER  - 

TY  - JOUR
T1  - Real-time explainable IoT security with machine learning and CTGAN-enhanced detection for resource-constrained devices
AU  - Hasan, Tasnimul
AU  - Tasnim, Samia
JO  - Ad Hoc Networks
VL  - 178
SP  - 103937
PY  - 2025
DA  - 2025/11/01/
SN  - 1570-8705
DO  - https://doi.org/10.1016/j.adhoc.2025.103937
UR  - https://www.sciencedirect.com/science/article/pii/S1570870525001854
KW  - Intrusion detection system (IDS)
KW  - Internet of Things (IoT)
KW  - Explainable Artificial Intelligence (XAI)
KW  - SHAP
KW  - LIME
KW  - Conditional Tabular GAN (CTGAN)
KW  - Edge computing
KW  - Machine learning (ML)
KW  - Jetson Nano
AB  - The security threats and risks posed by Internet of Things (IoT) devices have been increasing significantly in recent times. Hence, an Intrusion Detection System (IDS) is required to handle and filter out cyber-attacks. Traditional IDSs face a major challenge in class imbalance within the data, which is the case for many real-world datasets related to intrusion, and a lack of model interpretability. In this paper, we introduce a novel IDS by fusing Generative Adversarial Network (GAN) and Explainable AI (XAI) techniques. Our proposed IDS uses Conditional Tabular GAN (CTGAN) as the synthetic data generator to address class imbalance issues. Additionally, in order to have global and local model interpretability of the proposed IDS, two XAI approaches are followed: SHapley Additive exPlanations (SHAP) and Local Interpretable Model-agnostic Explanations (LIME). The proposed IDS achieves accuracy between 97.20% and 100%, F1 score between 89.34% and 100%, test time from 0.0104 s to 0.5686 s, and model size ranging from 2.73 kB to 1510 kB across different datasets. To validate practical applicability, we deploy the best-performing models on a resource-constrained edge device (e.g., Jetson Nano), achieving efficient testing times and demonstrating suitability for real-time applications. We conduct a quantitative comparison with state-of-the-art methods, demonstrating improved performance, enhanced interpretability, and increased model transparency through XAI integration.
ER  - 

TY  - JOUR
T1  - Copula entropy regularization transformer with C2 variational autoencoder and fine-tuned hybrid DL model for network intrusion detection
AU  - Akkepalli, Srinivas
AU  - K, Sagar
JO  - Telematics and Informatics Reports
VL  - 17
SP  - 100182
PY  - 2025
DA  - 2025/03/01/
SN  - 2772-5030
DO  - https://doi.org/10.1016/j.teler.2024.100182
UR  - https://www.sciencedirect.com/science/article/pii/S2772503024000689
KW  - Variational autoencoder
KW  - Euclidian convolutional neural network
KW  - Copula entropy
KW  - Self-paced regularization and intrusion detection
AB  - In cyber security, Intrusion Detection Systems (IDS) act as a network security tool, in which computational complexity and dynamic IDS detection issues are observed by conventional studies. In this paper, a novel Copula Entropy Regularization Transformer withC2 variational autoencoder and Fine-tuned Hybrid Deep Learning (DL) model is introduced for Network Intrusion Detection. In previous IDSs studies, flow-based feature extraction techniques are concentrated, which is ineffective for detecting high-dimensional anomaly data. This work proposes a novel Copula Entropy Regularization Transformer with C2 variational autoencoder for regularizing the feature extraction and feature selection, using a self-paced regularization mechanism. Recently, the pull towards IDS with Zero-Day (ZD) attacks gets increased, and the existing studies over it, possess high False-Negative Rates (FNR), leading to limited practical usage. For reducing the FNR and to improve the identification of ZD, a Fine-tuned Hybrid DL attack prediction model with deep Transudative Federated Transfer Learning (TFTL) is proposed. This gives out a map connection between known and zero-day attacks, data points for different dynamic network traffic, and classification of known and unknown network attacks. To investigate the ZD attack detection with the proposed model, it is validated in Python platform with Network Intrusion Detection dataset and the performance results show that the work gives better accuracy (98.54%), F1-score (97.5%), recall (97.302%), precision (98.2%) and detection rate of about 0.975%, while the comparative results show that this approach achieves a comparatively low false positive rate of 0.1, yielding high detection rate, and high accuracy in predicting attacks.
ER  - 

TY  - JOUR
T1  - Venous thromboembolism in the era of machine learning and artificial intelligence in medicine
AU  - Reyes Gil, Morayma
AU  - Pantanowitz, Joshua
AU  - Rashidi, Hooman H.
JO  - Thrombosis Research
VL  - 242
SP  - 109121
PY  - 2024
DA  - 2024/10/01/
SN  - 0049-3848
DO  - https://doi.org/10.1016/j.thromres.2024.109121
UR  - https://www.sciencedirect.com/science/article/pii/S0049384824002536
KW  - Venous thromboembolism
KW  - Artificial intelligence
KW  - Machine learning
KW  - Large language model (LLM)
KW  - Deep vein thrombosis
KW  - Pulmonary embolism
AB  - In this review, we embark on a comprehensive exploration of venous thromboembolism (VTE) in the context of medical history and its current practice within medicine. We delve into the landscape of artificial intelligence (AI), exploring its present utility and envisioning its transformative roles within VTE management, from prevention to screening and beyond. Central to our discourse is a forward-looking perspective on the integration of AI within VTE in medicine, advocating for rigorous study design, robust validation processes, and meticulous statistical analysis to gauge the efficacy of AI applications. We further illuminate the potential of large language models and generative AI in revolutionizing VTE care, while acknowledging their inherent limitations and proposing innovative solutions to overcome challenges related to data availability and integrity, including the strategic use of synthetic data. The critical importance of navigating ethical, legal, and privacy concerns associated with AI is underscored, alongside the imperative for comprehensive governance and policy frameworks to regulate its deployment in VTE treatment. We conclude on a note of cautious optimism, where we highlight the significance of proactively addressing the myriad challenges that accompany the advent of AI in healthcare. Through diligent design, stringent validation, extensive education, and prudent regulation, we can harness AI's potential to significantly enhance our understanding and management of VTE. As we stand on the cusp of a new era, our commitment to these principles will be instrumental in ensuring that the promise of AI is fully realized within the realm of VTE care.
ER  - 

TY  - JOUR
T1  - Skip-patching spatial–temporal discrepancy-based anomaly detection on multivariate time series
AU  - Xu, Yinsong
AU  - Ding, Yulong
AU  - Jiang, Jie
AU  - Cong, Runmin
AU  - Zhang, Xuefeng
AU  - Wang, Shiqi
AU  - Kwong, Sam
AU  - Yang, Shuang-Hua
JO  - Neurocomputing
VL  - 609
SP  - 128428
PY  - 2024
DA  - 2024/12/07/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2024.128428
UR  - https://www.sciencedirect.com/science/article/pii/S0925231224011998
KW  - Anomaly detection
KW  - Industrial Internet of Things
KW  - Self-supervised learning
KW  - Multivariate time series
AB  - Anomaly detection in the Industrial Internet of Things (IIoT) is a challenging task that relies heavily on the efficient learning of multivariate time series representations. We introduce Skip-patching and Spatial–Temporal discrepancy mechanisms to improve the efficiency of detecting anomalies. Traditional feature extraction is hindered by redundant information in limited datasets. The situation is that feature generation from stable operational processes results in low-quality representations. To address this challenge, we propose the Skip-Patching mechanism. This approach involves selectively extracting features from partial data patches, prompting the model to learn more meaningful knowledge through self-supervised learning. It also effectively doubles the training sample size by creating independent sub-groups of patches. Despite the complex spatial and temporal relationships in IIoT systems, existing methods mainly extracted features from a single domain, either temporal or spatial (sensor-wise), or simply cascaded two features, i.e., one after one, which limited anomaly detection capabilities. To address this, we introduce the Spatial–Temporal Association Discrepancy component, which leverages discrepancies between spatial and temporal features to enhance latent representation learning. Our Skip-Patching Spatial–Temporal Anomaly Detection (SSAD) framework combines these two components to provide a more diverse and comprehensive learning process. Tested across four multivariate time series anomaly detection benchmarks, SSAD demonstrates superior performance, confirming the efficacy of combining Skip-patching and Spatial–Temporal features to enhance anomaly detection in IIoT systems.
ER  - 

TY  - JOUR
T1  - Generative AI and process systems engineering: The next frontier
AU  - Decardi-Nelson, Benjamin
AU  - Alshehri, Abdulelah S.
AU  - Ajagekar, Akshay
AU  - You, Fengqi
JO  - Computers & Chemical Engineering
VL  - 187
SP  - 108723
PY  - 2024
DA  - 2024/08/01/
SN  - 0098-1354
DO  - https://doi.org/10.1016/j.compchemeng.2024.108723
UR  - https://www.sciencedirect.com/science/article/pii/S0098135424001418
KW  - Generative AI
KW  - Process systems engineering
KW  - Large language models
KW  - Multiscale
AB  - This review article explores how emerging generative artificial intelligence (GenAI) models, such as large language models (LLMs), can enhance solution methodologies within process systems engineering (PSE). These cutting-edge GenAI models, particularly foundation models (FMs), which are pre-trained on extensive, general-purpose datasets, offer versatile adaptability for a broad range of tasks, including responding to queries, image generation, and complex decision-making. Given the close relationship between advancements in PSE and developments in computing and systems technologies, exploring the synergy between GenAI and PSE is essential. We begin our discussion with a compact overview of both classic and emerging GenAI models, including FMs, and then dive into their applications within key PSE domains: synthesis and design, optimization and integration, and process monitoring and control. In each domain, we explore how GenAI models could potentially advance PSE methodologies, providing insights and prospects for each area. Furthermore, the article identifies and discusses potential challenges in fully leveraging GenAI within PSE, including multiscale modeling, data requirements, evaluation metrics and benchmarks, and trust and safety, thereby deepening the discourse on effective GenAI integration into systems analysis, design, optimization, operations, monitoring, and control. This paper provides a guide for future research focused on the applications of emerging GenAI in PSE.
ER  - 

TY  - JOUR
T1  - ReZG: Retrieval-augmented zero-shot counter narrative generation for hate speech
AU  - Jiang, Shuyu
AU  - Tang, Wenyi
AU  - Chen, Xingshu
AU  - Tang, Rui
AU  - Wang, Haizhou
AU  - Wang, Wenxian
JO  - Neurocomputing
VL  - 620
SP  - 129140
PY  - 2025
DA  - 2025/03/01/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2024.129140
UR  - https://www.sciencedirect.com/science/article/pii/S0925231224019118
KW  - Constrained text generation
KW  - Dialog
KW  - Constrained decoding
KW  - Hate speech
KW  - Pre-trained language model
KW  - Retrieval augmentation
AB  - The proliferation of hate speech (HS) on social media poses a serious threat to societal security. Automatic counter narrative (CN) generation, as an active strategy for HS intervention, has garnered increasing attention in recent years. Existing methods for automatically generating CNs mainly rely on re-training or fine-tuning pre-trained language models (PLMs) on human-curated CN corpora. Unfortunately, the annotation speed of CN corpora cannot keep up with the growth of HS targets, while generating specific and effective CNs for unseen targets remains a significant challenge for the model. To tackle this issue, we propose Retrieval-Augmented Zero-shot Generation (ReZG) to generate CNs with high-specificity for unseen targets. Specifically, we propose a multi-dimensional hierarchical retrieval method that integrates stance, semantics, and fitness, extending the retrieval metric from single dimension to multiple dimensions suitable for the knowledge that refutes HS. Then, we implement an energy-based constrained decoding mechanism that enables PLMs to use differentiable knowledge preservation, countering, and fluency constraint functions instead of in-target CNs as control signals for generation, thereby achieving zero-shot CN generation. With the above techniques, ReZG can integrate external knowledge flexibly and improve the specificity of CNs. Experimental results show that ReZG exhibits stronger generalization capabilities and outperforms strong baselines with significant improvements of 2.0%+ in the relevance and 4.5%+ in the countering success rate metrics.
ER  - 

TY  - JOUR
T1  - A robust hybrid machine learning model for Bengali cyber bullying detection in social media
AU  - Akhter, Arnisha
AU  - Acharjee, Uzzal Kumar
AU  - Talukder, Md. Alamin
AU  - Islam, Md. Manowarul
AU  - Uddin, Md Ashraf
JO  - Natural Language Processing Journal
VL  - 4
SP  - 100027
PY  - 2023
DA  - 2023/09/01/
SN  - 2949-7191
DO  - https://doi.org/10.1016/j.nlp.2023.100027
UR  - https://www.sciencedirect.com/science/article/pii/S2949719123000249
KW  - Cyberbully
KW  - Bengali
KW  - Bullying
KW  - Machine learning
KW  - Harassment
KW  - Language
KW  - Social media
AB  - Social networking platforms give users countless opportunities to share information, collaborate, and communicate positively. The same platform can be extended to a fabricated and poisonous atmosphere that gives an impersonal, harmful platform for online misuse and assault. Cyberstalking is when someone uses an internet system to ridicule, torment, insult, criticize, slander, and discredit a victim while never seeing them. With the growth of social networks, Facebook has become the online arena for bullying. Since the effects could result in a widespread contagion, it is vital to have models and mechanisms in place for the automatic identification and removal of internet cyberbullying data. This paper presents a robust hybrid ML model for cyberbullying detection in the Bengali language on social media. The Bengalibullying proposal involves an effective text preprocessing to make the Bengali text data into a useful text format, feature extraction using the TfidfVectorizer (TFID) to get the beneficial information of text data and resampling by Instance Hardness Threshold (IHT) procedure to balance the dataset to avoid overfitting or underfitting problems. In our experiment, we used the publicly available Bangla text dataset (44,001 comments) and got the highest performance ever published works on it. The model achieved the most elevated accuracy rate of 98.57% and 98.82% in binary and multilabel classification to detect cyberbullying on social media in the Bengali language. Our best performance findings are more effective than any previous effort in identifying and categorizing bullying in the Bengali language. As a result, we might use our model to correctly classify Bengali bullying in online bullying detection systems, protecting people from being the targets of social bullying.
ER  - 

TY  - JOUR
T1  - Industrial large models as carriers for malicious payloads: A fast and robust approach
AU  - Yuan, Yi
AU  - Deng, Ruijun
AU  - Lu, Zhihui
AU  - Hung, Patrick C.K.
JO  - Applied Soft Computing
VL  - 185
SP  - 113967
PY  - 2025
DA  - 2025/12/01/
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2025.113967
UR  - https://www.sciencedirect.com/science/article/pii/S1568494625012803
KW  - Industrial large model
KW  - Network security
KW  - Malicious payload injection
KW  - Steganography-powered attack
KW  - Deep neural network;Financial technology
AB  - As artificial intelligence (AI) technologies are increasingly deployed in industrial domains, the use of pre-trained industrial large models (ILMs) has become widespread due to their cost-effectiveness and high performance across complex tasks. However, this growing reliance introduces new cybersecurity threats, particularly concerning the integrity of model parameters. Attackers are increasingly targeting AI models, exploiting vulnerabilities in the software supply chain, providing a covert means of executing novel cyberattacks, and posing significant security risks. Although antivirus software and intrusion detection systems are effective in protecting systems, the evolving nature of attack strategies, particularly the use of widely available AI models as carriers for malicious payloads, poses increasingly sophisticated security threats. Most existing embedding techniques struggle in ILM application scenarios, where payloads are inefficiently embedded and extracted, and are easily disrupted by fine-tuning. Meanwhile, the few robustness techniques always face limitations in areas such as low efficiency, model performance degradation, and the challenge of achieving a balance between efficiency and robustness. In this paper, we introduce FREEZER: Fast Redundant Exponent Embedding with Robustness (Robustness refers to the ability to preserve the embedded payload after full fine-tuning, while fast speed denotes its substantially faster payload embedding and extraction compared to prior approaches), a framework for significantly improving efficiency while maintaining robustness during the injection of malicious payloads into ILMs. FREEZER effectively addresses the challenge of extensive bit errors—defined as the bitwise discrepancy between the originally embedded malicious payload and the payload recovered by the prescribed extractor after full-parameter fine-tuning. Moreover, the infected models obtained using FREEZER exhibit no significant performance degradation. Experimental results show that FREEZER achieves a 20x faster injection speed and a 240x faster extraction speed compared to the current state-of-the-art (SOTA) method while maintaining high robustness. FREEZER raises awareness of this emerging threat and inspires the development of novel defenses against new forms of cyberattacks.
ER  - 

TY  - JOUR
T1  - Generative artificial intelligence in healthcare from the perspective of digital media: Applications, opportunities and challenges
AU  - Xu, Rui
AU  - Wang, Zhong
JO  - Heliyon
VL  - 10
IS  - 12
SP  - e32364
PY  - 2024
DA  - 2024/06/30/
SN  - 2405-8440
DO  - https://doi.org/10.1016/j.heliyon.2024.e32364
UR  - https://www.sciencedirect.com/science/article/pii/S2405844024083956
KW  - ChatGPT
KW  - Healthcare
KW  - Digital media
KW  - Applications
KW  - Opportunities
KW  - Challenges
KW  - Digital health
KW  - Generative artificial intelligence
KW  - Large language models
KW  - Artificial intelligence generated content
AB  - Introduction
The emergence and application of generative artificial intelligence/large language models (hereafter GenAI LLMs) have the potential for significant impact on the healthcare industry. However, there is currently a lack of systematic research on GenAI LLMs in healthcare based on reliable data. This article aims to conduct an exploratory study of the application of GenAI LLMs (i.e., ChatGPT) in healthcare from the perspective of digital media (i.e., online news), including the application scenarios, potential opportunities, and challenges.
Methods
This research used thematic qualitative text analysis in five steps: firstly, developing main topical categories based on relevant articles; secondly, encoding the search keywords using these categories; thirdly, conducting searches for news articles via Google ; fourthly, encoding the sub-categories using the elaborate category system; and finally, conducting category-based analysis and presenting the results. Natural language processing techniques, including the TermRaider and AntConc tool, were applied in the aforementioned steps to assist in text qualitative analysis. Additionally, this study built a framework, using for analyzing the above three topics, from the perspective of five different stakeholders, including healthcare demanders and providers.
Results
This study summarizes 26 applications (e.g., provide medical advice, provide diagnosis and triage recommendations, provide mental health support, etc.), 21 opportunities (e.g., make healthcare more accessible, reduce healthcare costs, improve patients care, etc.), and 17 challenges (e.g., generate inaccurate/misleading/wrong answers, raise privacy concerns, lack of transparency, etc.), and analyzes the reasons for the formation of these key items and the links between the three research topics.
Conclusions
The application of GenAI LLMs in healthcare is primarily focused on transforming the way healthcare demanders access medical services (i.e., making it more intelligent, refined, and humane) and optimizing the processes through which healthcare providers offer medical services (i.e., simplifying, ensuring timeliness, and reducing errors). As the application becomes more widespread and deepens, GenAI LLMs is expected to have a revolutionary impact on traditional healthcare service models, but it also inevitably raises ethical and security concerns. Furthermore, GenAI LLMs applied in healthcare is still in the initial stage, which can be accelerated from a specific healthcare field (e.g., mental health) or a specific mechanism (e.g., GenAI LLMs’ economic benefits allocation mechanism applied to healthcare) with empirical or clinical research.
ER  - 

TY  - JOUR
T1  - Improving quality of indicators of compromise using STIX graphs
AU  - Chen, Sheng-Shan
AU  - Hwang, Ren-Hung
AU  - Ali, Asad
AU  - Lin, Ying-Dar
AU  - Wei, Yu-Chih
AU  - Pai, Tun-Wen
JO  - Computers & Security
VL  - 144
SP  - 103972
PY  - 2024
DA  - 2024/09/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.103972
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824002773
KW  - Indicators of Compromise (IoC)
KW  - Threat Intelligence Platform (TIP)
KW  - Cyber Threat Intelligence (CTI)
KW  - Structured Threat Information eXpression (STIX)
KW  - Open Source INTelligence (OSINT)
AB  - Cybersecurity relies on Indicators of Compromise (IoCs) to detect and address threats. Although Threat Intelligence Platforms (TIPs) and Open Source Intelligence (OSINT) are common sources for gathering IoCs, their reliability varies. In our study, we enhance the management of IoCs and OSINT by introducing a novel method that reliably assesses IoC’s threat severity and confidence scores, focusing on Structured Threat Information eXpression (STIX) for threat associations. Our approach, implemented on OpenCTI, significantly enhances IoC value, as it aggregates threat intelligence from diverse sources utilizing a STIX graph-based approach, which is a unique feature among TIPs. Additionally, our method employs heuristic analysis to optimize IoC scoring. It takes into account factors such as relevance, completeness, timeliness, accuracy, and consistency while emphasizing the confidence of the source. Notably, the proposed method has enhanced the precision of the confidence score, achieving a 25.18% reduction in the average difference of confidence scores compared to the benchmarked platform. The Emotet and Medusa case studies underscore the importance of source credibility in confidence scores, emphasizing our TIP’s precision in cybersecurity threat assessment and defense enhancement.
ER  - 

TY  - JOUR
T1  - A scoping review of ChatGPT research in accounting and finance
AU  - Dong, Mengming Michael
AU  - Stratopoulos, Theophanis C.
AU  - Wang, Victor Xiaoqi
JO  - International Journal of Accounting Information Systems
VL  - 55
SP  - 100715
PY  - 2024
DA  - 2024/12/01/
SN  - 1467-0895
DO  - https://doi.org/10.1016/j.accinf.2024.100715
UR  - https://www.sciencedirect.com/science/article/pii/S1467089524000484
KW  - ChatGPT
KW  - Generative AI
KW  - LLMs
KW  - Audit
KW  - Financial reporting
KW  - Tax
KW  - AIS
KW  - Asset pricing
KW  - Corporate finance
AB  - This paper provides a review of recent publications and working papers on ChatGPT and related Large Language Models (LLMs) in accounting and finance. The aim is to understand the current state of research in these two areas and identify potential research opportunities for future inquiry. We identify three common themes from these earlier studies. The first theme focuses on applications of ChatGPT and LLMs in various fields of accounting and finance. The second theme utilizes ChatGPT and LLMs as a new research tool by leveraging their capabilities such as classification, summarization, and text generation. The third theme investigates implications of LLM adoption for accounting and finance professionals, as well as for various organizations and sectors. While these earlier studies provide valuable insights, they leave many important questions unanswered or partially addressed. We propose venues for further exploration and provide technical guidance for researchers seeking to employ ChatGPT and related LLMs as a tool for their research.
ER  - 

TY  - JOUR
T1  - Detecting abnormal logins by discovering anomalous links via graph transformers
AU  - Gonçalves, Luís
AU  - Zanchettin, Cleber
JO  - Computers & Security
VL  - 144
SP  - 103944
PY  - 2024
DA  - 2024/09/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.103944
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824002499
KW  - Cyber security
KW  - Graph neural networks
KW  - Authentication
KW  - Lateral movement
KW  - Advanced persistent threats
AB  - Anomalous authentications are a critical indicator of advanced persistent threats (APTs), in which adversaries exploit network vulnerabilities to gain unauthorized access and move stealthily between devices using stolen credentials. As the set of interactions between entities in a network essentially forms graph-structured data, state-of-the-art algorithms such as graph neural networks (GNNs) can be used to detect anomalous interactions that may indicate an ongoing attack. However, the success of detecting anomalous authentications using GNNs is conditioned on the representational power and performance of those models. A crucial problem is how to aggregate the node embeddings so that the GNN can better represent the network topology. Existing graph neural networks traditionally use simple functions (e.g., sum, max, mean) on the node embeddings to preserve permutation invariance and achieve consistent node representations. However, we argue that an effective aggregation of node features into a graph-level representation cannot be achieved through simple sum or mean operations. In this work, we propose a residual soft-attention scheme that facilitates the aggregation of node representations through a weighted sum, resulting in enhanced node representations and improved filtration of irrelevant information. Experimental results on three relevant datasets have shown the proposed method can detect abnormal authentications with lower false positives than competitors.
ER  - 

TY  - JOUR
T1  - AI for science: Covert cyberattacks on energy storage systems
AU  - Zhao, Alexis Pengfei
AU  - Zhang, Qianzhi
AU  - Alhazmi, Mohannad
AU  - Hu, Paul Jen-Hwa
AU  - Zhang, Suhan
AU  - Yan, Xiaohe
JO  - Journal of Energy Storage
VL  - 99
SP  - 112835
PY  - 2024
DA  - 2024/10/01/
SN  - 2352-152X
DO  - https://doi.org/10.1016/j.est.2024.112835
UR  - https://www.sciencedirect.com/science/article/pii/S2352152X24024216
KW  - Convolutional neural networks
KW  - Cyberattack simulation
KW  - Double Deep Q-Networks
KW  - Hybrid energy storage systems
AB  - This paper develops and evaluates a novel three-stage strategic cyberattack framework designed for multi-energy systems incorporating hybrid energy storage, using an advanced integration of Convolutional Neural Networks (CNN) and Double Deep Q-Networks (Double DQN). The framework, rigorously tested within a simulated environment modeled after Texas' ERCOT region, focuses on exposing and exploiting vulnerabilities in hybrid hydrogen-power networks. The initial surveillance stage employs CNNs to analyze network data, identifying critical susceptibilities in the storage, production, and distribution systems—pinpointing 30 key bus lines that exhibit increased risk factors. This stage achieves subtle manipulations causing load variations between 5 and 10 %, designed to evade detection while assessing system responses. Following this, the intensification stage leverages Double DQN to refine and escalate the attack's intensity, targeting 50 bus lines during peak load periods, enhancing the precision of disruptions without detection. The culmination is a full-scale offensive, dynamically and aggressively assaulting the network, achieving a peak disruption of 40 % across targeted components while maintaining operational secrecy. This comprehensive strategy not only demonstrates the catastrophic potential of cyberattacks on critical energy infrastructure but also highlights significant vulnerabilities, particularly in hybrid energy storage systems, providing crucial insights for strengthening cybersecurity measures. The empirical findings from our simulations suggest that without robust security enhancements, hybrid energy networks are at risk of operational disruptions that could exceed 40 % of their capacity during peak times, underscoring the urgent need for advanced detection and mitigation strategies.
ER  - 

TY  - JOUR
T1  - APT-MMF: An advanced persistent threat actor attribution method based on multimodal and multilevel feature fusion
AU  - Xiao, Nan
AU  - Lang, Bo
AU  - Wang, Ting
AU  - Chen, Yikai
JO  - Computers & Security
VL  - 144
SP  - 103960
PY  - 2024
DA  - 2024/09/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.103960
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824002657
KW  - Advanced persistent threat
KW  - Cyber threat intelligence
KW  - Threat actor attribution
KW  - Indicators of compromise
KW  - Heterogeneous attributed graph
KW  - Multimodal features
KW  - Multilevel heterogeneous graph attention networks
AB  - Threat actor attribution is a crucial defense strategy for combating advanced persistent threats (APTs). Cyber threat intelligence (CTI), which involves analyzing multisource heterogeneous data from APTs, plays an important role in APT actor attribution. The current attribution methods extract features from different CTI perspectives and employ machine learning models to classify CTI reports according to their threat actors. However, these methods usually extract only one kind of feature and ignore heterogeneous information, especially the attributes and relations of indicators of compromise (IOCs), which form the core of CTI. To address these problems, we propose an APT actor attribution method based on multimodal and multilevel feature fusion (APT-MMF). First, we leverage a heterogeneous attributed graph to characterize APT reports and their IOC information. Then, we extract and fuse multimodal features, including attribute type features, natural language text features and topological relationship features, to construct comprehensive node representations. Furthermore, we design multilevel heterogeneous graph attention networks to learn the deep hidden features of APT report nodes; these networks integrate IOC type-level, metapath-based neighbor node-level, and metapath semantic-level attention. Utilizing multisource threat intelligence, we construct a heterogeneous attributed graph dataset and various variant datasets for verification purposes. Extensive experimental results show that our method not only outperforms the existing methods, but also demonstrates its considerable robustness to incomplete and noise information and good explainability for attribution analysis tasks.
ER  - 

TY  - JOUR
T1  - Development and validation of coreLang: A threat modeling language for the ICT domain
AU  - Katsikeas, Sotirios
AU  - Buhaiu, Andrei
AU  - Ekstedt, Mathias
AU  - Afzal, Zeeshan
AU  - Hacks, Simon
AU  - Mukherjee, Preetam
JO  - Computers & Security
VL  - 146
SP  - 104057
PY  - 2024
DA  - 2024/11/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104057
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824003626
KW  - Domain specific language
KW  - Attack graphs
KW  - Cyber attack modeling
KW  - Threat modeling
KW  - ICT domain
AB  - ICT infrastructures are getting increasingly complex, and defending them against cyber attacks is cumbersome. As cyber threats continue to increase and expert resources are limited, organizations must find more efficient ways to evaluate their resilience and take proactive measures. Threat modeling is an excellent method of assessing the resilience of ICT systems, for example, by building Attack Graphs that illustrate an adversary’s attack vectors. Previously, the Meta Attack Language (MAL) was proposed, which serves as a framework to develop Domain Specific Languages (DSLs) and generate Attack Graphs for modeled infrastructures. coreLang is a MAL-based threat modeling language that utilizes Attack Graphs to enable attack simulations and security assessments. In this work, we present the first release version of coreLang in which MITRE ATT&CK tactics and techniques are mapped onto to serve as a validation and identify strengths and weaknesses to benefit the development cycle. Our validation showed that coreLang does cover 46% of all the techniques included in the matrix, while if we additionally exclude the tactics that are intrinsically not covered by coreLang and MAL, the coverage percentage increases to 64%.
ER  - 

TY  - JOUR
T1  - APIARY: An API-based automatic rule generator for yara to enhance malware detection
AU  - Coscia, Antonio
AU  - Lorusso, Roberto
AU  - Maci, Antonio
AU  - Urbano, Giuseppe
JO  - Computers & Security
VL  - 153
SP  - 104397
PY  - 2025
DA  - 2025/06/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104397
UR  - https://www.sciencedirect.com/science/article/pii/S0167404825000860
KW  - API
KW  - Intrusion detection and prevention
KW  - Malware detection
KW  - Security tool
KW  - YARA rule
AB  - Cyber threats, primarily malware, have increased with rapid technological advancements in various fields. This growing complexity requires sophisticated and automated malware detection tools because traditional methods cannot keep up with the sheer volume of threats and their evolution. Detection mechanisms that are resilient against evolved malware behaviors, which are typically described by application programming interface (API) functions, are essential for real-time system protection. This paper presents APIARY, an innovative API-based Automatic Rule generator for the YARA tool, designed to enhance malware identification through customized signatures based on peculiar API-based patterns. It discovers distinctive APIs that distinguish malware from goodware, regardless of input data coming from dynamic and static analyses of Windows-like executable files. The algorithm assigns relevance scores to each variable and discards less significant features to identify critical malware indicators. In addition, the generation process optimizes the identified malware model categories to increase the detection rate while minimizing the number of rules produced. The experimental results obtained on nine datasets sourced from the literature demonstrate the potential of APIARY to automatically produce highly effective YARA rules in a short time. Moreover, the rules generated outperform those obtained using alternative state-of-the-art algorithms in terms of detection performance. Lastly, unlike competitors, the proposed procedure does not rely on additional malware analysis data, such as network connection attempts or API parameters, achieving a more streamlined and efficient detection process.
ER  - 

TY  - JOUR
T1  - Harnessing the power of AI-instructor collaborative grading approach: Topic-based effective grading for semi open-ended multipart questions
AU  - Win Myint, Phyo Yi
AU  - Lo, Siaw Ling
AU  - Zhang, Yuhao
JO  - Computers and Education: Artificial Intelligence
VL  - 7
SP  - 100339
PY  - 2024
DA  - 2024/12/01/
SN  - 2666-920X
DO  - https://doi.org/10.1016/j.caeai.2024.100339
UR  - https://www.sciencedirect.com/science/article/pii/S2666920X24001425
KW  - Large language model
KW  - Human-AI collaboration
KW  - Semi open-ended multipart questions
KW  - AI-Assisted grading
AB  - Semi open-ended multipart questions consist of multiple sub questions within a single question, requiring students to provide certain factual information while allowing them to express their opinion within a defined context. Human grading of such questions can be tedious, constrained by the marking scheme and susceptible to the subjective judgement of instructors. The emergence of large language models (LLMs) such as ChatGPT has significantly advanced the prospect of automatic grading in educational settings. This paper introduces a topic-based grading approach that harnesses LLM capabilities alongside a refined marking scheme to ensure fair and explainable assessment processes. The proposed approach involves segmenting student responses according to sub questions, extracting topics utilizing LLM, and refining the marking scheme in consultation with instructors. The refined marking scheme is derived from LLM-extracted topics, validated by instructors to augment the original grading criteria. Leveraging LLM, we match student responses with refined marking scheme topics and employ a Python program to assign marks based on the matches. Various prompt versions are compared using relevant metrics to determine the most effective prompts. We evaluate LLM's grading proficiency through three approaches: zero-shot prompting, few-shot prompting, and our proposed method. Results indicate that while zero-shot and few-shot prompting methods fall short compared to human grading, the proposed approach achieves the best performance (highest percentage of exact match marks, lowest mean absolute error, highest Spearman correlation, highest Cohen's weighted kappa) and closely mirrors the distribution observed in human grading. Specifically, the collaborative approach enhances the grading process by refining the marking scheme to student responses, improving transparency and explainability through topic-based matching, and significantly increasing the effectiveness of LLMs when combined with instructor input, rather than as standalone automated grading systems.
ER  - 

TY  - JOUR
T1  - COVID-19 lies and truths: Employing the Elaboration Likelihood Model (ELM) and Linguistic Inquiry and Word Count (LIWC) to gain insights into the persuasive techniques evident in disinformation (fake news)
AU  - Whitty, Monica T.
AU  - Ruddy, Christopher
JO  - Computers in Human Behavior Reports
VL  - 20
SP  - 100797
PY  - 2025
DA  - 2025/12/01/
SN  - 2451-9588
DO  - https://doi.org/10.1016/j.chbr.2025.100797
UR  - https://www.sciencedirect.com/science/article/pii/S245195882500212X
AB  - The spread of disinformation and the harm this causes continues to be a cybersecurity concern. Technical methods, such as Artificial Intelligence (AI), employed to detect disinformation automatically are often inadequate because they fail to consider psychological theory that may help to inform the models. This research aimed to overcome this shortcoming by examining persuasive language evident in disinformation compared with genuine news. It applied the Elaboration Likelihood Model (ELM), a Dual Process Theory, to examine distinguishable cues in COVID-19 news stories: 70 fake and 70 genuine news stories. As predicted, fake news stories were more likely to contain the following cues: emotional appeals, repetition, celebrity figures, visual cues and loudness cues. In contrast, as predicted, genuine news stories were more likely to contain the following cues: rational appeals and statistics. Additionally, we conducted a Linguistic Inquiry and Word Count (LIWC) analysis, which revealed that positive emotions and tones were more prevalent in genuine news stories. However, fake news stories did not contain more negative emotions and tones compared with genuine stories. Loudness cues (e.g., exclamation marks, bold text, overuse of capital letters) stood out as one of the most significant differences in the use of persuasiveness across news types. This study demonstrates the importance of investigating how fake and genuine news compare by applying a psychological lens to interrogate the data and the utility of drawing from the ELM to inform the development of Large Language Models (LLMs) for automatic detection of fake news.
ER  - 

TY  - JOUR
T1  - TrafficCLIP: A lightweight cross-modal framework for network traffic classification
AU  - Chen, Rui
AU  - Luo, Lailong
AU  - Guo, Deke
AU  - Wang, Xiaodong
AU  - Li, Shangsen
AU  - Qiu, Changhao
JO  - Computer Networks
VL  - 272
SP  - 111662
PY  - 2025
DA  - 2025/11/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2025.111662
UR  - https://www.sciencedirect.com/science/article/pii/S1389128625006292
KW  - Traffic classification
KW  - Cross-modal
KW  - Lightweight
KW  - CLIP
AB  - Network traffic classification serves as the first line of defense against malicious activities, making it crucial for cybersecurity. The state-of-the-art traffic classification methods leverage deep learning models (DL) and language models (LM) to automatically extract traffic features, achieving notable success. However, they still face two key challenges: (i) they predominantly learn from a single modality, either visual or textual, limiting representation capacity to capture the multi-dimensional characteristics of network traffic; and (ii) language models typically require extensive pretraining, resulting in high computational costs. To address the above challenges, we propose TrafficCLIP, a novel cross-modal traffic classification framework based on CLIP. Specifically, we construct a vision-text encoder architecture that integrates knowledge from both textual and visual modalities, effectively facilitating cross-modal interactions to enhance high-quality traffic representations. Furthermore, unlike methods that rely on pretraining, we design a lightweight traffic visual adapter that efficiently fine-tunes part of the encoder parameters, reducing the computational overhead. Extensive experiments on four public traffic datasets demonstrate that TrafficCLIP improves classification accuracy by 6.79% to 47.88% over DL-based methods, while reducing over 70% of updated parameters compared to LM-based approaches.
ER  - 

TY  - JOUR
T1  - Attention-guided adversarial sample generation for robust webshell detection
AU  - Xie, Yuqin
AU  - Li, Daofeng
AU  - Zhang, Yuan
AU  - Liang, Xiaoxue
AU  - Xiong, Guoren
JO  - Journal of Information Security and Applications
VL  - 95
SP  - 104270
PY  - 2025
DA  - 2025/12/01/
SN  - 2214-2126
DO  - https://doi.org/10.1016/j.jisa.2025.104270
UR  - https://www.sciencedirect.com/science/article/pii/S2214212625003072
KW  - Cybersecurity
KW  - Adversarial samples
KW  - Black-box transfer attack
KW  - Webshell
KW  - Abstract syntax code
KW  - Deep learning
AB  - Background:
Webshells are malicious scripts commonly used as backdoors to compromise web servers, posing severe cybersecurity threats. While deep learning models have achieved promising results in Webshell detection, their susceptibility to adversarial attacks remains a critical challenge. Such attacks can significantly degrade detection accuracy, enabling adversarial Webshells to bypass security mechanisms. Moreover, existing research on adversarial attacks against Webshells is limited and often constrained to a single programming language.
Approach:
To address these challenges, this paper proposes an efficient black-box transfer attack algorithm named Attention-Attack, which is designed to generate adversarial samples with consistent execution results, while also demonstrating strong cross-language applicability. The proposed method employs SecureBERT as an adversarial sample generator, leveraging its attention mechanism to identify high-attention words from benign samples as candidate terms. By replacing variable names in Webshells with these candidates, adversarial samples are constructed.
Experimental Results:
The proposed method is evaluated on Webshells written in both PHP and JSP, demonstrating strong cross-language adaptability. Furthermore, adversarial training using the generated samples is conducted to improve models robustness. The experimental results show that the average generation time for a PHP and JSP adversarial sample is 20.17 s and 7.31 s, respectively, with generation success rates of 76.12% and 83.54%. After adversarial training with our method, the detection accuracy of the models for PHP and JSP Webshells improved by at least 3.24% and 3.44%, respectively. Moreover, the robustness of the adversarially trained models is significantly superior to that of ML components of antivirus tools. Compared with existing techniques, Attention-Attack demonstrates superior efficiency, robustness enhancement, and cross-language generalizability, offering a practical and effective solution for securing deep learning-based Webshell detection systems.
ER  - 

TY  - JOUR
T1  - Embodied Digital Twin Driven Human-Centric Collaborative Robot Behavior: Cognitive Inference of Action Strategies
AU  - Tong, Xiaodong
AU  - Zheng, Hangbin
AU  - Wang, Baicun
AU  - Bao, Jinsong
JO  - Chinese Journal of Mechanical Engineering
SP  - 100164
PY  - 2025
DA  - 2025/11/22/
SN  - 1000-9345
DO  - https://doi.org/10.1016/j.cjme.2025.100164
UR  - https://www.sciencedirect.com/science/article/pii/S1000934525001683
KW  - Digital twin
KW  - Embodied AI
KW  - Collaborative robotics
KW  - Human-centric
KW  - Large language model multi-agent system (LLM-MAS)
AB  - Collaborative robot interacting autonomously with human operators through flexible behavioral strategies poses a significant challenge. The lack of sufficient attention to the status of human operators during autonomous collaboration has led to safety hazards, necessitating improvements in current robot behavioral strategy research. Digital twin (DT) can establish interactive ecosystems consisting of assets and human nodes, providing continuous optimization for industry and becoming a crucial means for human-centric approaches. In this context, we propose Embodied Digital Twin (EDT) and its driven cognitive inference of collaborative robot behavior strategies, achieving safe and flexible autonomous collaboration through three stages: human-robot communication, human-robot understanding, and collaborative intelligence. Our approach has several key features: firstly, EDT shifts focus from traditional task-oriented approaches to human-centric engineering methods, offering a digital twin architecture with human-centricity, system empathy, and collaborative adaptability. Secondly, we establish an embodied environment for robot learning and training to address complex and dynamic human behaviors, enabling deep perception through spatiotemporal multisensory semantic fusion. Finally, utilizing neural-symbolic cognitive reasoning based on Large Language Model Multi-Agent System (LLM-MAS), we achieve robot autonomous collaboration aligned with human intent. We validate our approach using retired lithium battery disassembly tasks. Experimental results demonstrate that our proposed solution overcomes safety hazards caused by task rearrangements, physiological fatigue, psychological aversion, and human individual differences, showcasing improved safety, smoothness, and efficiency in collaboration performance. This confirms EDT as a universal guideline providing higher performance for human-centered solutions.
ER  - 

TY  - JOUR
T1  - Weaponized AI for cyber attacks
AU  - Yamin, Muhammad Mudassar
AU  - Ullah, Mohib
AU  - Ullah, Habib
AU  - Katt, Basel
JO  - Journal of Information Security and Applications
VL  - 57
SP  - 102722
PY  - 2021
DA  - 2021/03/01/
SN  - 2214-2126
DO  - https://doi.org/10.1016/j.jisa.2020.102722
UR  - https://www.sciencedirect.com/science/article/pii/S2214212620308620
KW  - Artificial intelligence
KW  - Cybersecurity
KW  - Adversarial learning
KW  - Scenarios
KW  - Cyberattack
KW  - Cyber defense
AB  - Artificial intelligence (AI)-based technologies are actively used for purposes of cyber defense. With the passage of time and with decreasing complexity in implementing AI-based solutions, the usage of AI-based technologies for offensive purposes has begun to appear in the world. These attacks vary from tampering with medical images using adversarial machine learning for false identification of cancer to the generation of adversarial traffic signals for influencing the safety of autonomous vehicles. In this research, we investigated recent cyberattacks that utilize AI-based techniques and identified various mitigation strategies that are helpful in handling such attacks. Further, we identified existing methods and techniques that are used in executing AI-based cyberattacks and what probable future scenarios will be plausible to control such attacks by identifying existing trends in AI-based cyberattacks.
ER  - 

TY  - JOUR
T1  - Temporal feature aggregation with attention for insider threat detection from activity logs
AU  - Pal, Preetam
AU  - Chattopadhyay, Pratik
AU  - Swarnkar, Mayank
JO  - Expert Systems with Applications
VL  - 224
SP  - 119925
PY  - 2023
DA  - 2023/08/15/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2023.119925
UR  - https://www.sciencedirect.com/science/article/pii/S0957417423004268
KW  - Insider threat
KW  - Stacked ensemble
KW  - LSTM
KW  - GRU
KW  - Attention model
KW  - Imbalanced data
KW  - Equally-weighted random sampling
AB  - Nowadays, insider attacks are emerging as one of the top cybersecurity threats. However, the detection of insider threats is a more arduous task for many reasons. A significant cause is the availability of various data types related to insider activities and their possible behavioral drift. Another major reason is that threat activities rarely happen within any organizational environment and usually remain submerged within a massive amount of normal activities thereby creating data imbalance issues. Any insider threat event requires three major components to get materialized: proper motivation, suitable opportunity and a minimum skill set. The simultaneous occurrence of all these elements is rarely found in organizational environment compared to regular activity traits, and the data imbalance thus caused makes accurate detection of threat activities quite challenging. Existing insider threat detection techniques are mainly divided into statistical rule-based, machine learning-based, and deep learning-based methods. Although recent deep learning methods have been found to extract intrinsic behavioral properties from users’ activity patterns more effectively than traditional rule-based and machine-learning methods by utilizing their multilayer architecture. But sporadic approaches prioritize critical sections of activity patterns in their detection scheme. Also, rare methods focused on taking advantage of multiple deep learning-based feature extraction models together in their detection process. Finally, rare methods have adequately focused on data imbalance issues, especially over the unequal proportion of different categories of threat instances. In this paper, we proposed an insider threat detection approach using an ensemble of stacked-LSTM and stacked-GRU-based attention models. Our models are first trained on the user’s single-day sequential activity logs. Then a stacked ensemble of trained attention models is used to extract the user’s single-day activity information in the form of the feature vector, which is finally used for classification. To address the data imbalance issues, we propose a new equally-weighted random sampling approach for balancing the population of the different categories of threat patterns. We randomly undersample the nonmalicious instances followed by random oversampling of the different categories of threat instances in an equally-weighted manner so that the training models can learn the behavioral characteristics of the different types of insider activity patterns without getting biased towards any particular type, which is a major limitation of random oversampling and random undersampling-based techniques. Experiments have been performed on the different versions of the CMU CERT insider threat datasets. For robust evaluation, stratified division-based train-test sets have been used based on different categories of insider activities. An average AUC of 0.99 on CMU CERT v4.2 and v5.2 datasets and 0.97 on its v6.2 dataset shows the robustness of the proposed approach in detecting insider threats.
ER  - 

TY  - JOUR
T1  - A Multi-scale Patch Mixer Network for Time Series Anomaly Detection
AU  - Wang, Qiushi
AU  - Zhu, Yueming
AU  - Sun, Zhicheng
AU  - Li, Dong
AU  - Ma, Yunbin
JO  - Engineering Applications of Artificial Intelligence
VL  - 140
SP  - 109687
PY  - 2025
DA  - 2025/01/15/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2024.109687
UR  - https://www.sciencedirect.com/science/article/pii/S0952197624018451
KW  - Lightweight
KW  - Multi-scale
KW  - Time series anomaly detection
KW  - Fully connected layer
AB  - With the development of Internet of Things (IoT) technology, a large amount of data with temporal characteristics is collected and stored. How to efficiently and accurately identify anomalies from these data is a major challenge. At present, there are many problems in the application of anomaly detection, including non-stationary data, complex and difficult-to-collect anomalies, the need for real-time detection and the limitation of computing resources. But few methods can comprehensively consider these issues. To overcome these challenges, we propose a lightweight neural network, Multi-scale Patch Mixer Network (MP-MixerNet). It is mainly composed of a Mixer Block based on fully connected layer design, which contains a Temporal-Mixer and a Spatial-Mixer, and can simultaneously model the intra- and inter-series dependencies of multivariate time series. We also perform multi-scale patch segmentation based on frequency analysis, which helps the model extract robust features from multiple period views. In addition, we design an Input Stabilization module to help the model deal with data distribution shift. Experimental results on a public time series anomaly detection dataset show that we are able to achieve higher comprehensive performance with fewer parameters and inference time.
ER  - 
