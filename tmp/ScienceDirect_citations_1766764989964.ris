TY  - JOUR
T1  - CLEHTO — A multi-layered algorithm for secure, adaptive data transmission in IoT-enhanced healthcare networks
AU  - Hamrioui, Sofiane
AU  - Ciocan, Angela Voinea
AU  - Hamrioui, Camil Adam Mohamed
AU  - Lorenz, Pascal
JO  - Ad Hoc Networks
VL  - 180
SP  - 104056
PY  - 2026
DA  - 2026/01/01/
SN  - 1570-8705
DO  - https://doi.org/10.1016/j.adhoc.2025.104056
UR  - https://www.sciencedirect.com/science/article/pii/S157087052500304X
KW  - CLEHTO
KW  - IoT
KW  - E-health
KW  - Adaptive data transmission
KW  - Secure communication
KW  - Healthcare networks
KW  - Multi-layered algorithm
KW  - Telemedicine
KW  - Data prioritization
KW  - Energy efficiency
AB  - The rapid growth of IoT in healthcare demands reliable, secure, and energy-efficient communication solutions. We propose CLEHTO, a novel cross-layer optimization framework that dynamically adapts to network conditions by integrating real-time energy monitoring, joint mobility–security assessment, and adaptive congestion control. Unlike conventional approaches, CLEHTO introduces a unified reliability scoring system that simultaneously evaluates physical channel quality, link reliability, node mobility, and transport-layer congestion. Experimental results demonstrate CLEHTO’s exceptional performance: a 92.8% Packet Delivery Ratio under 20% link failure while maintaining 4.5 Mbps throughput, a 98.6% authentication success rate using SSL/TLS (outperforming IPSec’s 98.3%), and optimal energy consumption of 0.55 mAh for battery-powered devices. CLEHTO maintains 105 ms latency (vs. IPSec’s 95 ms) for secure medical data flows, showing significant improvements over single-layer approaches. These results establish CLEHTO as a robust and efficient solution for IoT-based healthcare systems.
ER  - 

TY  - JOUR
T1  - Tell me something new: data subject rights applied to inferred data and profiles
AU  - Custers, Bart
AU  - Vrabec, Helena
JO  - Computer Law & Security Review
VL  - 52
SP  - 105956
PY  - 2024
DA  - 2024/04/01/
SN  - 2212-473X
DO  - https://doi.org/10.1016/j.clsr.2024.105956
UR  - https://www.sciencedirect.com/science/article/pii/S0267364924000232
KW  - Data subject rights
KW  - GDPR
KW  - Data protection
KW  - Inferred data
KW  - Transparency
KW  - Profiling
KW  - Automated decisions
KW  - Automated decision-making
AB  - The EU General Data Protection Regulation (GDPR) contains several data subject rights, but for many of these rights it is not entirely clear how they should work in practice, especially in digital environments. Most data subject rights apply to personal data obtained directly or indirectly from the data subject. This is often personal data that data subjects already are familiar with, i.e., things they already know about themselves. Unclear, however, is to what extent ascribed personal data, such as inferred data and categories or profiles in which data subjects are placed by data controllers, are within the scope of these rights. Such ascribed personal data often concerns novel information, generated by data controllers, and includes insights into how controllers view and assess them, which may have practical and legal impact on data subjects. Given these characteristics, the ascribed personal data may be much more interesting to data subjects, so it appears beneficial, from the policy perspective, to have this novel information included in the scope of data subject rights. If data subject rights do not apply to inferred data and profiles, invoking these rights is unlikely to be informative and provide meaningful information for data subjects, particularly in complex, digital environments. However, if data subject rights do apply to inferred data and profiles, the scope of these rights may be hard to delineate and they may quickly interfere with rights and freedoms of others, including trade secrets of data controllers and privacy rights of other data subjects. In this article, we investigate the implications of applying data subject rights to inferred data and profiles. For each data subject right in the GDPR, we assess which types of personal data could and perhaps should be in scope, based on grammatical and teleological legal analyses as well as practical considerations. While the area of data subject rights received significant academic attention in the past years, our article contributes to the discussion by providing a systematic, holistic framework to consider the scope of the rights in relation to ascribed data.
ER  - 

TY  - JOUR
T1  - Bias and discrimination in ML-based systems of administrative decision-making and support
AU  - MAC, Trang Anh
JO  - Computer Law & Security Review
VL  - 55
SP  - 106070
PY  - 2024
DA  - 2024/11/01/
SN  - 2212-473X
DO  - https://doi.org/10.1016/j.clsr.2024.106070
UR  - https://www.sciencedirect.com/science/article/pii/S0267364924001365
KW  - Bias
KW  - Discrimination
KW  - AI
KW  - Machine learning
KW  - Decision-making
KW  - Support
AB  - In 2020, the alleged wilful and gross negligence of four social workers, who did not notice and failed to report the risks to an eight-year-old boy's life from the violent abuses by his mother and her boyfriend back in 2013, ultimately leading to his death, had been heavily criticised.11*Trang Anh MAC, LLM. Digital Law, University of Paris XII Est-Créteil, reporter at AstraIA Gear. This paper is the English version of her master thesis, under supervision of Dr. Laurie MARGUET and Prof. Florent MADELAINE A. Reyes-Velarde, Charges dismissed against social workers linked to Gabriel Fernandez's killing, Los Angeles Times, 16 Jul 2020, available online at https://www.latimes.com/california/story/2020-07-15/charges-against-the-social-workers-linked-to-gabriel-fernandez-killing-will-be-dropped The documentary, Trials of Gabriel Fernandez in 2020,22https://www.imdb.com/title/tt11822998/ has discussed the Allegheny Family Screening Tool (AFST33Allegheny County, Allegheny Family Screening Tool, available online at https://www.alleghenycounty.us/Services/Human-Services-DHS/DHS-News-and-Events/Accomplishments-and-Innovations/Allegheny-Family-Screening-Tool), implemented by Allegheny County, US since 2016 to foresee involvement with the social services system. Rhema Vaithianathan44Bio of Prof. Rhema Vaithianathan. Available online at https://academics.aut.ac.nz/rhema.vaithianathan, the Centre for Social Data Analytics co-director, and the Children's Data Network55Our team, Children’s Data Network. Available online at https://www.datanetwork.org/people/ members, with Emily Putnam-Hornstein66Bio of PhD. Emily Putnam-Hornstein. Available online at https://www.datanetwork.org/people/#emily-putnam-hornstein, established the exemplary and screening tool, integrating and analysing enormous amounts of data details of the person allegedly associating to injustice to children, housed in DHS Data Warehouse77Allegheny County, DHS Data Warehouse. Available online at https://www.alleghenycounty.us/Services/Human-Services-DHS/DHS-News-and-Events/Accomplishments-and-Innovations/DHS-Data-Warehouse. They considered that may be the solution for the failure of the overwhelmed manual administrative systems. However, like other applications of AI in our modern world, in the public sector, Algorithmic Decisions Making and Support systems, it is also denounced because of the data and algorithmic bias.88N. LaGrone, Can AI Reduce Harm to Children?: Gabriel Fernandez and the Case for Machine Learning, 9 April 2020, available online at https://www.azavea.com/blog/2020/04/09/can-ai-reduce-harm-to-children/ This topic has been weighed up for the last few years but not has been put to an end yet. Therefore, this humble research is a glance through the problems - the bias and discrimination of AI based Administrative Decision Making and Support systems. At first, I determined the bias and discrimination, their blur boundary between two definitions from the legal perspective, then went into the details of the causes of bias in each stage of AI system development, mainly as the results of bias data sources and human decisions in the past, society and political contexts, and the developers’ ethics. In the same chapter, I presented the non-discrimination legal framework, including their application and convergence with the administration laws in regard to the automated decision making and support systems, as well as the involvement of ethics and regulations on personal data protection. In the next chapter, I tried to outline new proposals for potential solutions from both legal and technical perspectives. In respect to the former, my focus was fairness definitions and other current options for the developers, for example, the toolkits, benchmark datasets, debiased data, etc. For the latter, I reported the strategies and new proposals governing the datasets and AI systems development, implementation in the near future.
ER  - 

TY  - JOUR
T1  - Biometric data landscape in Southeast Asia: Challenges and opportunities for effective regulation
AU  - Lim, Abigail Chiu Mei
AU  - Ng, Lynnette Hui Xian
AU  - Taeihagh, Araz
JO  - Computer Law & Security Review
VL  - 56
SP  - 106095
PY  - 2025
DA  - 2025/04/01/
SN  - 2212-473X
DO  - https://doi.org/10.1016/j.clsr.2024.106095
UR  - https://www.sciencedirect.com/science/article/pii/S0267364924001602
KW  - Biometrics
KW  - Biometrics regulation
KW  - ASEAN
KW  - Data protection
KW  - Southeast Asia
AB  - Technology evolves at a breakneck pace. As a result, legislatures are often unable to enact laws that can keep pace with technological changes. The dissonance between the state of the law and the state of technology intensifies with respect to biometric data because the purposes of biometric data use evolve, the types of biometric data expand, and its collection, processing and use have shifted from conventional biometric systems to online platforms. This dissonance is exemplified in the Association of Southeast Asian Nations, where no regional legal instrument regulates biometric data even though governmental agencies, private entities and social media platforms actively employ biometric data and artificial intelligence systems. At national level, only five countries, Malaysia, Singapore, Indonesia, Thailand, and the Philippines, have enacted omnibus data protection legislations that afford some protection to biometric data and govern its use. This article analyses these data protection legislations and assesses their suitability in protecting and governing biometric data in the contemporary era. It identifies common trends amongst the five countries and concludes that more needs to be done to protect biometric data and rights of data subjects. Thereafter, it makes recommendations for changes to improve the state of biometric regulation in Southeast Asia.
ER  - 

TY  - JOUR
T1  - Advanced multi-model prediction of aircraft engine remaining useful life with random sampling-based class balancing and voting-based features selection
AU  - Barry, Ibrahima
AU  - Hafsi, Meriem
JO  - Engineering Applications of Artificial Intelligence
VL  - 156
SP  - 111201
PY  - 2025
DA  - 2025/09/15/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2025.111201
UR  - https://www.sciencedirect.com/science/article/pii/S0952197625012023
KW  - Predictive maintenance
KW  - Prognostic and health management
KW  - Industry 4.0
KW  - Remaining useful life
KW  - Aircraft engine lifespan estimation
KW  - Deep learning
AB  - In Industry 4.0, predictive maintenance for critical systems like aircraft engines relies on accurate Remaining Useful Life (RUL) estimation to prevent unexpected failures and optimize maintenance schedules. However, existing models face several limitations that hinder their effectiveness in real-world applications. Common challenges include data imbalance, which can lead to biased predictions; suboptimal feature selection, which may overlook important predictive variables; and limitations in model accuracy, particularly when handling complex, high-dimensional datasets. These issues often reduce the reliability and generalizability of RUL predictions across varied operational contexts. To address these challenges, this study proposes a novel data-driven approach that integrates random-sampling class balancing, a voting-based feature selection method, and advanced machine learning techniques, including ensemble and deep learning models. Applied to the Commercial Modular Aero-Propulsion System Simulation dataset, our model demonstrates significant improvements in RUL prediction, achieving Root Mean Square Error values of 11.10% for FD001, 12.09% for FD002, 11.80% for FD003, and 12.88% for FD004. These results highlight the model’s robustness and its potential to enhance predictive maintenance in aeronautical engineering.
ER  - 

TY  - JOUR
T1  - Online sexist meme and its effects on moral and emotional processes in social media
AU  - Paciello, Marinella
AU  - D'Errico, Francesca
AU  - Saleri, Giorgia
AU  - Lamponi, Ernestina
JO  - Computers in Human Behavior
VL  - 116
SP  - 106655
PY  - 2021
DA  - 2021/03/01/
SN  - 0747-5632
DO  - https://doi.org/10.1016/j.chb.2020.106655
UR  - https://www.sciencedirect.com/science/article/pii/S0747563220304027
KW  - Sexist meme
KW  - Moral disengagement
KW  - Prosocial reasoning
KW  - Moral emotion
KW  - Online aggression
AB  - Online sexist aggression is still overlooked in psychosocial literature. The present study aims to investigate moral cognitive and emotional processes associated with different online stances during a heated online discussion prompted by a sexist meme. To this end, adopting a social cognitive framework, we analyzed Twitter comments in response to the public condemnation of a rude sexist meme made about Carola Rackete, the captain of the Sea-Watch. A total of 1249 comments were codified for moral disengagement mechanisms, prosocial reasoning, and moral emotions. The results show the impact of a sexist meme in terms of cognitive and emotional processes. While moral disengagement mechanisms and other-condemning emotions have characterized aggressive stances, prosocial reasoning and other-suffering emotions have characterized prosocial ones. Intermediate stances also emerged during the online discussion, showing a more complex interplay between cognition and emotional moral processes—beyond the mere polarization of two stances. Indeed, some comments defending women image were characterized in active negative emotions (e.g., anger) and prosocial moral reasoning, whereas others “avoiding” comments were characterized by moral disengagement and ironic expressions. The social and theoretical implications of these results are then discussed.
ER  - 

TY  - JOUR
T1  - Secured human-centric sustainable healthcare in industry 5.0 through artificial neural synchronization-guided blockchain and vertical federated learning
AU  - Sarkar, Arindam
JO  - Applied Soft Computing
VL  - 175
SP  - 113040
PY  - 2025
DA  - 2025/05/01/
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2025.113040
UR  - https://www.sciencedirect.com/science/article/pii/S1568494625003515
KW  - Federated Deep Learning
KW  - Artificial Neural Networks (ANNs)
KW  - Sustainable healthcare
KW  - Blockchain
KW  - Electronic Health Record (EHR)
AB  - This paper introduces a medical recommendation system that utilizes vertical Federated Learning (FL) to securely access real-time patient and healthcare data to provide personalized treatment recommendations. It utilizes insights from federated servers through sentiment and emotion analysis. The incorporation of blockchain technology into FL addresses concerns related to ownership and privacy by utilizing neural synchronization and hyperledger fabric to safeguard data. Data providers encrypt instances to improve dependability and store them on the blockchain using structured transactions. This solution combines these technologies with professional medical knowledge to cooperatively train Machine Learning (ML) models on dispersed healthcare data. Implementing a knowledge-based recommendation system improves the accuracy and interpretability of disease prediction models. Healthcare professionals can use various patient data while protecting privacy and using collective medical expertise. It builds a blockchain key using Artificial Neural Networks (ANNs) that are aligned neurally in opposite directions. This assures the confidentiality, transparency, and traceability of medical information. The system uses Bagging, Gradient Boost, Light-GBM, N-Gram, Random Forest, Gaussian Naive Bayes, and Federated Deep Learning to improve disease prediction while maintaining raw data privacy through collaborative learning. Evaluation metrics show increased privacy, security, and personalized medical advice, with a focus on safe storage, tailored treatment plans, individualized therapy recommendations, blockchain-based Electronic Health Record (EHR) storage, and performance monitoring. Hyperledger fabric tracks EHR changes on a cloud platform. A comprehensive assessment reveals that this technique has the potential for success in real-world healthcare.
ER  - 

TY  - JOUR
T1  - My AI, my code, my secret – Trade secrecy, informational transparency and meaningful litigant participation under the European Union's AI Liability Directive Proposal
AU  - Grozdanovski, Ljupcho
JO  - Computer Law & Security Review
VL  - 56
SP  - 106117
PY  - 2025
DA  - 2025/04/01/
SN  - 2212-473X
DO  - https://doi.org/10.1016/j.clsr.2025.106117
UR  - https://www.sciencedirect.com/science/article/pii/S0267364925000123
KW  - Artificial intelligence
KW  - AI liability
KW  - AI Liability Directive
KW  - AIA
KW  - Fair trial
KW  - Good administration
KW  - Evidence
KW  - Trade secrets
KW  - Reverse engineering
KW  - EU charter of fundamental rights
AB  - In European Union (EU) law, the AI Liability Directive (AILD) proposal included a right for victims of harm caused by high-risk AI systems to request the disclosure of relevant evidence. That right is, however, limited by the protection of trade secrets. During legal proceedings, business confidentiality can indeed restrict the victims’ access to evidence, potentially precluding them from fully understanding the disputed facts and effectively making their views known before a court. This article examines whether the AILD provided sufficient procedural mechanisms to ensure that litigants can effectively participate in judicial proceedings, even when critical evidence is withheld from them, due to legitimate trade secret protections. Our analysis draws on the evidentiary challenges highlighted in emerging global AI liability cases and selected CJEU case law, which provide guidance on how a balance can be struck between legitimate confidentiality and a workable level of informational transparency, necessary for an informed and fair resolution of future AI liability disputes.
ER  - 

TY  - JOUR
T1  - INOR—An Intelligent noise reduction method to defend against adversarial audio examples
AU  - Guo, Qingli
AU  - Ye, Jing
AU  - Chen, Yiran
AU  - Hu, Yu
AU  - Lan, Yazhu
AU  - Zhang, Guohe
AU  - Li, Xiaowei
JO  - Neurocomputing
VL  - 401
SP  - 160
EP  - 172
PY  - 2020
DA  - 2020/08/11/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2020.02.110
UR  - https://www.sciencedirect.com/science/article/pii/S0925231220303453
KW  - Adversarial audio examples
KW  - Defense against adversarial audio examples
KW  - INOR
AB  - Recently, Automatic Speech Recognition(ASR) systems are seriously threatened by adversarial audio examples. The defense against adversarial audio examples has become an urgent issue. Different from adversarial image examples whose target is limited in the finite categories, the target of adversarial audio examples can be any combination of the words in a language. Adversarial audio examples aim to change the semantic of the audio. The semantic is explicitly represented in transcription distance, which affects the adversarial perturbation. This paper analyzes the relationship between semantic difference and adversarial perturbation. Quantization and local smoothing are calibrated to evaluate their performance. We observe that, for adversarial audio examples with different transcription distance levels, the capability of different denoising strategies varies. Therefore, we first introduce the wavelet filter, which denoises the signal in the transformed domain. Then we explore the defense capability of combined filters. Finally, a new intelligent noise reduction method–INOR is proposed to improve the denoising performance of audios under different levels of transcription distance. Experimental results show that INOR is effective in mitigating the adversarial perturbations for adversarial examples with different transcription distance levels. The average CER and WER is reduced by 33% and 55%.
ER  - 

TY  - JOUR
T1  - The Paradoxes of Digital Tools in Hospitals: Qualitative Interview Study
AU  - Wosny, Marie
AU  - Strasser, Livia Maria
AU  - Hastings, Janna
JO  - Journal of Medical Internet Research
VL  - 26
PY  - 2024
DA  - 2024/01/01/
SN  - 1438-8871
DO  - https://doi.org/10.2196/56095
UR  - https://www.sciencedirect.com/science/article/pii/S1438887124003789
KW  - health care
KW  - health care technology
KW  - health care information technology
KW  - hospital information technology
KW  - clinical information systems
KW  - health care professionals
KW  - experience
KW  - frustration
KW  - clinician burnout
KW  - technology implementation
KW  - paradoxes
KW  - digital tool
KW  - digital tools
KW  - hospital
KW  - hospitals
KW  - qualitative interview study
KW  - interview
KW  - interviews
KW  - Switzerland
KW  - thematic analysis
AB  - Background
Digital tools are progressively reshaping the daily work of health care professionals (HCPs) in hospitals. While this transformation holds substantial promise, it leads to frustrating experiences, raising concerns about negative impacts on clinicians’ well-being.
Objective
The goal of this study was to comprehensively explore the lived experiences of HCPs navigating digital tools throughout their daily routines.
Methods
Qualitative in-depth interviews with 52 HCPs representing 24 medical specialties across 14 hospitals in Switzerland were performed.
Results
Inductive thematic analysis revealed 4 main themes: digital tool use, workflow and processes, HCPs’ experience of care delivery, and digital transformation and management of change. Within these themes, 6 intriguing paradoxes emerged, and we hypothesized that these paradoxes might partly explain the persistence of the challenges facing hospital digitalization: the promise of efficiency and the reality of inefficiency, the shift from face to face to interface, juggling frustration and dedication, the illusion of information access and trust, the complexity and intersection of workflows and care paths, and the opportunities and challenges of shadow IT.
Conclusions
Our study highlights the central importance of acknowledging and considering the experiences of HCPs to support the transformation of health care technology and to avoid or mitigate any potential negative experiences that might arise from digitalization. The viewpoints of HCPs add relevant insights into long-standing informatics problems in health care and may suggest new strategies to follow when tackling future challenges.
ER  - 

TY  - JOUR
T1  - Digitization of the enterprise - prospects for process automation with using RPA and GPT integration
AU  - Jasińska, Katarzyna
AU  - Lewicz, Michał
AU  - Rostalski, Mateusz
JO  - Procedia Computer Science
VL  - 225
SP  - 3243
EP  - 3254
PY  - 2023
DA  - 2023/01/01/
T2  - 27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2023.10.318
UR  - https://www.sciencedirect.com/science/article/pii/S187705092301476X
KW  - RPA
KW  - AI
KW  - integration, ChatGPT
AB  - The purpose of this article is to organize the concepts related to the digitization of the modern enterprise and to identify potential digitization directions for process automation using the integration of RPA and GPT technologies. As research methods, the article uses a literature review of the past 20 years and presents a case study. The first part of the article reviews the concepts of digitization and process automation. A distinction was made in the understanding of the terms, which became the basis for describing the possibilities of integrating ChatGPT with RPA. The key prospects for using ChatGPT were then identified, and limitations were discussed. The possibility of using ChatGPT integration with RPA was illustrated with a case study of a service company form green energy sector.
ER  - 

TY  - JOUR
T1  - Mapping research in the Journal of Innovation & Knowledge to sustainable development goals
AU  - Raman, Raghu
AU  - Pattnaik, Debidutta
AU  - Achuthan, Krishnashree
AU  - Hughes, Laurie
AU  - Al-Busaidi, Adil S.
AU  - Dwivedi, Yogesh K
AU  - Ramesh, Maneesha Vinodini
AU  - Nedungadi, Prema
JO  - Journal of Innovation & Knowledge
VL  - 9
IS  - 3
SP  - 100538
PY  - 2024
DA  - 2024/07/01/
SN  - 2444-569X
DO  - https://doi.org/10.1016/j.jik.2024.100538
UR  - https://www.sciencedirect.com/science/article/pii/S2444569X24000775
KW  - Sustainable development goal
KW  - Innovation
KW  - Knowledge
KW  - Digital transformation
KW  - Entrepreneurship
KW  - Topic modeling
KW  - Citation clusters
AB  - This study critically evaluates the contributions of the Journal of Innovation & Knowledge (JIK) toward advancing research aligned with the Sustainable Development Goals (SDGs), employing the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) protocol for systematic literature review. We meticulously examine JIK’s interdisciplinary research patterns, thematic focuses, and topic evolution, emphasizing the journal’s engagement with SDG 9 (Industry, Innovation, and Infrastructure), SDG 8 (Decent Work and Economic Growth), and SDG 4 (Quality Education). By utilizing advanced techniques such as co-citation mapping and BERTopic modeling, this study identifies six major topics within the JIK, aligning with specific SDGs: “EcoTech Revolution” highlights ‘green technology,’ “Entrepreneurial Innovation” focuses on ‘innovation management,’ “Economy 4.0” centers on ‘digital transformation,’ “Effectual Innovation” involves ‘technological innovation capability,’ “Collaborative Economy” addresses ‘sharing economy sustainability,’ and “Green Innovation” explores ‘eco-innovation.’ These topics underscore JIK’s role in advancing interdisciplinary research across key areas such as technology, entrepreneurship, the digital economy, practical innovation applications, collaborative consumption models, and environmental sustainability. Our findings highlight gaps, particularly in addressing SDG 5 (Gender Equality) and SDG 15 (Life on Land), presenting opportunities for JIK to diversify its research agenda toward a more inclusive sustainability discourse. Contributions from a global array of authors underscore JIK’s international impact and its role in fostering diverse sustainability perspectives.
ER  - 

TY  - JOUR
T1  - A digital twin framework for intelligent electric vehicle charging optimization in smart manufacturing systems
AU  - Liu, Chunting
AU  - Liu, Ruyu
AU  - Liu, Xiufeng
JO  - Applied Energy
VL  - 406
SP  - 127281
PY  - 2026
DA  - 2026/03/01/
SN  - 0306-2619
DO  - https://doi.org/10.1016/j.apenergy.2025.127281
UR  - https://www.sciencedirect.com/science/article/pii/S0306261925020112
KW  - Digital twin
KW  - Electric vehicle charging
KW  - Smart manufacturing
KW  - Optimization
KW  - Discrete-event simulation
KW  - Industry 4.0
KW  - Predictive control
AB  - The electrification of industrial vehicle fleets introduces complex coordination challenges in dynamic manufacturing environments, where vehicle availability directly influences operational continuity. This paper proposes a novel Digital Twin (DT) framework that integrates discrete-event simulation with a multi-objective optimization engine for intelligent electric vehicle (EV) charging. The system employs a hierarchical rolling-horizon strategy that accounts for battery states, production demands, and dynamic electricity pricing. Simulation studies across four representative manufacturing scenarios, evaluating five charging strategies including uncontrolled, first-come-first-served (FCFS), and our intelligent optimization, demonstrate the effectiveness of the proposed approach. Results reveal that the intelligent strategy delivers substantial energy cost reductions (up to 54.4 %), improved carbon efficiency, and increased infrastructure utilization. Compared to FCFS, which incurs 36.4–37.2 % higher energy and emission burdens, the intelligent framework consistently supports more sustainable and efficient charging. Scenario-specific variations in operational throughput offer opportunities for adaptive algorithmic refinement. These findings provide a scalable, modular, and data-driven solution for integrating EV charging infrastructure as a co-optimized component of smart manufacturing systems.
ER  - 

TY  - JOUR
T1  - The power of emotions: Leveraging user generated content for customer experience management
AU  - Sykora, Martin
AU  - Elayan, Suzanne
AU  - Hodgkinson, Ian R.
AU  - Jackson, Thomas W.
AU  - West, Andrew
JO  - Journal of Business Research
VL  - 144
SP  - 997
EP  - 1006
PY  - 2022
DA  - 2022/05/01/
SN  - 0148-2963
DO  - https://doi.org/10.1016/j.jbusres.2022.02.048
UR  - https://www.sciencedirect.com/science/article/pii/S0148296322001679
KW  - Customer experience management
KW  - Sentiment analysis
KW  - Social media
KW  - Emotion analytics
KW  - Bot automation
AB  - Customer experience management (CEM) in the social media age finds itself needing to adapt to a rapidly changing digital environment and hence there is a need for innovative digital data analytical solutions. Drawing on an action case study of a large global automotive manufacturer, this study presents a digital innovation for enhanced emotion analytics on user generated content (UGC) and behaviour (UGB), to improve consumer insights for CEM. The digital innovation captures customer experience in real time, enabling measurement of a wide range of discrete emotions on the studied social media platform, which goes beyond traditional tools that capture positive or negative sentiment only. During the digital intervention, a substantial number of inauthentic and bot like behaviours was revealed, unbeknown to the case organisation. These accounts were found to be posting and amplifying highly emotional and potentially damaging content surrounding the case brand and its products. The study illustrates how emotion in the context of customer experience should go beyond typical categorisations, given the complexity of human emotion, while a distinction between bot and authentic users is imperative for CEM.
ER  - 

TY  - JOUR
T1  - Advances in emerging digital technologies for energy efficiency and energy integration in smart cities
AU  - Zhou, Yuekuan
AU  - Liu, Jiangyang
JO  - Energy and Buildings
VL  - 315
SP  - 114289
PY  - 2024
DA  - 2024/07/15/
SN  - 0378-7788
DO  - https://doi.org/10.1016/j.enbuild.2024.114289
UR  - https://www.sciencedirect.com/science/article/pii/S0378778824004055
KW  - Energy digitalization
KW  - Internet of energy
KW  - Machine learning
KW  - Digital twin
KW  - Energy flexibility
KW  - Energy resilience
AB  - Advances and fast development in emerging digital technologies trigger the next generation revolution in energy areas and smart cities, while roles and mechanisms of digital technologies for smart and sustainable transition is unclear. Furthermore, energy flexibility enhancement in intermittent renewable-stochastic demand power management and survival capability in minimizing frequency of power outrage are still not clear, when suffering from climate change and extreme events with emerging digital technologies. In this study, advances in emerging digital technologies have been systematically and comprehensively reviewed, in terms of current development status and mechanisms for energy efficiency and energy integration in energy-efficient systems. Afterwards, roles of energy digitalization technologies are provided for high-efficiency, low-carbon and intelligent building energy systems, including artificial intelligence for dynamic performance predictions, advanced model predictive controls and optimisations of nonlinear systems (e.g., PVs, heat pumps, heat recovery systems and multi-energy storages). Furthermore, digital twin-based building energy digitalization technologies are applied for 3D modeling, monitoring, real-time visualization and virtual reality interaction. Frontier multi-agent based distributed energy systems are comprehensively proposed with multi-agent energy management, including RE-battery-building-EV, RE-building-hydrogen vehicles, and both centralised and distributed energy management systems. Considering the multi-energy system capability for power management (intermittent renewable energy and energy demands) and survival capability when suffering from high-impact and low-probability events, both energy flexibility and energy resilience with energy digitalization technologies are interconnected, for climate change adaption and internet of energy. This study provides a systematic and comprehensive review on emerging digital technologies for energy efficiency and energy integration in smart cities, providing guidelines on sustainable and smart transitions with multi-agent based distributed energy management and energy digitalization technologies.
ER  - 

TY  - JOUR
T1  - Forensic image classification with active learning and generative adversarial network-based data augmentation
AU  - Yu, Xin
AU  - Li, Fangkun
AU  - Wang, Qiaoyun
AU  - Chen, Wei
AU  - Fan, Bingzheng
JO  - Digital Signal Processing
VL  - 168
SP  - 105649
PY  - 2026
DA  - 2026/01/01/
SN  - 1051-2004
DO  - https://doi.org/10.1016/j.dsp.2025.105649
UR  - https://www.sciencedirect.com/science/article/pii/S1051200425006712
KW  - Crime scene investigation
KW  - Active learning
KW  - Reinforcement learning
KW  - Generative adversarial network
KW  - Differential evolution
AB  - Crime scene investigation (CSI) image classification is crucial for forensic analysis, as it facilitates the interpretation of evidence and supports criminal investigations. Conventional approaches depend heavily on deep convolutional neural networks (CNNs) trained on large, fully labeled datasets, which are costly and labor-intensive to obtain. Addressing this challenge, we introduce an innovative active learning (AL) approach that improves model performance with fewer labeled samples. Many AL techniques rely on static selection methods. These methods limit adaptability and do not perform well in dynamic environments. To overcome this, we propose an AL framework that integrates deep reinforcement learning (DRL) with a scope loss function (SLF) to dynamically select the most informative unlabeled samples. The SLF balances exploiting known data with exploring new data opportunities. The proposed model improves adaptability by using a GAN with selective gradient omission for dynamic data augmentation. Moreover, to optimize hyperparameters efficiently and stably, it employs an enhanced DE algorithm guided by k-means mutation. Experiments on the CIIP-CSID1, CIIP-CSID2, and CIIP-CSID3 datasets demonstrate that the proposed model achieves average F-measures of 93.62 %, 88.45 %, and 87.14 %, respectively. It outperforms existing methods and reduces the need for extensive manual labeling. These results confirm that combining AL, GAN-based augmentation, and optimized hyperparameters can significantly enhance the accuracy and efficiency of CSI image classification, providing a practical solution for real-world forensic applications.
ER  - 

TY  - JOUR
T1  - Investigative genetic genealogy in Europe: Why the “manifestly made public by the data subject” legal basis should be avoided
AU  - Kuru, Taner
JO  - Computer Law & Security Review
VL  - 56
SP  - 106106
PY  - 2025
DA  - 2025/04/01/
SN  - 2212-473X
DO  - https://doi.org/10.1016/j.clsr.2025.106106
UR  - https://www.sciencedirect.com/science/article/pii/S0267364925000019
KW  - DNA
KW  - Forensics
KW  - Investigative genetic genealogy
KW  - Law enforcement
KW  - Law enforcement directive
KW  - Legal basis
KW  - Manifestly made public by the data subject
AB  - Investigative genetic genealogy has emerged as an effective investigation tool in the last few years, gaining popularity, especially after the arrest of the Golden State Killer. Since then, hundreds of cases have been reported to be solved thanks to this novel and promising technique. Unsurprisingly, this success also led law enforcement authorities in the EU to experiment with it. However, there is an ambiguity on which legal basis in the EU data protection framework should be used to access the personal data of genetic genealogy database users for investigative purposes, which may put the legality and legitimacy of investigative genetic genealogy in Europe at stake. Accordingly, this article examines whether the “manifestly made public by the data subject” legal basis enshrined in Article 10(c) of the Law Enforcement Directive could be used for such purposes. Based on its analysis, the article argues that this legal basis cannot be used for such purposes, given that the personal data in question are not “manifestly made” “public”, and they are not disclosed “by the data subject” in all cases. Therefore, the article concludes by suggesting a way forward to ensure the lawfulness of this investigation method in the EU data protection framework.
ER  - 

TY  - JOUR
T1  - Advanced framework for risk coupling analysis applied to ship groundings in Shenzhen port
AU  - Fan, Cunlong
AU  - Qiu, Yuhui
AU  - Montewka, Jakub
AU  - Bolbot, Victor
AU  - Hu, Shenping
JO  - Reliability Engineering & System Safety
VL  - 268
SP  - 111988
PY  - 2026
DA  - 2026/04/01/
SN  - 0951-8320
DO  - https://doi.org/10.1016/j.ress.2025.111988
UR  - https://www.sciencedirect.com/science/article/pii/S0951832025011883
KW  - Grounding
KW  - Risk coupling effects
KW  - Conditional N-K model
KW  - Interval number
KW  - Uncertainty
AB  - In a socio-technical system, risk coupling mainly refers to the interaction among risk factors that jointly amplify the likelihood or severity of accidents. Grounding is a major type of maritime accident with significant environmental, economic, and societal impacts, making it essential to understand both individual risk factors and their coupling effects for effective prevention. However, existing coupling analysis methods often fail to account for multiple homogeneous risk factors, the uncertainty associated with risk coupling effects, and the specific operational conditions of vessels. This paper proposes a novel framework for quantifying risk coupling effects that addresses these limitations. By modifying the traditional N-K model, we quantify the mutual information (MI) of both homogeneous and heterogeneous coupled risk factors under specific conditions, such as seasonal variation, with interval-valued MI to represent coupling effects. The results reveal that these effects can be either amplified or attenuated depending on the risk group and the operational context. Within a single risk factor group, multiple factors exert a significant, though not absolute, influence. Based on an analysis of rescue and response measures, effective decoupling strategies are proposed. The findings enhance the understanding of the complex risk dynamics in grounding incidents and offer practical decision-support tools for ship crews, emergency responders, and maritime authorities.
ER  - 

TY  - JOUR
T1  - Spherical sustainability in construction and demolition: How aligned are policies, goals, regulations, markets, and stakeholder mindsets?
AU  - Havaei, Mohammad Amin
AU  - Malekitabar, Hassan
JO  - Cleaner Environmental Systems
VL  - 16
SP  - 100256
PY  - 2025
DA  - 2025/03/01/
SN  - 2666-7894
DO  - https://doi.org/10.1016/j.cesys.2025.100256
UR  - https://www.sciencedirect.com/science/article/pii/S2666789425000029
KW  - Construction and demolition (C&D)
KW  - Analytic hierarchy process
KW  - Life cycle sustainability assessment
KW  - Environmental pollution
KW  - Circular economy
KW  - Sustainable project management
AB  - Rapid urbanization in developing countries has intensified Construction and Demolition (C&D) socio-environmental impacts, substantially contributing to global environmental pollution and degradation. Despite numerous efforts, existing frameworks remain fragmented, often neglecting the full spectrum of indicators and stakeholder priorities, thus revealing critical gaps between sustainability policies, market dynamics, and stakeholder implementation. Considering the growing complexity and variety in construction methods, bridging the gap between theoretical models and real-world practices has become essential. This research addresses these challenges by covering 21 C&D-caused pollutants and identifying existing conflicts through a holistic framework encompassing the entire C&D lifecycle. It was achieved through an iterative process that integrates the Parsimonious Spherical Fuzzy Analytical Hierarchy Process (P-SF-AHP), Circular Life Cycle Sustainability Assessment (C-LCSA), and pre- and post-statistical analyses. A systematic mapping of construction activities with Sustainable Development Goals (SDGs), Green Building Rating Systems (GBRSs), and international standards established a network balancing scientific rigor with multi-stakeholder decision-making. The methodology employed an extended Delphi process, engaging 43 multidisciplinary experts over six months in 2 + 2 rounds, weighting 21 pollutants across nine categories. The findings underscore the primacy of air, noise, and water pollution in regional contexts while revealing conflicts within existing strategies and standards. The resulting framework provides stakeholders with quantitative tools for C&D-caused pollutant assessment, supporting the transition from linear to spherical sustainability models in rapidly urbanizing regions.
ER  - 

TY  - JOUR
T1  - Coherence mode: Characterizing local graph structural information for temporal knowledge graph
AU  - Si, Yuehang
AU  - Hu, Xingchen
AU  - Cheng, Qing
AU  - Liu, Xinwang
AU  - Liu, Shixuan
AU  - Huang, Jincai
JO  - Information Sciences
VL  - 686
SP  - 121357
PY  - 2025
DA  - 2025/01/01/
SN  - 0020-0255
DO  - https://doi.org/10.1016/j.ins.2024.121357
UR  - https://www.sciencedirect.com/science/article/pii/S0020025524012714
KW  - Temporal knowledge graph reasoning
KW  - Label-based TKG construction process
KW  - Coherence mode
KW  - SAIKG
AB  - A Temporal Knowledge Graph (TKG) is designed for the effective modelling of the temporal relationships and dynamics of entities, events and concepts. Owing to its temporal attributes, a TKG offers greater benefits for reasoning than a static knowledge graph (KG). However, existing approaches for TKG reasoning do not consider coherent relationships between numerous facts, a term borrowed from specific parlance reflecting the interaction between objectives, such as observation and removal agents. This characteristic suggests that the model can obtain more insights from simultaneous coherent relationships. To address this problem, we develop a label-based process to construct a TKG from temporal event data in these domains. Based on the process, we build a specific TKG called Simulated Agent Interaction Knowledge Graph (SAIKG). In addition, we propose a novel TKG reasoning mechanism, termed the Coherence Mode. It is premised on an event coherence manner, enabling the prediction of unknown facts. Extensive experimental studies on different datasets demonstrate the effectiveness of the Coherence Mode integrated with typical models.
ER  - 

TY  - JOUR
T1  - CHESSIoT: A model-driven approach for engineering multi-layered IoT systems
AU  - Ihirwe, Felicien
AU  - Di Ruscio, Davide
AU  - Gianfranceschi, Simone
AU  - Pierantonio, Alfonso
JO  - Journal of Computer Languages
VL  - 78
SP  - 101254
PY  - 2024
DA  - 2024/03/01/
SN  - 2590-1184
DO  - https://doi.org/10.1016/j.cola.2023.101254
UR  - https://www.sciencedirect.com/science/article/pii/S2590118423000643
KW  - Model-driven engineering
KW  - System design
KW  - Safety analysis
KW  - Code generation
KW  - System deployment
KW  - Internet of Things
AB  - Context:
The current technology revolution, which places the highest value on people’s welfare, is frequently seen as being mainly supported by Internet of Things (IoT) technologies. IoT is regarded as a powerful multi-layered network of systems that integrates several heterogeneous, independently networked (sub-)systems working together to achieve a shared purpose.
Objective:
In this article, we present CHESSIoT, a model-driven engineering environment that integrates high-level visual design languages, software development, safety analysis, and deployment approaches for engineering multi-layered IoT systems. With CHESSIoT, users may conduct different engineering tasks on system and software models under development to enable earlier decision-making and take prospective measures, all supported by a unique environment.
Methodology:
This is achieved through multi-staged designs, most notably the physical, functional, and deployment architectures. The physical model specification is used to perform both qualitative and quantitative safety analysis by employing logical Fault-Trees models (FTs). The functional model specifies the system’s functional behavior and is later used to generate platform-specific code that can be deployed on low-level IoT device nodes. Additionally, the framework supports modeling the system’s deployment plan and run-time service provisioning, which would ultimately be transformed into deployment configuration artifacts ready for execution on remote servers.
Results:
To showcase the effectiveness of our proposed approach, as well as the capability of the supporting tool, a multi-layered Home Automation system (HAS) scenario has been developed covering all its design, development, analysis, and deployment aspects. Furthermore, we present the results from different evaluation mechanisms which include a comparative analysis and a qualitative assessment. The evaluation mechanisms target mainly completeness of CHESSIoT by addressing specific research questions.
ER  - 

TY  - JOUR
T1  - Correct Audit Logging in Concurrent Systems
AU  - Amir-Mohammadian, Sepehr
AU  - Kari, Chadi
JO  - Electronic Notes in Theoretical Computer Science
VL  - 351
SP  - 115
EP  - 141
PY  - 2020
DA  - 2020/09/15/
T2  - Proceedings of LSFA 2020, the 15th International Workshop on Logical and Semantic Frameworks, with Applications (LSFA 2020)
SN  - 1571-0661
DO  - https://doi.org/10.1016/j.entcs.2020.08.007
UR  - https://www.sciencedirect.com/science/article/pii/S1571066120300438
KW  - Audit logging
KW  - Concurrent systems
KW  - Programming languages
KW  - Security
AB  - Audit logging provides post-facto analysis of runtime behavior for different purposes, including error detection, amelioration of system operations, and the establishment of security in depth. This necessitates some level of assurance on the quality of the generated audit logs, i.e., how well the audit log represents the events transpired during the execution. Information-algebraic techniques have been proposed to formally specify this relation and provide a framework to study correct audit log generation in a provable fashion. However, previous work fall short on how to guarantee this property of audit logging in concurrent environments. In this paper, we study an implementation model in a concurrent environment. We propose an algorithm that instruments a concurrent system according to a formal specification of audit logging requirements, so that any instrumented concurrent system guarantees correct audit log generation. As an application, we consider systems with microservices architecture, where logging an event by a microservice is conditioned on the occurrence of a collection of events that take place in other microservices of the system.
ER  - 

TY  - JOUR
T1  - A value-oriented Artificial Intelligence-as-a-Service business plan using integrated tools and services
AU  - Hajipour, Vahid
AU  - Hekmat, Siavash
AU  - Amini, Mohammad
JO  - Decision Analytics Journal
VL  - 8
SP  - 100302
PY  - 2023
DA  - 2023/09/01/
SN  - 2772-6622
DO  - https://doi.org/10.1016/j.dajour.2023.100302
UR  - https://www.sciencedirect.com/science/article/pii/S277266222300142X
KW  - Artificial Intelligence-as-a-service
KW  - Industry 4.0
KW  - Machine vision
KW  - Natural language processing
KW  - Data-driven systems
KW  - Heuristic pricing
AB  - The latest developments in Artificial Intelligence (AI) are the focal point in increasing the performance of other technologies and the evolution of Industry 4.0. Considering the benefits of AI in today’s world, businesses must move towards using Integrated AI tools and services. This paper introduces a business model based on AI-as-a-Service (AIaaS), which provides an integrated bundle of AI products and services. The strategic approach, roadmap, and heuristic pricing model provided in this paper can be considered as a benchmark for AIaaS companies.
ER  - 

TY  - JOUR
T1  - MSL: A pattern language for engineering self-adaptive systems
AU  - Arcaini, Paolo
AU  - Mirandola, Raffaela
AU  - Riccobene, Elvinia
AU  - Scandurra, Patrizia
JO  - Journal of Systems and Software
VL  - 164
SP  - 110558
PY  - 2020
DA  - 2020/06/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2020.110558
UR  - https://www.sciencedirect.com/science/article/pii/S0164121220300406
KW  - Pattern-oriented modeling
KW  - Architecture-based self-adaptation
KW  - MAPE-K pattern loops
KW  - Self-adaptive ASMs
KW  - Adaptive smart home systems
AB  - In architecture-based self-adaptation of decentralized systems, design patterns have been introduced to ease the design of complex adaptation solutions that usually require the interaction of different MAPE-K (Monitor-Analyze-Plan-Execute over a shared Knowledge) control loops, each dealing with an adaptation concern of the managed system. Such MAPE patterns have been proposed by means of a graphical notation, but without a well-defined way to document them and to express the semantics of components interactions. In this paper, we propose an approach to overcome these limitations. We present a domain-specific language, called MSL for MAPE Specification Language, to define and instantiate MAPE patterns and to give semantics to some semantic variation points of the equivalent graphical notation for MAPE pattern. We also provide a formal semantics of the language by means of self-adaptive Abstract State Machines, an extension of the Abstract State Machines (ASMs) formalism to model self-adaptation. Such semantics definition comes with an automatic transformation of MSL models into formal executable models, and opens to the possibility of performing rigorous analysis (validation w.r.t. the adaptation requirements and verification of adaptation properties) of MSL models. Moreover, we present our current results toward a (long-term) realization of an MSL-centric framework, where MSL is the notation of a modeling front-end, on top of richer and more specific modeling, analysis, and implementation back-end frameworks. As proof of concept of our approach, we show the application of MSL and its formal support to a running case study in the field of home automation, by modeling an adaptive control of a virtual smart home developed with the OpenHAB runtime platform.
ER  - 

TY  - JOUR
T1  - Towards an extensible model-based digital twin framework for space launch vehicles
AU  - Wei, Ran
AU  - Yang, Ruizhe
AU  - Liu, Shijun
AU  - Fan, Chongsheng
AU  - Zhou, Rong
AU  - Wu, Zekun
AU  - Wang, Haochi
AU  - Cai, Yifan
AU  - Jiang, Zhe
JO  - Journal of Industrial Information Integration
VL  - 41
SP  - 100641
PY  - 2024
DA  - 2024/09/01/
SN  - 2452-414X
DO  - https://doi.org/10.1016/j.jii.2024.100641
UR  - https://www.sciencedirect.com/science/article/pii/S2452414X24000852
KW  - Digital twins
KW  - Model based systems engineering
KW  - Model based digital twins
KW  - Space missions
AB  - The concept of Digital Twin (DT) is increasingly applied to systems on different levels of abstraction across domains, to support monitoring, analysis, diagnosis, decision making and automated control. Whilst the interest in applying DT is growing, the definition of DT is unclear, neither is there a clear pathway to develop DT to fully realise its capacities. In this paper, we revise the concept of DT and its categorisation. We propose a DT maturity matrix, based on which we propose a model-based DT development methodology. We also discuss how model-based tools can be used to support the methodology and present our own supporting tool. We report our preliminary findings with a discussion on a case study, in which we use our proposed methodology and our supporting tool to develop an extensible DT platform for the assurance of Electrical and Electronics systems of space launch vehicles.
ER  - 

TY  - JOUR
T1  - A Predictive Maintenance Application for A Robot Cell using LSTM Model
AU  - Joseph, Doyel
AU  - Gallege, Tilani
AU  - Bekar, Ebru Turanoglu
AU  - Dudas, Catarina
AU  - Skoogh, Anders
JO  - IFAC-PapersOnLine
VL  - 55
IS  - 19
SP  - 115
EP  - 120
PY  - 2022
DA  - 2022/01/01/
T2  - 5th IFAC Workshop on Advanced Maintenance Engineering, Services and Technologies AMEST 2022
SN  - 2405-8963
DO  - https://doi.org/10.1016/j.ifacol.2022.09.193
UR  - https://www.sciencedirect.com/science/article/pii/S2405896322014082
KW  - Smart Maintenance
KW  - Predictive Maintenance
KW  - Machine Learning
KW  - Long Short-Term Memory (LSTM)
KW  - CRISP-DM
KW  - Industrial Robots
KW  - Manufacturing
AB  - Maintaining equipment is critical for increasing production capacity and decreasing production time. With the advent of digitalization, industries are able to access massive amounts of data that can be used to ensure their long-term viability and competitive advantage by implementing predictive maintenance. Therefore, this study aims to demonstrate a predictive maintenance application for a robot cell using real-world manufacturing big data coming from a company in the automotive industry. A hyperparameter tuned Long Short-Term Memory (LSTM) model is developed, and the results show that this model is capable of predicting the day of failure with good accuracy. The difficulties inherent in conducting real-world industrial initiatives are analyzed, and recommendations for improvement are presented.
ER  - 

TY  - JOUR
T1  - To err is human: Managing the risks of contracting AI systems
AU  - Herbosch, Maarten
JO  - Computer Law & Security Review
VL  - 56
SP  - 106110
PY  - 2025
DA  - 2025/04/01/
SN  - 2212-473X
DO  - https://doi.org/10.1016/j.clsr.2025.106110
UR  - https://www.sciencedirect.com/science/article/pii/S0267364925000056
KW  - Artificial Intelligence
KW  - Unilateral mistake
KW  - Automated contracts
KW  - Intent
KW  - Contract validity
KW  - law and technology
KW  - Law and artificial intelligence
KW  - Contract law and AI
AB  - Artificial intelligence (AI) increasingly influences contract law. Applications like virtual home assistants can form contracts on behalf of users, while other AI tools can assist parties in deciding whether to contract. The advent of Generative AI has further accelerated and broadened the proliferation of such applications. However, AI systems are inherently imperfect, sometimes leading to unexpected or undesirable contracts, raising concerns about the legal protection of AI deployers. Some authors have suggested that autonomous AI deployment cannot lead to a legally binding contract in the absence of a human “intent”. Others have argued that the system deployer is completely unprotected in cases of undesirable AI output. They argue that that deployment implies that the deployer should bear the risk of any mistake. This article challenges these views by leveraging existing contract formation and mistake frameworks. Traditional analysis demonstrates that AI deployment can produce valid contracts. It also suggests that deployers may invoke the unilateral mistake doctrine, drawing parallels to clerical errors in human contracts. While AI outputs are probabilistic and unpredictable, similar characteristics apply to human decision-making. The potential benefits of AI development justify affording AI deployers protections analogous to those provided in traditional scenarios. To enhance protection, deployers should use high-performing systems with safeguards such as oversight mechanisms and registration tools. As industry standards evolve, these safeguards will become more defined. The analysis concludes that current contract law frameworks are flexible enough to accommodate AI systems, negating the need for a complete overhaul.
ER  - 

TY  - JOUR
T1  - Role of Ethics in Developing AI-Based Applications in Medicine: Insights From Expert Interviews and Discussion of Implications
AU  - Weidener, Lukas
AU  - Fischer, Michael
JO  - JMIR AI
VL  - 3
PY  - 2024
DA  - 2024/01/01/
SN  - 2817-1705
DO  - https://doi.org/10.2196/51204
UR  - https://www.sciencedirect.com/science/article/pii/S2817170524000048
KW  - artificial intelligence
KW  - AI
KW  - medicine
KW  - ethics
KW  - expert interviews
KW  - AI development
KW  - AI ethics
AB  - Background
The integration of artificial intelligence (AI)–based applications in the medical field has increased significantly, offering potential improvements in patient care and diagnostics. However, alongside these advancements, there is growing concern about ethical considerations, such as bias, informed consent, and trust in the development of these technologies.
Objective
This study aims to assess the role of ethics in the development of AI-based applications in medicine. Furthermore, this study focuses on the potential consequences of neglecting ethical considerations in AI development, particularly their impact on patients and physicians.
Methods
Qualitative content analysis was used to analyze the responses from expert interviews. Experts were selected based on their involvement in the research or practical development of AI-based applications in medicine for at least 5 years, leading to the inclusion of 7 experts in the study.
Results
The analysis revealed 3 main categories and 7 subcategories reflecting a wide range of views on the role of ethics in AI development. This variance underscores the subjectivity and complexity of integrating ethics into the development of AI in medicine. Although some experts view ethics as fundamental, others prioritize performance and efficiency, with some perceiving ethics as potential obstacles to technological progress. This dichotomy of perspectives clearly emphasizes the subjectivity and complexity surrounding the role of ethics in AI development, reflecting the inherent multifaceted nature of this issue.
Conclusions
Despite the methodological limitations impacting the generalizability of the results, this study underscores the critical importance of consistent and integrated ethical considerations in AI development for medical applications. It advocates further research into effective strategies for ethical AI development, emphasizing the need for transparent and responsible practices, consideration of diverse data sources, physician training, and the establishment of comprehensive ethical and legal frameworks.
ER  - 

TY  - JOUR
T1  - From data jungle to data governance in digital ecosystems: Empirical evidence from a multiple holistic case study
AU  - Volz, Felix
AU  - Münch, Christopher
AU  - Lohmüller, Marcel
AU  - Küffner, Christoph
JO  - Journal of Business Research
VL  - 201
SP  - 115747
PY  - 2025
DA  - 2025/12/01/
SN  - 0148-2963
DO  - https://doi.org/10.1016/j.jbusres.2025.115747
UR  - https://www.sciencedirect.com/science/article/pii/S0148296325005703
KW  - Digital ecosystem
KW  - Data governance
KW  - Institutional complexity
KW  - Organizational responses
AB  - With increasing access to external data sources, firms are engaging in digital ecosystems to create data-driven products and services. However, governing data in these multi-actor environments is a critical challenge characterized by the need to reconcile conflicting institutional logics. Applying institutional complexity as theoretical lens, this study utilizes a multiple holistic case study of five digital ecosystems. Our findings reveal that data governance principles are not simply top-down mandates but are emergent institutional arrangements that resolve underlying tensions between actors. Based on this, we develop a framework for data governance comprised of four interdependent pillars. We theorize that these pillars operate as a dynamic control-loop, where continuous mutual adjustment enables ecosystems to adapt and maintain stability in response to internal and external pressures. This study contributes to governance theory by reframing data governance from a static design problem to a continuous process of adaptation.
ER  - 

TY  - JOUR
T1  - Beyond code: Is there a difference between comments in visual and textual languages?
AU  - Boll, Alexander
AU  - Rani, Pooja
AU  - Schultheiß, Alexander
AU  - Kehrer, Timo
JO  - Journal of Systems and Software
VL  - 215
SP  - 112087
PY  - 2024
DA  - 2024/09/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2024.112087
UR  - https://www.sciencedirect.com/science/article/pii/S0164121224001328
KW  - Documentation
KW  - Graphical
KW  - Diagram
KW  - Knowledge-transfer
KW  - Simulink
KW  - Model-driven engineering
KW  - Comment clones
KW  - Taxonomy
AB  - Code comments are crucial for program comprehension and maintenance. To better understand the nature and content of comments, previous work proposed taxonomies of comment information for textual languages, notably classical programming languages. However, paradigms such as model-driven or model-based engineering often promote the use of visual languages, to which existing taxonomies are not directly applicable. Taking MATLAB/Simulink as a representative of a sophisticated and widely used modeling environment, we extend a multi-language comment taxonomy onto new (visual) comment types and two new languages: Simulink and MATLAB. Furthermore, we outline Simulink commenting practices and compare them to textual languages. We analyze 259,267 comments from 9095 Simulink models and 17,792 MATLAB scripts. We identify the comment types, their usage frequency, classify comment information, and analyze their correlations with model metrics. We manually analyze 757 comments to extend the taxonomy. We also analyze commenting guidelines and developer adherence to them. Our extended taxonomy, SCoT (Simulink Comment Taxonomy), contains 25 categories. We find that Simulink comments, although often duplicated, are used at all model hierarchy levels. Of all comment types, Annotations are used most often; Notes scarcely. Our results indicate that Simulink developers, instead of extending comments, add new ones, and rarely follow commenting guidelines. Overall, we find Simulink comment information comparable to textual languages, which highlights commenting practice similarity across languages.
ER  - 

TY  - JOUR
T1  - A comprehensive survey of research towards AI-enabled unmanned aerial systems in pre-, active-, and post-wildfire management
AU  - Boroujeni, Sayed Pedram Haeri
AU  - Razi, Abolfazl
AU  - Khoshdel, Sahand
AU  - Afghah, Fatemeh
AU  - Coen, Janice L.
AU  - O’Neill, Leo
AU  - Fule, Peter
AU  - Watts, Adam
AU  - Kokolakis, Nick-Marios T.
AU  - Vamvoudakis, Kyriakos G.
JO  - Information Fusion
VL  - 108
SP  - 102369
PY  - 2024
DA  - 2024/08/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2024.102369
UR  - https://www.sciencedirect.com/science/article/pii/S1566253524001477
KW  - Wildfire management
KW  - Artificial intelligence (AI)
KW  - Unmanned aerial vehicle (UAV)
KW  - Machine learning
KW  - Deep learning (DL)
KW  - Reinforcement learning (RL)
KW  - Computer vision
AB  - Wildfires have emerged as one of the most destructive natural disasters worldwide, causing catastrophic losses. These losses have underscored the urgent need to improve public knowledge and advance existing techniques in wildfire management. Recently, the use of Artificial Intelligence (AI) in wildfires, propelled by the integration of Unmanned Aerial Vehicles (UAVs) and deep learning models, has created an unprecedented momentum to implement and develop more effective wildfire management. Although existing survey papers have explored learning-based approaches in wildfire, drone use in disaster management, and wildfire risk assessment, a comprehensive review emphasizing the application of AI-enabled UAV systems and investigating the role of learning-based methods throughout the overall workflow of multi-stage wildfire management, including pre-fire (e.g., vision-based vegetation fuel measurement), active-fire (e.g., fire growth modeling), and post-fire tasks (e.g., evacuation planning) is notably lacking. This survey synthesizes and integrates state-of-the-science reviews and research at the nexus of wildfire observations and modeling, AI, and UAVs — topics at the forefront of advances in wildfire management, elucidating the role of AI in performing monitoring and actuation tasks from pre-fire, through the active-fire stage, to post-fire management. To this aim, we provide an extensive analysis of the existing remote sensing systems with a particular focus on the UAV advancements, device specifications, and sensor technologies relevant to wildfire management. We also examine the pre-fire and post-fire management approaches, including fuel monitoring, prevention strategies, as well as evacuation planning, damage assessment, and operation strategies. Additionally, we review and summarize a wide range of computer vision techniques in active-fire management, with an emphasis on Machine Learning (ML), Reinforcement Learning (RL), and Deep Learning (DL) algorithms for wildfire classification, segmentation, detection, and monitoring tasks. Ultimately, we underscore the substantial advancement in wildfire modeling through the integration of cutting-edge AI techniques and UAV-based data, providing novel insights and enhanced predictive capabilities to understand dynamic wildfire behavior.
ER  - 

TY  - JOUR
T1  - Discrete Bayesian Optimization via Machine Learning
AU  - Sala, Roberto
AU  - Guindani, Bruno
AU  - Ardagna, Danilo
AU  - Guglielmi, Alessandra
JO  - Performance Evaluation
VL  - 169
SP  - 102487
PY  - 2025
DA  - 2025/09/01/
SN  - 0166-5316
DO  - https://doi.org/10.1016/j.peva.2025.102487
UR  - https://www.sciencedirect.com/science/article/pii/S0166531625000215
KW  - Discrete variables
KW  - Bayesian Optimization
KW  - Machine learning
KW  - Black-box optimization
KW  - Cloud computing
AB  - Bayesian Optimization (BO) is a family of powerful algorithms designed to solve complex optimization problems involving expensive black-box functions. These sequential algorithms iteratively update a surrogate model of the objective function (OF), effectively balancing exploration and exploitation to identify near-optimal solutions within a limited number of iterations. Originally designed for continuous, unconstrained domains, its efficiency has inspired adaptations for discrete, constrained optimization problems. On the other hand, Machine Learning (ML) models allow accurate predictions for black-box functions, although they typically require large amounts of data for training. Leveraging the strengths of BO and ML, research tackles the challenge of identifying optimal configurations in the context of cloud computing. This paradigm has become pervasive due to its ability to provide flexible and scalable resources. Identifying the optimal hardware-software configuration is essential for minimizing costs while meeting Quality of Service constraints. This task involves solving complex optimization problems over multidimensional discrete domains and black-box objective functions and constraints, within a limited number of iterations. To address this challenge, this work introduces d-MALIBOO, a BO-based algorithm that integrates ML techniques to enhance the efficiency of finding near-optimal solutions in discrete and bounded domains. While BO builds the surrogate model of the OF, ML models determine the feasible region of the black-box constraints and guide the BO algorithm toward promising regions of the discrete domain. Furthermore, we introduce an ɛ-greedy approach to favor exploration in domains with multiple local optima. Experimental results show that our algorithm outperforms OpenTuner, a popular framework for constrained optimization, by reducing the average regret by 29%, and SVM-CBO, a BO-based algorithm that integrates SVM models to determine the feasible region, by 82%.
ER  - 

TY  - JOUR
T1  - Exploiting deep transformer models in textual review based recommender systems
AU  - Gheewala, Shivangi
AU  - Xu, Shuxiang
AU  - Yeom, Soonja
AU  - Maqsood, Sumbal
JO  - Expert Systems with Applications
VL  - 235
SP  - 121120
PY  - 2024
DA  - 2024/01/01/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2023.121120
UR  - https://www.sciencedirect.com/science/article/pii/S0957417423016226
KW  - Information systems
KW  - Recommender systems
KW  - Deep learning
KW  - Deep transformers
KW  - Textual reviews
AB  - Textual reviews contain fine-grained information that can effectively infer user preferences over the items. Accordingly, the latest studies in the field of recommender systems exploit content-rich review texts to complement user and item representations and improve the ability to make personalized recommendations. Furthermore, the interactive deep learning mechanism can better model the user-item interaction from fine-grained textual reviews compared to traditional recommendation approaches improving the predictive performances. Therefore, it becomes important to investigate the design of existing deep learning methods for review-based recommender systems and innovate to make them capable of meeting desired recommendation schemes. The purpose of this research is to explore the performance of deep learning networks and deep transformer models in review-based recommender systems. In this paper, we conduct a compendious survey of the latest deep learning techniques in review-based recommender systems. Then investigation calls to employ and analyze deep transformer models for the review-based recommender systems. The wide range of experiments shows that deep transformer models can extract interpretable and relevant user/item representations than traditional deep learning networks. The findings indicate that the best deep transformer performance gains the maximum relative improvement (RMSE = 4.6%, MAE = 7.4%) with Amazon electronics, compared to the best outcome from traditional deep learning networks. In the end, this article highlights research gaps and outlines research opportunities for future research in this field.
ER  - 

TY  - JOUR
T1  - A survey on uncertainty reasoning and quantification in belief theory and its application to deep learning
AU  - Guo, Zhen
AU  - Wan, Zelin
AU  - Zhang, Qisheng
AU  - Zhao, Xujiang
AU  - Zhang, Qi
AU  - Kaplan, Lance M.
AU  - Jøsang, Audun
AU  - Jeong, Dong H.
AU  - Chen, Feng
AU  - Cho, Jin-Hee
JO  - Information Fusion
VL  - 101
SP  - 101987
PY  - 2024
DA  - 2024/01/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2023.101987
UR  - https://www.sciencedirect.com/science/article/pii/S1566253523003032
KW  - Belief theory
KW  - Uncertainty reasoning
KW  - Uncertainty quantification
KW  - Decision making
KW  - Machine/deep learning
AB  - An in-depth understanding of uncertainty is the first step to making effective decisions under uncertainty. Machine/deep learning (ML/DL) has been hugely leveraged to solve complex problems involved with processing high-dimensional data. However, reasoning and quantifying different uncertainties to achieve effective decision-making have been much less explored in ML/DL than in other Artificial Intelligence (AI) domains. In particular, belief/evidence theories have been studied in Knowledge representation and reasoning (KRR) since the 1960s to reason and measure uncertainties to enhance decision-making effectiveness. Based on our in-depth literature review, only a few studies have leveraged mature uncertainty research in belief/evidence theories in ML/DL to tackle complex problems under different types of uncertainty. Our present survey paper discusses major belief theories and their core ideas dealing with uncertainty causes and types and quantifying them, along with the discussions of their applicability in ML/DL. Particularly, we discuss three main approaches leveraging belief theories in Deep Neural Networks (DNNs), including Evidential DNNs, Fuzzy DNNs, and Rough DNNs, in terms of their uncertainty causes, types, and quantification methods along with their applicability in diverse problem domains. Through an in-depth understanding of the extensive survey on this topic, we discuss insights, lessons learned, limitations of the current state-of-the-art bridging belief theories and ML/DL, and future research directions. This paper conducts an extensive survey by bridging belief theories and deep learning in reasoning and quantifying uncertainty to help researchers initiate uncertainty and decision-making research.
ER  - 

TY  - JOUR
T1  - HL-DPoS: An enhanced anti-long-range attack DPoS algorithm
AU  - Li, Yang
AU  - Xia, Chunhe
AU  - Li, Chunyan
AU  - Zhao, Yuan
AU  - Chen, Chen
AU  - Wang, Tianbo
JO  - Computer Networks
VL  - 249
SP  - 110473
PY  - 2024
DA  - 2024/07/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2024.110473
UR  - https://www.sciencedirect.com/science/article/pii/S1389128624003050
KW  - Blockchain
KW  - Consensus algorithm
KW  - Game theory
KW  - Verify random function
AB  - The consensus algorithm is crucial in blockchain for ensuring the validity and security of transactions across the decentralized network. However, achieving consensus among nodes and packaging blocks in blockchain networks is a complex task that requires efficient and secure consensus algorithms. The DPoS consensus algorithm has emerged as a popular choice due to its fast transaction processing and high throughput. Despite these advantages, the algorithm still suffers from weaknesses such as centralization and vulnerability to long-range attacks, which can compromise the integrity of the blockchain network. To combat these problems, we developed an Enhanced Anti-Long-Range Attack DPoS algorithm (HL-DPoS). First, we split nodes into pieces to reduce centralization issues while giving witness nodes the power to report and benefit from malicious node’s reports, maintaining high efficiency and high security. Second, we propose a validation method in HL-DPoS that compares consensuses transactions with the longest chain to detect long-range attacks. Algorithm analysis and simulation experiment results demonstrate that our HL-DPoS consensus algorithm improves security while achieving better consensus performance.
ER  - 

TY  - JOUR
T1  - Deep learning techniques for hand vein biometrics: A comprehensive review
AU  - Hemis, Mustapha
AU  - Kheddar, Hamza
AU  - Bourouis, Sami
AU  - Saleem, Nasir
JO  - Information Fusion
VL  - 114
SP  - 102716
PY  - 2025
DA  - 2025/02/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2024.102716
UR  - https://www.sciencedirect.com/science/article/pii/S1566253524004949
KW  - Biometrics
KW  - Finger vein recognition
KW  - Palm vein recognition
KW  - Dorsal hand vein
KW  - Deep learning
KW  - Transfer learning
AB  - Biometric authentication has garnered significant attention as a secure and efficient method of identity verification. Among the various modalities, hand vein biometrics, including finger vein, palm vein, and dorsal hand vein recognition, offer unique advantages due to their high accuracy, low susceptibility to forgery, and non-intrusiveness. The vein patterns within the hand are highly complex and distinct for each individual, making them an ideal biometric identifier. Additionally, hand vein recognition is contactless, enhancing user convenience and hygiene compared to other modalities such as fingerprint or iris recognition. Furthermore, the veins are internally located, rendering them less susceptible to damage or alteration, thus enhancing the security and reliability of the biometric system. The combination of these factors makes hand vein biometrics a highly effective and secure method for identity verification. This review paper delves into the latest advancements in deep learning techniques applied to finger vein, palm vein, and dorsal hand vein recognition. It encompasses all essential fundamentals of hand vein biometrics, summarizes publicly available datasets, and discusses state-of-the-art metrics used for evaluating the three modes. Moreover, it provides a comprehensive overview of suggested approaches for finger, palm, dorsal, and multimodal vein techniques, offering insights into the best performance achieved, data augmentation techniques, and effective transfer learning methods, along with associated pretrained deep learning models. Additionally, the review addresses research challenges faced and outlines future directions and perspectives, encouraging researchers to enhance existing methods and propose innovative techniques.
ER  - 

TY  - JOUR
T1  - The decentralisation defence
AU  - Kokorin, Ilya
JO  - Computer Law & Security Review
VL  - 57
SP  - 106148
PY  - 2025
DA  - 2025/07/01/
SN  - 2212-473X
DO  - https://doi.org/10.1016/j.clsr.2025.106148
UR  - https://www.sciencedirect.com/science/article/pii/S2212473X25000215
KW  - Decentralised finance
KW  - Decentralisation
KW  - Crypto exchange
KW  - Liability
KW  - AI
KW  - Software developers
KW  - User interface
AB  - This article explores the phenomenon of the decentralisation defence, which refers to instances where ‘decentralisation’ is invoked either as a shield against liability or as insulation from the reach of the law. This defence is rooted in the technological features of distributed ledger technology and smart contracts built on the blockchain settlement layer, including pseudonymity, programmability, immutability and decentralisation. Together, these features enable transactions while reducing reliance on centralised intermediaries. Although major decentralised finance (DeFi) applications, such as decentralised crypto exchanges, are not harmful per se, their misuse by bad actors creates risks for market participants. The recent cases of Uniswap Labs and Tornado Cash illustrate that the decentralisation defence can result in unaddressed harms and produce other negative externalities. These outcomes have prompted efforts to identify regulatory hooks along the centralisation vectors. The search for a responsible party in blockchain-enabled decentralised arrangements resembles processes observed with two other key technological advancements in the digital space – the internet and artificial intelligence. Drawing inspiration from the modern EU regulation of these transformative technologies, this article focuses on the role of user interfaces as DeFi gatekeepers, and software developers engaged in the creation of smart contract code and blockchain protocols.
ER  - 

TY  - JOUR
T1  - CitySpec with shield: A secure intelligent assistant for requirement formalization
AU  - Chen, Zirong
AU  - Li, Isaac
AU  - Zhang, Haoxiang
AU  - Preum, Sarah
AU  - Stankovic, John A.
AU  - Ma, Meiyi
JO  - Pervasive and Mobile Computing
VL  - 92
SP  - 101802
PY  - 2023
DA  - 2023/05/01/
SN  - 1574-1192
DO  - https://doi.org/10.1016/j.pmcj.2023.101802
UR  - https://www.sciencedirect.com/science/article/pii/S1574119223000603
KW  - Requirement specification
KW  - Intelligent assistant
KW  - Monitoring
KW  - Safety shield
KW  - Smart city
AB  - An increasing number of monitoring systems have been developed in smart cities to ensure that a city’s real-time operations satisfy safety and performance requirements. However, many existing city requirements are written in English with missing, inaccurate, or ambiguous information. There is a high demand for assisting city policymakers in converting human-specified requirements to machine-understandable formal specifications for monitoring systems. To tackle this limitation, we build CitySpec (Chen et al., 2022), the first intelligent assistant system for requirement specification in smart cities. To create CitySpec, we first collect over 1,500 real-world city requirements across different domains (e.g., transportation and energy) from over 100 cities and extract city-specific knowledge to generate a dataset of city vocabulary with 3,061 words. We also build a translation model and enhance it through requirement synthesis and develop a novel online learning framework with shielded validation. The evaluation results on real-world city requirements show that CitySpec increases the sentence-level accuracy of requirement specification from 59.02% to 86.64%, and has strong adaptability to a new city and a new domain (e.g., the F1 score for requirements in Seattle increases from 77.6% to 93.75% with online learning). After the enhancement from the shield function, CitySpec is now immune to most known textual adversarial inputs (e.g., the attack success rate of DeepWordBug (Gao et al., 2018) after the shield function is reduced to 0% from 82.73%). We test the CitySpec with 18 participants from different domains. CitySpec shows its strong usability and adaptability to different domains, and also its robustness to malicious inputs.
ER  - 

TY  - JOUR
T1  - A literature review of fault diagnosis based on ensemble learning
AU  - Mian, Zhibao
AU  - Deng, Xiaofei
AU  - Dong, Xiaohui
AU  - Tian, Yuzhu
AU  - Cao, Tianya
AU  - Chen, Kairan
AU  - Jaber, Tareq Al
JO  - Engineering Applications of Artificial Intelligence
VL  - 127
SP  - 107357
PY  - 2024
DA  - 2024/01/01/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2023.107357
UR  - https://www.sciencedirect.com/science/article/pii/S0952197623015415
KW  - Ensemble learning
KW  - Fault diagnosis
KW  - Intelligent maintenance
KW  - System reliability
AB  - The accuracy of fault diagnosis is an important indicator to ensure the reliability of key equipment systems. Ensemble learning integrates different weak learning methods to obtain stronger learning and has achieved remarkable results in the field of fault diagnosis. This paper reviews the recent research on ensemble learning from both technical and field application perspectives. The paper summarizes 87 journals in recent web of science and other academic resources, with a total of 209 papers. It summarizes 78 different ensemble learning based fault diagnosis methods, involving 18 public datasets and more than 20 different equipment systems. In detail, the paper summarizes the accuracy rates, fault classification types, fault datasets, used data signals, learners (traditional machine learning or deep learning-based learners), ensemble learning methods (bagging, boosting, stacking and other ensemble models) of these fault diagnosis models. The paper uses accuracy of fault diagnosis as the main evaluation metrics supplemented by generalization and imbalanced data processing ability to evaluate the performance of those ensemble learning methods. The discussion and evaluation of these methods lead to valuable research references in identifying and developing appropriate intelligent fault diagnosis models for various equipment. This paper also discusses and explores the technical challenges, lessons learned from the review and future development directions in the field of ensemble learning based fault diagnosis and intelligent maintenance.
ER  - 

TY  - JOUR
T1  - Designing a composite deep learning based differential protection scheme of power transformers
AU  - Afrasiabi, Shahabodin
AU  - Afrasiabi, Mousa
AU  - Parang, Benyamin
AU  - Mohammadi, Mohammad
JO  - Applied Soft Computing
VL  - 87
SP  - 105975
PY  - 2020
DA  - 2020/02/01/
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2019.105975
UR  - https://www.sciencedirect.com/science/article/pii/S1568494619307562
KW  - Differential protection
KW  - Power transformers
KW  - Inrush current
KW  - Internal fault
KW  - Deep learning
KW  - Convolutional neural network (CNN)
KW  - Light gated recurrent unit (LGRU)
AB  - This paper proposes a novel differential protection scheme based on deep neural networks (DNN). The goal is to propose a fast, reliable, and independent protection scheme in distinguishing inrush current from internal fault in power transformers, as the most challenging issue in power transformers protection. Shallow-based techniques require spectral analysis and handcraft feature extraction to be proper methods in this major. However, they require a significant computational cost. In order to address this issue, in this paper, a novel DNN-based approach is proposed based on combining convolutional neural network (CNN) and light-gated recurrent unit (LGRU), namely CLGNN. The results show a more accurate and more reliable performance than three different shallow and three state-of-the-art DNN based techniques. Adaptability and robustness of the proposed scheme are evaluated considering CT saturation, superconducting fault current limiter (SFCL), and series compensation impacts. The obtained results prove the effectiveness and validity of the proposed DNN-based protection scheme in this paper.
ER  - 

TY  - JOUR
T1  - Authentication and Authorization in Modern Web Apps for Data Security Using Nodejs and Role of Dark Web
AU  - Pant, Piyush
AU  - Rajawat, Anand Singh
AU  - Goyal, S.B.
AU  - Bedi, Pradeep
AU  - Verma, Chaman
AU  - Raboaca, Maria Simona
AU  - Enescu, Florentina Magda
JO  - Procedia Computer Science
VL  - 215
SP  - 781
EP  - 790
PY  - 2022
DA  - 2022/01/01/
T2  - 4th International Conference on Innovative Data Communication Technology and Application
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2022.12.080
UR  - https://www.sciencedirect.com/science/article/pii/S1877050922021512
KW  - Artificial Intelligence
KW  - Authentication
KW  - Authorization
KW  - Blockchain
KW  - NodeJS
KW  - Hashing Algorithm
KW  - Dark Web
KW  - MongoDB
AB  - Authentication and Authorization are the base of security for all the Technologies present in this world today. Starting from your smartphone where a user authenticates himself before he could access the data inside to Entering into the White House, you must authenticate yourself, and based on that you are authorized. In this digital world where every Business, MNC, Government Body, Companies, Users, etc. needs a website to inform the world about their presence on the internet, provide services online and become a “Brand”, the risk of leaking user's sensitive information increases. It could be dangerous to the users of the hacked website because their sensitive information like a credit card, bank account details, etc. could be sold in the black market of the “dark web”. The role of the dark web is described in the paper and how the data is sold there and what becomes of it. The paper helps to understand how a secure website is developed that promises the user to keep the sensitive information safe, increases the bond of trust between a client and server which results in a long-term relationship. The aim behind developing an authentication system is to keep users’ sensitive information safe so that hackers cannot steal and sell the information on the dark web's back market. To perform this, the developer needs to understand how to implement authentication. NodeJS, with the help of its framework expressJS and some other packages, is used to develop the authentication and authorization system of the website by the research. Previous papers on this field covered the authentication topic in general. This paper overcame that by going deeper into the field and being server-side language specific. The common types of authentication methods used in different types of websites are discussed in detail and the best methods are purposed for the developer to be implemented for a more secure website. This research put light on Artificial Intelligence and blockchain as the future of security of big data.
ER  - 

TY  - JOUR
T1  - Evaluation of clinical practice guideline-derived clinical decision support systems using a novel quality model
AU  - García-García, Julián Alberto
AU  - Carrero, Manuel
AU  - Escalona, María José
AU  - Lizcano, David
JO  - Journal of Biomedical Informatics
VL  - 149
SP  - 104573
PY  - 2024
DA  - 2024/01/01/
SN  - 1532-0464
DO  - https://doi.org/10.1016/j.jbi.2023.104573
UR  - https://www.sciencedirect.com/science/article/pii/S1532046423002940
KW  - Comparative studies
KW  - Clinical practice guideline
KW  - Clinical decision support system
KW  - Quality model
AB  - Over the last decade, clinical practice guidelines (CPGs) have become an important asset for daily life in healthcare organizations. Efficient management and digitization of CPGs help achieve organizational objectives and improve patient care and healthcare quality by reducing variability. However, digitizing CPGs is a difficult, complex task because they are usually expressed as text, and this often leads to the development of partial software solutions. At present, different research proposals and CPG-derived CDSS (clinical decision support system) do exist for managing CPG digitalization lifecycles (from modeling to deployment and execution), but they do not all provide full lifecycle support, making it more difficult to choose solutions or proposals that fully meet the needs of a healthcare organization. This paper proposes a method based on quality models to uniformly compare and evaluate technological tools, providing a rigorous method that uses qualitative and quantitative analysis of technological aspects. In addition, this paper also presents how this method has been instantiated to evaluate and compare CPG-derived CDSS by highlighting each phase of the CPG digitization lifecycle. Finally, discussion and analysis of currently available tools are presented, identifying gaps and limitations.
ER  - 

TY  - JOUR
T1  - Barriers to district heating deployment: insights from literature and experts
AU  - Sneum, Daniel Møller
AU  - Billerbeck, Anna
AU  - Kachirayil, Febin
AU  - McKenna, Russell
JO  - Energy Policy
VL  - 206
SP  - 114780
PY  - 2025
DA  - 2025/11/01/
SN  - 0301-4215
DO  - https://doi.org/10.1016/j.enpol.2025.114780
UR  - https://www.sciencedirect.com/science/article/pii/S0301421525002873
KW  - Barriers
KW  - District heating
KW  - District energy
KW  - Expert survey
KW  - Review
KW  - Sector coupling
AB  - Over the last century, district heating (DH) has only achieved global market shares of around 10 %. To reach its potential market shares of 25–50 % in Europe by 2050, growth must drastically accelerate. But deployment of DH is hindered by barriers, potentially slowing this fast-paced transition of the heat system. In this paper, we identify barriers to the deployment of DH through manual and GPT-aided literature reviews. These reviews are complemented by a survey of 94 DH experts from Europe and North America, regions which account for approximately 20 % of global- and 93 % of European DH supply. We find that economic and political barriers are considered both most significant and most difficult to overcome. The importance of individual barriers varies between countries based on the existing shares of DH and renewable heat in DH supply respectively. The most important individual barriers include high installation costs, regulatory uncertainty and insufficient policies to integrate DH with other energy sectors. If a faster pace of system-integrated DH deployment is desired, it is critical to reduce the underlying investment risk of district heating projects through an expansion of integrated energy system planning, and regulations such as zoning and mandates.
ER  - 

TY  - JOUR
T1  - STTraj2Vec: A spatio-temporal trajectory representation learning approach
AU  - Zhu, Jiahui
AU  - Niu, Xinzheng
AU  - Li, Fan
AU  - Wang, Yixuan
AU  - Fournier-Viger, Philippe
AU  - She, Kun
JO  - Knowledge-Based Systems
VL  - 300
SP  - 112207
PY  - 2024
DA  - 2024/09/27/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2024.112207
UR  - https://www.sciencedirect.com/science/article/pii/S0950705124008414
KW  - Trajectory similarity computation
KW  - Representation learning
KW  - Point-region quadtree
KW  - Transformer
KW  - Spatio-temporal random walk
AB  - Computing trajectory similarity plays a critical role in various spatio-temporal applications that involve trajectory analysis. In recent years, trajectory representation learning has been extensively studied and applied for trajectory similarity calculation. However the majority of existing algorithms for trajectory representation generally have two problems. The first problem is the emphasis of spatial similarity over temporal similarity, and even to discard the temporal dimension of spatio-temporal trajectories. As a result, the outputs of these approaches cannot fully represent the similarity of spatio-temporal trajectories. The second problem is the introduction of additional information, such as the topology of the road network, which increases the uncertainty of capturing the spatio-temporal correlation of trajectories and prevents their application in scenarios where it is difficult to obtain such information. This poses a significant challenge when dealing with complex and time-varying traffic networks. This paper proposes a novel method, named STTraj2Vec (Spatio-temporal Trajectory 2 Vector), which relies only on spatio-temporal trajectories to capture their similarity without spatio-temporal separation. This takes into account the whole spatio-temporal trajectory information. In this method, an extended clustering algorithm is introduced, which maps the trajectory into a point-region quadtree, and constructs a time-varying virtual network structure based on the point-region quadtree. In this method, an extended clustering algorithm is introduced, which maps each trajectory into a point-region quadtree, and then completes density clustering through the adjacency relation of leaf nodes to construct a time-varying virtual network structure. This virtual network structure not only considers the spatial proximity, but also the time, so as to reflect the spatio-temporal characteristics of the trajectory more accurately. Then, a novel spatially and temporally integrated random walk algorithm is designed, which carries out spatiotemporal random walk on the virtual network structure, to capture the spatiotemporal characteristics of the trajectory, and thus obtains the representation of all nodes in the virtual network. Furthermore, each trajectory is converted into a sequence of vectors on the virtual road network according to the latitude, longitude, and time of the trajectory points. Finally, based on these node representations and trajectories, a transformer model with ranking loss is employed to capture the distinct contributions of the various locations and times to the similarity computation and encode each sequence of vectors into target vectors. Experiments on two public datasets show that STTraj2Vec is superior to the state-of-the-art methods in terms of effectiveness for top-k trajectory similarity search and trajectory clustering, while exhibiting low parameter sensitivity and high model robustness.
ER  - 

TY  - JOUR
T1  - Can the consumer perception of corporate social responsibility be saved? An examination into the effects of corporate greenwashing on the consumer and financial market
AU  - Teichmann, Fabian Maximilian Johannes
AU  - Wittmann, Chiara
AU  - Boticiu, Sonia Ruxandra
AU  - Sergi, Bruno Sergio S
JO  - Journal of Financial Crime
VL  - 31
IS  - 6
SP  - 1320
EP  - 1331
PY  - 2024
DA  - 2024/03/21/
SN  - 1359-0790
DO  - https://doi.org/10.1108/JFC-11-2023-0303
UR  - https://www.sciencedirect.com/science/article/pii/S1359079024000113
KW  - Greenwashing behaviour
KW  - Marketplace trust
KW  - Investor trust
KW  - Environmental regulation
AB  - Purpose
The purpose of this paper is to examine the influence that the occurrence of greenwashing has on the consumer perception of corporate social responsibility (CSR).
Design/methodology/approach
This paper observed the market indication that a consistent undermining of authentic commitment to CSR taints consumer perception. Investigating how the motivations behind greenwashing contribute to the presentation of CSR was the first means of examining the market forces. Consumer orientation was used as a guiding principle to consider the short- and long-term perspective of a greenwasher.
Findings
Individual instances of greenwashing contribute to a collective deterioration of marketplace trust in the promises of CSR. The negative influence on CSR is not isolated to the greenwashing perpetrator but casts a wider effect. The consequences of greenwashing are not isolated but widely dispersed.
Originality/value
Whilst much of the literature focuses on the stigmatisation of individual firms, it is crucial to note how marketplace trust is eroded. In addition, the perception of CSR-related regulations is for example influenced but rarely recognised as a consequence of greenwashing behaviour.
ER  - 

TY  - JOUR
T1  - Capturing institutional logics and the construction of digital technologies: A macro-discursive perspective using formal text analysis methods
AU  - Poschmann, Philipp
JO  - Information and Organization
VL  - 35
IS  - 4
SP  - 100598
PY  - 2025
DA  - 2025/12/01/
SN  - 1471-7727
DO  - https://doi.org/10.1016/j.infoandorg.2025.100598
UR  - https://www.sciencedirect.com/science/article/pii/S1471772725000442
KW  - Digital technologies
KW  - Meaning
KW  - Institutional logics
KW  - Macro-discourse
KW  - Natural language processing
KW  - Topic modeling
KW  - Word embeddings
AB  - Research suggests that the meanings of new technologies in the digital age are constructed through discourses shaped by diverse actors and a variety of social, material, and institutional aspects. This paper introduces a novel methodological approach that enables large-scale investigations into the construction of the meanings of these technologies from a macro-discursive perspective. This macro-discursive perspective allows researchers to capture and analyze overarching patterns of the aspects that shape a technology's meaning in discourses at the macro level. Specifically, the methodological approach involves analyzing texts to capture the co-occurrence of social actors, problems, and solutions associated with a particular technology, as well as the prevalence of institutional logics' symbolic representations. The approach is grounded in theoretical insights from the social construction of technology (SCOT) and institutional logics. On a technical level, this paper proposes that the methodological approach presented can be implemented by combining formal methods of text analysis. Three methods will be discussed in detail: named-entity recognition, topic modeling, and word embeddings. The practical application of this methodological approach will be demonstrated in an empirical illustration based on the public discourse surrounding artificial intelligence in Germany from 2015 to 2022.
ER  - 

TY  - JOUR
T1  - Automated program repair for variability bugs in software product line systems
AU  - Nguyen, Thu-Trang
AU  - Zhang, Xiao-Yi
AU  - Arcaini, Paolo
AU  - Ishikawa, Fuyuki
AU  - Vo, Hieu Dinh
JO  - Journal of Systems and Software
VL  - 221
SP  - 112152
PY  - 2025
DA  - 2025/03/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2024.112152
UR  - https://www.sciencedirect.com/science/article/pii/S0164121224001973
KW  - Software product line
KW  - Variability bugs
KW  - Automated program repair
AB  - Software product line (SPL) systems are widely employed to develop industrial projects. For an SPL system, different products/variants are created by combining different subsets of the system features. Because of the interaction of the different features, a bug in the system could cause failures for some products (failing products), but not for others (passing products); such types of bugs are called variability bugs. Due to their variability characteristics, detecting and fixing bugs in SPL systems is challenging. There are several solutions for localizing buggy statements in these systems. However, there is still a lack of research on automatically fixing these bugs. In this work, we aim to make the first attempt at automatically fixing buggy statements in the source code of SPL systems. This paper proposes two approaches, single-product-based and multi-product-based, to repair the variability bugs in an SPL system to fix the failures of the failing products and not to break the correct behaviors of the passing products. For the single-product-based approach, each failing product is fixed individually, and the obtained patches are then propagated and validated on the other products of the system. For the multi-product-based approach, all the products are repaired simultaneously. The patches are generated and validated by all the sampled products of the system in each repair iteration. Moreover, to improve the repair performance of both approaches, we also introduce several heuristic rules for effectively and efficiently deciding where to fix (navigating modification points) and how to fix (selecting suitable modifications). These heuristic rules use intermediate validation results of the repaired programs as feedback to refine the fault localization results and evaluate the suitability of the modifications before actually applying and validating them by test execution. Our experimental results on a dataset of 318 variability bugs of five popular SPL systems show that the single-product-based approach is around 20 times better than the multi-product-based approach in the number of correct fixes. Notably, the heuristic rules could improve the performance of both approaches by increasing of 30%–150% the number of correct fixes, and decreasing of 30%–50% the number of attempted modification operations.
ER  - 

TY  - JOUR
T1  - Towards practical cancelable biometrics for finger vein recognition
AU  - Kauba, Christof
AU  - Piciucco, Emanuela
AU  - Maiorana, Emanuele
AU  - Gomez-Barrero, Marta
AU  - Prommegger, Bernhard
AU  - Campisi, Patrizio
AU  - Uhl, Andreas
JO  - Information Sciences
VL  - 585
SP  - 395
EP  - 417
PY  - 2022
DA  - 2022/03/01/
SN  - 0020-0255
DO  - https://doi.org/10.1016/j.ins.2021.11.018
UR  - https://www.sciencedirect.com/science/article/pii/S0020025521011385
KW  - Biometrics
KW  - Template protection scheme
KW  - Cancelable biometrics
KW  - Finger vein recognition
KW  - Bloom filters
AB  - Biometrics has nowadays become a preferred solution for systems requiring secure authentication. However, the usage of biometric characteristics raises significant concerns regarding personal data protection and privacy. Several template protection schemes have been therefore proposed to conceal the employed identifiers, while still ensuring the ability to efficiently recognise users. In this paper, we propose and analyse three different approaches generating cancelable templates from finger vein features. A thorough analysis of the considered methods is conducted to investigate their impact on the achievable recognition performance, as well as their security in terms of renewability and unlinkability. Furthermore, a specific attack is designed to evaluate the irreversibility of the protection scheme providing the best recognition performance.
ER  - 

TY  - JOUR
T1  - State of charge estimation of lithium-ion batteries using improved multi-attention long short-term memory extended Kalman filtering model
AU  - Bobobee, Etse Dablu
AU  - Wang, Shunli
AU  - Takyi-Aninakwa, Paul
AU  - Liu, Guangchen
AU  - Koukoyi, Ebenezer
JO  - Engineering Applications of Artificial Intelligence
VL  - 158
SP  - 111526
PY  - 2025
DA  - 2025/10/15/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2025.111526
UR  - https://www.sciencedirect.com/science/article/pii/S0952197625015283
KW  - Lithium-ion batteries
KW  - State of charge
KW  - Multi-attention
KW  - Long short-term memory
KW  - Extended Kalman filter
KW  - Temperature compensation
AB  - An improved multi-attention long short-term memory extended Kalman filtering (MALSTM-EKF) model is proposed for high-precision state of charge (SOC) estimation of lithium-ion batteries. The model integrates a multi-head attention mechanism into the long short-term memory (LSTM) to enhance temporal feature extraction and accelerate learning by focusing on relevant information at each time step. The MALSTM model first provides an initial SOC estimation, which is then refined through an EKF for noise filtering and state correction, ensuring enhanced accuracy and robustness under dynamic conditions. This combination provides higher accuracy and stability, especially in complex battery conditions. The University of Maryland's public dataset for the A123 18650 LiFePO4 battery validates the model, covering diverse temperatures and complex working conditions. Performance comparisons with the adaptive EKF (AEKF), conventional LSTM, and MALSTM models show that the proposed MALSTM-EKF achieves faster convergence and higher accuracy. Key evaluation metrics indicate a root mean square error (RMSE) of 0.343 %, a mean absolute error (MAE) of 0.236 %, and a mean absolute percentage error (MAPE) of 1.135 %. Additionally, a statistical analysis of variance (ANOVA) confirms that the performance differences between models are statistically significant, validating the superiority of the MALSTM-EKF. The results highlight its effectiveness for real-world applications, such as electric vehicles (EVs), which ensure optimal energy management and driving range, and renewable energy systems, improving power distribution and grid stability. The findings establish the improved MALSTM-EKF as a robust and reliable SOC estimation method, surpassing existing techniques in precision and adaptability across varying conditions.
ER  - 

TY  - JOUR
T1  - Integrating the pressure-state-response model with the extension catastrophe progression for flood risk and resilience assessment
AU  - Band, Shahab S.
AU  - Qasem, Sultan Noman
AU  - Eslami, Sajad
AU  - Mansor, Zulkefli
AU  - Gupta, Brij B.
AU  - Pai, Hao-Ting
AU  - Biyari, Meghdad
AU  - Mosavi, Amir
AU  - Sajedi Hosseini, Farzaneh
JO  - Environmental and Sustainability Indicators
VL  - 27
SP  - 100727
PY  - 2025
DA  - 2025/09/01/
SN  - 2665-9727
DO  - https://doi.org/10.1016/j.indic.2025.100727
UR  - https://www.sciencedirect.com/science/article/pii/S2665972725001485
KW  - Flood
KW  - Risk
KW  - Resilience
KW  - Pressure-state-response model
KW  - Extension catastrophe progression method
AB  - Despite the devastating effects of floods, the concept of resilience is still not fully considered in the assessment and management of flood risk. To study how resilience can lower the risk of floods and further enhance disaster response, this research aims to close this knowledge gap. With a focus on the Kashkan watershed in Iran, the study combines the extended catastrophe progression method with the pressure-state-response model. Three catastrophe models, namely the cusp, swallowtail, and butterfly, are applied. According to the findings, southern regions, i.e., Pol-Dokhtar city, have the highest risk of floods and the lowest resilience. Resilience and flood risk have a complementary relationship, according to the analysis, and resilience is a helpful metric for risk assessment. The results emphasize the necessity to incorporate resilience-focused pre-disruption planning and post-disaster recovery into flood risk management strategy. This work offers a foundation to incorporate resilience into future flood policies and strategies.
ER  - 

TY  - JOUR
T1  - A review of sentiment analysis research in Arabic language
AU  - Oueslati, Oumaima
AU  - Cambria, Erik
AU  - HajHmida, Moez Ben
AU  - Ounelli, Habib
JO  - Future Generation Computer Systems
VL  - 112
SP  - 408
EP  - 430
PY  - 2020
DA  - 2020/11/01/
SN  - 0167-739X
DO  - https://doi.org/10.1016/j.future.2020.05.034
UR  - https://www.sciencedirect.com/science/article/pii/S0167739X19311537
KW  - Arabic sentiment analysis
KW  - Arabic sentiments resources
KW  - Arabic dialects
AB  - Sentiment analysis is a task of natural language processing that has recently attracted increasing attention. However, sentiment analysis research has mainly been carried out for the English language. Although Arabic is ramping up as one of the most used languages on the Internet, only a few studies have focused on Arabic sentiment analysis so far. In this paper, we carry out an in-depth qualitative study of the most important research works in this context by discussing strengths and limitations of existing approaches. In particular, we survey both approaches that leverage machine translation or transfer learning to adapt English resources to Arabic and approaches that stem directly from the Arabic language.
ER  - 

TY  - JOUR
T1  - Capturing creative requirements via requirements reuse: A machine learning-based approach
AU  - Do, Quoc Anh
AU  - Bhowmik, Tanmay
AU  - Bradshaw, Gary L.
JO  - Journal of Systems and Software
VL  - 170
SP  - 110730
PY  - 2020
DA  - 2020/12/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2020.110730
UR  - https://www.sciencedirect.com/science/article/pii/S0164121220301631
KW  - Requirements reuse
KW  - Requirements engineering
KW  - Creativity in RE
KW  - Boilerplate
KW  - Natural language processing
KW  - Machine learning
AB  - The software industry has become increasingly competitive as we see multiple software serving the same domain and striving for customers. To that end, modern software needs to provide creative features to improve sustainability. To advance software creativity, research has proposed several techniques, including multi-day workshops involving experienced requirements analysts, and semi-automated tools to support creative thinking in a limited scope. Such approaches are either useful only for software with already rich issue tracking systems, or require substantial engagement from analysts with creative minds. In a recent work, we have demonstrated a novel framework that is beneficial for both novel and existing software and allows end-to-end automation promoting creativity. The framework reuses requirements from similar software freely available online, utilizes advanced natural language processing and machine learning techniques, and leverages the concept of requirement boilerplate to generate candidate creative requirements. An application of our framework on software domains: Antivirus, Web Browser, and File Sharing followed by a human subject evaluation have shown promising results. In this invited extension, we present further analysis for our research questions and report an additional evaluation by human subjects. The results exhibit the framework’s ability in generating creative features even for a relatively matured application domain, such as Web Browser, and provoking creative thinking among developers irrespective of their experience levels.
ER  - 

TY  - JOUR
T1  - Enhancing the horizon scanning utility of futures-oriented systematic and scoping reviews
AU  - Akartuna, Eray Arda
AU  - Johnson, Shane D.
AU  - Thornton, Amy
JO  - Futures
VL  - 158
SP  - 103340
PY  - 2024
DA  - 2024/04/01/
SN  - 0016-3287
DO  - https://doi.org/10.1016/j.futures.2024.103340
UR  - https://www.sciencedirect.com/science/article/pii/S0016328724000235
KW  - Scoping reviews
KW  - Horizon scanning
KW  - Cone of plausibility
KW  - Alternative scenarios
KW  - Quality appraisal
KW  - Weak signals
AB  - We propose modifications for scoping (and by extension systematic) review methodologies to improve their contribution to horizon scanning exercises. As a means of systematically collecting, coding and synthesising literature, we argue that scoping reviews are ideal for conducting initial environmental scans of a topic of interest, trend analyses and scenario developments. To demonstrate this utility, this paper uses a futures-oriented scoping review of technology-enhanced money laundering and terrorist financing risks as an example. At the forefront of the proposed modifications is a quality assessment framework assessing reviewed publications for their neutrality, evidence, relevance and clarity (NERC). This proposed framework is not only ideal for appraising publications but also as an indication of likelihood, namely whether their discussed insights constitute possible, plausible or probable alternative futures. The validity of the NERC framework in achieving these aims is assessed successfully through statistical correlation tests. The overall aim of this paper is to motivate the proposed modifications, the NERC framework and (modified) scoping reviews more generally as a formidable tool for informing horizon scanning, decision-making and pre-emptive policy development.
ER  - 

TY  - JOUR
T1  - An efficient hybrid deep neural network model for multi-horizon forecasting of power loads in academic buildings
AU  - Akter, Rubina
AU  - Shirkoohi, Majid Gholami
AU  - Wang, Jing
AU  - Mérida, Walter
JO  - Energy and Buildings
VL  - 329
SP  - 115217
PY  - 2025
DA  - 2025/02/15/
SN  - 0378-7788
DO  - https://doi.org/10.1016/j.enbuild.2024.115217
UR  - https://www.sciencedirect.com/science/article/pii/S0378778824013331
KW  - Building energy systems
KW  - Data analysis
KW  - Deep learning
KW  - Data-driven modeling
KW  - Load forecasting
KW  - Optimization models
KW  - Power consumption
AB  - Accurate power consumption forecasting is crucial for optimizing energy use in smart buildings, improving efficiency and decision-making to enhance overall energy management. However, forecasting models encounter challenges in capturing complex load patterns and often focus on single-horizon predictions. Moreover, they lack advanced Deep Learning (DL) integration and overlook computational complexity, limiting adaptability across diverse environments. Motivated by existing research gaps, this study develops a novel hybrid DL model that integrates three blocks deploying Convolutional Neural Network (CNN), Long-Short-Term Memory (LSTM), and Multi-Layer Perceptron (MLP) with concatenation and residual connectivity to enhance forecasting accuracy and robustness. Our model consistently outperforms statistical, hybrid, baseline forecast, and deep learning models, achieving a Mean Absolute Error (MAE) of 5.93 and 5.93, Mean Squared Error (MSE) of 71.52 and 78.52, Root Mean Squared Error (RMSE) of 8.46 and 8.86, and Mean Absolute Percentage Error (MAPE) of 7.81% and 2.60% for the two distinct academic buildings, respectively. Moreover, the power consumption forecasting results in both buildings demonstrate that the proposed model reduces the computing time and memory usage up to 89.7% and 79.95%, respectively, for single-horizon forecasting and 91.9% and 96% for multi-horizon forecasting compared to traditional LSTM, BiLSTM, and GRU models. This paper demonstrates the benefits provided by advanced hybrid DL models in forecasting power consumption by capturing complex load patterns and temporal dependencies. Our findings emphasize the potential of single and multi-horizon forecasting to enhance energy efficiency, offering more reliable and adaptable solutions for smart building management.
ER  - 

TY  - JOUR
T1  - Computation and communication efficient approach for federated learning based urban sensing applications against inference attacks
AU  - Kapoor, Ayshika
AU  - Kumar, Dheeraj
JO  - Pervasive and Mobile Computing
VL  - 98
SP  - 101875
PY  - 2024
DA  - 2024/02/01/
SN  - 1574-1192
DO  - https://doi.org/10.1016/j.pmcj.2024.101875
UR  - https://www.sciencedirect.com/science/article/pii/S1574119224000014
KW  - Urban sensing
KW  - Federated learning
KW  - Spatial–temporal entropy
KW  - Secure multiparty computation
KW  - Privacy
KW  - Kullback–Leibler divergence
AB  - Federated learning based participatory sensing has gained much attention lately for the vital task of urban sensing due to privacy and security issues in conventional machine learning. However, inference attacks by the honest-but-curious application server or a malicious adversary can leak the personal attributes of the participants, such as their home and workplace locations, routines, and habits. Approaches proposed in the literature to prevent such information leakage, such as secure multi-party computation and homomorphic encryption, are infeasible for urban sensing applications owing to high communication and computation costs due to multiple rounds of communication between the user and the server. Moreover, for effective modeling of urban sensing phenomenon, the application model needs to be updated frequently — every few minutes or hours, resulting in periodic data-intensive updates by the participants, which severely strains the already limited resources of their mobile devices. This paper proposes a novel low-cost privacy-preserving framework for enhanced protection against the inference of participants’ personal and private attributes from the data leaked through inference attacks. We propose a novel approach of strategically leaking selected location traces by providing computation and communication-light direct (local) model updates, whereas the rest of the model updates (when the user is at sensitive locations) are provided using secure multi-party computation. We propose two new methods based on spatiotemporal entropy and Kullback–Leibler divergence for automatically deciding which model updates need to be sent through secure multi-party computation and which can be sent directly. The proposed approach significantly reduces the computation and communication overhead for participants compared to the fully secure multi-party computation protocols. It provides enhanced protection against the deduction of personal attributes from inferred location traces compared to the direct model updates by confusing the application server or malicious adversary while inferring personal attributes from location traces. Numerical experiments on the popular Geolife GPS trajectories dataset validate our proposed approach by reducing the computation and communication requirements by the participants significantly and, at the same time, enhancing privacy by decreasing the number of inferred sensitive and private locations of participants.
ER  - 

TY  - JOUR
T1  - Reflections and attentiveness on eXplainable Artificial Intelligence (XAI). The journey ahead from criticisms to human–AI collaboration
AU  - Herrera, Francisco
JO  - Information Fusion
VL  - 121
SP  - 103133
PY  - 2025
DA  - 2025/09/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2025.103133
UR  - https://www.sciencedirect.com/science/article/pii/S1566253525002064
KW  - eXplainable Artificial Intelligence
KW  - XAI criticisms
KW  - XAI audience
KW  - Explanations
KW  - Human–AI decision-making
KW  - Human–AI collaboration
KW  - AI safety
KW  - Maturity level of explainability
KW  - Auditability
KW  - AI governance
AB  - The emergence of deep learning over the past decade has driven the development of increasingly complex AI models, amplifying the need for Explainable Artificial Intelligence (XAI). As AI systems grow in size and complexity, ensuring interpretability and transparency becomes essential, especially in high-stakes applications. With the rapid expansion of XAI research, addressing emerging debates and criticisms requires a comprehensive examination. This paper explores the complexities of XAI from multiple perspectives, proposing six key axes that shed light on its role in human–AI interaction and collaboration. First, it examines the imperative of XAI under the dominance of black-box AI models. Given the lack of definitional cohesion, the paper argues that XAI must be framed through the lens of audience and understanding, highlighting its different uses in AI–human interaction. The recent BLUE vs. RED XAI distinction is analyzed through this perspective. The study then addresses the criticisms of XAI, evaluating its maturity, current trajectory, and limitations in handling complex problems. The discussion then shifts to explanations as a bridge between AI models and human understanding, emphasizing the importance of usability of explanations in human–AI decision making. Key aspects such as AI reliance, human intuition, and emerging collaboration theories — including the human-algorithm centaur and co-intelligence paradigms — are explored in connection with XAI. The medical field is considered as a case study, given its extensive research on collaboration between doctors and AI through explainability. The paper proposes a framework to evaluate the maturity of XAI using three dimensions: practicality, auditability, and AI governance. Provide the final lessons learned focused on trends and questions to tackle in the near future. This is an in-depth exploration of the impact and urgency of XAI in the era of pervasive expansion of AI. Three Key reflections from this study include: (a) XAI must enhance cognitive engagement with explanations, (b) it must evolve to fully address why, what, and for what purpose explanations are needed, and (c) it plays a crucial role in building societal trust in AI. By advancing XAI in these directions, we can ensure that AI remains transparent, auditable, and accountable, and aligned with human needs.
ER  - 

TY  - JOUR
T1  - Digital Image Encryption Algorithm Based on Double Chaotic Map and LSTM
AU  - Feng, Luoyin
AU  - Du, Jize
AU  - Fu, Chong
JO  - Computers, Materials and Continua
VL  - 77
IS  - 2
SP  - 1645
EP  - 1662
PY  - 2023
DA  - 2023/11/29/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2023.042630
UR  - https://www.sciencedirect.com/science/article/pii/S1546221823006288
KW  - Digital image encryption
KW  - LSTM
KW  - particle swarm optimization algorithm
KW  - DCM
AB  - In the era of network communication, digital image encryption (DIE) technology is critical to ensure the security of image data. However, there has been limited research on combining deep learning neural networks with chaotic mapping for the encryption of digital images. So, this paper addresses this gap by studying the generation of pseudo-random sequences (PRS) chaotic signals using dual logistic chaotic maps. These signals are then predicted using long and short-term memory (LSTM) networks, resulting in the reconstruction of a new chaotic signal. During the research process, it was discovered that there are numerous training parameters associated with the LSTM network, which can hinder training efficiency. To overcome this challenge and improve training efficiency, the paper proposes an improved particle swarm optimization (IPSO) algorithm to optimize the LSTM network. Subsequently, the obtained chaotic signal from the optimized model training is further scrambled, obfuscated, and diffused to achieve the final encrypted image. This research presents a digital image encryption (DIE) algorithm based on a double chaotic map (DCM) and LSTM. The algorithm demonstrates a high average NPCR (Number of Pixel Change Rate) of 99.56% and a UACI (Unified Average Changing Intensity) value of 33.46%, indicating a strong ability to resist differential attacks. Overall, the proposed algorithm realizes secure and sensitive digital image encryption, ensuring the protection of personal information in the Internet environment.
ER  - 

TY  - JOUR
T1  - CubeAgent: Efficient query-based video adversarial examples generation through deep reinforcement learning
AU  - Shi, Heyuan
AU  - Zeng, Binqi
AU  - Zhan, Yu
AU  - Liu, Rongkai
AU  - Yang, Yulin
AU  - Chen, Li
AU  - Hu, Chao
AU  - Fu, Ying
JO  - Journal of Systems and Software
VL  - 226
SP  - 112437
PY  - 2025
DA  - 2025/08/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2025.112437
UR  - https://www.sciencedirect.com/science/article/pii/S0164121225001050
KW  - Adversarial example generation
KW  - Video classification system
KW  - Black-box testing
AB  - In commercial deep-learning-based video systems, testers utilize query-based methods to generate adversarial examples (AEs) and effectively uncover system vulnerabilities. The current research has primarily focused on selecting the key perturbation units, such as video patches, keyframes, and combinations of keyframes and regions, to add adversarial perturbation and generate AEs. Furthermore, deep reinforcement learning (DRL) frameworks have been utilized to model the results of sequence-based feedback to reduce query numbers. However, considering the pixels of spatial and temporal dimensions separately in the search process results in a large number of queries and intolerable failure rates for video AE generation. This paper proposes a new AEs perturbation unit called the “video cube”, which simultaneously extracts video pixels in neighbor frames and regions. We develop a new DRL framework called “CubeAgent”, which incorporates controllable policy actions for selecting the number and index of key video cubes segmented by time intervals. We conducted exhaustive experiments across diverse video DNN systems, utilizing the UCF101 and JESTER datasets, which conclusively demonstrated that CubeAgent can expedite the generation process by a factor of two, diminishing the average query count from 5,768 to 4,602, representing a 20% reduction, while simultaneously mitigating the average generation failure rate from 9% to 7%. The results show that CubeAgent improves the performance of adversarial example generation while achieving comparable.
ER  - 

TY  - JOUR
T1  - Losing control: Exposing security weaknesses of Kubernetes control plane interfaces
AU  - Wang, Chen
AU  - Tang, Hongbo
AU  - Zhao, Yu
AU  - You, Wei
AU  - Yang, Jie
AU  - Qiu, Hang
JO  - Computers & Security
VL  - 160
SP  - 104704
PY  - 2026
DA  - 2026/01/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104704
UR  - https://www.sciencedirect.com/science/article/pii/S0167404825003931
KW  - Kubernetes
KW  - Control plane interfaces
KW  - Control plane interface attacks
KW  - DoS
AB  - Kubernetes has become the dominant container orchestration platform, relying on a centralized control plane to manage workloads across nodes. However, its exposed control plane interfaces introduce critical security risks. This paper conducts a systematic static analysis of these interfaces and uncovers insufficient access controls and missing rate-limiting mechanisms. We design four attack strategies and implement seven representative attacks in both local and cloud environments. The experiments demonstrate severe consequences, including sensitive data leakage, denial-of-service conditions, up to 90% CPU overhead, and 70% packet loss in co-located containers, which also lose the ability to resolve non-local DNS queries. Based on these findings, we propose mitigation strategies that have been acknowledged by cloud vendors and the Kubernetes community, with plans for deployment in future releases. This work provides the first systematic study of control plane interface vulnerabilities, and future research should explore automated analysis frameworks and isolated experimental environments to strengthen Kubernetes security in multi-tenant commercial platforms.
ER  - 

TY  - JOUR
T1  - Metadata schema for virtual building models in digital twins: VB schema implemented in GPT-based applications
AU  - Lee, Jeyoon
AU  - Yoon, Sungmin
JO  - Energy and Buildings
VL  - 327
SP  - 115039
PY  - 2025
DA  - 2025/01/15/
SN  - 0378-7788
DO  - https://doi.org/10.1016/j.enbuild.2024.115039
UR  - https://www.sciencedirect.com/science/article/pii/S0378778824011551
KW  - GPT
KW  - Virtual models
KW  - Virtual buildings
KW  - Ontology
KW  - HVAC
KW  - Digital twins
KW  - Model metadata
KW  - Operation and maintenance (O&M)
KW  - Built environments
AB  - A virtual building model (VBM) is a virtual entity that represents the physical behavior of a target building mathematically within a digital twin environment. The creation and synchronization of a VBM are achieved by utilizing various interrelated virtual sub-models, including behavior, correction, and distance models. To achieve continuous digital twinning, it is essential to manage the VBM with virtual sub-models. However, existing metadata schemas have limitations in describing VBMs representing operational building behaviors within the concept of building digital twins (DTs). Therefore, this study proposes a novel metadata schema, termed the virtual building model metadata schema (VB schema), to represent and manage VBMs in DT-built environments. The VB schema is established according to the mathematical and semantic ontology of the in-situ modeling and calibration approach for constructing and correcting virtual models during building operations, and it is linked to physical entities, data, and applications within DTs. Specifically, it involves: (1) determining classes for operational data and virtual models; (2) establishing relationships for interactions between model and data entities, between model classes, between model and physical entities, and between model and applications; (3) defining properties for each class of models; and (4) extending into the exiting metadata schema of Brick. To demonstrate the proposed VB schema, a virtual model describing supply pressure behaviors in a central heating system was developed and represented using the VB schema for DT-enabled building operations. Additionally, the VB schema was utilized for implementing generative pre-trained transformer (GPT)-based DT applications, which highlights its benefits in enhancing ontology comprehension of DTs in the context of VBMs, improving autonomous problem-solving capabilities in real building systems, and providing better interpretation of application results compared to cases where only the Brick schema was used. The VB schema is expected to enable continuous and autonomous in-situ management of VBMs for intelligent building services within the DT.
ER  - 

TY  - JOUR
T1  - Digitalization, internationalization, and firm performance: A resource-orchestration perspective on new OLI advantages
AU  - Bhandari, Krishna Raj
AU  - Zámborský, Peter
AU  - Ranta, Mikko
AU  - Salo, Jari
JO  - International Business Review
VL  - 32
IS  - 4
SP  - 102135
PY  - 2023
DA  - 2023/08/01/
SN  - 0969-5931
DO  - https://doi.org/10.1016/j.ibusrev.2023.102135
UR  - https://www.sciencedirect.com/science/article/pii/S0969593123000355
KW  - Digitalization
KW  - Internationalization
KW  - Performance
KW  - Digital transformation
KW  - Digital resources
KW  - Resource orchestration
KW  - Resource-based view
KW  - New OLI advantages
KW  - FDI spillovers
AB  - Digital forces and digital global connection weaken traditional ownership, location and internalization (OLI) advantages and intensify new OLI advantages (open resources, linkages and integration). However, by building on the resource-orchestration theory, we raise the question of how digitalization (utilization and orchestration of digital resources) and internationalization (firm-level outward internationalization and country-level inward internationalization) affect firm performance. We introduce the degree of outward internationalization and home-country inward foreign direct investment (FDI) inflows as moderators in achieving firm performance as a result of digitalization. Using a panel dataset of 571 U.S. manufacturing firms, we find a curvilinear relationship between digitalization and performance. The top quartile of digitalization efforts is rewarded by significant profitability. Moreover, high levels of outward internationalization and high net-FDI inflows increase the performance gains attributable to high levels of digitalization. Overall, the resource-orchestration theory complements new OLI advantages in explaining firm performance in the digital world.
ER  - 

TY  - JOUR
T1  - Distributed artificial intelligence: Taxonomy, review, framework, and reference architecture
AU  - Janbi, Nourah
AU  - Katib, Iyad
AU  - Mehmood, Rashid
JO  - Intelligent Systems with Applications
VL  - 18
SP  - 200231
PY  - 2023
DA  - 2023/05/01/
SN  - 2667-3053
DO  - https://doi.org/10.1016/j.iswa.2023.200231
UR  - https://www.sciencedirect.com/science/article/pii/S266730532300056X
KW  - Artificial intelligence
KW  - Distributed artificial intelligence
KW  - Distributed pre-processing
KW  - Distributed training
KW  - Distributed inference, distributed decision making
KW  - Data parallelism
KW  - Model parallelism
KW  - Pipelined parallelism
KW  - Hybrid parallelism
KW  - Federated learning
KW  - Multi-layer architecture
KW  - 6th generation (6 g) networks
KW  - Future networking
KW  - Fog computing
KW  - edge computing
KW  - cloud computing
AB  - Artificial intelligence (AI) research and market have grown rapidly in the last few years, and this trend is expected to continue with many potential advancements and innovations in this field. One of the emerging AI research directions is Distributed Artificial Intelligence (DAI). It has been motivated by technological advances in communication, networking, and hardware, together with the nature of data being generated from connected, distributed, and diverse objects. DAI is expected to create a fertile environment for innovative, advanced, robust, and scalable approaches for AI supporting the vision of smart societies. In this paper, we explore state of the art on DAI and identify the opportunities and challenges of provisioning distributed AI as a service (DAIaaS). We provide a taxonomy and a comprehensive review covering the literature from 2016 to 2022. It comprises various aspects of DAI, including AI workflow, distribution paradigms, supporting infrastructure, management techniques, and applications. Based on the gained insights from the conducted review, we propose Imtidad, a framework for provisioning DAIaaS over the cloud, fog, and edge layers. We refine this framework and propose the Imtidad software Reference Architecture (RA) for designing and deploying DAI services. In addition, we extended the framework and developed a future networking infrastructure transformation framework, as it is one of the main enablers for DAI. This framework and RA can be used as guidance facilitating the transition to the future DAI, where DAI is decoupled from the design and development of smart applications. This paper, including the proposed framework, RA, taxonomy, and detailed review, is expected to have an extensive impact on DAI research and accelerate innovations in this area.
ER  - 

TY  - JOUR
T1  - Intelligent manufacturing, media attention, and sustainable development performance
AU  - Shi, Wenlei
AU  - Ying, Limeng
AU  - Ma, Guohua
AU  - Niu, Yanfang
AU  - Lv, Yuanyuan
AU  - Xu, Xiaofang
JO  - International Review of Financial Analysis
VL  - 106
SP  - 104481
PY  - 2025
DA  - 2025/10/01/
SN  - 1057-5219
DO  - https://doi.org/10.1016/j.irfa.2025.104481
UR  - https://www.sciencedirect.com/science/article/pii/S105752192500568X
KW  - Intelligent manufacturing
KW  - Sustainable development performance
KW  - Media attention
KW  - Resource-based view
KW  - Signaling theory
KW  - Data analytics
AB  - This study explores the impact of intelligent manufacturing (IM) on sustainable development performance (SDP) and finds a significant positive relationship that is further strengthened by media attention. IM promotes SDP by stimulating technological innovation, which improves production efficiency and drives green innovation; easing financing constraints, thereby providing essential funding for sustainable initiatives; and optimizing human capital by enhancing workforce skills. Heterogeneity analysis reveals that these positive effects are more pronounced in high-tech, mature, and labor-intensive firms. The study contributes to the literature by identifying media attention as an important moderating factor and elucidates the mediating pathways through which IM promotes sustainability. These findings offer practical guidance for firms seeking to integrate IM into their sustainability strategies and provide policymakers with insights for formulating targeted incentives to promote technological transformation for comprehensive sustainable development.
ER  - 

TY  - JOUR
T1  - Ensuring security of personal data in library services platforms of academic libraries in the EU
AU  - Katulic, Anita
AU  - Katulic, Tihomir
JO  - Digital Library Perspectives
VL  - 41
IS  - 3
SP  - 403
EP  - 418
PY  - 2025
DA  - 2025/05/02/
SN  - 2059-5816
DO  - https://doi.org/10.1108/DLP-11-2024-0183
UR  - https://www.sciencedirect.com/science/article/pii/S2059581625000029
KW  - Academic libraries
KW  - GDPR
KW  - Data protection compliance
KW  - Data protection impact assessments
KW  - Library service platforms
KW  - Privacy by design and by default
AB  - Purpose
The purpose of this paper is to outline the risks and issues libraries face when using a next-generation library services platform (LSP) from the perspective of current data protection requirements. By examining the specific legal obligations in the context of LSP, approaches will be considered to achieve compliance and ways of ensuring patrons’ data protection rights.
Design/methodology/approach
The methods authors applied in this research observe standard legal research methodology, including analysis of legal practice and comparative legal analysis methods to identify key normative elements of library management system (LMS) or LSP compliance with applicable EU data protection requirements. A systematic overview of personal data processing activities usually performed by library services platforms is given with an overview of risks and possible applicable technical or organizational protection measures.
Findings
To ensure the rights of library patrons, an LSP needs to meet a number of data protection requirements: provide tools and techniques to provide the patron with insight into his personal data, enable the patron to independently edit their own data in the online interface of the LSP, enable the control of unauthorized access, enable the anonymization of data about the patron and his activities for the purpose of creating statistical reports, enable the library to define mandatory and optional data collected about the patron, provide a function for deleting patron data and/or patron records after a certain period of time. There are also obligations for libraries, like contractual obligations with vendors, privacy by design and by default and data protection impact assesment.
Practical implications
Since libraries as data controllers are required to ensure that personal data collected through these platforms is processed in strict accordance with General Data Protection Regulation (GDPR) principles, the research results can be practically applied to adapt the library service platform or to evaluate options when procuring a new platform.
Originality/value
The research contributes to understanding the implementation of specific technical and organizational measures for the protection of library patrons’ personal data processed within library services platforms, including the exercise of data subjects’ rights and privacy by design and by default.
ER  - 

TY  - JOUR
T1  - Richer Document Embeddings for Author Profiling tasks based on a heuristic search
AU  - López-Santillán, Roberto
AU  - Montes-Y-Gómez, Manuel
AU  - González-Gurrola, Luis Carlos
AU  - Ramírez-Alonso, Graciela
AU  - Prieto-Ordaz, Olanda
JO  - Information Processing & Management
VL  - 57
IS  - 4
SP  - 102227
PY  - 2020
DA  - 2020/07/01/
SN  - 0306-4573
DO  - https://doi.org/10.1016/j.ipm.2020.102227
UR  - https://www.sciencedirect.com/science/article/pii/S0306457319306466
KW  - Author profiling
KW  - Document embeddings
KW  - Word embeddings
KW  - Genetic programming
KW  - Weighting scheme
AB  - In this study we propose a novel method to generate Document Embeddings (DEs) by means of evolving mathematical equations that integrate classical term frequency statistics. To accomplish this, we employed a Genetic Programming (GP) strategy to build competitive formulae to weight custom Word Embeddings (WEs), produced by cutting edge feature extraction techniques (e.g., word2vec, fastText, BERT), and then we create DEs by their weighted averaging. We exhaustively evaluated the proposed method over 9 datasets that are composed of several multilingual social media sources, with the aim to predict personal attributes of authors (e.g., gender, age, personality traits) in 17 tasks. In each dataset we contrast the results obtained by our method against state-of-the-art competitors, placing our approach at the top-quartile in all cases. Furthermore, we introduce a new numerical statistic feature called Relevance Topic Value (rtv), which could be used to enhance the forecasting of characteristics of authors, by numerically describing the topic of a document and the personal use of words by users. Interestingly, based on a frequency analysis of terminals used by GP, rtv turned out to be the most likely feature to appear alone in a single equation, then suggesting its usefulness as a WE weighting scheme.
ER  - 

TY  - JOUR
T1  - An automatic software vulnerability classification framework using term frequency-inverse gravity moment and feature selection
AU  - Chen, Jinfu
AU  - Kudjo, Patrick Kwaku
AU  - Mensah, Solomon
AU  - Brown, Selasie Aformaley
AU  - Akorfu, George
JO  - Journal of Systems and Software
VL  - 167
SP  - 110616
PY  - 2020
DA  - 2020/09/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2020.110616
UR  - https://www.sciencedirect.com/science/article/pii/S0164121220300947
KW  - Software vulnerability
KW  - Classification
KW  - Feature selection
KW  - Machine learning algorithms
KW  - Severity
KW  - Term-weighting
AB  - Vulnerability classification is an important activity in software development and software quality maintenance. A typical vulnerability classification model usually involves a stage of term selection, in which the relevant terms are identified via feature selection. It also involves a stage of term-weighting, in which the document weights for the selected terms are computed, and a stage for classifier learning. Generally, the term frequency-inverse document frequency (TF-IDF) model is the most widely used term-weighting metric for vulnerability classification. However, several issues hinder the effectiveness of the TF-IDF model for document classification. To address this problem, we propose and evaluate a general framework for vulnerability severity classification using the term frequency-inverse gravity moment (TF-IGM). Specifically, we extensively compare the term frequency-inverse gravity moment, term frequency-inverse document frequency, and information gain feature selection using five machine learning algorithms on ten vulnerable software applications containing a total number of 27,248 security vulnerabilities. The experimental result shows that: (i) the TF-IGM model is a promising term weighting metric for vulnerability classification compared to the classical term-weighting metric, (ii) the effectiveness of feature selection on vulnerability classification varies significantly across the studied datasets and (iii) feature selection improves vulnerability classification.
ER  - 

TY  - JOUR
T1  - Explainable Artificial Intelligence (XAI): What we know and what is left to attain Trustworthy Artificial Intelligence
AU  - Ali, Sajid
AU  - Abuhmed, Tamer
AU  - El-Sappagh, Shaker
AU  - Muhammad, Khan
AU  - Alonso-Moral, Jose M.
AU  - Confalonieri, Roberto
AU  - Guidotti, Riccardo
AU  - Del Ser, Javier
AU  - Díaz-Rodríguez, Natalia
AU  - Herrera, Francisco
JO  - Information Fusion
VL  - 99
SP  - 101805
PY  - 2023
DA  - 2023/11/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2023.101805
UR  - https://www.sciencedirect.com/science/article/pii/S1566253523001148
KW  - Explainable Artificial Intelligence
KW  - Interpretable machine learning
KW  - Trustworthy AI
KW  - AI principles
KW  - Post-hoc explainability
KW  - XAI assessment
KW  - Data Fusion
KW  - Deep Learning
AB  - Artificial intelligence (AI) is currently being utilized in a wide range of sophisticated applications, but the outcomes of many AI models are challenging to comprehend and trust due to their black-box nature. Usually, it is essential to understand the reasoning behind an AI model’s decision-making. Thus, the need for eXplainable AI (XAI) methods for improving trust in AI models has arisen. XAI has become a popular research subject within the AI field in recent years. Existing survey papers have tackled the concepts of XAI, its general terms, and post-hoc explainability methods but there have not been any reviews that have looked at the assessment methods, available tools, XAI datasets, and other related aspects. Therefore, in this comprehensive study, we provide readers with an overview of the current research and trends in this rapidly emerging area with a case study example. The study starts by explaining the background of XAI, common definitions, and summarizing recently proposed techniques in XAI for supervised machine learning. The review divides XAI techniques into four axes using a hierarchical categorization system: (i) data explainability, (ii) model explainability, (iii) post-hoc explainability, and (iv) assessment of explanations. We also introduce available evaluation metrics as well as open-source packages and datasets with future research directions. Then, the significance of explainability in terms of legal demands, user viewpoints, and application orientation is outlined, termed as XAI concerns. This paper advocates for tailoring explanation content to specific user types. An examination of XAI techniques and evaluation was conducted by looking at 410 critical articles, published between January 2016 and October 2022, in reputed journals and using a wide range of research databases as a source of information. The article is aimed at XAI researchers who are interested in making their AI models more trustworthy, as well as towards researchers from other disciplines who are looking for effective XAI methods to complete tasks with confidence while communicating meaning from data.
ER  - 

TY  - JOUR
T1  - Graph4Web: A relation-aware graph attention network for web service classification
AU  - Zhao, Kunsong
AU  - Liu, Jin
AU  - Xu, Zhou
AU  - Liu, Xiao
AU  - Xue, Lei
AU  - Xie, Zhiwen
AU  - Zhou, Yuxuan
AU  - Wang, Xin
JO  - Journal of Systems and Software
VL  - 190
SP  - 111324
PY  - 2022
DA  - 2022/08/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2022.111324
UR  - https://www.sciencedirect.com/science/article/pii/S0164121222000681
KW  - Web services
KW  - Graph neural network
KW  - Attention mechanism
KW  - Service discovery
AB  - Software reuse is a popular way to utilize existing software components to ensure the quality of newly developed software in service-oriented architecture. However, how to find a suitable web service from existing repositories to meet requirements is still an open issue. Among others, web service classification is one of the most essential and effective means for web service recommendation. Previous studies have concerned this problem, but a critical issue, i.e., the semantic and syntactic information for the web service, is often ignored. To address such an issue, in this work, we propose Graph4Web, which uses a relation-aware graph attention network for web service classification. Specifically, we first parse the web service description sequence into the dependency graph and initialize the embedding vector of each node in the graph by tuning the pre-trained BERT model. We further propose a relation-aware graph attention layer to learn and update the node embedding vector by aggregating the information of neighborhood nodes and the distinct types of relationships between nodes. In addition, we introduce the self-attention mechanism to acquire the high-level global representation for web service classification. Various experiments demonstrate that Graph4Web has better classification performance compared with seven baseline methods with three indicators.
ER  - 

TY  - JOUR
T1  - Assessing behavioral data science privacy issues in government artificial intelligence deployment
AU  - Saura, Jose Ramon
AU  - Ribeiro-Soriano, Domingo
AU  - Palacios-Marqués, Daniel
JO  - Government Information Quarterly
VL  - 39
IS  - 4
SP  - 101679
PY  - 2022
DA  - 2022/10/01/
SN  - 0740-624X
DO  - https://doi.org/10.1016/j.giq.2022.101679
UR  - https://www.sciencedirect.com/science/article/pii/S0740624X22000120
KW  - Behavioral data sciences
KW  - Governments
KW  - Collective behavior analysis
KW  - Artificial intelligence
KW  - Surveillance capitalism
KW  - Privacy
AB  - In today's global culture where the Internet has established itself as the main tool for communication and commerce, the capability to massively analyze and predict citizens' behavior has become a priority for governments in terms of collective intelligence and security. At the same time, in the context of novel possibilities that artificial intelligence (AI) brings to governments in terms of understanding and developing collective behavior analysis, important concerns related to citizens' privacy have emerged. In order to identify the main uses that governments make of AI and to define citizens' concerns about their privacy, in the present study, we undertook a systematic review of the literature, conducted in-depth interviews, and applied data-mining techniques. Based on our results, we classified and discussed the risks to citizens' privacy according to the types of AI strategies used by governments that may affect collective behavior and cause massive behavior modification. Our results revealed 11 uses of AI strategies used by the government to improve their interaction with citizens, organizations in cities, services provided by public institutions or the economy, among other areas. In relation to citizens' privacy when AI is used by governments, we identified 8 topics related to human behavior predictions, intelligence decision making, decision automation, digital surveillance, data privacy law and regulation, and the risk of behavior modification. The paper concludes with a discussion of the development of regulations focused on the ethical design of citizen data collection, where implications for governments are presented aimed at regulating security, ethics, and data privacy. Additionally, we propose a research agenda composed by 16 research questions to be investigated in further research.
ER  - 

TY  - JOUR
T1  - Artificial Intelligence (AI): Multidisciplinary perspectives on emerging challenges, opportunities, and agenda for research, practice and policy
AU  - Dwivedi, Yogesh K.
AU  - Hughes, Laurie
AU  - Ismagilova, Elvira
AU  - Aarts, Gert
AU  - Coombs, Crispin
AU  - Crick, Tom
AU  - Duan, Yanqing
AU  - Dwivedi, Rohita
AU  - Edwards, John
AU  - Eirug, Aled
AU  - Galanos, Vassilis
AU  - Ilavarasan, P. Vigneswara
AU  - Janssen, Marijn
AU  - Jones, Paul
AU  - Kar, Arpan Kumar
AU  - Kizgin, Hatice
AU  - Kronemann, Bianca
AU  - Lal, Banita
AU  - Lucini, Biagio
AU  - Medaglia, Rony
AU  - Le Meunier-FitzHugh, Kenneth
AU  - Le Meunier-FitzHugh, Leslie Caroline
AU  - Misra, Santosh
AU  - Mogaji, Emmanuel
AU  - Sharma, Sujeet Kumar
AU  - Singh, Jang Bahadur
AU  - Raghavan, Vishnupriya
AU  - Raman, Ramakrishnan
AU  - Rana, Nripendra P.
AU  - Samothrakis, Spyridon
AU  - Spencer, Jak
AU  - Tamilmani, Kuttimani
AU  - Tubadji, Annie
AU  - Walton, Paul
AU  - Williams, Michael D.
JO  - International Journal of Information Management
VL  - 57
SP  - 101994
PY  - 2021
DA  - 2021/04/01/
SN  - 0268-4012
DO  - https://doi.org/10.1016/j.ijinfomgt.2019.08.002
UR  - https://www.sciencedirect.com/science/article/pii/S026840121930917X
KW  - Artificial intelligence
KW  - AI
KW  - Cognitive computing
KW  - Expert systems
KW  - Machine learning
KW  - Research agenda
AB  - As far back as the industrial revolution, significant development in technical innovation has succeeded in transforming numerous manual tasks and processes that had been in existence for decades where humans had reached the limits of physical capacity. Artificial Intelligence (AI) offers this same transformative potential for the augmentation and potential replacement of human tasks and activities within a wide range of industrial, intellectual and social applications. The pace of change for this new AI technological age is staggering, with new breakthroughs in algorithmic machine learning and autonomous decision-making, engendering new opportunities for continued innovation. The impact of AI could be significant, with industries ranging from: finance, healthcare, manufacturing, retail, supply chain, logistics and utilities, all potentially disrupted by the onset of AI technologies. The study brings together the collective insight from a number of leading expert contributors to highlight the significant opportunities, realistic assessment of impact, challenges and potential research agenda posed by the rapid emergence of AI within a number of domains: business and management, government, public sector, and science and technology. This research offers significant and timely insight to AI technology and its impact on the future of industry and society in general, whilst recognising the societal and industrial influence on pace and direction of AI development.
ER  - 

TY  - JOUR
T1  - FedBrain: A robust multi-site brain network analysis framework based on federated learning for brain disease diagnosis
AU  - Zhang, Chang
AU  - Meng, Xiangzhu
AU  - Liu, Qiang
AU  - Wu, Shu
AU  - Wang, Liang
AU  - Ning, Huansheng
JO  - Neurocomputing
VL  - 559
SP  - 126791
PY  - 2023
DA  - 2023/11/28/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2023.126791
UR  - https://www.sciencedirect.com/science/article/pii/S0925231223009141
KW  - Functional magnetic resonance image
KW  - Brain network
KW  - Federated learning
KW  - Deep neural networks
KW  - Brain disease diagnosis
AB  - In recent years, deep learning models have shown their advantages in neuroimage analysis, such as brain disease diagnosis. Unfortunately, it is usually difficult to acquire numerous brain networks at a single centralized site to effectively train a high-quality deep learning model. To address this issue, federated learning (FL) has gained popularity in brain disease diagnosis, which allows deep learning models to be trained without centralizing data. However, most FL-based works might still face two following challenges. Firstly, the high-dimensional features of brain networks are often far larger than sample size, which might lead to poor performance due to the curse of dimensionality. Secondly, differences in data distributions across different sites can impact the communication efficiency and performance of FL models. To overcome these challenges, we design a novel FL framework for diagnosing brain disorders, named FedBrain. Firstly, FedBrain proposes data augmentation based on L1 regularization to select significant features shared by all clients. The domain alignment loss based on the maximum mean discrepancy criterion is introduced to minimize differences in the marginal and conditional distributions between local clients. Furthermore, FedBrain proposes a personalized predictor based on mixture of experts to adapt to different clients, using a global and private predictor as two experts. Eventually, FedBrain integrates the above modules with differential privacy and homomorphic encryption into a unified FL framework. Experimental results on the Autism Brain Imaging Data Exchange (ABIDE) dataset demonstrate its effectiveness and robustness, which shows that FedBrain can reduce the communication burden of FL and achieve the highest average accuracy of 79% against other counterparts.
ER  - 

TY  - JOUR
T1  - Reinforcement learning for data center energy efficiency optimization: A systematic literature review and research roadmap
AU  - Kahil, Hussain
AU  - Sharma, Shiva
AU  - Välisuo, Petri
AU  - Elmusrati, Mohammed
JO  - Applied Energy
VL  - 389
SP  - 125734
PY  - 2025
DA  - 2025/07/01/
SN  - 0306-2619
DO  - https://doi.org/10.1016/j.apenergy.2025.125734
UR  - https://www.sciencedirect.com/science/article/pii/S0306261925004647
KW  - Data center
KW  - Energy efficiency optimization
KW  - Cooling system
KW  - ICT system
KW  - Reinforcement learning (RL)
KW  - Deep reinforcement learning (DRL)
AB  - With today’s challenges posed by climate change, global attention is increasingly focused on reducing energy consumption within sustainable communities. As significant energy consumers, data centers represent a crucial area for research in energy efficiency optimization. To address this issue, various algorithms have been employed to develop sophisticated solutions for data center systems. Recently, Reinforcement Learning (RL) and its advanced counterpart, Deep Reinforcement Learning (DRL), have demonstrated promising potential in improving data center energy efficiency. However, a comprehensive review of the deployment of these algorithms remains limited. In this systematic review, we explore the application of RL/DRL algorithms for optimizing data center energy efficiency, with a focus on optimizing the operation of cooling systems and Information and Communication Technology (ICT) processes, including task scheduling, resource allocation, virtual machine (VM) consolidation/placement, and network traffic control. Following the Preferred Reporting Items for Systematic review and Meta-Analysis (PRISMA) protocol, we provide a detailed overview of the methodologies and objectives of 65 identified studies, along with an in-depth analysis of their energy-related results. We also summarize key aspects of these studies, including benchmark comparisons, experimental setups, datasets, and implementation platforms. Additionally, we present a structured qualitative comparison of the Markov Decision Process (MDP) elements for joint optimization studies. Our findings highlight vital research gaps, including the lack of real-time validation for developed algorithms and the absence of multi-scale standardized metrics for reporting energy efficiency improvements. Furthermore, we propose joint optimization of multi-system objectives as a promising direction for future research.
ER  - 

TY  - JOUR
T1  - Monitoring tools for DevOps and microservices: A systematic grey literature review
AU  - Giamattei, L.
AU  - Guerriero, A.
AU  - Pietrantuono, R.
AU  - Russo, S.
AU  - Malavolta, I.
AU  - Islam, T.
AU  - Dînga, M.
AU  - Koziolek, A.
AU  - Singh, S.
AU  - Armbruster, M.
AU  - Gutierrez-Martinez, J.M.
AU  - Caro-Alvaro, S.
AU  - Rodriguez, D.
AU  - Weber, S.
AU  - Henss, J.
AU  - Vogelin, E. Fernandez
AU  - Panojo, F. Simon
JO  - Journal of Systems and Software
VL  - 208
SP  - 111906
PY  - 2024
DA  - 2024/02/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2023.111906
UR  - https://www.sciencedirect.com/science/article/pii/S0164121223003011
KW  - Monitoring
KW  - Microservice
KW  - DevOps
KW  - MSA
KW  - Tools
AB  - Microservice-based systems are usually developed according to agile practices like DevOps, which enables rapid and frequent releases to promptly react and adapt to changes. Monitoring is a key enabler for these systems, as they allow to continuously get feedback from the field and support timely and tailored decisions for a quality-driven evolution. In the realm of monitoring tools available for microservices in the DevOps-driven development practice, each with different features, assumptions, and performance, selecting a suitable tool is an as much difficult as impactful task. This article presents the results of a systematic study of the grey literature we performed to identify, classify and analyze the available monitoring tools for DevOps and microservices. We selected and examined a list of 71 monitoring tools, drawing a map of their characteristics, limitations, assumptions, and open challenges, meant to be useful to both researchers and practitioners working in this area. Results are publicly available and replicable. Editor’s note: Open Science material was validated by the Journal of Systems and Software Open Science Board.
ER  - 

TY  - JOUR
T1  - The digital prior restraint: Applying human rights safeguards to upload filters in the EU
AU  - Vargas Penagos, Emmanuel
JO  - Computer Law & Security Review
VL  - 59
SP  - 106219
PY  - 2025
DA  - 2025/11/01/
SN  - 2212-473X
DO  - https://doi.org/10.1016/j.clsr.2025.106219
UR  - https://www.sciencedirect.com/science/article/pii/S2212473X25000914
KW  - Upload filters
KW  - freedom of expression
KW  - Social media
KW  - Digital services act
KW  - TERREG
KW  - Copyright directive
KW  - Prior restraints
KW  - Very large online platforms
KW  - VLOPs
AB  - This article examines the human rights standards relevant to the use of upload filters for content moderation within EU secondary legislation. Upload filters, which automatically screen user-generated content before publication, are a type of prior restraint, which raises critical concerns on freedom of expression. EU secondary legislation establishes rules for both mandatory and voluntary use of these technologies, which must be read in light of human rights protections. This article analyses the characteristics of both mandatory and voluntary upload filters as prior restraints, the relevant EU legal provisions governing their use, and the safeguards required to prevent disproportionate restrictions on speech. Additionally, it explores the procedural and institutional safeguards under EU law, viewed through the lens of the CJEU and ECtHR case law on prior restraints and the rights to a fair trial and to an effective remedy.
ER  - 

TY  - JOUR
T1  - An empirical study of IoT security aspects at sentence-level in developer textual discussions
AU  - Mandal, Nibir
AU  - Uddin, Gias
JO  - Information and Software Technology
VL  - 150
SP  - 106970
PY  - 2022
DA  - 2022/10/01/
SN  - 0950-5849
DO  - https://doi.org/10.1016/j.infsof.2022.106970
UR  - https://www.sciencedirect.com/science/article/pii/S0950584922001082
KW  - IoT
KW  - Security
KW  - Stack overflow
KW  - Deep learning
KW  - Empirical study
AB  - Context:
IoT is a rapidly emerging paradigm that now encompasses almost every aspect of our modern life. As such, ensuring the security of IoT devices is crucial. IoT devices can differ from traditional computing (e.g., low power, storage, computing), thereby the design and implementation of proper security measures can be challenging in IoT devices. We observed that IoT developers discuss their security-related challenges in developer forums like Stack Overflow (SO). However, we find that IoT security discussions can also be buried inside non-security discussions in SO.
Objective:
In this paper, we aim to understand the challenges IoT developers face while applying security practices and techniques to IoT devices. We have two goals: (1) Develop a model that can automatically find security-related IoT discussions in SO, and (2) Study the model output (i.e., the security discussions) to learn about IoT developer security-related challenges.
Methods:
First, we download all 53K posts from StackOverflow (SO) that contain discussions about various IoT devices, tools, and techniques. Second, we manually labeled 5,919 sentences from 53K posts as 1 or 0 (i.e., whether they contain a security aspect or not). Third, we then use this benchmark to investigate a suite of deep learning transformer models. The best performing model is called SecBot. Fourth, we apply SecBot on the entire 53K posts and find around 30K sentences labeled as security. Fifth, we apply topic modeling to the 30K security-related sentences labeled by SecBot. Then we label and categorize the topics. Sixth, we analyze the evolution of the topics in SO.
Results:
We found that (1) SecBot is based on the retraining of the deep learning model RoBERTa. SecBot offers the best F1-Score of .935, (2) there are six error categories in misclassified samples by SecBot. SecBot was mostly wrong when the keywords/contexts were ambiguous (e.g., ‘gateway’ can be a security gateway or a simple gateway), (3) there are 9 security topics grouped into three categories: Software, Hardware, and Network, and (4) the highest number of topics belongs to software security, followed by network security and hardware security.
Conclusion:
IoT researchers and vendors can use SecBot to collect and analyze security-related discussions from developer discussions in SO. The analysis of nine security-related topics can guide major IoT stakeholders like IoT Security Enthusiasts, Developers, Vendors, Educators, and Researchers in the rapidly emerging IoT ecosystems.
ER  - 

TY  - JOUR
T1  - Artificial intelligence adoption challenges from healthcare providers’ perspectives: A comprehensive review and future directions
AU  - Abdelwanis, Moustafa
AU  - Simsekler, Mecit Can Emre
AU  - Gabor, Adriana F.
AU  - Sleptchenko, Andrei
AU  - Omar, Mohammad
JO  - Safety Science
VL  - 193
SP  - 107028
PY  - 2026
DA  - 2026/01/01/
SN  - 0925-7535
DO  - https://doi.org/10.1016/j.ssci.2025.107028
UR  - https://www.sciencedirect.com/science/article/pii/S092575352500253X
KW  - Artificial intelligence
KW  - Healthcare
KW  - Patient safety
KW  - AI adoption
KW  - Healthcare providers
KW  - Resilience
KW  - Human factors
AB  - The adoption of artificial intelligence in healthcare holds great promise for improving clinical decision-making and patient safety, optimizing administrative processes, and ultimately enhancing patient outcomes. However, the successful and safe integration of AI technologies into clinical practice is hindered by several challenges and concerns. This study provides a systematic literature review to identify and analyze the key barriers with the aim of facilitating the successful implementation of AI-driven technologies in healthcare. Searches were conducted across Web of Science, PubMed, and Scopus, yielding 92 relevant studies. From these, 16 key barriers were identified, including data quality and bias, infrastructure limitations, financial constraints, workflow misalignment, inadequate training, and issues of transparency and accountability. These challenges were subsequently categorized into three clusters using the Human-Organization-Technology (HOT) framework. Human-related challenges include insufficient training, resistance from healthcare providers, and the potential for increased workload. Technology-related challenges concern issues of accuracy, explainability, and the lack of contextual adaptability. Organizational challenges involve infrastructure limitations, inadequate leadership support, and regulatory constraints. To address these barriers, this study proposes a system-level conceptual framework designed to guide both the evaluation and the effective integration of AI into healthcare systems. The framework adopts a sequential structure comprising three main phases: assessment, implementation, and continuous monitoring. Therefore, it ensures that integration is both systematic and sustainable. By linking the identified barriers to targeted strategies across these phases, the framework provides a practical roadmap for overcoming challenges and advancing the safe and effective adoption of AI in healthcare.
ER  - 

TY  - JOUR
T1  - Development of the Machine Learning-based Safety Significant Factor Inference Model for Diagnosis in Autonomous Control System
AU  - Lee, Joomyung
AU  - Lin, Linyu
AU  - Athe, Paridhi
AU  - Dinh, Nam
JO  - Annals of Nuclear Energy
VL  - 162
SP  - 108443
PY  - 2021
DA  - 2021/11/01/
SN  - 0306-4549
DO  - https://doi.org/10.1016/j.anucene.2021.108443
UR  - https://www.sciencedirect.com/science/article/pii/S0306454921003194
KW  - Diagnosis
KW  - Digital twin
KW  - Recurrent Neural Network
KW  - Safety significant factor
KW  - Machine Learning
AB  - As a critical component to the autonomous control system, Digital Twin for Diagnosis (DT-D) is a virtual replica of physical systems for an accurate understanding of reactor states. Since the physical damage state cannot be measured directly in transient or accident conditions, safety significant factor (SSF) is introduced as a surrogate index for physical damage states to support safety-related decision making. This study develops a machine learning (ML) based SSF inference model (SSFIM) using the Recurrent Neural Network (RNN) with acceptable accuracy, generalization capability, effectiveness, and robustness against sensor errors. To demonstrate the capability of the ML-based SSFIM, case studies are implemented on a plant simulator for Experimental Breeder Reactor – II. For partial loss of flow accident scenarios, the SSFIM is able to infer the peak fuel centerline temperature with minimally one sensor. Meanwhile the SSFIM is also found to be robust against manipulated sensor drifts and/or random noises.
ER  - 

TY  - JOUR
T1  - Enhancing wind power prediction with self-attentive variational autoencoders: A comparative study
AU  - Harrou, Fouzi
AU  - Dairi, Abdelkader
AU  - Dorbane, Abdelhakim
AU  - Sun, Ying
JO  - Results in Engineering
VL  - 23
SP  - 102504
PY  - 2024
DA  - 2024/09/01/
SN  - 2590-1230
DO  - https://doi.org/10.1016/j.rineng.2024.102504
UR  - https://www.sciencedirect.com/science/article/pii/S259012302400759X
KW  - Wind power forecasting
KW  - Data-driven
KW  - Deep learning
KW  - Self-attentive VAE
KW  - RNN
AB  - Accurate wind power prediction is critical for efficient grid management and the integration of renewable energy sources into the power grid. This study presents an effective deep-learning approach that improves short-term wind power forecasting accuracy. The method incorporates a Variational Autoencoder (VAE) with a self-attention mechanism applied in both the encoder and decoder. This empowers the model to leverage VAE's strengths in time-series modeling and nonlinear approximation while focusing on the most relevant features within the wind power data. The effectiveness of this approach is evaluated through a comprehensive comparison with eight established deep learning methods, including Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM) networks, Bidirectional LSTMs (BiLSTMs), Convolutional LSTMs (ConvLSTMs), Gated Recurrent Units (GRUs), Stacked Autoencoders (SAEs), Restricted Boltzmann Machines (RBMs), and vanilla VAEs. Real-world data from five wind turbines in France and Turkey is used for the evaluation. Five statistical metrics are employed to quantitatively assess the prediction performance of each method. The results indicate that the SA-VAE model consistently outperformed other models, achieving the highest average R2 value of 0.992, demonstrating its superior predictive capability compared to existing techniques.
ER  - 

TY  - JOUR
T1  - Finding associations between natural and computer languages: A case-study of bilingual LDA applied to the bleeping computer forum posts
AU  - Yao, Kundi
AU  - Oliva, Gustavo A.
AU  - Hassan, Ahmed E.
AU  - Asaduzzaman, Muhammad
AU  - Malton, Andrew J.
AU  - Walenstein, Andrew
JO  - Journal of Systems and Software
VL  - 201
SP  - 111651
PY  - 2023
DA  - 2023/07/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2023.111651
UR  - https://www.sciencedirect.com/science/article/pii/S0164121223000468
KW  - Technical support
KW  - Logs
KW  - LDA
KW  - Multilingual LDA
KW  - Topic models
AB  - In the context of technical support, trails of technical discussions often contain a mixture of natural language (e.g., English) and software log excerpts. Uncovering latent links between certain problems and log excerpts that are often requested during the discussions of those problems enables the construction of a valuable knowledge base. Nevertheless, uncovering such latent links is challenging because English and software logs are two fundamentally different languages. In this paper, we investigate the suitability of multilingual LDA models to address the problem at hand. We study three models, namely: enriched LDA (M+), two-layer LDA (M2L), and off-the-shelf bilingual LDA (Mbi). We use approximately 8K discussion threads from a Bleeping Computer forum as our dataset. We observe that M2L performs the best overall, although it yields a substantially coarser-grained view of the discussed themes in the threads (20 topics, 0.3% of the documents). We also note that M+ outperforms Mbi achieving higher coherence, lower perplexity, and higher cross-lingual coverage ratio. We invite future studies to qualitatively assess the quality of the topics produced by the LDA models, such that the feasibility of employing such models in practice can be better determined.
ER  - 
