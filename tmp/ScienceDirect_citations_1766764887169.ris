TY  - JOUR
T1  - Continuous multi-task pre-training for malicious URL detection and webpage classification
AU  - Li, Yujie
AU  - Liu, Yiwei
AU  - Li, Peiyue
AU  - Jia, Yifan
AU  - Wang, Yanbin
JO  - Computer Networks
VL  - 270
SP  - 111513
PY  - 2025
DA  - 2025/10/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2025.111513
UR  - https://www.sciencedirect.com/science/article/pii/S1389128625004803
KW  - Malicious URL detection
KW  - Multi-task learning
KW  - Pre-trained model
KW  - URL topic classification
AB  - Malicious URL detection and webpage classification are critical tasks in cybersecurity and information management. In recent years, extensive research has explored using BERT or similar language models to replace traditional machine learning methods for detecting malicious URLs and classifying webpages. While previous studies show promising results, they often apply existing language models to these tasks without accounting for the inherent differences in domain data (e.g., URLs being loosely structured and semantically sparse compared to text), leaving room for performance improvement. Furthermore, current approaches focus on single tasks and have not been tested in multi-task scenarios. To address these challenges, we propose urlBERT, a pre-trained URL encoder leveraging Transformer to encode foundational knowledge from billions of unlabeled URLs. To achieve it, we propose to use 5 unsupervised pretraining tasks to capture multi-level information of URL lexical, syntax, and semantics, and generate contrastive and adversarial representations. Furthermore, to avoid inter-pre-training competition and interference, we proposed a grouped sequential learning method to ensure effective training across multi-tasks. Finally, we leverage a two-stage fine-tuning approach to improve the training stability and efficiency of the task model. To assess the multitasking potential of urlBERT, we fine-tune the task model in both single-task and multi-task modes. The former creates a classification model for a single task, while the latter builds a classification model capable of handling multiple tasks. We evaluate URLBERT on three downstream tasks: phishing URL detection, advertising URL detection, and webpage classification. The results demonstrate that urlBERT outperforms standard pre-trained models, and its multi-task mode is capable of addressing the real-world demands of multitasking. The code is available at https://github.com/Davidup1/URLBERT.
ER  - 

TY  - JOUR
T1  - A multimodal interpretable framework for adversarial intent attribution and forensics in unmanned systems
AU  - Zhang, Zhentong
AU  - Li, Xinde
AU  - Zhang, Zeyu
AU  - Wang, Kui
AU  - Gao, Tianrong
AU  - Shen, Tao
JO  - Reliability Engineering & System Safety
VL  - 267
SP  - 111917
PY  - 2026
DA  - 2026/03/01/
SN  - 0951-8320
DO  - https://doi.org/10.1016/j.ress.2025.111917
UR  - https://www.sciencedirect.com/science/article/pii/S0951832025011172
KW  - Unmanned systems safety
KW  - Explainable artificial intelligence
KW  - Intent attribution
KW  - Multimodal reasoning
KW  - Adversarial attacks
AB  - Adversarial attacks pose safety risks in unmanned systems, where victim models can cause critical accidents. Existing approaches generally lack sufficient traceability and interpretability for post-incident analysis. This paper proposes an interpretable framework for adversarial intent attribution to improve the reliability of accident forensics in attacked unmanned systems. Specifically, we develop an attack localization algorithm leveraging frequency-domain sensitivity of adversarial perturbations to identify affected regions. Next, a jointly trained denoising module and original class classifier restore the true semantic labels of attacked regions, upon which an adversarial intent predictor reveals the manipulated target categories. Structured predictions are integrated into prompts for a multimodal large language model (MLLM) to generate intent explanations via cross-modal reasoning, with a multi-agent game strategy optimizing semantic consistency and causal logic. To validate the framework’s effectiveness, an automatic evaluation module based on large language models (LLM-Judge) simulates expert review to assess explanation quality. The framework transparently attributes attacker behaviors, supporting both proactive warning and post-incident auditing. Experiments on the attacked Cityscapes and iSAID datasets show Motivation gains of 2.8%/2.73% and Professionalism gains of 3.6%/4.1%, outperforming state-of-the-art baselines. The source code and datasets are publicly available at GitHub.
ER  - 

TY  - JOUR
T1  - Role of Natural Language Processing in Automatic Detection of Unexpected Findings in Radiology Reports: A Comparative Study of RoBERTa, CNN, and ChatGPT
AU  - López-Úbeda, Pilar
AU  - Martín-Noguerol, Teodoro
AU  - Escartín, Jorge
AU  - Luna, Antonio
JO  - Academic Radiology
VL  - 31
IS  - 12
SP  - 4833
EP  - 4842
PY  - 2024
DA  - 2024/12/01/
SN  - 1076-6332
DO  - https://doi.org/10.1016/j.acra.2024.07.057
UR  - https://www.sciencedirect.com/science/article/pii/S1076633224005622
KW  - Natural Language Processing
KW  - Unexpected Findings
KW  - RoBERTa
KW  - ChatGPT
KW  - CNN
AB  - Rationale and Objectives
Large Language Models can capture the context of radiological reports, offering high accuracy in detecting unexpected findings. We aim to fine-tune a Robustly Optimized BERT Pretraining Approach (RoBERTa) model for the automatic detection of unexpected findings in radiology reports to assist radiologists in this relevant task. Second, we compared the performance of RoBERTa with classical convolutional neural network (CNN) and with GPT4 for this goal.
Materials and Methods
For this study, a dataset consisting of 44,631 radiological reports for training and 5293 for the initial test set was used. A smaller subset comprising 100 reports was utilized for the comparative test set. The complete dataset was obtained from our institution's Radiology Information System, including reports from various dates, examinations, genders, ages, etc. For the study's methodology, we evaluated two Large Language Models, specifically performing fine-tuning on RoBERTa and developing a prompt for ChatGPT. Furthermore, extending previous studies, we included a CNN in our comparison.
Results
The results indicate an accuracy of 86.15% in the initial test set using the RoBERTa model. Regarding the comparative test set, RoBERTa achieves an accuracy of 79%, ChatGPT 64%, and the CNN 49%. Notably, RoBERTa outperforms the other systems by 30% and 15%, respectively.
Conclusion
Fine-tuned RoBERTa model can accurately detect unexpected findings in radiology reports outperforming the capability of CNN and ChatGPT for this task.
ER  - 

TY  - JOUR
T1  - A domain-specific autonomous agent for network traffic analysis
AU  - Adanza, Daniel
AU  - Gifre, Lluis
AU  - Ojaghi, Behnam
AU  - Alemany, Pol
AU  - Muñoz, Raul
AU  - Vilalta, Ricard
JO  - Computer Networks
VL  - 274
SP  - 111809
PY  - 2026
DA  - 2026/01/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2025.111809
UR  - https://www.sciencedirect.com/science/article/pii/S1389128625007753
KW  - Autonomous agents
KW  - Traffic predictions
KW  - Automatization
KW  - LLM
KW  - Generative AI
KW  - Explainable AI
AB  - Network traffic analysis is critical for managing network availability, detecting anomalies, and mitigating security threats. However, modern network infrastructures are increasingly complex, with growing volumes of data making real-time traffic prediction and analysis more challenging. To cope with this issue, a custom autonomous agent has been designed to automate network traffic analysis and prediction in an efficient manner. Unlike general-purpose autonomous agents such as babyAGI and autoGPT, the presented agent is specifically tailored for network traffic management, incorporating domain-specific optimizations for data extraction, classification, and forecasting. The agent processes user requests by determining whether traffic analysis or prediction is required, extracting relevant data, generating predictions when necessary, and writing structured reports to assist network operators in decision-making. The approach was tested by implementing LLama 8B and ChatGPT 4.0 Large Language Models (LLMs), integrating Retrieval-Augmented Generation (RAG) techniques to provide useful information and improve the responses of the LLM. The results prove the efficacy of the RAG, showcasing a noticeable improvement in the factual accuracy in a subset of 40 intents implemented in a real-case scenario. The factual accuracy indicator showcased some robustness, reaching results in a range from 70 % to 100 % for both LLMs. The results prove the potential of agent-driven approaches to enhance automation and efficiency in network traffic analysis, demonstrating their applicability in real-world scenarios.
ER  - 

TY  - JOUR
T1  - Artificial intelligence for cybersecurity: Literature review and future research directions
AU  - Kaur, Ramanpreet
AU  - Gabrijelčič, Dušan
AU  - Klobučar, Tomaž
JO  - Information Fusion
VL  - 97
SP  - 101804
PY  - 2023
DA  - 2023/09/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2023.101804
UR  - https://www.sciencedirect.com/science/article/pii/S1566253523001136
KW  - Detection
KW  - Protection
KW  - Response
KW  - Recovery
KW  - Identify
KW  - Learning
KW  - Cyberattacks
KW  - Taxonomy
AB  - Artificial intelligence (AI) is a powerful technology that helps cybersecurity teams automate repetitive tasks, accelerate threat detection and response, and improve the accuracy of their actions to strengthen the security posture against various security issues and cyberattacks. This article presents a systematic literature review and a detailed analysis of AI use cases for cybersecurity provisioning. The review resulted in 2395 studies, of which 236 were identified as primary. This article classifies the identified AI use cases based on a NIST cybersecurity framework using a thematic analysis approach. This classification framework will provide readers with a comprehensive overview of the potential of AI to improve cybersecurity in different contexts. The review also identifies future research opportunities in emerging cybersecurity application areas, advanced AI methods, data representation, and the development of new infrastructures for the successful adoption of AI-based cybersecurity in today's era of digital transformation and polycrisis.
ER  - 

TY  - JOUR
T1  - StreamVAD: A streaming framework with progressive context integration for multi-temporal scale video anomaly detection
AU  - Han, Lijun
AU  - Liang, Gang
AU  - Wang, Pengcheng
AU  - Liu, Dingming
AU  - Zhao, Kui
JO  - Neurocomputing
VL  - 658
SP  - 131669
PY  - 2025
DA  - 2025/12/28/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2025.131669
UR  - https://www.sciencedirect.com/science/article/pii/S0925231225023410
KW  - Anomaly detection
KW  - Streaming framework
KW  - Weakly supervised learning
KW  - Hierarchical memory
KW  - Multiscale behavioral analysis
AB  - Video anomaly detection (VAD) plays a crucial role in intelligent surveillance systems by identifying abnormal events in video streams. However, most existing methods either rely on isolated feature extraction—failing to model inter-action contextual relationships critical for complex anomaly recognition—or demand full-video processing via graph/hierarchical architectures, which incur high latency, computational burden, and parameter/memory inefficiency with depth. Lightweight designs mitigate costs but sacrifice temporal sensitivity through shallow networks and short-clip inputs, limiting detection of subtle or multi-scale anomalies in streaming scenarios. To address these challenges, we propose StreamVAD, a lightweight streaming anomaly detection framework that achieves low-latency, long-term temporal modeling with minimal computational overhead. A Key Clip Generator (KCG) filters redundant inputs in a streaming manner, allowing the model to focus on informative content while reducing computational cost. A progressive context integration (PCI) module incrementally expands the temporal receptive field by integrating historical context without full-sequence buffering, enabling efficient detection of complex long-term anomalies. Additionally, a multi-scale temporal selection (MTS) strategy dynamically adapts temporal resolution to capture both short- and long-term abnormalities. Extensive experiments on UCF-Crime, XD-Violence, and a supplemental long-term anomaly dataset demonstrate that StreamVAD achieves effective video anomaly detection with fewer parameters and lower latency. The code and dataset are available at https://github.com/Han-lijun/StreamVAD.
ER  - 

TY  - JOUR
T1  - A Quantitative Framework for the Validation of Twin-Based Cyber Defense
AU  - Baiardi, Fabrizio
AU  - Sammartino, Vincenzo
JO  - Procedia Computer Science
VL  - 274
SP  - 721
EP  - 730
PY  - 2025
DA  - 2025/01/01/
T2  - 22nd International Multidisciplinary Modeling & Simulation Multiconference (I3M)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2025.12.070
UR  - https://www.sciencedirect.com/science/article/pii/S1877050925037913
KW  - validation
KW  - security twin
KW  - adversary emulation
KW  - intrusion graph
KW  - Monte Carlo simulations
KW  - cyber defense
AB  - The validation of cyber defense strategies is a critical challenge that becomes even more critical as we consider the lack of realistic data on intrusions enabled by new attack strategies. This paper presents a framework for continuous validation using security twins. Our approach is founded on creating a high-fdelity digital model of an ICT infrastructure, the security twin, and another model of an adversary, an attacker. We use these twins to apply a Monte Carlo method that runs a number of simulations of the intrusions of the attacker. Using the output of these simulations, we generate and validate an Intrusion Graph, a model that details how vulnerabilities can be exploited to orchestrate intrusions into the infrastructure. Each step in the simulated intrusion is validated through a system of pre- and postconditions, ensuring logical and temporal consistency. The primary advantage of this approach is its non-intrusive nature and this results in a rigorous validation and the generation of high-quality synthetic data without disrupting the operational infrastructure. This validated model serves as a powerful tool for training AI-driven defense agents, evaluating countermeasures, and predicting the impact of emerging threats in a dynamic risk landscape.
ER  - 

TY  - JOUR
T1  - Few-shot relation extraction approach for threat intelligence based on multi-level attention mechanism and hybrid prototypical network
AU  - Xie, Yushun
AU  - Bao, Junchi
AU  - Zong, Rui
AU  - Gu, Zhaoquan
AU  - Wang, Haiyan
JO  - Array
VL  - 26
SP  - 100405
PY  - 2025
DA  - 2025/07/01/
SN  - 2590-0056
DO  - https://doi.org/10.1016/j.array.2025.100405
UR  - https://www.sciencedirect.com/science/article/pii/S2590005625000323
KW  - Relation extraction
KW  - Few-shot learning
KW  - Cyber Threat Intelligence
KW  - Multi-level attention mechanism
KW  - Hybrid prototypical network
KW  - Meta-learning
AB  - With the increasing complexity of cyberattacks, the frequency and severity of cybersecurity incidents have escalated dramatically. Cyber Threat Intelligence (CTI) relation extraction plays a critical role in cybersecurity event analysis by identifying semantic relationships between security-related entities, thereby converting unstructured information into structured data formats. Nevertheless, within the domain of CTI, labeled datasets are limited, and the process of manual labeling incurs substantial costs, rendering it impractical on a large scale. To address these challenges, we propose a novel few-shot relation extraction method for small-scale threat intelligence data, termed RETI-MA-HP, which is based on a multi-level attention mechanism and a hybrid prototypical network. By integrating these advanced techniques, the RETI-MA-HP model is capable of learning from limited data and rapidly generalize to new relation classification tasks. To enhance the representational capacity of feature vectors, RETI-MA-HP incorporates a self-training module to refine the BERT-based encoder. Meanwhile, to mitigate misclassification arising from syntactically similar sentences, RETI-MA-HP employ contrastive learning to strengthen the hybrid prototypical network. Furthermore, we constructed a dedicated CTI dataset. Extensive experiments demonstrate that RETI-MA-HP achieves excellent performance across multiple tasks, attaining a maximum relation extraction accuracy of 75.44%, which constitutes a 15.5% improvement over compared models. These results prove that the effectiveness of RETI-MA-HP for relation extraction within the CTI domain.
ER  - 

TY  - JOUR
T1  - Knowledge enhancement and disentanglement learning for video captioning
AU  - Wang, Mingyue
AU  - Ma, Yujun
AU  - Cai, Biao
AU  - Li, Dongfen
AU  - He, Xiangjian
AU  - Wang, Ruili
JO  - Knowledge-Based Systems
VL  - 326
SP  - 114003
PY  - 2025
DA  - 2025/09/27/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2025.114003
UR  - https://www.sciencedirect.com/science/article/pii/S0950705125010482
KW  - Video captioning
KW  - Large language model
KW  - Disentanglement learning
KW  - Knowledge enhancement
AB  - Video captioning, bridging computer vision and natural language, is crucial for various knowledge-based systems in the age of video streaming. Recent video captioning approaches have shown promise by integrating additional text-related knowledge to enhance understanding of video content and generate more informative captions. However, methods relying heavily on knowledge graphs face several limitations, including (i) a restricted capacity to reason complex relations among object words due to static logic rules, (ii) a lack of context awareness for spatio-temporal relation analysis in videos, and (iii) the complexity of manually constructing a knowledge graph. These limitations lead to insufficient semantic information and obstruct effective alignment between visual and textual modalities. To tackle these issues, we propose a novel knowledge enhancement and disentanglement learning method for video captioning. Our approach introduces a comprehensive and adaptable knowledge source to enhance text-related knowledge, thus directly improving caption generation. Specifically, we leverage a large language model to infer enriched semantic relations between object words and speech transcripts within video frames. By integrating visual, auditory, and textual information into universal tokens with task-specific prompts, our approach enhances semantic understanding and captures more diverse relations. Furthermore, we propose a novel modality-shared disentanglement learning strategy to better align modalities, enabling a more precise link of visual cues to their corresponding textual descriptions. Specifically, we disentangle two modalities into shared and specific features, leveraging shared features to ensure alignment while mitigating uncorrelated information. Extensive experiments demonstrate that our proposed method outperforms existing methods in both quantitative and qualitative results.
ER  - 

TY  - JOUR
T1  - Tabular Federated Learning to detect cyber faults in smart buildings
AU  - Annam, Sangeetha
AU  - Khullar, Vikas
JO  - Proceedings of the Institution of Civil Engineers - Smart Infrastructure and Construction
PY  - 2024
DA  - 2024/11/29/
SN  - 2397-8759
DO  - https://doi.org/10.1680/jsmic.23.00070
UR  - https://www.sciencedirect.com/science/article/pii/S2397875924000139
KW  - artificial intelligence
KW  - cyber-physical systems
KW  - cyber security
KW  - data privacy
KW  - Federated Learning
KW  - internet of things
KW  - sustainable cities and communities
AB  - By incorporating artificial intelligence into applications, everyone in the current circumstance has become intelligent, thereby reducing the burden of incessant interruption or human control. In today’s environment, most of the hardware infrastructure in buildings is connected to the internet, transforming the building infrastructure into a smart building infrastructure. In a similar vein, it should be noted that intelligent building infrastructure is susceptible to cyber-induced defects, and the issue of data privacy is a significant worry within the realm of collaborative learning. The primary objective of this study is to devise and implement an Attentive Interpretable Tabular-based Federated Learning methodology for safeguarding data privacy while detecting cyber-induced problems in the infrastructure of intelligent buildings. In this paper, Federated Learning ecosystem–based deep learning models are used to find and describe cyber-induced faults and vulnerabilities. The suggested system will be evaluated using various measures, including accuracy, precision, recall, and losses. In addition, the built ecosystem is examined using various data distributions to determine whether the outcomes are stable.
ER  - 

TY  - JOUR
T1  - AI-generated content in cross-domain applications: Research trends, challenges and propositions
AU  - Li, Jianxin
AU  - Qu, Liang
AU  - Cai, Taotao
AU  - Zhao, Zhixue
AU  - Al Hasan Haldar, Nur
AU  - Krishna, Aneesh
AU  - Kong, Xiangjie
AU  - Romero Macau, Flavio
AU  - Chakraborty, Tanmoy
AU  - Deroy, Aniket
AU  - Lin, Binshan
AU  - Blackmore, Karen
AU  - Noman, Nasimul
AU  - Cheng, Jingxian
AU  - Cui, Ningning
AU  - Xu, Jianliang
JO  - Knowledge-Based Systems
VL  - 330
SP  - 114634
PY  - 2025
DA  - 2025/11/25/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2025.114634
UR  - https://www.sciencedirect.com/science/article/pii/S0950705125016739
KW  - Artificial intelligence generated content (AIGC)
KW  - Generative AI
KW  - Large language models (LLMs)
KW  - Content detection
KW  - Online marketing
AB  - Artificial Intelligence Generated Content (AIGC) has rapidly emerged with the capability to generate different forms of content, including text, images, videos, and other modalities, which can achieve a quality similar to content created by humans. As a result, AIGC is now widely applied across various domains such as digital marketing, education, and public health, and has shown promising results by enhancing content creation efficiency and improving information delivery. However, there are few studies that explore the latest progress and emerging challenges of AIGC across different domains. To bridge this gap, this paper brings together 16 scholars from multiple disciplines to provide a cross-domain perspective on the trends and challenges of AIGC. Specifically, the contributions of this paper are threefold: (1) It first provides a broader overview of AIGC, spanning the training techniques of Generative AI, detection methods, and both the spread and use of AI-generated content across digital platforms. (2) It then introduces the societal impacts of AIGC across diverse domains, along with a review of existing methods employed in these contexts. (3) Finally, it discusses the key technical challenges and presents research propositions to guide future work. Through these contributions, this vision paper seeks to offer readers a cross-domain perspective on AIGC, providing insights into its current research trends, ongoing challenges, and future directions.
ER  - 

TY  - JOUR
T1  - Automatic phishing website detection and prevention model using transformer deep belief network
AU  - Majgave, Amol Babaso
AU  - Gavankar, Nitin L.
JO  - Computers & Security
VL  - 147
SP  - 104071
PY  - 2024
DA  - 2024/12/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104071
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824003766
KW  - Phishing website
KW  - Transformer-based deep belief networks
KW  - One hot encoding
KW  - Variation auto encoder
KW  - DarkNet19
KW  - Intelligence binary bat algorithm detection
AB  - In the digitally connected world cybersecurity is paramount, phishing where attackers pose as trusted entities to steal sensitive data, looms large. The proliferation of phishing attacks on the internet poses a substantial threat to individuals and organizations, compromising sensitive information and causing financial and reputational damage. This study's goal is to establish an automated system for the early detection and prevention of phishing websites, thereby enhancing online security and protecting users from cyber threats. This research initially employs One Hot Encoding (OHE) mechanism-based pre-processing mechanism that converts every URL string into a numerical vector with a particular dimension. This study utilizes two feature selection techniques which are transfer learning-based feature extraction using DarkNet19 and Variational Autoencoder (VAE) to select the value of the most important feature. The robust security mechanisms are presented to prevent phishing attacks and safeguard personal information on websites. List-based deep learning-based systems to prevent and detect phishing URLs more efficiently. The study proposes a transformer-based Deep Belief Network (TB-DBN), a veritable pre-trained deep transformer network model for phishing behaviour detection. A cross-validation technique with grid search hyper-parameter tuning based on the Intelligence Binary Bat Algorithm (IBBA) was designed using the proposed hybrid model. Predictions were made to classify the phishing URLs using a probabilistic estimation guided boosting classifier model and evaluate their performance in terms of accuracy, precision, recall, specificity, and F1- score. The risk level associated with the URL will be assessed based on various factors, such as the source's reputation, content analysis results, and behavioural anomalies. The computational complexity of DL model training is influenced by various factors, such as the model's complexity, the training data's size, and the optimization algorithm exploited, for training. The outcome demonstrates that tweaking variables increases the effectiveness of Python-based deep learning systems. The findings of the proposed method excel, achieving an accuracy of 99.4 %, precision of 99.2 %, recall of 99.3 %, and an F1-score of 99.2 %. This innovative automatic phishing website detection and prevention model, based on a Transformer-based Deep Belief Network, offers advanced accuracy and adaptability, strengthening cybersecurity measures to safeguard sensitive user information and mitigate the substantial threat of phishing attacks in the digitally connected world.
ER  - 

TY  - JOUR
T1  - CCLog: Actionable APT forensics via fused log semantics and provenance graph topology
AU  - Hu, Zhichao
AU  - Liu, Likun
AU  - Li, Hongjie
AU  - Song, Chen
AU  - Ge, Mengmeng
AU  - Guo, Qing
AU  - Ma, Lina
AU  - Yu, Xiangzhan
JO  - Computer Networks
VL  - 272
SP  - 111660
PY  - 2025
DA  - 2025/11/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2025.111660
UR  - https://www.sciencedirect.com/science/article/pii/S1389128625006279
KW  - APT
KW  - Provenance graph
KW  - Pretrained model
KW  - Attack provenance
AB  - Advanced Persistent Threats (APTs) are highly targeted, stealthy, and sophisticated cyber attacks that pose significant risks to network services, infrastructure, and data security. APT actors primarily target government agencies, research institutions, defense systems, and e-commerce platforms, creating growing cybersecurity challenges. Existing APT detection methods rely on rule-based models with predefined attack signatures or deep learning approaches that learn attack patterns from large-scale data. However, they suffer from high false positive rates, limited contextual understanding, and high computational overhead, making them ineffective against evolving threats. To overcome these limitations, we propose CCLog, a context-aware correlation analysis framework for APT detection and attack provenance. CCLog constructs a provenance graph from system logs, applies a BERT-based pre-trained model for log analysis, and employs a Variational Autoencoder for anomaly detection. Attack path reconstruction is optimized using a Steiner tree approach with shortest-path heuristics and a greedy algorithm, improving accuracy while reducing computational costs. Experimental results show that in the APT attack detection phase, CCLog achieves an average F1-score of 0.9012 across five datasets including CADETS, ARENA, THEIA, Trace, and clearscope, with an average improvement of 18.66% and a 4.23% improvement over the second-ranked method. In the APT attack provenance phase, it achieves an average F1-score of 0.8663, with an average improvement of 16.78% and a 0.59% improvement over the second-ranked method. Additionally, attack path reconstruction achieves optimal or near-optimal performance while reducing resource consumption by 30%. These findings highlight the effectiveness and practicality of CCLog for real-world APT detection and forensic analysis, advancing cybersecurity analytics.
ER  - 

TY  - JOUR
T1  - Homophobia and transphobia span identification in low-resource languages
AU  - Kumaresan, Prasanna Kumar
AU  - Kayande, Devendra Deepak
AU  - Priyadharshini, Ruba
AU  - Buitelaar, Paul
AU  - Chakravarthi, Bharathi Raja
JO  - Natural Language Processing Journal
VL  - 12
SP  - 100169
PY  - 2025
DA  - 2025/09/01/
SN  - 2949-7191
DO  - https://doi.org/10.1016/j.nlp.2025.100169
UR  - https://www.sciencedirect.com/science/article/pii/S2949719125000457
KW  - LGBTQ＋ hate speech
KW  - Span-based classification
KW  - Low-resource language
KW  - BERT architecture
KW  - Sequence labeling
AB  - Online platforms have become prevalent because they promote free speech and group discussions. However, they also serve as platforms for hate speech, which can negatively impact the psychological well-being of vulnerable people. This is especially true for members of the LGBTQ＋ community, who are often the targets of homophobia and transphobia in online environments. Our study makes three main contributions: (1) we developed a new dataset with span-level annotations for homophobia and transphobia in Tamil, English, and Marathi; (2) we employed advanced language models using BERT-based architectures, Conditional Random Field (CRF), and Bidirectional Long Short-Term Memory (BiLSTM) layers to enhance span-level detection of harmful content; and (3) we conducted benchmarking to evaluate the effectiveness of monolingual and multilingual models in detecting subtle forms of hate speech. The annotated dataset, which is collected from real-world social media (YouTube) content, provides diverse language contexts and enhances the representation of low-resource languages. The span-based detection approach enables models to detect subtle linguistic nuances, leading to more precise content moderation that accounts for cultural differences. The experimental results show that our models achieve effective span detection, which provides valuable information for creating inclusive moderation tools. Our research leads to the development of AI systems, and we aim to reduce the burden on moderators and improve the quality of online experiences for LGBTQ＋ vulnerable.
ER  - 

TY  - JOUR
T1  - LLM-Agent-UMF: LLM-based Agent Unified Modeling Framework for Seamless Design of Multi Active/Passive Core-Agent Architectures
AU  - Ben Hassouna, Amine
AU  - Chaari, Hana
AU  - Belhaj, Ines
JO  - Information Fusion
VL  - 127
SP  - 103865
PY  - 2026
DA  - 2026/03/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2025.103865
UR  - https://www.sciencedirect.com/science/article/pii/S1566253525009273
KW  - LLM-based agent
KW  - Software architecture
KW  - Modularity
KW  - Security
KW  - Privacy
KW  - Safety
KW  - Core-agent classification
KW  - Multi-core agent
AB  - In an era where vast amounts of data are collected and processed from diverse sources, there is a growing demand for sophisticated AI systems capable of intelligently fusing and analyzing this information. To address these challenges, researchers have turned towards integrating tools into LLM-powered agents to enhance the overall information fusion process. However, the conjunction of these technologies and the proposed enhancements in several state-of-the-art works followed a non-unified software architecture, resulting in a lack of modularity and terminological inconsistencies among researchers. To address these issues, we propose a novel LLM-based Agent Unified Modeling Framework (LLM-Agent-UMF) that establishes a clear foundation for agent development from both functional and software architectural perspectives, developed and evaluated using the Architecture Tradeoff and Risk Analysis Framework (ATRAF). Our framework clearly distinguishes between the different components of an LLM-based agent, setting LLMs and tools apart from a new element, the core-agent, which plays the role of central coordinator. This pivotal entity comprises five modules: planning, memory, profile, action, and security—the latter often neglected in previous works. By classifying core-agents into passive and active types based on their authoritative natures, we propose various multi-core agent architectures that combine unique characteristics of distinctive agents to tackle complex tasks more efficiently. We evaluate our framework by applying it to thirteen state-of-the-art agents, thereby demonstrating its alignment with their functionalities and clarifying overlooked architectural aspects. Moreover, we thoroughly assess five architecture variants of our framework by designing new agent architectures that combine characteristics of state-of-the-art agents to address specific goals. Throughout this evaluation, we leveraged ATRAF’s Architectural Framework Tradeoff and Risk Analysis Method (AFTRAM), identifying quality attribute goals, developing scenarios, and analyzing architectural risks, which provided clear insights into potential improvements and highlighted challenges involved in both designing new agents and combining existing ones.
ER  - 

TY  - JOUR
T1  - Enhancing anomaly detection Efficiency: Introducing grid searchbased multi-population particle Swarm optimization algorithm based optimized Regional based Convolutional neural network for robust and scalable solutions in High-Dimensional data
AU  - Nalini, M.
AU  - Yamini, B.
AU  - Fernandez, F. Mary Harin
AU  - Uma Priyadarsini, P.S.
JO  - Biomedical Signal Processing and Control
VL  - 96
SP  - 106651
PY  - 2024
DA  - 2024/10/01/
SN  - 1746-8094
DO  - https://doi.org/10.1016/j.bspc.2024.106651
UR  - https://www.sciencedirect.com/science/article/pii/S1746809424007092
KW  - Data mining
KW  - Feature selection
KW  - Redundancy avoidance
KW  - Storage
KW  - Regional based convolutional neural network
AB  - Anomaly detection is critically important for enhancing data security across networks, industrial applications, and fraud detection systems. Traditional methods in anomaly detection often struggle with the challenges posed by high-dimensional data, leading to increased computational complexity and reduced accuracy due to minimal support value thresholds associated with uncertain data. To address these issues, this paper proposes a novel approach: the Grid Search-based multi-population Particle Swarm Optimization algorithm optimized Regional based Convolutional Neural Network (GSMPSO-MM-RCNN). This method aims to minimize computational time while maintaining high accuracy in anomaly detection tasks. By leveraging GSMPSO for parameter optimization, the approach efficiently tunes the RCNN model to handle complex data structures effectively. Moreover, GSMPSO-MM-RCNN incorporates mechanisms to eliminate redundant data from uncertain databases, enhancing the relevance and quality of information used for anomaly detection. The method also focuses on maximizing robustness by mitigating the impact of anomalies during the training process, thereby reducing overfitting and improving the model’s ability to detect hidden patterns in network data. Experimental validations conducted on four diverse datasets demonstrate the effectiveness of the proposed approach in terms of scalability and accuracy. The results reveal a significant achievement, with the GSMPSO-MM-RCNN method achieving an impressive accuracy of 90%, surpassing the performance of existing approaches. This underscores the potential of the proposed methodology to offer a reliable solution for handling complex, high-dimensional datasets in anomaly detection, promising substantial advancements in data security and fraud prevention applications.
ER  - 

TY  - JOUR
T1  - Developing ethical principle awareness and reasoning in a cybersecurity context: Enhancing user understanding using ripple down rules
AU  - Abdulrahman, Amal
AU  - Richards, Deborah
AU  - Bilgin, Ayse Aysin
AU  - Formosa, Paul
JO  - Computers & Security
VL  - 161
SP  - 104761
PY  - 2026
DA  - 2026/02/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104761
UR  - https://www.sciencedirect.com/science/article/pii/S016740482500450X
KW  - Ethical decision-making
KW  - Ripple down rules (RDR)
KW  - Principlist ethics framework
KW  - Behaviour change in cybersecurity
KW  - Case-based reasoning
AB  - Cybersecurity breaches are often attributed to human behaviour, where individuals fail to integrate ethical principles in their decision-making. This empirical study investigates the effectiveness of the Ripple Down Rules (RDR) method, a knowledge acquisition and representation method, in enhancing ethical awareness and reasoning in cybersecurity contexts. The proposed approach combines rule-based reasoning, case-based learning, reflection, and situated cognition to bridge the gap between ethical knowledge and action by systematically connecting scenario elements to ethical principles. Participants, recruited from a cohort of first-year psychology students, were exposed to training incorporating five ethical principles—Beneficence, Non-Maleficence, Justice, Autonomy, and Explicability—applied to realistic cybersecurity scenarios. The study employed a randomised controlled design with two treatment and one control groups, using pre- and post-study assessments to evaluate improvements in ethical principle identification and reasoning. Participants rated RDR as a clear and helpful tool for understanding ethical reasoning, with sensibility and helpfulness scores ranging from moderate to high. Results demonstrate that RDR training significantly improved participants' ability to identify ethical principles compared to learning without RDR, particularly for principles like autonomy and explicability. However, challenges persisted in distinguishing overlapping principles, such as beneficence and non-maleficence. Implications and guidance for use of RDR for ethics training are discussed.
ER  - 

TY  - JOUR
T1  - HarmonyNet: Navigating hate speech detection
AU  - Raza, Shaina
AU  - Chatrath, Veronica
JO  - Natural Language Processing Journal
VL  - 8
SP  - 100098
PY  - 2024
DA  - 2024/09/01/
SN  - 2949-7191
DO  - https://doi.org/10.1016/j.nlp.2024.100098
UR  - https://www.sciencedirect.com/science/article/pii/S2949719124000463
KW  - Hate speech
KW  - Transformer-based models
KW  - Language models
AB  - In the digital era, social media platforms have become central to communication across various domains. However, the vast spread of unregulated content often leads to the prevalence of hate speech and toxicity. Existing methods to detect this toxicity struggle with context sensitivity, accommodating diverse dialects, and adapting to varied communication styles. To tackle these challenges, we introduce an ensemble classifier that leverages the strengths of language models and traditional deep neural network architectures for more effective hate speech detection on social media. Our evaluations show that this hybrid approach outperforms individual models and exhibits robustness against adversarial attacks. Future efforts will aim to enhance the model’s architecture to further boost its efficiency and extend its capability to recognize hate speech across an even wider range of languages and dialects.
ER  - 

TY  - JOUR
T1  - Automotive Intelligence for supporting Vehicle-SOC analysts
AU  - Barletta, Vita Santa
AU  - Caivano, Danilo
AU  - Catalano, Christian
AU  - De Vincentiis, Mirko
AU  - Scalera, Michele
JO  - Computer Standards & Interfaces
VL  - 96
SP  - 104088
PY  - 2026
DA  - 2026/03/01/
SN  - 0920-5489
DO  - https://doi.org/10.1016/j.csi.2025.104088
UR  - https://www.sciencedirect.com/science/article/pii/S0920548925001175
KW  - CAN
KW  - NLP
KW  - Automotive
KW  - Cybersecurity
KW  - Artificial intelligence
KW  - Threat intelligence
AB  - The automotive industry is designing increasingly sophisticated electronic components in order to make modern vehicles safer and more connected. This means not only more functionality available but also an increased risk to vehicle security and driver safety. Over the years, academia and industry have identified security issues in Electronic Control Units (ECUs) software and the protocols they use to communicate. Many of the attacks proposed in the literature exploit weaknesses in the Controller Area Network (CAN), one of the most widely used protocols for internal network communication. Researchers have proposed techniques focused on using Machine Learning (ML) models to identify attacks that exploit vulnerabilities in the CAN protocol. However, these techniques are not enough, as it is necessary to introduce the knowledge of how these attacks occurred and propose remediations to counter them to design more secure components. So, it is necessary to use ML models that use a multi-class classification to obtain the attack typology to obtain information that aims to resolve or understand the threat. To this end, this paper proposes a Pachamama methodology that identifies CAN attacks by proposing a simulation environment in which an ML algorithm is deployed. Then, a Vehicle-Security Operation Center (Vehicle-SOC) allows the classification of the received message from the Intrusion Detection System (IDS) to propose remediations for security analysts or developers working in the automotive world.
ER  - 

TY  - JOUR
T1  - Detection and mitigation against false data injection attacks using SHT and ANN in distributed control of DC microgrid
AU  - Alankrita, 
AU  - Pati, Avadh
AU  - Adhikary, Nabanita
JO  - Electric Power Systems Research
VL  - 241
SP  - 111356
PY  - 2025
DA  - 2025/04/01/
SN  - 0378-7796
DO  - https://doi.org/10.1016/j.epsr.2024.111356
UR  - https://www.sciencedirect.com/science/article/pii/S0378779624012422
KW  - Cyberattack mitigation
KW  - Cyber security
KW  - Distributed control
KW  - False data injection attack
KW  - Microgrid
KW  - Sequential hypothesis testing
AB  - This article explores the susceptibility of network-connected DC Microgrids (MGs) to cyber threats, specifically focusing on combating false data injection attacks (FDIAs). It introduces a collaborative model that merges FDIA detection using Sequential Hypothesis Testing (SHT) with countermeasures derived from Artificial Neural Network (ANN) based control. Employing distributed control via adaptive droop, the proposed model integrates a detector that scrutinizes input currents for anomalies by comparing them with forecasted values provided by an ANN-based estimator. Upon detecting any deviation from the anticipated state, a countermeasure is activated, adjusting the adaptive droop control to utilize alternative measurements, thus minimizing the impact of an attack. To assess the efficacy of this approach, the study conducts dynamic simulations across diverse operational scenarios and tolerance thresholds. The findings demonstrate that the proposed method adeptly identifies falsely injected data and compensates for it even amidst severe attacks and prediction inaccuracies, thereby fortifying the security, reliability, and stability of DC MGs.
ER  - 

TY  - JOUR
T1  - A step-by-step definition of a reference architecture for cyber ranges
AU  - Kampourakis, Vyron
AU  - Gkioulos, Vasileios
AU  - Katsikas, Sokratis
JO  - Journal of Information Security and Applications
VL  - 88
SP  - 103917
PY  - 2025
DA  - 2025/02/01/
SN  - 2214-2126
DO  - https://doi.org/10.1016/j.jisa.2024.103917
UR  - https://www.sciencedirect.com/science/article/pii/S2214212624002199
KW  - Cyber range
KW  - Cybersecurity
KW  - Standardization
KW  - Evaluation formula
KW  - Reference architecture
AB  - Being on the advent of Industry 5.0, organizations have been progressively incorporating information technology into their formerly air-gapped operational technology architectures. This coalescence has nevertheless amplified the attack surface, ringing the bells of preparedness. In this direction, Cyber Ranges (CRs) have cropped up as a valuable and attractive solution, providing a diverse perspective on reinforcing the overall cybersecurity stance. However, there exists a significant literature gap in attempts to define a complete approach for CR design, development, evaluation, and operation as per the up-to-date guidelines. To address this shortcoming, this work introduces the first to our knowledge overarching, fine-grained reference architecture for CR. This is done by adopting a three-step, systematic methodology. First, we scrutinize contemporary guidelines to extract an abstract architectural model that structurally entrenches the foundations of CR reference architecture. Then, we percolate and pinpoint common functionalities and capabilities of existing CRs, towards delineating the functional and informational aspects of the reference architecture. Finally, we devise an evaluation formula that approximates the conformance of a CR with the state-of-the-art. Through the latter step, we impart a unified means of identifying the most appropriate components to implement the structural, functional, and informational aspects of a CR. Overall, this work can be seen as an attempt towards CR unification and standardization, therefore it is anticipated to serve as a basis and point of reference for multiple stakeholders at varying levels.
ER  - 

TY  - JOUR
T1  - PyPIMalDet: A malicious PyPI package detection method combining code features and metadata features
AU  - Yan, Jiale
AU  - Zhao, Bo
JO  - Neural Networks
VL  - 197
SP  - 108487
PY  - 2026
DA  - 2026/05/01/
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2025.108487
UR  - https://www.sciencedirect.com/science/article/pii/S0893608025013681
KW  - Malicious package detection
KW  - Python package index (PyPI)
KW  - Software supply chain security
KW  - Ensemble model
KW  - Machine learning
AB  - In recent years, there has been a surge in malicious software packages on the open-source PyPI software package registry. Given the vast number of software packages and frequent updates on PyPI, existing detection methods based on dynamic analysis or large language models are computationally and time-consuming, hindering the feasibility of real-time or large-scale scanning due to efficiency and cost constraints. To address these challenges, we propose a novel malicious package detection method named PyPIMalDet. This method constructs a detector by fusing source code behavior features and metadata features to improve detection performance. To address the feature overlap problem, we introduce a denoising autoencoder module in the code behavior feature extraction process to obtain robust code feature vectors. We design an adaptive fusion stacking ensemble framework for two types of features to achieve efficient and lightweight detection. The experimental results show that PyPIMalDet outperforms six baseline methods in malicious package detection tasks, improving precision and recall by 1.6 %-25.93 % and 1.93 %-14.39 %, respectively. It also demonstrates significant advantages in detection speed. The ablation studies thoroughly validate the effectiveness of multi-dimensional feature fusion, denoising autoencoder module, and the lightweight adaptive fusion stacking ensemble framework.
ER  - 

TY  - JOUR
T1  - CyberEntRel: Joint extraction of cyber entities and relations using deep learning
AU  - Ahmed, Kashan
AU  - Khurshid, Syed Khaldoon
AU  - Hina, Sadaf
JO  - Computers & Security
VL  - 136
SP  - 103579
PY  - 2024
DA  - 2024/01/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2023.103579
UR  - https://www.sciencedirect.com/science/article/pii/S0167404823004893
KW  - Cyber threat intelligence
KW  - Deep learning
KW  - Named entity recognition
KW  - Relation extraction
KW  - Knowledge graph
AB  - The cyber threat intelligence (CTI) knowledge graph is beneficial for making robust defense strategies for security professionals. These are built from cyber threat intelligence data based on relation triples where each relation triple contains two entities associated with one relation. The main problem is that the CTI data is increasing more rapidly than expected and existing techniques are becoming ineffective for extracting the CTI information. This work mainly focuses on the extraction of cyber relation triples in an effective way using the joint extraction technique, which resolves the issues in the classical pipeline technique. Firstly, the ‘BIEOS’ tagging scheme was applied to CTI data using the joint tagging technique and then the relation triples were jointly extracted. This study utilized the attention-based RoBERTa-BiGRU-CRF model for sequential tagging. Finally, the relation triples were extracted using the relation-matching technique after matching the best suitable relation for the two predicted entities. The experimental results showed that this technique outperformed the state-of-the-art models in knowledge triple extraction on CTI data. Furthermore, a 7% increase in the F1 score also proved the effectiveness of this technique for the information extraction task on CTI data.
ER  - 

TY  - JOUR
T1  - Thai-language chatbot security: Detecting instruction attacks with XLM-RoBERTa and Bi-GRU
AU  - Vajrobol, Vajratiya
AU  - Gupta, Brij B.
AU  - Gaurav, Akshat
JO  - Computers and Electrical Engineering
VL  - 116
SP  - 109186
PY  - 2024
DA  - 2024/05/01/
SN  - 0045-7906
DO  - https://doi.org/10.1016/j.compeleceng.2024.109186
UR  - https://www.sciencedirect.com/science/article/pii/S0045790624001149
KW  - Instruction attack
KW  - Chatbot
KW  - Thai language
KW  - Bi-GRU
KW  - XLM-roBERTa
AB  - Instruction attack is a malicious attempt to manipulate a chatbot by providing misleading or harmful prompts to achieve unintended outcomes. Detecting instruction attacks is crucial to protect the integrity and safety of chatbot interactions. In this study, we focus on identifying different types of instruction attacks which includes Goal Hijacking, Prompt Leaking, Reverse Exposure, Role Play Instruction and Unsafe Instruction Topic. Given the widening threat scope and the lack of research thus far in this field in a Thai language-oriented context, our intentions are to develop an effective defence system. We suggest an innovative approach: combining XLM-RoBERTa, a state-of-the art language model, with a Bidirectional Gated Recurrent Unit (Bi-GRU). By combining rigorous experimentation and comprehensive evaluation, our method provides outstanding accuracy of 96.52% , precision 96.50% , Recall and F1-score 96.41%. This research contributes to creating a safer and more trustworthy environment for chatbot-mediated interactions in the Thai language context.
ER  - 

TY  - JOUR
T1  - SIoV-IDS: SDN-enabled zero-trust framework for explainable intrusion detection in IoVs using Variational Autoencoders and EX-LSTM
AU  - Laghari, Muddasar
AU  - Zhong, Yuanchang
AU  - Tahir, Muhammad Junaid
AU  - Adil, Muhammad
JO  - Journal of Network and Computer Applications
VL  - 245
SP  - 104389
PY  - 2026
DA  - 2026/01/01/
SN  - 1084-8045
DO  - https://doi.org/10.1016/j.jnca.2025.104389
UR  - https://www.sciencedirect.com/science/article/pii/S1084804525002863
KW  - Intrusion detection system
KW  - Internet of Vehicles
KW  - Explainable AI
AB  - In response to cyber attacks targeting the Internet of Vehicles (IoV) ecosystem, we propose SIoV-DS, a secure framework addressing inter-vehicle communication, intra-vehicle networks, and infrastructure threats using a zero-trust approach. Vehicle data is first encoded with a Variational Autoencoder (V-AE) to mitigate inference attacks, then analyzed by an Extended Long Short-Term Memory (EX-LSTM) detector capable of identifying diverse attacks, including Denial of Service (DoS), spoofing, and malware. For interpretability, Shapley Additive Explanations (SHAP) provide insights into EX-LSTM decisions, assisting Security Operations Center (SOC) analysts. SIoV-DS is deployed over a Software-Defined Networking (SDN) architecture to ensure scalability. Evaluations on CIC-IoV2024 and Edge-IIoTset2022 datasets demonstrate high accuracy (99.78% and 95.01%, respectively), while inference-time analysis confirms feasibility for real-time detection, effectively securing the IoV ecosystem against advanced cyber threats.
ER  - 

TY  - JOUR
T1  - Fuzzing drones for anomaly detection: A systematic literature review
AU  - Malviya, Vikas K.
AU  - Minn, Wei
AU  - Shar, Lwin Khin
AU  - Jiang, Lingxiao
JO  - Computers & Security
VL  - 148
SP  - 104157
PY  - 2025
DA  - 2025/01/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104157
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824004620
KW  - Drone
KW  - Fuzzing
KW  - Anomaly detection
KW  - MAVLink protocol
AB  - Drones, also referred to as Unmanned Aerial Vehicles (UAVs), are becoming popular today due to their uses in different fields and recent technological advancements which provide easy control of UAVs via mobile apps. However, UAVs may contain vulnerabilities or software bugs that cause serious safety and security concerns. For example, the communication protocol used by the UAV may contain authentication and authorization vulnerabilities, which may be exploited by attackers to gain remote access over the UAV. Drones must therefore undergo extensive testing before being released or deployed to identify and fix any software bugs or security vulnerabilities. Fuzzing is one commonly used technique for finding bugs and vulnerabilities in software programs and protocols. This article reviews various approaches where fuzzing is applied to detect bugs and vulnerabilities in UAVs. Our goal is to assess the current state-of-the-art fuzzing approaches for UAVs, which are yet to be explored in the literature. We identified open challenges that call for further research to improve the current state-of-the-art.
ER  - 

TY  - JOUR
T1  - Cyber–physical resilience and security strategies for renewable energy-driven IoT power grids
AU  - Li, Thomas Tongxin
AU  - Huang, Yujia
AU  - Hua, Yuxin
AU  - Hu, Tianyu
AU  - Yang, Hongming
AU  - Alhazmi, Mohannad
AU  - Alsaif, Saif
AU  - Liu, Guangliang
JO  - Sustainable Energy Technologies and Assessments
VL  - 84
SP  - 104696
PY  - 2025
DA  - 2025/12/01/
SN  - 2213-1388
DO  - https://doi.org/10.1016/j.seta.2025.104696
UR  - https://www.sciencedirect.com/science/article/pii/S2213138825005272
KW  - Cyber–physical resilience
KW  - Renewable energy-driven IoT grids
KW  - Vulnerability assessment
KW  - Distributionally robust optimization
KW  - Multi-agent reinforcement learning
AB  - The increasing penetration of renewable energy resources, coupled with the rapid proliferation of Internet of Things (IoT) technologies, has transformed the architecture of modern power grids into highly interconnected and intelligent systems. While these advances improve sustainability, flexibility, and operational efficiency, they also expand the attack surface, exposing critical infrastructures to sophisticated cyber and physical threats. This paper proposes a cyber–physical resilience and security framework designed to safeguard IoT-enabled power grids under adversarial conditions. First, a vulnerability assessment methodology is developed that integrates renewable generation variability, IoT communication dependencies, and network topology to identify systemic weak points across both cyber and physical domains. Second, resilient control strategies are introduced by combining distributionally robust optimization with multi-agent reinforcement learning to achieve secure energy allocation, adaptive task scheduling, and rapid system recovery under uncertainty. Third, a set of security strategies is proposed, including blockchain-based authentication for trustworthy data exchange, lightweight cryptographic techniques for IoT nodes, and deep learning-driven intrusion detection to counter evolving attack patterns. This study highlights the necessity of integrating optimization, learning-based control, and secure system design to enable the next generation of cyber–physically resilient renewable energy-driven IoT power grids.
ER  - 

TY  - JOUR
T1  - Attack surface analysis and mitigation for near-field communication networks and devices in smart grids
AU  - Guo, Jing
AU  - Gu, Zhimin
AU  - Jiang, Haitao
AU  - Li, Yan
AU  - Zhu, Daohua
JO  - Array
VL  - 27
SP  - 100447
PY  - 2025
DA  - 2025/09/01/
SN  - 2590-0056
DO  - https://doi.org/10.1016/j.array.2025.100447
UR  - https://www.sciencedirect.com/science/article/pii/S2590005625000748
KW  - Smart grid
KW  - Edge devices
KW  - Attack surface analysis
KW  - Network protocol
KW  - Communication network
AB  - With growing demand and increasing concern for energy sustainability, smart grids (SGs) have emerged as a promising solution by integrating information and communication technologies to enhance the efficiency, reliability, and flexibility of power systems. While SGs enable real-time monitoring, they also introduce new security risks, particularly for endpoint and edge devices such as smart meters and inverters. Although earlier attacks primarily targeted centralized systems, recent studies have highlighted vulnerabilities on the consumer side, especially in the context of MadIoT-style attacks (MadIoT, short for Manipulation of Demand via IoT, refers to a class of coordinated attacks exploiting high-wattage IoT devices to destabilize power grids). This paper analyzes the attack surfaces of near-field communication network (NFN) protocols and devices within SGs, with a focus on widely adopted public protocols. We propose mitigation strategies to address these risks, including a reverse engineering-based edge device firmware emulation and execution method, a large language model-based protocol analysis approach, and a fuzzing-based malicious behavior simulation technique in a NFN. In our experiments, the proposed AFL-Netzob framework discovered 6 vulnerabilities across 3 firmware samples and achieved up to a 2× improvement in fuzzing efficiency compared to Boofuzz. These results demonstrate the practical effectiveness and general applicability of our framework in real-world smart grid scenarios.
ER  - 

TY  - JOUR
T1  - Multi-tier linguistic and emotional modeling for cyberbullying detection in Tamil social media
AU  - V․, Jothi Prakash
AU  - S․, Arul Antran Vijay
JO  - Expert Systems with Applications
VL  - 297
SP  - 129270
PY  - 2026
DA  - 2026/02/01/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2025.129270
UR  - https://www.sciencedirect.com/science/article/pii/S0957417425028866
KW  - Cyberbullying detection
KW  - Tamil language processing
KW  - Emotion recognition
KW  - Graph neural networks
KW  - Transformer models,
AB  - Cyberbullying presents a growing threat in online communities, with low-resource linguistic contexts like Tamil remaining critically underexplored. This study introduces a novel multi-tier computational framework designed for culturally-aware cyberbullying detection in Tamil-language social media content. We first present the Tamil Cyberbullying (TCB) dataset-comprising 47,692 manually annotated tweets-spanning age, gender, ethnicity, religion-based abuse, and non-bullying categories. Our framework integrates four key processing layers: (i) FastText-based linguistic embedding and TF-IDF noise reduction; (ii) Aho-Corasick-driven rule-based filtering for abusive lexical patterns; (iii) contextual representation learning via fine-tuned mBERT; and (iv) deep sentiment-emotion fusion using BiLSTM and Emotion-Cause Pair Extraction (ECPE), followed by hybrid classification using CNN and GNN modules. The proposed model achieves 84.00% accuracy, outperforming baseline multilingual transformers and large language models (LLMs) such as LLAMA3.1 and Mistral-405B. Precision, recall, and F1-score are 82.28%, 83.28%, and 82.75%, respectively. Human-AI comparative analysis reveals improved sensitivity to cultural expressions, while ablation studies validate the contribution of each tier. Our approach addresses the nuances of sarcasm, emotion, and linguistic diversity in Tamil, providing a scalable blueprint for multilingual cyberbullying detection. All models and data are released under open-access licensing, with rigorous ethical and privacy compliance. The framework accounts for emotion label distribution and cultural nuances in Tamil discourse, ensuring interpretability and ethical robustness.
ER  - 

TY  - JOUR
T1  - A comprehensive survey on AI-enabled secure social industrial Internet of Things in the agri-food supply chain
AU  - Halder, Sajal
AU  - Rafiqul Islam, Md
AU  - Mamun, Quazi
AU  - Mahboubi, Arash
AU  - Walsh, Patrick
AU  - Zahidul Islam, Md
JO  - Smart Agricultural Technology
VL  - 11
SP  - 100902
PY  - 2025
DA  - 2025/08/01/
SN  - 2772-3755
DO  - https://doi.org/10.1016/j.atech.2025.100902
UR  - https://www.sciencedirect.com/science/article/pii/S2772375525001352
KW  - Agri-food industry
KW  - Supply chain
KW  - AI
KW  - Industrial IoT
KW  - Cyber security
KW  - Social security
AB  - The rapid evolution of Artificial Intelligence (AI) and the Social Industrial Internet of Things (SIIoT) has significantly impacted the agri-food supply chain, offering transformative solutions for security, efficiency, and sustainability. However, challenges related to data integrity, cyber threats, and system interoperability remain. This study provides a comprehensive analysis of AI-enabled secure SIIoT applications in the agri-food supply chain, addressing key security concerns and efficiency bottlenecks. It aims to develop a structured taxonomy of AI-driven security mechanisms, highlighting their roles in safeguarding SIIoT systems. A systematic literature review was conducted using reputable databases, including Google Scholar, ACM, DBLP, IEEE Xplore, SCOPUS, and Web of Science, focusing on peer-reviewed articles from the last six years. Additionally, multiple case studies were examined to validate the real-world application of AI-driven security frameworks in the agri-food industry. The findings indicate that AI-driven security solutions significantly enhance trust management, anomaly detection, and data privacy in SIIoT networks. The proposed taxonomy categorizes AI-enabled security mechanisms into five distinct areas, offering a structured reference for future research and practical implementations. Furthermore, case study analysis demonstrates the successful deployment of AI-driven security in real-world agri-food applications, emphasizing improved traceability and resilience against cyber threats. This study advances the field by identifying gaps in current research, proposing strategic recommendations, and outlining future directions for AI-enabled secure SIIoT systems in the agri-food research domain. The insights presented here provide a strong foundation for researchers, policymakers, and stakeholders in the agri-food sector to build more resilient and intelligent ecosystems.
ER  - 

TY  - JOUR
T1  - Enhanced (cyber) situational awareness: Using interpretable principal component analysis (iPCA) to automate vulnerability severity scoring
AU  - Pourbehzadi, Motahareh
AU  - Javidi, Giti
AU  - Howell, C. Jordan
AU  - Kamar, Eden
AU  - Sheybani, Ehsan
JO  - Decision Support Systems
VL  - 186
SP  - 114308
PY  - 2024
DA  - 2024/11/01/
SN  - 0167-9236
DO  - https://doi.org/10.1016/j.dss.2024.114308
UR  - https://www.sciencedirect.com/science/article/pii/S0167923624001416
KW  - Cybersecurity
KW  - CVE
KW  - CVSS
KW  - Machine learning
KW  - Situational awareness
AB  - The Common Vulnerability Scoring System (CVSS) is widely used in the cybersecurity industry to assess the severity of vulnerabilities. However, manual assessments and human error can lead to delays and inconsistencies. This study employs situational awareness theory to develop an automated decision support system, integrating perception, comprehension, and projection components to enhance effectiveness. Specifically, an interpretable principal component analysis (iPCA) combined with machine learning is utilized to forecast CVSS scores using text descriptions from the Common Vulnerabilities and Exposures (CVE) database. Different forecasting approaches, including traditional machine learning models, Long-Short Term Memory Neural Networks, and Transformer architectures (ChatGPT) are compared to determine the best performance. The results show that iPCA combined with support vector regression achieves a high performance (R2 = 98%) in predicting CVSS scores using CVE text descriptions. The results indicate that the variability, length, and details in the vulnerability description contribute to the performance of the transformer model. These findings are consistent across vulnerability descriptions from six companies between 2017 and 2019. The study's outcomes have the potential to enhance organizations' security posture, improving situational awareness and enabling better managerial decision-making in cybersecurity.
ER  - 

TY  - JOUR
T1  - Evaluating password strength based on information spread on social networks: A combined approach relying on data reconstruction and generative models
AU  - Atzori, Maurizio
AU  - Calò, Eleonora
AU  - Caruccio, Loredana
AU  - Cirillo, Stefano
AU  - Polese, Giuseppe
AU  - Solimando, Giandomenico
JO  - Online Social Networks and Media
VL  - 42
SP  - 100278
PY  - 2024
DA  - 2024/08/01/
SN  - 2468-6964
DO  - https://doi.org/10.1016/j.osnem.2024.100278
UR  - https://www.sciencedirect.com/science/article/pii/S246869642400003X
KW  - Privacy-preserving
KW  - Password-disclosure
KW  - Data wrapping
KW  - Data reconstruction
KW  - Social network
AB  - Ensuring the security of personal accounts has become a key concern due to the widespread password attack techniques. Although passwords are the primary defense against unauthorized access, the practice of reusing easy-to-remember passwords increases security risks for people. Traditional methods for evaluating password strength are often insufficient since they overlook the public personal information that users frequently share on social networks. In addition, while users tend to limit access to their data on single profiles, personal data is often unintentionally shared across multiple profiles, exposing users to password threats. In this paper, we present an extension of a data reconstruction tool, namely soda advance, which incorporates a new module to evaluate password strength based on publicly available data across multiple social networks. It relies on a new metric to provide a comprehensive evaluation of password strength. Moreover, we investigate the capabilities and risks associated with emerging Large Language Models (LLMs) in evaluating and generating passwords, respectively. Specifically, by exploiting the proliferation of LLMs, it has been possible to interact with many LLMs through Automated Template Learning methodologies. Experimental evaluations, performed with 100 real users, demonstrate the effectiveness of LLMs in generating strong passwords with respect to data associated with users’ profiles. Furthermore, LLMs have proved to be effective also in evaluation tasks, but the combined usage of LLMs and soda advance guaranteed better classifications up to more than 10% in terms of F1-score.
ER  - 

TY  - JOUR
T1  - CANSat-IDS: An adaptive distributed Intrusion Detection System for satellites, based on combined classification of CAN traffic
AU  - Driouch, Otman
AU  - Bah, Slimane
AU  - Guennoun, Zouhair
JO  - Computers & Security
VL  - 146
SP  - 104033
PY  - 2024
DA  - 2024/11/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104033
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824003389
KW  - Intrusion detection
KW  - Satellite
KW  - Space technology
KW  - Cybersecurity
KW  - Machine learning
KW  - Deep learning
KW  - Controller area network
AB  - The increasing dependence on satellite technology for critical applications, such as telecommunications, Earth observation, and navigation, underscores the need for robust security measures to safeguard these assets from potential cyber threats. Moreover, as many satellite systems rely on the Controller Area Network (CAN) protocol for efficient data exchange among onboard subsystems, they become prime targets for cyberattacks. While contributions present various options for detecting attacks in the CAN bus, no one proposes an architecture suitable for satellite systems. To address this concern, this paper presents a novel approach to develop an adaptive distributed Intrusion Detection System (IDS) for satellites, which integrates machine and deep learning techniques for the classification of CAN frames. This system is specifically designed to overcome the inherent power and computational challenges of satellite operations by executing time-based anomaly detection on board, and content-based detection at the ground segment. To evaluate the effectiveness of the proposed solution, experiments are conducted using representative Datasets. The obtained results demonstrate that the distributed IDS presented in this research offers a promising solution to improve the security of satellite systems by achieving high detection rates ranging from 91.12% to 99.86% (F1-score).
ER  - 

TY  - JOUR
T1  - Securing the metaverse: Machine learning–based perspectives on risk, trust, and governance
AU  - Achuthan, Krishnashree
AU  - Ramanathan, Sasangan
AU  - Raman, Raghu
JO  - International Journal of Information Management Data Insights
VL  - 5
IS  - 2
SP  - 100356
PY  - 2025
DA  - 2025/12/01/
SN  - 2667-0968
DO  - https://doi.org/10.1016/j.jjimei.2025.100356
UR  - https://www.sciencedirect.com/science/article/pii/S2667096825000382
KW  - Metaverse security
KW  - Cybersecurity governance
KW  - Decentralized identity
KW  - Privacy protection
KW  - User behavior
KW  - ADO-TCM framework
KW  - Threat detection
KW  - Regulatory compliance
KW  - BERTopic modeling
AB  - The rapid expansion of the metaverse presents significant cybersecurity and privacy challenges, requiring structured, data-driven analysis. This study applies the ADO-TCM framework and BERTopic modeling to examine drivers of cybersecurity risk, theoretical responses, and interdisciplinary research gaps. Using PRISMA guidelines, 86 peer-reviewed studies were analyzed to identify key antecedents—technological vulnerabilities, user behavior, regulatory fragmentation, economic incentives, and cultural factors—shaping decisions in compliance, deployment, and education. These, in turn, influence outcomes like trust, threat mitigation, and scalability. The review identifies five latent themes: secure identity, privacy, trust, governance, and AI’s role in shaping risk. The study maps diverse theoretical lenses—cognitive, behavioral, strategic, and technological—used to interpret immersive threats and decision-making in metaverse contexts. Contributing a novel, empirically grounded synthesis, this research advances the information management literature and proposes a forward-looking agenda focused on adaptive security, ethical AI, interoperability, regulatory convergence, and intelligent, user-centric architecture for immersive ecosystems.
ER  - 

TY  - JOUR
T1  - Public sentiment and engagement on cybersecurity: Insights from Reddit discussions
AU  - Achuthan, Krishnashree
AU  - Khobragade, Sugandh
AU  - Kowalski, Robin
JO  - Computers in Human Behavior Reports
VL  - 17
SP  - 100573
PY  - 2025
DA  - 2025/03/01/
SN  - 2451-9588
DO  - https://doi.org/10.1016/j.chbr.2024.100573
UR  - https://www.sciencedirect.com/science/article/pii/S2451958824002069
KW  - Public sentiment
KW  - Cybercrime
KW  - BERTopic modeling
KW  - Text classification
KW  - Reddit social media
KW  - Artificial intelligence
AB  - Cyber insecurity is recognized amongst the top severe global risks by the World Economic Forum.This study addresses a significant gap in our understanding of the social dynamics of public perception and online discourse related to cybersecurity, with a particular focus on how social media platforms shape and reflect public engagement. We employ sentiment analysis, topic modeling, and zero-shot text classification to analyze 33,893 news and user posts, along with the corresponding 194,591 news and user comments, across five subreddit discussion forums between 2012 and 2022. Through the lens of the Social Amplification of Risk Framework (SARF) and Protection Motivation Theory (PMT), we uncover patterns in topic engagement, emotional responses, community support, and the interplay of sentiment and comment types. Our findings reveal a complex landscape of public engagement with cybersecurity news, characterized by high interest in government surveillance, cyber warfare, and software vulnerabilities. Comments vary across topics, with technical advice dominating discussions, while skepticism and concern are prevalent in privacy-related areas. Community reactions tend towards critical engagement, with comments expressing concern, disappointment, and anger receiving high upvotes. Post sentiment weakly correlates with comment types, where more negative posts elicit increased expressions of concern, anger, and skepticism. The community's dynamic engagement with cybersecurity issues underscores the need for tailored communication strategies that acknowledge both emotional responses and the desire for practical solutions. This study contributes to an understanding of public engagement with cybersecurity issues on social media while offering insights for stakeholders seeking to foster informed, resilient, and engaged online communities.
ER  - 

TY  - JOUR
T1  - Sociotechnical Cybersecurity Framework for Securing Health Care From Vulnerabilities and Cyberattacks: Scoping Review
AU  - Ewoh, Pius
AU  - Vartiainen, Tero
AU  - Mantere, Timo
JO  - Journal of Medical Internet Research
VL  - 27
PY  - 2025
DA  - 2025/01/01/
SN  - 1438-8871
DO  - https://doi.org/10.2196/75584
UR  - https://www.sciencedirect.com/science/article/pii/S1438887125013706
KW  - computer security
KW  - network security
KW  - digital health
KW  - health information
KW  - electronic health record system
KW  - cyber threats
KW  - ransomware
KW  - breaches
AB  - Background
The vulnerability of health care systems to cyberattacks and breaches of health information is on the rise worldwide. Considering the increasing rate of reported cyber incidents and the risks they pose to patient safety, privacy, and financial losses, there is a need to examine the way cybersecurity is conceptualized in health care organizations, taking into account technology, processes, and humans.
Objective
This study examined the dynamics of the factors of vulnerabilities and cyberattacks in the context of sociotechnical systems theory underlying the relationships among humans, technology, and processes. It developed a conceptual sociotechnical cybersecurity framework for preventing vulnerabilities and responding to cyberattacks and threats in health care systems.
Methods
A scoping review was conducted to search the extant literature in 3 databases—Web of Science, PubMed (MEDLINE), and Scopus. A total of 1375 papers from the period of 2012-2024 were retrieved, 76 of which, in the domain of health care and cybersecurity, were reviewed and analyzed. Original research and review papers were included. Only published English-language papers were included to focus on contemporary issues, challenges, and solutions. Relevant information from the included sources was charted and summarized. The study characteristics were extracted from the included papers, and the evidence was synthesized using thematic analysis.
Results
Of the 1375 papers identified, 76 (5.5%) met the inclusion criteria. The results showed that the factors of vulnerabilities to cyberattacks comprise 12 subfactors in health care systems. Concerning technology-related factors of vulnerabilities, most studies described the complex system design and usability (16/76, 21%) and integration of new technology (15/76, 20%) as challenges in health care systems. Concerning human-related factors, most studies described a shortage of skilled professionals and limited budgets as contributing to poor cybersecurity management. The study found that processes involved both technology and humans relative to the unit factors of vulnerabilities to cyberattacks. There was a sociotechnical interplay across the factors of vulnerabilities. The concept of sociotechnical cybersecurity offers a comprehensive and explicit perspective on the sociotechnical underpinning and joint optimization required to advance cybersecurity toward achieving sustainable health care systems.
Conclusions
The conceptual framework of sociotechnical cybersecurity provides a contemporary foundation and deep insight for identifying and preventing vulnerabilities and responding to cyberattacks in health care systems. The framework is important due to its suitability, applicability, and customizability for dynamic and complex health care systems. The study also provides compliance standards for applying the proposed conceptual framework to guide health care organizations in cybersecurity practices. The study of cybersecurity through the sociotechnical lens in the health care domain is limited. Further studies are needed on cybersecurity incident management. Health care organizations should leverage the strength of cybersecurity through the implementation of risk assessment and incident response plans.
ER  - 

TY  - JOUR
T1  - Toxicity in online platforms and AI systems: A survey of needs, challenges, mitigations, and future directions
AU  - Khapre, Smita
AU  - Mersha, Melkamu Abay
AU  - Shakil, Hassan
AU  - Baruah, Jonali
AU  - Kalita, Jugal
JO  - Expert Systems with Applications
VL  - 299
SP  - 129832
PY  - 2026
DA  - 2026/03/01/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2025.129832
UR  - https://www.sciencedirect.com/science/article/pii/S0957417425034475
KW  - Toxicity
KW  - Fallacy
KW  - Fake news
KW  - Misinformation
KW  - Social media
KW  - Large language models
KW  - Hate speech
KW  - LLM safety personality
KW  - Traits
AB  - The evolution of digital communication systems and the designs of online platforms have inadvertently facilitated the subconscious propagation of toxic behavior. Giving rise to reactive responses to toxic behavior. Toxicity in online content and Artificial Intelligence Systems has become a serious challenge to individual and collective well-being around the world. It is more detrimental to society than we realize. Toxicity, expressed in language, image, and video, can be interpreted in various ways depending on the context of usage. Therefore, a comprehensive taxonomy is crucial to detect and mitigate toxicity in online content, Artificial Intelligence systems, and/or Large Language Models in a proactive manner. A comprehensive understanding of toxicity is likely to facilitate the design of practical solutions for toxicity detection and mitigation. The classification in published literature has focused on only a limited number of aspects of this very complex issue, with a pattern of reactive strategies in response to toxicity. This survey attempts to generate a comprehensive taxonomy of toxicity from various perspectives. It presents a holistic approach to explain the toxicity by understanding the context and environment that society is facing in the Artificial Intelligence era. This survey summarizes the toxicity-related datasets and research on toxicity detection and mitigation for Large Language Models, social media platforms, and other online platforms, detailing their attributes in textual mode, focused on the English language. Finally, we suggest the research gaps in toxicity mitigation based on datasets, mitigation strategies, Large Language Models, adaptability, explainability, and evaluation.
ER  - 

TY  - JOUR
T1  - The evolution of cybersecurity in self-driving cars: insights from bibliometric research
AU  - Dias Lousã, Mãrio
AU  - Teixeira, Henrique
AU  - Pereira de Morais, Josè Carlos
JO  - International Journal of Innovation Science
VL  - 17
IS  - 4
SP  - 880
EP  - 900
PY  - 2025
DA  - 2025/05/13/
SN  - 1757-2223
DO  - https://doi.org/10.1108/IJIS-06-2024-0158
UR  - https://www.sciencedirect.com/science/article/pii/S1757222325000054
KW  - V2X (vehicles-to-everything)
KW  - V2V (vehicle-to-vehicle)
KW  - V2I (vehicle-to-infrastructure)
KW  - 5G and 6G
KW  - Mobility security
KW  - Communication network security
KW  - Attack prevention
AB  - Purpose
This study aims to investigate the evolution of cybersecurity in autonomous vehicles over the past decade, focusing on influential publications, leading authors, key themes and emerging research trends.
Design/methodology/approach
A systematic literature review was conducted using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses approach, with data extracted from The Lens database and analyzed using VOSviewer and Bibliometrix. This study provides a quantitative overview of academic trends from 2014 to 2023. The analysis reveals significant growth in scientific production, predominantly driven by the USA, China and the UK. Central themes include network security, cyberattack prevention and regulatory frameworks.
Findings
The findings emphasize that cybersecurity, artificial intelligence (AI) and regulation are critical for developing secure and reliable vehicular systems.
Research limitations/implications
Future research should focus on enhancing security in vehicle-to-everything, vehicle-to-vehicle and vehicle-to-infrastructure communications by improving protocols and integrating AI.
Practical implications
Key themes identified include trust in security, reliability and user experience.
Social implications
The analysis highlights future research directions, particularly the integration of AI with sustainable development and autonomous transportation policies.
Originality/value
This study provides a quantitative overview of academic trends from 2014 to 2023 regarding the theme of cybersecurity and self-driving cars.
ER  - 

TY  - JOUR
T1  - Cybersecurity risk and firm growth: Empirical evidence based on text analysis
AU  - Xu, Gengxi
AU  - Li, Yugang
AU  - Liu, Shanshan
AU  - Ye, Zhuhong
JO  - The North American Journal of Economics and Finance
VL  - 81
SP  - 102542
PY  - 2026
DA  - 2026/01/01/
SN  - 1062-9408
DO  - https://doi.org/10.1016/j.najef.2025.102542
UR  - https://www.sciencedirect.com/science/article/pii/S1062940825001822
KW  - Cybersecurity risk
KW  - Firm growth
KW  - Text analysis
AB  - Despite cybersecurity risk emerging as a critical firm threat, research on effective prevention and response strategies remains limited. Using a sample of A-share listed companies in Shanghai and Shenzhen from 2010 to 2022, this study adopts text analysis to construct indicators that portray the cybersecurity risk of Chinese listed companies and systematically examines the impact of cybersecurity risk on firm growth. The findings reveal that cybersecurity risk significantly inhibits firm growth. Mechanism analysis indicates that cybersecurity risk adversely impacts growth by increasing firms’ excessive cash holdings, amplifying operational risks, and exacerbating financing constraints. Further analysis shows that the growth-inhibiting effect is more pronounced among firms in technology-intensive industries, larger scale, higher media attention, and higher analyst attention. This study provides empirical evidence to guide firms in developing preemptive cybersecurity strategies, supports regulators in implementing differentiated governance, and helps governments refine cybersecurity incentives. These measures help firms strike a balance between growth and risk while supporting effective cybersecurity governance.
ER  - 

TY  - JOUR
T1  - Log-Based Anomaly Detection of System Logs Using Graph Neural Network
AU  - Alsalmi, Eman
AU  - Alhuzali, Abeer
AU  - Alhothali, Areej
JO  - Computers, Materials and Continua
VL  - 86
IS  - 2
SP  - 1
EP  - 20
PY  - 2025
DA  - 2025/12/09/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2025.071012
UR  - https://www.sciencedirect.com/science/article/pii/S1546221825012482
KW  - Log anomaly detection
KW  - BERT
KW  - graph convolutional network
KW  - system logs
KW  - explainable anomaly detection
AB  - Log anomaly detection is essential for maintaining the reliability and security of large-scale networked systems. Most traditional techniques rely on log parsing in the reprocessing stage and utilize handcrafted features that limit their adaptability across various systems. In this study, we propose a hybrid model, BertGCN, that integrates BERT-based contextual embedding with Graph Convolutional Networks (GCNs) to identify anomalies in raw system logs, thereby eliminating the need for log parsing. The BERT module captures semantic representations of log messages, while the GCN models the structural relationships among log entries through a text-based graph. This combination enables BertGCN to capture both the contextual and semantic characteristics of log data. BertGCN showed excellent performance on the HDFS and BGL datasets, demonstrating its effectiveness and resilience in detecting anomalies. Compared to multiple baselines, our proposed BertGCN showed improved precision, recall, and F1 scores.
ER  - 

TY  - JOUR
T1  - Privacy and cybersecurity issues facing the metaverse: An analysis of technological and institutional factors
AU  - Kshetri, Nir
JO  - Telecommunications Policy
SP  - 103140
PY  - 2025
DA  - 2025/12/12/
SN  - 0308-5961
DO  - https://doi.org/10.1016/j.telpol.2025.103140
UR  - https://www.sciencedirect.com/science/article/pii/S030859612500237X
KW  - Augmented reality
KW  - Brain-computer interface
KW  - Cybersecurity
KW  - Institutions
KW  - Privacy
KW  - Rare enemy syndrome
KW  - Virtual reality
AB  - The metaverse presents several unique challenges from security and privacy standpoints. This paper offers a detailed description and analysis of technological environment and institutional factors that can lead to increased privacy violations and security breaches in the metaverse. On the technological front, it discusses how various features of the metaverse such as newness, novelty and complexity of technologies involved, data intensiveness and weak architectural security of the metaverse are likely to provide a fruitful environment for cybercriminals and other perpetrators. The paper analyzes the level and nature of the impacts of privacy violations and security breaches on consumers and victims in the metaverse environment. It also demonstrates how security breaches in the metaverse are likely to lead to immediate harms to victims. It promotes an understanding of how institutions at various level are related to privacy and security risks in the metaverse. On the regulatory front, it points out that privacy and security laws of the Web2 era are not sufficient to deal with the environments of the metaverse. It also argues that the preparedness to provide security and privacy in the metaverse’s multidimensional and multi-sensory environment is currently lacking at the industry level.
ER  - 

TY  - JOUR
T1  - Measuring the impact of cyber policy: A news-based cyber policy index and its spillover to U.S. stock sectors
AU  - Zong, Lu
AU  - Tao, Zheng
AU  - Zhai, Jia
AU  - Shi, Shimeng
JO  - Research in International Business and Finance
VL  - 78
SP  - 103030
PY  - 2025
DA  - 2025/06/01/
SN  - 0275-5319
DO  - https://doi.org/10.1016/j.ribaf.2025.103030
UR  - https://www.sciencedirect.com/science/article/pii/S0275531925002867
KW  - Cyber policy
KW  - Cyber risk
KW  - Spillover
KW  - Stock sectors
KW  - Quantile regression
AB  - This study examines the dynamic impact of cyber policies on mitigating cyber risks and their subsequent spillover effects across U.S. equity sectors. We develop a news-based Cyber Policy Index that gauges the time-varying intensity of cyber policy, utilizing its dynamics to capture the global cyber polcy stance in response to intensifying threats. We uncover how policy developments interact with cyber risks and their impact on sector-specific stock returns. Our analysis reveals that cyber policies, while responding to short-term surges in cyber-attacks, exhibit a delayed effect on stock returns, typically manifesting in medium-level adjustments rather than extreme fluctuations. We find that the current policy framework is proficient at reducing the number of cyber-attacks, but is less effective at preventing severe damages from large-scale incidents. Notably, stocks in dataand technology-intensive sectors show reduced returns in response to cyber policy changes, highlighting their sensitivity. Additionally, the risk-mitigating effect of these policies vary across sectors, showing potential for reducing stock market risks in higher quantiles. This study offers valuable insights into how cyber policies can influence market dynamics and highlights the need for tailored strategies to enhance financial stability in the face of evolving cyber threats.
ER  - 

TY  - JOUR
T1  - AI as a shield against cyberattacks - employee awareness in the EU
AU  - Żywiołek, Justyna
AU  - Matulewski, Marek
AU  - Frąś, Józef
JO  - Procedia Computer Science
VL  - 270
SP  - 5510
EP  - 5519
PY  - 2025
DA  - 2025/01/01/
T2  - 29th International Conference on Knowledge-Based and Intelligent Information & Engineering Systems (KES 2025)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2025.10.019
UR  - https://www.sciencedirect.com/science/article/pii/S1877050925033526
KW  - Type your keywords here
KW  - separated by semicolons
AB  - The increasing sophistication of cyber threats has driven enterprises to adopt artificial intelligence (AI) as a key component of cybersecurity strategies. This study explores user perceptions of AI-driven cybersecurity solutions by applying the Kano model, marking the first stage of a broader investigation into AI effectiveness in cyberattack prevention. The research was conducted through a large-scale survey in Poland, Germany, Sweden, and Hungary, collecting 26,314 responses to assess how users classify various AI security attributes. The Kano model enabled the categorization of AI functions into must-have, one-dimensional, and attractive attributes, highlighting which AI-driven security features are deemed essential and which enhance user satisfaction. The findings indicate that real-time threat detection, automated risk assessment, and AI-based authentication are considered critical, whereas AI-driven security education and adaptive learning mechanisms, while valued, are not yet universally expected. The study also identifies concerns related to excessive AI monitoring and algorithmic bias in cybersecurity decision-making. These insights provide a foundation for further research into optimizing AI-based security frameworks and enhancing user trust in autonomous cybersecurity systems.
ER  - 

TY  - JOUR
T1  - Explainable AI and Random Forest based reliable intrusion detection system
AU  - Wali, Syed
AU  - Farrukh, Yasir Ali
AU  - Khan, Irfan
JO  - Computers & Security
VL  - 157
SP  - 104542
PY  - 2025
DA  - 2025/10/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104542
UR  - https://www.sciencedirect.com/science/article/pii/S0167404825002317
KW  - Network Intrusion Detection
KW  - Adversarial attacks
KW  - Cybersecurity
KW  - Machine learning
KW  - Explainable AI
AB  - Emerging cyber threats — particularly adversarial attacks on machine learning-based Intrusion Detection Systems (IDS) — pose critical risks to network security by exploiting model vulnerabilities and training blind spots. These attacks, often carried out under black-box threat models, involve crafting perturbations that force misclassification without direct access to model parameters, making them especially dangerous in real-world deployments. Traditional IDS models remain ill-equipped to handle such scenarios, relying heavily on adversarial retraining, which is computationally expensive and limited to known attack patterns. To address these challenges, we propose a novel IDS framework that enhances adversarial resilience without retraining by integrating Explainable AI (XAI)-driven credibility assessment with a dual-layered defense pipeline. At its core is a Credibility Assessment Module (CAM) that leverages SHAP (Shapley Additive Explanations) to identify inconsistencies between local and global feature attributions, flagging suspicious predictions for reassessment. The secondary pipeline employs Transformer-based semantic payload inspection alongside behavioral classifiers operating on contextual features, ensuring modal and architectural separation to prevent adversarial transferability. These capabilities enable the system to counter a wide spectrum of threats, ranging from traditional attacks to advanced black-box adversarial techniques such as HopSkipJump and ZOO, which craft minimal perturbations to evade detection. The proposed system is evaluated on two comprehensive and diverse datasets: CSE-CIC IDS 2018, which captures modern attack vectors such as SSH brute force, DoS, and DDoS; and CIC-IoT 23, which focuses on IoT-specific traffic and threats. These datasets were chosen for their realism, broad protocol coverage, and relevance to both conventional and emerging network environments. Our framework outperforms state-of-the-art adversarial defenses and multimodal IDS models, maintaining high accuracy under clean conditions while significantly improving resilience against black-box adversarial attacks. This work introduces a new paradigm in trustworthy IDS design, where explainability and processing diversity form the backbone of proactive, resilient cybersecurity.
ER  - 

TY  - JOUR
T1  - A.I. Assisted Malware Capabilities Capturing
AU  - Mogage, Andrei
JO  - Procedia Computer Science
VL  - 246
SP  - 860
EP  - 869
PY  - 2024
DA  - 2024/01/01/
T2  - 28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.09.505
UR  - https://www.sciencedirect.com/science/article/pii/S187705092402550X
KW  - large language models
KW  - cybersecurity
KW  - malware
KW  - malware analysis
KW  - formal logic
AB  - Malware analysis is a demanding task regarding techniques, time and creativity. On multiple occasions, however, security researchers are interested in checking if the analyzed threat possesses specific capabilities, disregarding the overall picture. In this paper, we combine our malware expertise with the results of a Large Language Model, in order to expand the knowledge and creativity in generating specific rules that encode these capabilities. The rules, along with malicious applications, are then used as inputs for a malware analysis framework created by us, in order to determine if the application has those specific capabilities. The findings show promising results, sustained by synthetic and real-life experiments.
ER  - 

TY  - JOUR
T1  - AWMT: Automatic jailbreaking attack framework utilizing working-memory trees
AU  - Zhang, Zhiqiang
AU  - Xu, Junjie
AU  - Li, Bing
AU  - Sun, Yuankang
AU  - Mo, Hai Miao
AU  - Chen, Yanhong
JO  - Expert Systems with Applications
VL  - 303
SP  - 130643
PY  - 2026
DA  - 2026/03/25/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2025.130643
UR  - https://www.sciencedirect.com/science/article/pii/S0957417425042587
KW  - Jailbreak vulnerability
KW  - Tree structure
KW  - Working memory
KW  - Multi-prompt
AB  - With the rapid advancement of Large Language Models (LLMs), which have demonstrated exceptional performance across various domains, they also face significant security challenges, particularly the threat of jailbreak attacks. Previous jailbreak studies have primarily focused on single-prompt or token-level techniques, overlooking vulnerabilities in multi-prompt attacks and the readability of adversarial prompts. To address these issues, we propose a novel framework, Automatic Jailbreaking Attack Framework Utilizing Working-Memory Trees (AWMT), which leverages a tree-structured iterative optimization approach to significantly enhance the efficiency of adversarial attacks. Specifically, we first develop a data category analysis module to identify vulnerabilities across different categories. Guided by working memory theory, we meticulously design demonstration examples to enhance the attack strategy. By optimizing the generation of sub-node prompts, our framework progressively constructs more effective adversarial prompts, thereby improving both the precision and success rate of attacks. Additionally, we introduce a multi-prompt combination strategy that integrates multiple prompts to maximize attack effectiveness while maintaining the interpretability of the generated adversarial prompts. Experimental results show that AWMT achieves exceptional performance across both open-source and closed-source LLMs, achieving an impressive 86 % attack success rate on GPT-3.5-turbo, an 18 % improvement over existing methods.
ER  - 

TY  - JOUR
T1  - PAttL-GAN: Pixel Attention Localization Generative Adversarial Network for unsupervised anomaly detection in medical images
AU  - Li, Guangli
AU  - Zou, Yuxing
AU  - Liu, Boyang
AU  - Jiang, Nan
AU  - Lv, Jingqin
AU  - Ai, Wenhao
AU  - Ji, Donghong
AU  - Zhou, Qingzhong
AU  - Zhang, Hongbin
JO  - Neurocomputing
VL  - 654
SP  - 131345
PY  - 2025
DA  - 2025/11/14/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2025.131345
UR  - https://www.sciencedirect.com/science/article/pii/S092523122502017X
KW  - Medical anomaly detection
KW  - Image reconstruction
KW  - Unsupervised learning
KW  - Generative adversarial network
KW  - Pixel-level anomaly localization
AB  - Medical anomaly detection (MAD) plays a vital role in clinical diagnosis because the detected results provide interpretable pathological information for actual diagnosis. Unlabeled datasets, which include abundant normal and abnormal images, have not been effectively utilized. Further, most works cannot achieve fine-grained localization of pixel-level anomaly region. To solve these problems, we propose Pixel Attention Localization Generative Adversarial Network (PAttL-GAN). We first design a multi-level efficient fusion (MEF) module to adaptively assign weights to different layers, enabling the effective fusion of both local and global information. We then create a pixel-level anomaly localization (PAL) module which consists of an adaptive multi-scale attention (AMA) mechanism and a pixel-level weighting (PLW) strategy to improve the saliency of localized abnormal regions and distinguish abnormal regions from complex textures. Comprehensive experiments on four publicly available datasets validate the effectiveness and generalization capability of PAttL-GAN. It surpasses state-of-the-art baselines while maintaining a relatively lightweight structure. PAttL-GAN is a robust, efficient, and interpretable solution for MAD across different imaging modalities and body regions. We also provide sufficient visualization results to enhance the model’s interpretability, offering an innovative perspective for eXplicable Artificial Intelligence (XAI).
ER  - 

TY  - JOUR
T1  - Open-CyKG: An Open Cyber Threat Intelligence Knowledge Graph
AU  - Sarhan, Injy
AU  - Spruit, Marco
JO  - Knowledge-Based Systems
VL  - 233
SP  - 107524
PY  - 2021
DA  - 2021/12/05/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2021.107524
UR  - https://www.sciencedirect.com/science/article/pii/S0950705121007863
KW  - Cyber Threat Intelligence
KW  - Knowledge Graph
KW  - Named Entity Recognition
KW  - Open Information Extraction
KW  - Attention network
AB  - Instant analysis of cybersecurity reports is a fundamental challenge for security experts as an immeasurable amount of cyber information is generated on a daily basis, which necessitates automated information extraction tools to facilitate querying and retrieval of data. Hence, we present Open-CyKG: an Open Cyber Threat Intelligence (CTI) Knowledge Graph (KG) framework that is constructed using an attention-based neural Open Information Extraction (OIE) model to extract valuable cyber threat information from unstructured Advanced Persistent Threat (APT) reports. More specifically, we first identify relevant entities by developing a neural cybersecurity Named Entity Recognizer (NER) that aids in labeling relation triples generated by the OIE model. Afterwards, the extracted structured data is canonicalized to build the KG by employing fusion techniques using word embeddings. As a result, security professionals can execute queries to retrieve valuable information from the Open-CyKG framework. Experimental results demonstrate that our proposed components that build up Open-CyKG outperform state-of-the-art models.11Our implementation of Open-CyKG is publicly available at https://github.com/IS5882/Open-CyKG.
ER  - 

TY  - JOUR
T1  - Generative AI in EU law: Liability, privacy, intellectual property, and cybersecurity
AU  - Novelli, Claudio
AU  - Casolari, Federico
AU  - Hacker, Philipp
AU  - Spedicato, Giorgio
AU  - Floridi, Luciano
JO  - Computer Law & Security Review
VL  - 55
SP  - 106066
PY  - 2024
DA  - 2024/11/01/
SN  - 2212-473X
DO  - https://doi.org/10.1016/j.clsr.2024.106066
UR  - https://www.sciencedirect.com/science/article/pii/S0267364924001328
KW  - Generative AI
KW  - EU law
KW  - Liability
KW  - Privacy
KW  - Intellectual property
KW  - Cybersecurity
AB  - The complexity and emergent autonomy of Generative AI systems introduce challenges in predictability and legal compliance. This paper analyses some of the legal and regulatory implications of such challenges in the European Union context, focusing on four areas: liability, privacy, intellectual property, and cybersecurity. It examines the adequacy of the existing and proposed EU legislation, including the Artificial Intelligence Act (AIA), in addressing the challenges posed by Generative AI in general and LLMs in particular. The paper identifies potential gaps and shortcomings in the EU legislative framework and proposes recommendations to ensure the safe and compliant deployment of generative models.
ER  - 

TY  - JOUR
T1  - Investigating ChatGPT and cybersecurity: A perspective on topic modeling and sentiment analysis
AU  - Okey, Ogobuchi Daniel
AU  - Udo, Ekikere Umoren
AU  - Rosa, Renata Lopes
AU  - Rodríguez, Demostenes Zegarra
AU  - Kleinschmidt, João Henrique
JO  - Computers & Security
VL  - 135
SP  - 103476
PY  - 2023
DA  - 2023/12/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2023.103476
UR  - https://www.sciencedirect.com/science/article/pii/S0167404823003863
KW  - ChatGPT
KW  - Cybersecurity
KW  - Sentiment analysis
KW  - Generative pre-trained transformers
KW  - Artificial intelligence
KW  - Data security
AB  - In early 2023, the Artificial Intelligence (AI) industry experienced a significant advancement with the emergence of OpenAI's ChatGPT, a research product that demonstrated remarkable capabilities and garnered widespread attention. ChatGPT is an advanced chatbot powered by the Generative Pretrained Transformers (GPT) architecture, designed to generate human-like conversations encompassing a wide range of knowledge domains. Many AI researchers are currently engaging with the new technology to understand its functionality and limitations. Various expressions across a range of social media platforms, including Twitter, YouTube, Facebook, and numerous others, are currently under investigation. This research seeks to analyze the opinions of ChatGPT users as it regards cybersecurity. This research is important due to its contribution towards gaining enhanced understanding and devising intricate improvements for the chatbot. The Latent Dirichlet Allocation (LDA) algorithm is utilized to extract relevant topics from the texts. Additionally, to analyze user opinions and decipher the sentiments as either positive, negative, or neutral, we use the Natural language tool kit Valence Aware Dictionary for sEntiment Reasoning (NLTK's VADER) and Robustly Optimized BERT Pretraining Approach (roBERTa) libraries. The data used is obtained from Twitter via the SNScrape library, which aided in the retrieval of over 700,000 tweets via the search terms #chatgptsecurity, #chatgpthackers, #chatgptcybersecurity, and #chatgptcyberthreats. The analysis of the results by the VADER model shows 43.8% positive, 36.3% neutral, and 19.9% negative sentiments. Similarly, the roBERTa model shows 14.1% positive, 53.2% neutral, and 32.7% negative. These results show that there is an ongoing concern about ChatGPT and cybersecurity, especially in malware code generation, hacking, intelligence gathering, and phishing attacks.
ER  - 

TY  - JOUR
T1  - LineJLocRepair: A line-level method for Automated Vulnerability Repair based on joint training
AU  - Hou, Jing
AU  - Han, Jiaxuan
AU  - Huang, Cheng
AU  - Wang, Nannan
AU  - Li, Lerong
JO  - Future Generation Computer Systems
VL  - 166
SP  - 107671
PY  - 2025
DA  - 2025/05/01/
SN  - 0167-739X
DO  - https://doi.org/10.1016/j.future.2024.107671
UR  - https://www.sciencedirect.com/science/article/pii/S0167739X24006356
KW  - Vulnerability localization
KW  - Vulnerability repair
KW  - Code LLM
AB  - In recent years, the progress in large language models has made automatic vulnerability repair a viable solution. Security researchers have proposed a series of Automated Vulnerability Repair (AVR) methods. However, for AVR models to be effective, precise identification of the vulnerability trigger points (i.e., the exact lines of code where the vulnerability resides) is essential. Although current vulnerability detection methods can highlight the relevant lines of code, their accuracy remains suboptimal. Consequently, there is still a necessity for manual refinement of the detection outcomes, which is both time-consuming and labor-intensive. To tackle this challenge, this paper introduces LineJLocRepair, an end-to-end approach for automated vulnerability localization and repair. Grounded on a joint framework, this method seamlessly integrates the tasks of vulnerability localization and repair, thereby enabling simultaneous training of vulnerability localization and repair models. Our approach enables the automatic identification and repair of vulnerable code lines simply by inputting the vulnerable function into our model, which subsequently generates the patched code as output. Experimental results demonstrate that compared to state-of-the-art AVR methods, LineJLocRepair achieves a 12% improvement, effectively repairing 600 out of 1200 real-world vulnerabilities. Furthermore, when benchmarked against the leading methods for vulnerability line localization, LineJLocRepair attains a 32% improvement, achieving an accuracy rate exceeding 99% in pinpointing vulnerable code lines. These results substantiate the effectiveness of our approach in reducing manual intervention during automated vulnerability repair, thereby enhancing both the degree of automation and the accuracy of the repair process.
ER  - 

TY  - JOUR
T1  - Actminer: Applying causality tracking and increment aligning for graph-based threat hunting
AU  - Ma, Mingjun
AU  - Zhu, Tiantian
AU  - Li, Shuang
AU  - Chen, Tieming
AU  - Lv, Mingqi
AU  - Weng, Zhengqiu
AU  - Chen, Guolang
JO  - Knowledge-Based Systems
VL  - 327
SP  - 114169
PY  - 2025
DA  - 2025/10/09/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2025.114169
UR  - https://www.sciencedirect.com/science/article/pii/S0950705125012109
KW  - Threat hunting
KW  - Attack scenario graph
KW  - Data provenance
KW  - Cyber threat intelligence
KW  - Graph-based knowledge,
AB  - To defend against advanced persistent threats on the endpoint, threat hunting employs security knowledge, such as cyber threat intelligence (CTI), to continuously analyze system audit logs through retrospective scanning, querying, or pattern matching, aiming to uncover attack patterns/graphs that traditional detection methods (e.g., recognition for point of interest) fail to capture. However, existing threat hunting systems based on provenance graphs face challenges of high false negatives (FNs), high false positives (FPs), and low efficiency when confronted with diverse attack tactics and voluminous audit logs. To address these issues, we propose a system called Actminer, which constructs query graphs from descriptive relationships in CTI reports for precise threat hunting (i.e., graph alignment) on provenance graphs. First, we present a heuristic search strategy based on equivalent semantic transfer to reduce FNs. Second, we establish a filtering mechanism based on causal relationships of attack behaviors to mitigate FPs. Finally, we design a tree structure to incrementally update the alignment results, significantly improving hunting efficiency. Evaluation on the DARPA Engagement dataset demonstrates that compared with the SOTA POIROT, Actminer reduces FPs by 39.1 %, eliminates all FNs, and effectively counters adversarial attacks.
ER  - 

TY  - JOUR
T1  - TrafficT5: Multi-stage self-correcting framework for traffic generation
AU  - Huang, Yizhao
AU  - Li, Xiaohui
AU  - Geng, Jiaxuan
AU  - Zhu, Xiaolan
JO  - Computer Networks
VL  - 274
SP  - 111858
PY  - 2026
DA  - 2026/01/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2025.111858
UR  - https://www.sciencedirect.com/science/article/pii/S1389128625008242
KW  - Network traffic generation
KW  - Malicious traffic
KW  - Self-correction mechanism
KW  - Protocol consistency
KW  - Large language model
KW  - Data augmentation
AB  - The generation of high-fidelity, controllable malicious network traffic is essential for simulating realistic cyberattacks, evaluating defense mechanisms, and enhancing intrusion detection systems (IDS). However, existing approaches often suffer from low protocol fidelity, limited structural control, and poor adaptability, reducing their effectiveness in practical cybersecurity applications. We introduce TrafficT5, a three-stage, self-correcting framework that turns natural-language intents into executable PCAPs. It (i) predicts flow-level features, (ii) generates byte-aligned hex under a fixed 00–FF vocabulary, and (iii) invokes a repair module that deterministically enforces protocol invariants and performs detector-guided, iterative byte-level correction trained with multi-task objectives. The result is traffic that is both semantically coherent and protocol-compliant. Extensive evaluations on five network datasets demonstrate that TrafficT5 achieves an average Bad Packet Rate (BPR) of only 0.32 %, significantly outperforming existing methods. Furthermore, synthetic malicious flows generated by TrafficT5 are reliably detected as threats by mainstream IDSs, and augmenting datasets with these flows improves F1 detection scores by over 5 % under low-resource conditions.
ER  - 

TY  - JOUR
T1  - A2C: A modular multi-stage collaborative decision framework for human–AI teams
AU  - Tariq, Shahroz
AU  - Baruwal Chhetri, Mohan
AU  - Nepal, Surya
AU  - Paris, Cecile
JO  - Expert Systems with Applications
VL  - 282
SP  - 127318
PY  - 2025
DA  - 2025/07/05/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2025.127318
UR  - https://www.sciencedirect.com/science/article/pii/S0957417425009406
KW  - Human–AI systems
KW  - Collaborative decision-making
KW  - Intelligent systems
KW  - Human-centric AI
KW  - Decision-making under uncertainty
KW  - AI-augmented decision support
AB  - The increasing complexity of decision-making in dynamic environments, particularly in high-stakes domains like cybersecurity, demands more than automated solutions—it requires effective integration of human expertise with advanced AI capabilities. While approaches like ensemble learning and Mixture of Experts (MoE) enhance automated decision-making, they struggle with handling uncertainty and novel scenarios. Techniques such as learning to defer and learning to complement mitigate this by incorporating human input, but assume that a definitive expert is always available—an assumption that often fails in real-world settings. To bridge this gap, we introduce A2C, a modular, multi-stage collaborative decision-making framework that enhances adaptability and decision robustness under uncertainty by seamlessly transitioning between three decision-making modes: Automated, Augmented Deferral, and Collaborative Exploration (CoEx). A key innovation of CoEX is its ability to handle cases where both AI and human experts face uncertainty, overcoming a critical limitation of traditional deferral systems. We validate A2C through experiments on benchmark datasets, Large Language Model (LLM) simulations of human–AI collaboration, and real-world human–AI interaction studies with cybersecurity researchers. Results show that A2C consistently outperforms conventional approaches that rely solely on full automation or selective human intervention, demonstrating its potential as a practical and scalable solution for expert decision-making in complex domains. For image detection on CIFAR-10, detection rates improved from 37.8% with automation alone to 64.75% with augmented deferral, and further to 92.95% with collaborative exploration. Similarly, for intrusion detection on KDDCup, rates rose from 33.43% with automation to 35.18% with augmented deferral, and finally reached 87.04% with CoEx, highlighting its effectiveness in handling uncertainty.
ER  - 

TY  - JOUR
T1  - Advanced computational methods for news classification: A study in neural networks and CNN integrated with GPT
AU  - Sufi, Fahim
JO  - Journal of Economy and Technology
VL  - 3
SP  - 264
EP  - 281
PY  - 2025
DA  - 2025/11/01/
SN  - 2949-9488
DO  - https://doi.org/10.1016/j.ject.2024.09.001
UR  - https://www.sciencedirect.com/science/article/pii/S2949948824000404
KW  - Computational methods
KW  - News report intelligence
KW  - GPT
KW  - Event prediction
KW  - Anomaly detection
KW  - CNN
AB  - In an era inundated with vast amounts of information, the imperative for efficient news classification is paramount. This research explores the sophisticated integration of neural networks and convolutional neural networks (CNN) with Generative Pre-trained Transformers (GPT) to enhance the precision and efficacy of news categorization. The rapid digital dissemination of news necessitates advanced computational methodologies capable of accurate classification and event prediction that include finance and economic events. Leveraging recent advancements in machine learning and natural language processing (NLP), this study utilizes large language models (LLMs) such as GPT and BERT, known for their exceptional comprehension and generation of human-like text. Over 232 days, our methodology classified 33,979 news articles into Education & Learning, Health & Medicine, and Science & Technology, with further subcategorization into 32 distinct subcategories. For evaluation, a sample of 5000 articles was assessed using metrics such as True Positive (TP), True Negative (TN), False Positive (FP), False Negative (FN), Precision, Recall, and F1-Score. In comparison with the existing studies, the proposed method achieving significantly higher with average scores of 0.986 (Precision), 0.987 (Recall), and 0.987 (F1-Score). This research offers substantial practical contributions, providing detailed insights into news source contributions, effective anomaly detection, and predictive trend analysis using neural networks. The theoretical contributions are profound, demonstrating the mathematical integration of GPT with CNNs and recurrent neural networks. This integration advances computational news classification and exemplifies how sophisticated mathematical frameworks enhance large-scale text data analysis, marking a pivotal advancement in applying advanced computational methods in real-world scenarios.
ER  - 

TY  - JOUR
T1  - Managing Linux servers with LLM-based AI agents: An empirical evaluation with GPT4
AU  - Cao, Charles
AU  - Wang, Feiyi
AU  - Lindley, Lisa
AU  - Wang, Zejiang
JO  - Machine Learning with Applications
VL  - 17
SP  - 100570
PY  - 2024
DA  - 2024/09/01/
SN  - 2666-8270
DO  - https://doi.org/10.1016/j.mlwa.2024.100570
UR  - https://www.sciencedirect.com/science/article/pii/S266682702400046X
KW  - LLM
KW  - GPT4
KW  - AI agent
KW  - Server management
KW  - Linux
AB  - This paper presents an empirical study on the application of Large Language Model (LLM)-based AI agents for automating server management tasks in Linux environments. We aim to evaluate the effectiveness, efficiency, and adaptability of LLM-based AI agents in handling a wide range of server management tasks, and to identify the potential benefits and challenges of employing such agents in real-world scenarios. We present an empirical study where a GPT-based AI agent autonomously executes 150 unique tasks across 9 categories, ranging from file management to editing to program compilations. The agent operates in a Dockerized Linux sandbox, interpreting task descriptions and generating appropriate commands or scripts. Our findings reveal the agent’s proficiency in executing tasks autonomously and adapting to feedback, demonstrating the potential of LLMs in simplifying complex server management for users with varying technical expertise. This study contributes to the understanding of LLM applications in server management scenarios, and paves the foundation for future research in this domain.
ER  - 

TY  - JOUR
T1  - Few-VulD: A Few-shot learning framework for software vulnerability detection
AU  - Zheng, Tianming
AU  - Liu, Haojun
AU  - Xu, Hang
AU  - Chen, Xiang
AU  - Yi, Ping
AU  - Wu, Yue
JO  - Computers & Security
VL  - 144
SP  - 103992
PY  - 2024
DA  - 2024/09/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.103992
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824002979
KW  - Vulnerability detection
KW  - Few-shot learning
KW  - Meta-learning
KW  - BiLSTM
KW  - Artificial intelligence
KW  - Deep learning
AB  - The rapid development of artificial intelligence (AI) has led to the introduction of numerous software vulnerability detection methods based on deep learning algorithms. However, a significant challenge is their dependency on large volumes of code samples for effective training. This requirement poses a considerable hurdle, particularly when adapting to diverse software application scenarios and various vulnerability types, where gathering sufficient and relevant training data for different classification tasks is often arduous. To address the challenge, this paper introduces Few-VulD, a novel framework for software vulnerability detection based on few-shot learning. This framework is designed to be efficiently trained with a minimal number of samples from a variety of existing classification tasks. Its key advantage lies in its ability to rapidly adapt to new vulnerability detection tasks, such as identifying new types of vulnerabilities, with only a small set of learning samples. This capability is particularly beneficial in scenarios where available vulnerability samples are limited. We compare Few-VulD with five state-of-the-art methods on the SySeVR and Big-Vul datasets. On the SySeVR dataset, Few-VulD outperforms all other methods, achieving a recall rate of 87.9% and showing an improvement of 11.7% to 57.8%. On the Big-Vul dataset, Few-VulD outperforms three of the methods, including one that utilizes a pretrained large language model (LLM), with recall improvements ranging from 8.5% to 40.1%. The other two methods employ pretrained LLMs from Microsoft CodeXGLUE (Lu et al., 2021). Few-VulD reaches 78.7% and 95.5% of their recall rates without the need for extensive data pretraining. The performance proves the effectiveness of Few-VulD in vulnerability detection tasks with limited samples.
ER  - 

TY  - JOUR
T1  - Your forensic AI-assistant, SERENA: Systematic extraction and reconstruction for enhanced A2P message forensics
AU  - Kim, Jieon
AU  - Jeong, Byeongchan
AU  - Park, Seungeun
AU  - Lee, Sangjin
AU  - Park, Jungheum
JO  - Forensic Science International: Digital Investigation
VL  - 53
SP  - 301931
PY  - 2025
DA  - 2025/07/01/
T2  - DFRWS USA 2025 - Selected Papers from the 25th Annual Digital Forensics Research Conference USA
SN  - 2666-2817
DO  - https://doi.org/10.1016/j.fsidi.2025.301931
UR  - https://www.sciencedirect.com/science/article/pii/S2666281725000708
KW  - Digital forensics
KW  - Application-to-person (A2P) message
KW  - Textual data processing
KW  - AI-assisted data analysis
KW  - Named entity recognition (NER)
KW  - Large language mode (LLM)
KW  - Forensic tool development
AB  - The integration of physical and online activities in today's hyper-connected world has blurred previously distinct boundaries. Online actions such as reservations, payments, and logins generate application-to-person (A2P) messages, which serve as valuable datasets for tracking user behavior. Although A2P messages from different service providers may vary in structure, the information within each message can be systematically normalized based on user behavior and service characteristics. However, traditional forensic tools have been unable to effectively identify and extract such forensically valuable information from these A2P messages. In this study, we leverage large language models (LLMs) combined with prompt engineering to analyze A2P messages from multiple service providers, addressing the limitations of existing forensic tools in extracting meaningful insights from unstructured or semi-structured text stored in messages and emails. The proposed methodology employs A2P messages to elaborately reconstruct user activity, enabling digital forensic investigations to identify case-relevant information with enhanced efficiency and accuracy.
ER  - 

TY  - JOUR
T1  - Ripple2Detect: A semantic similarity learning based framework for insider threat multi-step evidence detection
AU  - Liu, Hongle
AU  - Liu, Ming
AU  - Han, Lansheng
AU  - Sun, Haili
AU  - Fu, Cai
JO  - Computers & Security
VL  - 154
SP  - 104387
PY  - 2025
DA  - 2025/07/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104387
UR  - https://www.sciencedirect.com/science/article/pii/S0167404825000768
KW  - Anamoly detection
KW  - Insider threat detection
KW  - Semantic similarity
KW  - Contrastive learning
KW  - Knowledge graph
AB  - Insider threat attacks occur when individuals misuse their access to an organization’s systems, data, or networks. These attacks, including Advanced Persistent Threats (APT), Pivoting, and Lateral Movement, often involve prolonged timelines and similar sensitive actions. Given the complexity of these attacks, current internal threat detection methods have their shortcomings. Firstly, internal threat attacks typically involve multiple sequences of malicious operations, making it challenging to capture the entire attack process using a single model. Secondly, current research often overlooks the interconnections between user behavior sequences, failing to differentiate between malicious intentions, actions, and outcomes. This neglect may lead to forensic inaccuracies and the misattribution of benign activities as attacks, potentially causing erroneous responses. Furthermore, existing internal threat detection methods fail to mine relevant attack evidence from known sensitive behaviors to thoroughly analyze the attack mechanisms. To address these challenges, we propose Ripple2Detect, a multi-step evidence detection framework for insider threat detection. First, Ripple2Detect builds an evidence sequence library by decomposing known attack behaviors into sequences and constructing a knowledge graph to measure their correlations. Next, we train a semantic similarity model based on the BERT architecture, tailored for operation sequences, to improve the detection of attack evidence. To overcome data imbalance, we introduce a contrastive learning loss to better distinguish between attack and non-attack behaviors. Finally, a preference propagation mechanism is used to predict attack behaviors within the knowledge graph. We conduct experiments on Cert-r4.2 and Cert-r5.2 benchmark datasets, comparing our model with state-of-the-art approaches. The results suggest that our model can identify malicious sequences with 0.96 F1 score and achieve an attack identification F1 score of up to 0.99. The source code can be obtained from https://github.com/L3LeTrigger-F/Ripple2Detect_code
ER  - 

TY  - JOUR
T1  - Ransomware detection and family classification using fine-tuned BERT and RoBERTa models
AU  - Hussain, Amjad
AU  - Saadia, Ayesha
AU  - Alserhani, Faeiz M.
JO  - Egyptian Informatics Journal
VL  - 30
SP  - 100645
PY  - 2025
DA  - 2025/06/01/
SN  - 1110-8665
DO  - https://doi.org/10.1016/j.eij.2025.100645
UR  - https://www.sciencedirect.com/science/article/pii/S1110866525000386
KW  - Ransomware detection
KW  - Ransomware classification
KW  - Transfer learning
KW  - Ransomware family attribution
AB  - Integrating Internet of Things (IoT) technologies in healthcare has revolutionized patient care, enabling real-time monitoring, predictive analytics, and personalized treatments. However, it presents significant challenges that must be addressed to ensure secure and reliable implementation. IoT devices in healthcare, such as remote patient monitors, are often constrained by limited computational power, making them vulnerable to sophisticated cyberattacks, including ransomware. In 2017 the WannaCry ransomware attack disrupted many National Health Service facilities in the United Kingdom and emphasized the critical need for robust cybersecurity measures. The lack of standardization across IoT devices creates interoperability issues and complicates data transfer between medical devices and healthcare systems. This research explores these challenges and proposes a novel approach using hyperparameter-optimized transfer learning-based models, Bidirectional Encoder Representations from Transformers (BERT), and a Robustly Optimized BERT Approach (RoBERTa), to not only detect but also classify ransomware targeting IoT devices by analyzing dynamically executed API call sequences in a sandbox environment. A total of 3300 samples from 10 ransomware families including 300 benign cases are analyzed dynamically in a sandbox environment. The newly created dataset is then preprocessed and fed to the BERT and RoBERTa models for training. The BERT achieved 95.60% accuracy with a minimal loss of 0.1650 while the RoBERTa achieved 94.39% accuracy with 0.1948 loss in classifying ransomware families. These results indicate that the proposed approach is game-changing in the classification of previously unidentified behavioral patterns inside ransomware and enhances the ability to tackle newly developing threats. By leveraging the dynamic analysis with API call sequences in a correct format, and training hyperparameter-optimized transformer learning-based models, the methodology efficiently captures behavioral patterns unique to ransomware. The research provides a scalable framework for integrating advanced detection mechanisms into real-world healthcare IoT systems, enhancing their resilience against cyber threats.
ER  - 

TY  - JOUR
T1  - An automated unsupervised anomaly detection framework for DCS controller logs in nuclear power plants
AU  - Cai, Jiajun
AU  - Zheng, Sheng
AU  - Zhang, Caike
AU  - Dai, Xinyu
AU  - Ye, Xiaozhou
AU  - Li, Xiaolong
JO  - Nuclear Engineering and Design
VL  - 446
SP  - 114567
PY  - 2026
DA  - 2026/01/01/
SN  - 0029-5493
DO  - https://doi.org/10.1016/j.nucengdes.2025.114567
UR  - https://www.sciencedirect.com/science/article/pii/S0029549325007447
KW  - Nuclear power plants
KW  - DCS
KW  - Anomaly detection
KW  - Log-text analysis
KW  - Feature engineering
AB  - Digital Control Systems (DCS) are pivotal in ensuring nuclear power plant safety by providing real-time monitoring and precise control, with their controllers serving as the critical backbone for reliable operation and fault mitigation. Despite the critical importance of controllers, their operational logs remain an underexploited resource for anomaly detection in nuclear power plant DCS, where current manual-dominated approaches are not only time-consuming but also inefficient. To address this challenge, this study develops an automated unsupervised anomaly detection framework for DCS controller logs. Our approach is composed of three key stages: log parsing, feature engineering, and anomaly detection. In the log parsing stage, raw logs are processed to extract structured information; in feature engineering, logs are grouped by device and events are counted within fixed time windows to build informative feature representations; finally, anomalies are detected by modeling the normal behavior with Principal Component Analysis (PCA) and identifying significant projection errors in the PCA subspace. The framework is validated on a real-world DCS controller log dataset from a nuclear power plant that was manually annotated. Experimental results demonstrate the framework’s effectiveness in accurately detecting abnormal events, reinforcing its potential for enhancing safety in nuclear DCS applications.
ER  - 

TY  - JOUR
T1  - Offloading-verified framework for adversary detection and mitigation in IoT
AU  - Ebrahim, Nadhem
AU  - Elloumi, Mourad
AU  - Alharthi, Abdullah Mohammed
AU  - Altuwaijri, Fahad S.
AU  - Alsaadi, Mohammed
JO  - Applied Soft Computing
VL  - 177
SP  - 113312
PY  - 2025
DA  - 2025/06/01/
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2025.113312
UR  - https://www.sciencedirect.com/science/article/pii/S1568494625006234
KW  - Adversary Detection
KW  - CPS
KW  - IoT
KW  - Offloading Security
KW  - Partial Order Network
AB  - Cyber-physical systems (CPSs) designed for the Internet of Things (IoT) enhanced security and resource infrastructures to support various applications and services, undetected adversaries in the temporarily connected IoT network impose different user and data privacy threats, this research introduces an Offloading-verified Adversary Detection and Mitigation Scheme (OADMS), this proposed scheme coexists with the IoT communication and CPS security infrastructure for adversary detection, conventional behavior-based adversary detection with partial order adversarial network training validates the infrastructure security support against cyber-attacks. The behavior is analyzed for independent and offloaded service exchanges, reducing communication failures and is recurrently analyzed in the detection process until the service termination, communication metrics of the infrastructure units are used to verify adversary and user channel behavior. The learning process recommendations are exploited to validate the channel's reliability through IoT-sharing platforms, and the performance of the proposed system is assessed using communication latency, failure rate, response ratio, and detection factor. The model achieved an excellent detection accuracy rate of 96.8 %.
ER  - 

TY  - JOUR
T1  - AIS-NIDS: An intelligent and self-sustaining network intrusion detection system
AU  - Farrukh, Yasir Ali
AU  - Wali, Syed
AU  - Khan, Irfan
AU  - Bastian, Nathaniel D.
JO  - Computers & Security
VL  - 144
SP  - 103982
PY  - 2024
DA  - 2024/09/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.103982
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824002876
KW  - Cybersecurity
KW  - Network intrusion detection
KW  - Open set recognition
KW  - Incremental learning
KW  - Intelligent system
AB  - The ever-evolving landscape of network security is continually molded by the dynamic evolution of attack vectors and the relentless emergence of new, highly sophisticated attacks. Attackers consistently employ increasingly advanced techniques, rendering their actions elusive and formidable. In response to this ever-growing threat, the demand for intelligent and autonomous security systems has reached paramount importance. In this paper, we introduce AIS-NIDS (An Intelligent and Self-Sustaining Network Intrusion Detection System), an innovative network intrusion detection system (NIDS) that delves into the realm of packet-level analysis. By doing so, AIS-NIDS is capable of identifying threats with intricate payload-level details, a level of granularity that traditional NIDS relying solely on flow-level data may overlook. The defining feature of AIS-NIDS is its dual functionality, driven by autonomous and intelligent learning. It not only autonomously distinguishes between benign and unknown attacks using machine learning models but also conducts incremental learning, adapting to new attack classes. In essence, AIS-NIDS bridges the gap between traditional NIDS and the next generation of intelligent systems, endowing the system with the capacity for independent decision-making and real-time adaptability in the face of evolving threats. Our extensive experiments stand as a testament to AIS-NIDS’ ability to efficiently manage and identify new attack classes, thus establishing it as a valuable asset in the reinforcement of network infrastructures. Through our experimentation, we have demonstrated the practical efficacy of the proposed approach by simulating a real-world scenario in which certain attack classes are unknown. AIS-NIDS not only effectively identified these unknown threats but also autonomously learned to recognize them as it encountered them, enhancing the system’s capabilities for future encounters with these threats.
ER  - 

TY  - JOUR
T1  - AI can be cyberbullying perpetrators: Investigating individuals’ perceptions and attitudes towards AI-generated cyberbullying
AU  - Pei, Weiping
AU  - Wang, Fangzhou
AU  - Chua, Yi Ting
JO  - Technology in Society
VL  - 84
SP  - 103089
PY  - 2026
DA  - 2026/03/01/
SN  - 0160-791X
DO  - https://doi.org/10.1016/j.techsoc.2025.103089
UR  - https://www.sciencedirect.com/science/article/pii/S0160791X25002799
KW  - Cyberbullying
KW  - Artificial intelligence (AI)
KW  - Large language models (LLMs)
KW  - AI-Generated content
KW  - Harmful content
AB  - Cyberbullying is a critical social problem that can cause significant psychological harm, particularly to vulnerable individuals. While Artificial Intelligence (AI) is increasingly leveraged to combat cyberbullying, its misuse to generate harmful content raises new concerns. This study examines human perception of AI-generated cyberbullying messages and their potential psychological impact. Using large language models (LLMs), we generated cyberbullying messages across three categories (sexism, racism, and abuse) and conducted a user study (n = 363), where participants engaged with hypothetical social media scenarios. Findings reveal that AI-generated messages can be just as or even more harmful than human-written ones in terms of participants’ comfort levels, perceived harm, and severity. Additionally, AI-generated messages were almost indistinguishable from human-written ones, with many participants misidentifying AI-generated messages as human-written. Furthermore, participants with prior experience using AI tools consistently demonstrated higher accuracy in identification, while their attitudes towards online harm significantly influenced their comfort levels. This study emphasizes the urgent need for robust mitigation strategies to counter AI-generated harmful content, ensuring that AI technologies are deployed responsibly and do not exacerbate online harm.
ER  - 

TY  - JOUR
T1  - Survey of Cybersecurity in Smart Grids Protocols and Datasets
AU  - Muhammad, Mamdouh
AU  - S. Alshra‘a, Abdullah
AU  - German, Reinhard
JO  - Procedia Computer Science
VL  - 241
SP  - 365
EP  - 372
PY  - 2024
DA  - 2024/01/01/
T2  - 19th International Conference on Future Networks and Communications/ 21th International Conference on Mobile Systems and Pervasive Computing/14th International Conference on Sustainable Energy Information Technology
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.08.049
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924017605
KW  - Cyber-Physical Systems
KW  - cybersecurity
KW  - Information Technology
KW  - IT/OT convergence
KW  - smart grids
AB  - Smart grids are two-way communications grids that converge Information Technology (IT) and Operational Technology (OT) to transfer energy-related information between different industry components within the grid. Smart grids have changed the energy sector by increasing sustainability, efficiency and integrating renewable energy sources. However, smart grids are vulnerable to IT-related attacks because they rely on Information and Communication Technology (ICT). By surveying relevant papers and evaluating accessible statistics, this study explores cybersecurity in smart grids by examining current communication protocols and standards. We carefully compile various datasets with general information about four of the most smart grid-related datasets. Our study and conclusions address the key components of a smart grid and offer information that can help create cybersecurity plans specifically for smart grids. This research contributes to the discourse on smart grid security, which is important for preserving the stability of contemporary energy systems.
ER  - 

TY  - JOUR
T1  - Unveiling shadows: A comprehensive framework for insider threat detection based on statistical and sequential analysis
AU  - Xiao, Haitao
AU  - Zhu, Yan
AU  - Zhang, Bin
AU  - Lu, Zhigang
AU  - Du, Dan
AU  - Liu, Yuling
JO  - Computers & Security
VL  - 138
SP  - 103665
PY  - 2024
DA  - 2024/03/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2023.103665
UR  - https://www.sciencedirect.com/science/article/pii/S0167404823005758
KW  - Insider threat detection
KW  - Statistical analysis
KW  - Sequential analysis
KW  - Deep learning
AB  - With the increasing importance of internal information security, detecting insider threats has become a critical issue to safeguard organizations' information systems. However, most of the previous studies either overlook temporal relationships or have difficulty attaining accurate performance. One of the primary factors contributing to this challenge is their approach, which lacks a holistic perspective. To our knowledge, none of these studies has considered the integration of statistical and sequential information in addressing this issue. Therefore, we propose a comprehensive framework for insider threat detection based on statistical and sequential analysis to address this challenge. Leveraging the strengths of both statistical analysis and sequential analysis, we deploy an efficient implementation for analyzing and modeling user data based on convolutional attention and a transformer encoder, referred to as CATE. First, user behavior logs are consolidated from diverse sources and preprocessed into a suitable format for subsequent analysis. Then, two parallel analysis modules analyze user data in two different dimensions. The analysis modules are entirely constructed using a neural network for its high adaptability and efficient integration of information from distinct dimensions. Specifically, a subnetwork structure based on convolutional attention is designed to effectively learn statistical information, while a separate subnetwork structure based on transformers is tailored for learning sequential information. Finally, we perform a series of solid experiments utilizing the publicly available CERT dataset to evaluate our framework's effectiveness and robustness in detecting insider threats and identifying malicious scenarios.
ER  - 

TY  - JOUR
T1  - Indicators of employee phishing email behaviours: Intuition, elaboration, attention, and email typology
AU  - Buckley, J.
AU  - Lottridge, D.
AU  - Murphy, J.G.
AU  - Corballis, P.M.
JO  - International Journal of Human-Computer Studies
VL  - 172
SP  - 102996
PY  - 2023
DA  - 2023/04/01/
SN  - 1071-5819
DO  - https://doi.org/10.1016/j.ijhcs.2023.102996
UR  - https://www.sciencedirect.com/science/article/pii/S1071581923000022
KW  - Cybersecurity
KW  - Phishing
KW  - Habit
KW  - Intuition
KW  - Cognitive elaboration
KW  - Employee
AB  - Employees’ behaviour to phishing emails can strengthen or undermine business organisations’ cyber security. This phishing simulation and survey study explored the relationship between sociodemographic, cyber security training, phishing email typology and information processing factors and risky and secure email response behaviours. Participants (N = 590) were employees of a large financial institution who received one of four types of phishing emails. Participants who engaged in risky cyber email behaviour clicked on the link in the phishing email whereas those who engaged in secure cyber email behaviour reported the email to the institutions cyber security team. Our findings show that the likelihood of clicking on a link in a phishing email was lower for participants who had greater faith in their intuition and paid more attention to the sender's email address. The likelihood of clicking on a link in a phishing email was greater for participants who received the ‘Undelivered package’ email relative to the ‘Received PDF’. The likelihood of reporting a phishing email was greater for participants who engaged in greater elaborative processing to evaluate the email than those who used less elaboration. Theoretical and practical implications as well as future directions are discussed.
ER  - 

TY  - JOUR
T1  - Collective intelligence-based service migration enabling zoom-in functionality within industry 5.0
AU  - Venanzi, Riccardo
AU  - Colombi, Lorenzo
AU  - Tazzioli, Davide
AU  - Dahdal, Simon
AU  - Tortonesi, Mauro
AU  - Foschini, Luca
JO  - Internet of Things
VL  - 35
SP  - 101830
PY  - 2026
DA  - 2026/01/01/
SN  - 2542-6605
DO  - https://doi.org/10.1016/j.iot.2025.101830
UR  - https://www.sciencedirect.com/science/article/pii/S2542660525003440
KW  - Collective intelligence
KW  - Artificial intelligence
KW  - Industry 5.0
KW  - Service migration
KW  - Zoom-In functionality
KW  - Industrial internet of things
KW  - Kubernetes
AB  - The rapid evolution of Industry 5.0 emphasizes the integration of human expertise with machine intelligence to create resilient, adaptive, and human-centric industrial systems. This paper introduces a novel Collective Intelligence (CI)-based service migration framework designed for Industry 5.0 environments, enabling dynamic orchestration of stateful services across heterogeneous edge-to-cloud infrastructures. At its core, the framework leverages Kubernetes (K8s) enhanced with AI-driven decision-making and human-in-the-loop collaboration to address the limitations of traditional orchestration in industrial settings. A key innovation of this work is the Zoom-In functionality, which empowers human operators to escalate anomaly detection and analysis by deploying advanced machine learning models on demand, seamlessly migrating services to resource-rich nodes when deeper investigation is warranted. The proposed framework integrates Large Language Models (LLMs) to translate operator intent into actionable policies, ensuring context-aware and explainable decision-making. Experimental validation in real industrial scenarios demonstrates high anomaly detection accuracy (F1-scores up to 1.0), reliable operator intent translation (over 70 % correct JSON generations with lightweight LLMs), and efficient multi-criteria scheduling with millisecond-level decision times. Moreover, the proposed migration mechanism reduces downtime by more than 50 % compared to vanilla Kubernetes, ensuring service continuity in mission-critical tasks. This work advances the vision of collaborative intelligence in IoT systems, bridging the gap between human judgment and automated orchestration for Industry 5.0 applications.
ER  - 

TY  - JOUR
T1  - Entity and relation extractions for threat intelligence knowledge graphs
AU  - Mouiche, Inoussa
AU  - Saad, Sherif
JO  - Computers & Security
VL  - 148
SP  - 104120
PY  - 2025
DA  - 2025/01/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104120
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824004255
KW  - Threat intelligence knowledge graphs (TiKG)
KW  - Cyber threat intelligence (CTI)
KW  - Cyber knowledge graphs (CKGs)
KW  - Pipeline extraction
KW  - Joint extraction
KW  - Entity-relation extraction
KW  - Knowledge Ontology
KW  - NER Datasets
AB  - Advanced persistent threats (APTs) represent a complex challenge in cybersecurity as they infiltrate networks stealthily to conduct espionage, steal data, and maintain a long-term presence. To combat these threats, security professionals increasingly rely on cyber knowledge graphs (CKGs), which provide scalable solutions to analyze and structure vast amounts of cyber threat intelligence (CTI) from diverse sources in real-time, enabling the automation of proactive security measures. Developing CKGs requires extracting entity and their relationships from unstructured CTI reports. However, existing approaches face significant limitations, such as difficulties with the nuances of cybersecurity language, diverse threat terminologies, and high rates of error propagation, resulting in low accuracy and poor generalizability. This paper introduces a novel Threat Intelligence Knowledge Graph (TiKG) pipeline designed to address these challenges. The TiKG framework leverages SecureBERT, a domain-specific transformer-based model optimized for cybersecurity, and integrates it with an attention-based BiLSTM to capture the context and nuances of security texts, reducing error propagation and improving extraction accuracy. Additionally, the pipeline incorporates a domain-specific ontology and inference model to ensure precise relation mapping in relation extraction. Using three large-scale TI open-source datasets (DNRTI, STUCCO, and CYNER) and a curated CTI dataset, extensive evaluations demonstrate the effectiveness of our framework, showing significant improvements over existing methods in detecting and linking cyber threats. These contributions provide a robust platform for security professionals to analyze and predict potential attacks, develop effective defenses, and enhance the strategic capabilities of cybersecurity operations.
ER  - 

TY  - JOUR
T1  - From attack descriptions to vulnerabilities: A sentence transformer-based approach
AU  - Othman, Refat
AU  - Rimawi, Diaeddin
AU  - Rossi, Bruno
AU  - Russo, Barbara
JO  - Journal of Systems and Software
VL  - 231
SP  - 112615
PY  - 2026
DA  - 2026/01/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2025.112615
UR  - https://www.sciencedirect.com/science/article/pii/S0164121225002845
KW  - Cyber threat intelligence
KW  - MITRE ATT&CK
KW  - CAPEC
KW  - CVE
KW  - Sentence transformer
KW  - Attack–vulnerability linking
KW  - Pretrained language models
AB  - In the domain of security, vulnerabilities frequently remain undetected even after their exploitation. In this work, vulnerabilities refer to publicly disclosed flaws documented in Common Vulnerabilities and Exposures (CVE) reports. Establishing a connection between attacks and vulnerabilities is essential for enabling timely incident response, as it provides defenders with immediate, actionable insights. However, manually mapping attacks to CVEs is infeasible, thereby motivating the need for automation. This paper evaluates 14 state-of-the-art (SOTA) sentence transformers for automatically identifying vulnerabilities from textual descriptions of attacks. Our results demonstrate that the multi-qa-mpnet-base-dot-v1 (MMPNet) model achieves superior classification performance when using attack Technique descriptions, with an F1-score of 89.0, precision of 84.0, and recall of 94.7. Furthermore, it was observed that, on average, 56% of the vulnerabilities identified by the MMPNet model are also represented within the CVE repository in conjunction with an attack, while 61% of the vulnerabilities detected by the model correspond to those cataloged in the CVE repository. A manual inspection of the results revealed the existence of 275 predicted links that were not documented in the MITRE repositories. Consequently, the automation of linking attack techniques to vulnerabilities not only enhances the detection and response capabilities related to software security incidents but also diminishes the duration during which vulnerabilities remain exploitable, thereby contributing to the development of more secure systems.
ER  - 

TY  - JOUR
T1  - A Proactive Decoy Selection Scheme for Cyber Deception using MITRE ATT&CK
AU  - Zambianco, Marco
AU  - Facchinetti, Claudio
AU  - Siracusa, Domenico
JO  - Computers & Security
VL  - 148
SP  - 104144
PY  - 2025
DA  - 2025/01/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104144
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824004498
KW  - Cyber deception
KW  - Decoy selection
KW  - Cyber-threat intelligence
KW  - Attack graph
KW  - Optimization
AB  - Cyber deception allows compensating the late response of defenders countermeasures to the ever evolving tactics, techniques, and procedures (TTPs) of attackers. This proactive defense strategy employs decoys resembling legitimate system components to lure stealthy attackers within the defender environment, slowing and/or denying the accomplishment of their goals. In this regard, the selection of decoys that can expose the techniques used by malicious users plays a central role to incentivize their engagement. However, this is a difficult task to achieve in practice, since it requires an accurate and realistic modeling of the attacker capabilities and his possible targets. In this work, we tackle this challenge and we design a decoy selection scheme that is supported by an adversarial modeling based on empirical observation of real-world attackers. We take advantage of a domain-specific threat modeling language using MITRE ATT&CK© framework as source of attacker TTPs targeting enterprise systems. In detail, we extract the information about the execution preconditions of each technique as well as its possible effects on the environment to generate attack graphs modeling the adversary capabilities. Based on this, we formulate a graph partition problem that minimizes the number of decoys detecting a corresponding number of techniques employed in various attack paths directed to specific targets. We compare our optimization-based decoy selection approach against several benchmark schemes that ignore the preconditions between the various attack steps. Results reveal that the proposed scheme provides the highest interception rate of attack paths using the lowest amount of decoys.
ER  - 

TY  - JOUR
T1  - Leveraging evolutionary algorithms with a dynamic weighted search space approach for fraud detection in healthcare insurance claims
AU  - Tubishat, Mohammad
AU  - Tbaishat, Dina
AU  - Al-Zoubi, Ala’ M.
AU  - Hraiz, Abed-Elalim
AU  - Habib, Maria
JO  - Knowledge-Based Systems
VL  - 317
SP  - 113436
PY  - 2025
DA  - 2025/05/23/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2025.113436
UR  - https://www.sciencedirect.com/science/article/pii/S0950705125004836
KW  - Medical fraud
KW  - Detection
KW  - Claims
KW  - SVM
KW  - LLM
KW  - Dynamic search space
KW  - Feature weighing
KW  - Optimization algorithms
AB  - The healthcare industry has been suffering from fraud in many facets for decades, resulting in millions of dollars lost to fictitious claims at the expense of other patients who cannot afford appropriate care. As such, accurately identifying fraudulent claims is one of the most important factors in a well-functioning healthcare system. However, over time, fraud has become harder to detect because of increasingly complex and sophisticated fraud scheme development, data unpreparedness, as well as data privacy concerns. Moreover, traditional methods are proving increasingly inadequate in addressing this issue. To solve this issue a novel evolutionary dynamic weighted search space approach (DW-WOA-SVM) is presented in the current study. The approach has different levels that work simultaneously, where the optimization algorithm is responsible for tuning the Support Vector Machine (SVM) parameters, applying the weighting procedure for the features, and using a dynamic search space to adjust the range values. Tuning the parameters benefits the performance of SVM, and the weighting technique makes it updated with importance and lets the algorithm focus on data structure in addition to optimization objectives. The dynamic search space enhances the search range during the process. Furthermore, large language models have been applied to generate the dataset to improve the quality of the data and address the lack of good dimensionality, helping to enhance the richness of the data. The experiments highlighted the superior performance of this proposed approach than other algorithms.
ER  - 

TY  - JOUR
T1  - One For All: LLM-based Heterogeneous Mission Planning in Precision Agriculture
AU  - Zuzuárregui, Marcos Abel
AU  - Toslak, Mustafa Melih
AU  - Carpin, Stefano
JO  - IFAC-PapersOnLine
VL  - 59
IS  - 23
SP  - 344
EP  - 349
PY  - 2025
DA  - 2025/01/01/
T2  - 8th IFAC Conference on Sensing, Control and Automation Technologies for Agriculture AGRICONTROL 2025
SN  - 2405-8963
DO  - https://doi.org/10.1016/j.ifacol.2025.11.811
UR  - https://www.sciencedirect.com/science/article/pii/S2405896325025170
KW  - Machine learning – AI applications
KW  - Precision Agriculture
KW  - Automation
KW  - Robotics in Specialty Crops
KW  - Field Crops
AB  - Artificial intelligence is transforming precision agriculture, offering farmers new tools to streamline their daily operations. While these technological advances promise increased efficiency, they often introduce additional complexity and steep learning curves that are particularly challenging for non-technical users who must balance tech adoption with existing workloads. In this paper, we present a natural language (NL) robotic mission planner that enables non-specialists to control heterogeneous robots through a common interface. By leveraging large language models (LLMs) and predefined primitives, our architecture seamlessly translates human language into intermediate descriptions that can be executed by different robotic platforms. With this system, users can formulate complex agricultural missions without writing any code. In the work presented in this paper, we extend our previous system tailored for wheeled robot mission planning through a new class of experiments involving robotic manipulation and computer vision tasks. Our results demonstrate that the architecture is both general enough to support a diverse set of robots and powerful enough to execute complex mission requests. This work represents a significant step toward making robotic automation in precision agriculture more accessible to non-technical users.
ER  - 

TY  - JOUR
T1  - Walkthrough phishing detection techniques
AU  - Singh, Tejveer
AU  - Kumar, Manoj
AU  - Kumar, Santosh
JO  - Computers and Electrical Engineering
VL  - 118
SP  - 109374
PY  - 2024
DA  - 2024/08/01/
SN  - 0045-7906
DO  - https://doi.org/10.1016/j.compeleceng.2024.109374
UR  - https://www.sciencedirect.com/science/article/pii/S0045790624003021
KW  - Phishing
KW  - Machine learning
KW  - Deep learning
KW  - Features
KW  - Cyber threat
KW  - Social engineering
KW  - Internet users
KW  - Cyber vulnerabilities
KW  - Phishing countermeasures
KW  - User authentication
AB  - Phishing has emerged as a significant cyber threat, resulting in huge financial frauds for internet users annually. This malicious activity uses social engineering and upgraded methodologies (like file archiver in the browser, content injection, calendar phishing, more convincing fake websites or emails, voice manipulation, or other tools designed to deceive and exploit the target’s confidence) to extract sensitive information from unsuspected victims. In order to mitigate these attacks, several methods and tools have been devised; various detection techniques and block phishing websites, and browser extensions that notify users about suspicious websites. Our work elaborates on meticulous analysis of the detection of phishing attacks by classifying them into four broader categories based on the adopted methodologies like List-Based Detection, Heuristic-Based Detection, machine learning (ML)-based, and deep learning (DL)-based. Additionally, it summarizes the popular devised schemes, highlighting their advantages and limitations, and how these are suitable for the different types of deployments.
ER  - 

TY  - JOUR
T1  - Data management in Polish SMEs in the era of AI – threats and benefits of AI-based tools
AU  - Chmielarz, Grzegorz
JO  - Procedia Computer Science
VL  - 246
SP  - 5439
EP  - 5447
PY  - 2024
DA  - 2024/01/01/
T2  - 28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.09.681
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924027406
KW  - cyberthreats
KW  - cybersecurity
KW  - Artificial Intelligence
KW  - Small
KW  - Medium-Sized Enterprises
AB  - The primary goal of the article is to analyse whether the benefits of implementing AI-based solutions in the area of cybersecurity may be a sufficient stimulus for Polish Small and Medium-Sized Enterprises (SMEs) to decide for their adoption. With this view in mind, the author of the paper analyses recent legislative changes in the domain of data protection such as General Data Protection Regulation. Additionally, the need for legislative changes is highlighted in the light of ever increasing adoption of AI-based solutions in all types of organisations. Then, the research focus pertains to contemporary threats to data security in Polish SMEs, with a particular stress on the latest AI-based attacks. For this purpose data from national cybersecurity institutions are analysed to determine the most serious attacks aimed at Polish organisations. This is followed by the analysis of the defence potential of the investigated enterprises in terms of financial funds they spend on cybersecurity as well as persons in these organisations responsible for handling data protection issues. The next part of the paper is an analysis of the benefits stemming from application of AI-based tools in the cybersecurity domain. Its main objective is to find out the answer to the research question: What benefits stemming from application AI-based solutions can encourage Polish SMEs to make investments into these cybersecurity tools given their size and budget capacities)? The paper finishes with the conclusion and indication of potential further research avenues.
ER  - 

TY  - JOUR
T1  - FLAD: Adaptive Federated Learning for DDoS attack detection
AU  - Doriguzzi-Corin, Roberto
AU  - Siracusa, Domenico
JO  - Computers & Security
VL  - 137
SP  - 103597
PY  - 2024
DA  - 2024/02/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2023.103597
UR  - https://www.sciencedirect.com/science/article/pii/S0167404823005072
KW  - Network security
KW  - Intrusion detection
KW  - Distributed denial of service
KW  - Federated Learning
KW  - Heterogeneous data
AB  - Federated Learning (FL) has been recently receiving increasing consideration from the cybersecurity community as a way to collaboratively train deep learning models with distributed profiles of cyber threats, with no disclosure of training data. Nevertheless, the adoption of FL in cybersecurity is still in its infancy, and a range of practical aspects have not been properly addressed yet. Indeed, the Federated Averaging algorithm at the core of the FL concept requires the availability of test data to control the FL process. Although this might be feasible in some domains, test network traffic of newly discovered attacks cannot be always shared without disclosing sensitive information. In this paper, we address the convergence of the FL process in dynamic cybersecurity scenarios, where the trained model must be frequently updated with new recent attack profiles to empower all members of the federation with the latest detection features. To this aim, we propose FLAD (adaptive Federated Learning Approach to DDoS attack detection), an FL solution for cybersecurity applications based on an adaptive mechanism that orchestrates the FL process by dynamically assigning more computation to those members whose attacks profiles are harder to learn, without the need of sharing any test data to monitor the performance of the trained model. Using a recent dataset of DDoS attacks, we demonstrate that FLAD outperforms state-of-the-art FL algorithms in terms of convergence time and accuracy across a range of unbalanced datasets of heterogeneous DDoS attacks. We also show the robustness of our approach in a realistic scenario, where we retrain the deep learning model multiple times to introduce the profiles of new attacks on a pre-trained model.
ER  - 

TY  - JOUR
T1  - Anomaly detection in attributed networks via local multi-order contrastive learning and global topology awareness
AU  - Li, Mark Junjie
AU  - Zhao, Gen
AU  - Huang, Sunjie
AU  - Zhang, Qin
AU  - Liu, Jiang
AU  - Li, Meiting
AU  - Li, Jun
JO  - Neurocomputing
VL  - 650
SP  - 130829
PY  - 2025
DA  - 2025/10/14/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2025.130829
UR  - https://www.sciencedirect.com/science/article/pii/S0925231225015012
KW  - Attributed networks
KW  - Anomaly detection
KW  - Contrastive learning
KW  - Data augmentation
KW  - Topology awareness
AB  - Detecting anomalies in attributed networks has become increasingly important in practical applications such as cybersecurity and e-commerce. Most existing methods primarily focus on the local graph dimension, relying on a single substructure to construct contrastive instance pairs. These approaches limit the representation of interactive relationships within the network, negatively impacting the performance of subsequent learning tasks. Moreover, current methods inadequately consider global topology information in attributed networks, which hinders their ability to capture abnormal topology patterns within the graphs. To address these limitations, we propose LMGTA (Local Multi-Order Contrastive Learning and Global Topology Awareness), a novel framework for anomaly detection in attributed networks. In the local dimension, LMGTA utilizes a specially designed data augmentation strategy to enhance local graph representations by enriching the network’s structural diversity and broadening interaction relationships within subgraphs. These enhanced subgraphs are then processed with a contrastive learning model to capture comprehensive local neighborhood information. At the global level, LMGTA effectively links node attributes with global topology through community structures, enabling the identification of topology-based anomalies. By integrating complementary local and global views, LMGTA achieves precise detection of anomalous nodes. Extensive experiments on eight real-world datasets demonstrate the effectiveness and superiority of LMGTA compared to state-of-the-art baseline methods.
ER  - 

TY  - JOUR
T1  - Predictive Analytics-Based Cybersecurity Framework for Cloud Infrastructure
AU  - Bhardwaj, Akashdeep
AU  - Kaushik, Keshav
JO  - International Journal of Cloud Applications and Computing
VL  - 12
IS  - 1
PY  - 2022
DA  - 2022/01/01/
SN  - 2156-1834
DO  - https://doi.org/10.4018/IJCAC.297106
UR  - https://www.sciencedirect.com/science/article/pii/S215618342200047X
KW  - Artificial Intelligence
KW  - Cyber-Attacks
KW  - Cybersecurity Framework
KW  - Machine Learning
KW  - Predictive Analysis
AB  - ABSTRACT
The most valuable asset for any organization and individual is data and the information it holds. This is the main reason for information security to be the top concern in boardrooms and executive meetings. Security failures and data breaches now can impact an organization or a country's budget economy. To reduce cybersecurity risks and improve data protection, there is an urgent need to implement a standard framework for cybersecurity. This framework utilizes AI and ML by including policies, guidelines, standards and practices, and data sources from cloud infrastructure systems like networks, servers, security systems, and end-user devices. Combining the data set gathered and risk governance information with artificial intelligence and machine learning, this research presents a framework that collects datasets, enriches and validates logs and datasets, then correlates them to analyze and predict the response to cyber-attacks with a high level of accuracy using the ML model.
ER  - 

TY  - JOUR
T1  - Human-centred cybersecurity for critical infrastructure: the case of the Florida water plant hack
AU  - Ninan, Johan
AU  - Mantha, Bharadwaj R. K.
AU  - Kesavan, Balaji
JO  - Engineering, Construction and Architectural Management
VL  - 32
IS  - 13
SP  - 547
EP  - 569
PY  - 2025
DA  - 2025/10/28/
SN  - 0969-9988
DO  - https://doi.org/10.1108/ECAM-02-2025-0213
UR  - https://www.sciencedirect.com/science/article/pii/S0969998825000220
KW  - Cybersecurity
KW  - Lean construction
KW  - Critical infrastructure
KW  - Crisis
KW  - Stages of grief
KW  - Social media
AB  - Purpose
Cyberattacks on critical infrastructure (CI) pose serious risks to societal resilience, requiring a human-centred approach to crisis management. This study examines public responses to the Florida water plant hack by analysing social media discourse and its role in shaping cybersecurity strategies.
Design/methodology/approach
A qualitative case study approach applies the Kübler-Ross five stages of grief model to analyse Twitter posts from the first week following the attack. Abductive thematic analysis identifies patterns in public sentiment, emphasizing the role of social media as a real-time feedback mechanism. Lean principles are integrated to highlight stakeholder-driven cybersecurity improvements.
Findings
Public responses followed a structured emotional progression, from denial and humour to anger, bargaining, depression and acceptance. Social media discourse revealed concerns over systemic vulnerabilities, accountability demands and calls for cybersecurity reform. These insights emphasize the importance of transparent crisis communication, proactive risk management and public engagement in strengthening cybersecurity resilience.
Practical implications
Findings offer actionable insights for the public, media, private sector and government agencies into crisis response planning, fostering trust and resilience in digital infrastructure security by integrating public feedback into cybersecurity planning through structured social media analysis and iterative learning practices.
Originality/value
This study uniquely applies the Kübler-Ross model to cybersecurity crises, offering a novel framework for understanding public reactions. It highlights the role of social media in bridging communication between policymakers and end users and demonstrates how lean thinking can enhance adaptive cybersecurity strategies in CI management.
ER  - 

TY  - JOUR
T1  - Silent emissions: The cyber-infrastructure environmental impacts of autonomous vehicles
AU  - Hardaway, Kendrick
AU  - Teran, Oscar
AU  - Cai, Hua
JO  - Applied Energy
VL  - 392
SP  - 125949
PY  - 2025
DA  - 2025/08/15/
SN  - 0306-2619
DO  - https://doi.org/10.1016/j.apenergy.2025.125949
UR  - https://www.sciencedirect.com/science/article/pii/S0306261925006798
KW  - Autonomous vehicles
KW  - Energy use
KW  - Data management
KW  - Cyber infrastructure
KW  - Environmental assessment
KW  - Digital economy
AB  - In the consideration of how autonomous vehicles (AVs) can contribute to or hinder in achieving environmental goals, there is a critical aspect that must be included: AV data management. This aspect, encompassing both in-vehicle and cyber infrastructure energy requirements, has been neglected in many AV environmental impact studies. To address this gap, we calculated the energy requirements and greenhouse gas emissions associated with AV data management, including previously neglected cyber infrastructure components such as data storage and security. With a mathematical model, we tested various scenarios within a United States-based AV fleet, consisting of 15 key variables like computational efficiency, vehicle models (e.g., Waymo, Tesla), sensor capabilities, data transfer, storage, and cybersecurity. Our findings reveal that neglecting to include cyber infrastructure components underestimates the environmental impact of AV data management by at least 20 %. In the context of increased adoption, a 40 % market penetration of fully autonomous vehicles in the United States could demand up to 6278 GWh/year for data management alone (about 4.3 % of current US solar capacity for reference), highlighting the potential for AV adoption to intensify energy needs amidst the renewable energy transition. Thus, our results emphasize the significance of including the essential cyber infrastructure for AV data management in environmental assessments.
ER  - 

TY  - JOUR
T1  - Zilean: A modularized framework for large-scale temporal concept drift type classification
AU  - Deng, Zhao
AU  - Feng, QuanXi
AU  - Lin, Bin
AU  - Yen, Gary G.
JO  - Information Sciences
VL  - 712
SP  - 122134
PY  - 2025
DA  - 2025/09/01/
SN  - 0020-0255
DO  - https://doi.org/10.1016/j.ins.2025.122134
UR  - https://www.sciencedirect.com/science/article/pii/S002002552500266X
KW  - Time series
KW  - Concept drift classification
KW  - Large language model
AB  - In the analysis of time series data, particularly in real-world applications, concept drift classification is crucial for enabling models to adapt in a differentiated manner to future data. To address the challenge of identifying diverse types of drift, we propose Zilean, a novel framework that integrates feature-based and predictor-based techniques while accounting for drift residues and fragmentation during repeated drift detection. The framework incorporates the pre-trained BERT-Base language model into its classifier design, leveraging deep learning for automatic drift classification and eliminating the need for judgment curve analysis. To evaluate its performance, experiments were conducted on a variety of real-world and synthetic datasets, each exhibiting different types of concept drift. The results show that on real-world datasets, our framework achieves a classification accuracy of 91.03%, outperforming XGBoost by 7.94% and surpassing TCN-CNN by 4.28%. Additionally, experiments exploring a frozen parameter strategy and the use of a more lightweight language model, DistilBERT, further enhance accuracy to 96.93% and 97.17%, respectively. These findings underscore the framework's effectiveness in large-scale temporal concept drift classification.
ER  - 

TY  - JOUR
T1  - DualAttlog: Context aware dual attention networks for log-based anomaly detection
AU  - Yang, Haitian
AU  - Sun, Degang
AU  - Huang, Weiqing
JO  - Neural Networks
VL  - 180
SP  - 106680
PY  - 2024
DA  - 2024/12/01/
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2024.106680
UR  - https://www.sciencedirect.com/science/article/pii/S089360802400604X
KW  - Log analysis
KW  - Anomaly detection
KW  - Word level semantic
KW  - Sequence level semantic
KW  - Self-matching attention
KW  - Context aware dual attention
AB  - Most existing log-driven anomaly detection methods assume that logs are static and unchanged, which is often impractical. To address this, we propose a log anomaly detection model called DualAttlog. This model includes word-level and sequence-level semantic encoding modules, as well as a context-aware dual attention module. Specifically, The word-level semantic encoding module utilizes a self-matching attention mechanism to explore the interactive properties between words in log sequences. By performing word embedding and semantic encoding, it captures the associations and evolution processes between words, extracting local-level semantic information. while The sequence-level semantic encoding module encoding the entire log sequence using a pre-trained model. This extracts global semantic information, capturing overall patterns and trends in the logs. The context-aware dual attention module integrates these two levels of encoding, utilizing contextual information to reduce redundancy and enhance detection accuracy. Experimental results show that the DualAttlog model achieves an F1-Score of over 95% on 7 public datasets. Impressively, it achieves an F1-Score of 82.35% on the Real-Industrial W dataset and 83.54% on the Real-Industrial Q dataset. It outperforms existing baseline techniques on 9 datasets, demonstrating its significant advantages.
ER  - 

TY  - JOUR
T1  - Guiding cybersecurity compliance: An ontology for the NIS 2 directive
AU  - Castiglione, Gianpietro
AU  - Santamaria, Daniele Francesco
AU  - Bella, Giampaolo
AU  - Brisindi, Laura
AU  - Puccia, Gaetano
JO  - Computers & Security
VL  - 157
SP  - 104617
PY  - 2025
DA  - 2025/10/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104617
UR  - https://www.sciencedirect.com/science/article/pii/S0167404825003062
KW  - Semantic Web
KW  - Ontology
KW  - NIS 2
KW  - Compliance
KW  - Cybersecurity
AB  - Security compliance constitutes a significant source of concern for many corporate decision-makers due to its complexity and cost. These may be due, first and foremost, to the style of juridical language, which is often challenging to translate into concrete operational procedures. To facilitate such a translation and ultimately optimise the compliance effort, this article presents “NIS2Onto”, an Web Ontology Language (OWL) ontology designed to translate the Network and Information Security Directive version 2 (NIS 2) into an ontological format aimed to favour unambiguous understanding and security operations of cybersecurity professionals, legal experts, and all organisational stakeholders. Through the semantic representation of the NIS 2 entities, relationships, and security measures, NIS2Onto enables automated compliance verification, streamlined risk assessments, and effective policy implementation. Our evaluation employs both metrical and qualitative analysis through a real case study to witness the robustness and practical applicability of NIS2Onto. The ontology not only supports the accurate interpretation of complex legal texts but also aids in systematically enforcing cybersecurity measures. Furthermore, the extensibility of NIS2Onto allows for integration with other regulatory frameworks, thereby fostering a comprehensive and unified approach to cybersecurity governance.
ER  - 

TY  - JOUR
T1  - ChatGPT for digital forensic investigation: The good, the bad, and the unknown
AU  - Scanlon, Mark
AU  - Breitinger, Frank
AU  - Hargreaves, Christopher
AU  - Hilgert, Jan-Niclas
AU  - Sheppard, John
JO  - Forensic Science International: Digital Investigation
VL  - 46
SP  - 301609
PY  - 2023
DA  - 2023/10/01/
SN  - 2666-2817
DO  - https://doi.org/10.1016/j.fsidi.2023.301609
UR  - https://www.sciencedirect.com/science/article/pii/S266628172300121X
KW  - ChatGPT
KW  - Digital forensics
KW  - Artificial intelligence
KW  - Generative pre-trained transformers (GPT)
KW  - Large language models (LLM)
AB  - The disruptive application of ChatGPT (GPT-3.5, GPT-4) to a variety of domains has become a topic of much discussion in the scientific community and society at large. Large Language Models (LLMs), e.g., BERT, Bard, Generative Pre-trained Transformers (GPTs), LLaMA, etc., have the ability to take instructions, or prompts, from users and generate answers and solutions based on very large volumes of text-based training data. This paper assesses the impact and potential impact of ChatGPT on the field of digital forensics, specifically looking at its latest pre-trained LLM, GPT-4. A series of experiments are conducted to assess its capability across several digital forensic use cases including artefact understanding, evidence searching, code generation, anomaly detection, incident response, and education. Across these topics, its strengths and risks are outlined and a number of general conclusions are drawn. Overall this paper concludes that while there are some potential low-risk applications of ChatGPT within digital forensics, many are either unsuitable at present, since the evidence would need to be uploaded to the service, or they require sufficient knowledge of the topic being asked of the tool to identify incorrect assumptions, inaccuracies, and mistakes. However, to an appropriately knowledgeable user, it could act as a useful supporting tool in some circumstances.
ER  - 

TY  - JOUR
T1  - Security script arrangement based on enhanced BERT for cooperative defense in networked control systems
AU  - Wan, Ming
AU  - Liu, Xueqing
AU  - An, Shengbao
AU  - Tan, Aiping
AU  - Jin, Xi
AU  - Sheng, Chuan
JO  - Expert Systems with Applications
VL  - 298
SP  - 129753
PY  - 2026
DA  - 2026/03/01/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2025.129753
UR  - https://www.sciencedirect.com/science/article/pii/S0957417425033688
KW  - Security script
KW  - BERT
KW  - Cooperative defense
KW  - Industrial cyber threats
AB  - Due to the mutual collaboration and in-depth integration among multiple defense technologies through information sharing, the cooperative defense in networked control systems has emerged as a feasible solution to counter increasingly diversified cyber threats under the unique security characteristics and requirements of industrial environments. However, one of the chief challenges is how to automatically and intelligently develop effective cooperative working strategies when an attack occurs. Leveraging the advantages of large-scale AI (Artificial Intelligence) models, this paper defines a new concept named “security script”, and proposes a security script arrangement approach based on enhanced BERT to achieve fine-grained cooperative defense in networked control systems. Furthermore, this approach introduces intrusion detection and industrial firewall as two practical examples, and can automatically arrange effective security scripts to enable the dynamic interaction of two defense technologies. Additionally, to improve efficiency, the encoder structure adjusting and AdamW optimizing are further presented to enhance the traditional BERT. Experimental results clearly demonstrate that: for one thing, these two optimization ways can make greater achievements in reducing unnecessary time consumption and enhancing accuracy of security script arrangement; for another, compared with other typical BERT and large-scale AI models, the proposed approach can exhibit more favorable performance advantages in achieving cooperative defense based on security script arrangement. In particular, through its successful application and verification in one real-world manufacturing control system, our approach may bring a potential opportunity or direction for further research and improvement of AI-based cooperative defense.
ER  - 

TY  - JOUR
T1  - ATHITD: Attention-based temporal heterogeneous graph neural network for insider threat detection
AU  - Qi, Yinhao
AU  - Yan, Chuyi
AU  - Wang, Zehui
AU  - Zhang, Chen
AU  - Liu, Song
AU  - Lu, Zhigang
AU  - Jiang, Bo
JO  - Computers & Security
VL  - 157
SP  - 104587
PY  - 2025
DA  - 2025/10/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104587
UR  - https://www.sciencedirect.com/science/article/pii/S0167404825002767
KW  - Insider threat detection
KW  - Temporal heterogeneous graph
KW  - Graph neural network
KW  - Attention neural network
AB  - Insider threats can lead to data leakage and system crashes within an organization, seriously compromising the security of information systems. Most existing detection methods focus on analyzing user behavior sequences or constructing user relationship networks based on behavior feature similarities between users to uncover malicious insiders. However, these methods ignore the association between users and entities (e.g., files, processes, PCs, websites, and removable devices) and the evolution of user behavior patterns over time. This paper proposes an attention-based temporal heterogeneous graph neural network for insider threat detection (ATHITD) to address these issues. Firstly, ATHITD constructs sequences of temporal heterogeneous graphs from various logs based on the specified time window to depict the evolving and complex relationships between users and entities. Secondly, it introduces temporal neighbors for target nodes within each time window to describe short-term temporal dependencies. Temporal neighbors are nodes identical to the target nodes and appeared in the previous time windows. It then employs the attention mechanism to learn the spatial heterogeneity of target nodes and the short-term feature evolution from temporal neighbors to target nodes. Additionally, it uses the self-attention mechanism in Transformer to learn the long-term feature evolution of user nodes across various time windows. Furthermore, ATHITD can focus on the time windows in which malicious activities occur, helping security personnel analyze potential malicious activities in the highlighted time windows. Extensive experiments on the public datasets CERT and LANL demonstrate that the long and short-term spatio-temporal node embeddings learned by ATHITD can be effectively used to identify malicious insiders. ATHITD achieves F1 scores of 0.96 and 0.97 on the CERT and LANL datasets, respectively, outperforming existing state-of-the-art methods.
ER  - 

TY  - JOUR
T1  - Foundation models and Transformers for anomaly detection: A survey
AU  - Ammar, Mouin Ben
AU  - Mendoza, Arturo
AU  - Belkhir, Nacim
AU  - Manzanera, Antoine
AU  - Franchi, Gianni
JO  - Information Fusion
VL  - 126
SP  - 103517
PY  - 2026
DA  - 2026/02/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2025.103517
UR  - https://www.sciencedirect.com/science/article/pii/S1566253525005895
KW  - Anomaly detection
KW  - Transformers
KW  - Foundation models
KW  - Deep learning
KW  - Computer vision
KW  - Unsupervised learning
KW  - Self-supervised learning
KW  - Survey
AB  - In line with the development of deep learning, this survey examines the transformative role of Transformers and foundation models in advancing visual anomaly detection (VAD). We explore how these architectures, with their global receptive fields and adaptability, address challenges such as long-range dependency modeling, contextual modeling and data scarcity. The survey categorizes VAD methods into reconstruction-based, feature-based and zero/few-shot approaches, highlighting the paradigm shift brought about by foundation models. By integrating attention mechanisms and leveraging large-scale pre-training, Transformers and foundation models enable more robust, interpretable, and scalable anomaly detection solutions. This work provides a comprehensive review of state-of-the-art techniques, their strengths, limitations, and emerging trends in leveraging these architectures for VAD.
ER  - 

TY  - JOUR
T1  - Automated vulnerability score prediction through lightweight generative AI
AU  - Mirtaheri, Seyedeh Leili
AU  - Pugliese, Andrea
AU  - Pascucci, Valerio
JO  - Knowledge-Based Systems
VL  - 329
SP  - 114406
PY  - 2025
DA  - 2025/11/04/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2025.114406
UR  - https://www.sciencedirect.com/science/article/pii/S0950705125014455
KW  - Generative AI
KW  - Vulnerability scoring
KW  - LLM
KW  - BERT
KW  - Transformer
AB  - Given the constantly increasing number of newly published vulnerabilities, manually assessing their scores (e.g., under the Common Vulnerability Scoring System) has become unfeasible. Recently, learning-based systems have been proposed to automatically predict vulnerability scores. Such systems use vulnerability indexing databases to train deep learning algorithms. However, their practical applicability has important limitations, including a high dependency on the quality and diversity of training data, and high computational requirements. In addition, vulnerability descriptions often do not follow the standard templates and are not rich enough with respect to the expected features. In this paper, we propose a novel architecture that takes advantage of both generative artificial intelligence and lightweight deep learning techniques to provide an efficient and effective solution for automated vulnerability scoring. Data extracted from the National Vulnerability Dataset is fed into a large language model layer, whose output (i.e., an augmented dataset) is then used in a lightweight fine-tuned BERTsmall layer. We provide the results of an extensive experimental assessment of the effect of both each layer of the architecture and end-to-end performances. The results suggest that the combination of GPT3.5-Turbo and BERTsmall provides the most effective accuracy-time trade-off. We also compare the performance of the proposed architecture with other LLMs, BERT models, and cutting-edge approaches. The results show good improvements in prediction quality also when compared to a recent technique that incorporates data from 66 different sources, including the NVD.
ER  - 

TY  - JOUR
T1  - De-identification of open-source intelligence using finetuned LLaMA-3
AU  - Sun, Chin-Yu
AU  - Chen, Sheng-Shan
AU  - Ho, Ya-Han
JO  - High-Confidence Computing
SP  - 100357
PY  - 2025
DA  - 2025/10/13/
SN  - 2667-2952
DO  - https://doi.org/10.1016/j.hcc.2025.100357
UR  - https://www.sciencedirect.com/science/article/pii/S2667295225000613
KW  - CTI
KW  - BERT
KW  - Generative AI
KW  - De-identification
KW  - OSINT
AB  - Open-source intelligence is extensively utilized by enterprises and organizations to build intelligence networks for mitigating cyber threats. However, industries such as healthcare and finance often handle highly sensitive personal information, posing significant challenges for privacy-preserving intelligence sharing. A commonly adopted privacy protection approach is data de-identification, which involves various de-identification techniques; however, cross-referencing datasets can still result in the re-identification of original information. To address this challenge, this study proposes a novel framework leveraging LLaMA-3, an open-source generative model, fine-tuned using Low-Rank Adaptation (LoRA) for threat intelligence de-identification. This approach facilitates secure data sharing while preserving privacy. Furthermore, 8,435 real-world threat intelligence records were collected from a threat intelligence platform and categorized across multiple industries. To evaluate the effectiveness of the proposed de-identification technique, a classification model was trained and tested for industry classification. The results indicate that the industry classification model achieved an F1 score of 99% on the original dataset and 86% on the de-identified dataset. In contrast, a baseline method based on categorical replacement technology, which employs a Named Entity Recognition (NER) model to detect entities within the text and substitutes them directly with predefined categorical labels, achieved only a 75% F1 score. These findings highlight the superiority of the fine-tuned generative model, which generates context-aware and semantically coherent substitutions that more effectively preserve both the linguistic and analytical integrity of threat intelligence compared to categorical replacement. This capability enhances privacy-preserving intelligence sharing while maintaining the analytical utility and industry-specific relevance of the data.
ER  - 

TY  - JOUR
T1  - MambaAD: Multivariate time series anomaly detection in IoT via multi-view Mamba
AU  - Qin, Shuxin
AU  - Zhu, Jing
AU  - Guo, Aipeng
AU  - Yang, Yansong
AU  - Wang, Lu
AU  - Tao, Gaofeng
JO  - Neurocomputing
VL  - 655
SP  - 131385
PY  - 2025
DA  - 2025/11/28/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2025.131385
UR  - https://www.sciencedirect.com/science/article/pii/S0925231225020570
KW  - Anomaly detection
KW  - Mamba
KW  - Contrastive learning
KW  - Multivariate time series
AB  - Multivariate time series anomaly detection (MTSAD) in Internet of Things (IoT) systems is a crucial area of research that aims to increase cybersecurity, prevent disruptions and improve quality of service. To cope with the growing complexity of sensory data, recent approaches emphasize learning the temporal dynamics of each signal with Transformers and capturing correlations between signals with graph learning. However, these methods still struggle with two major challenges. First, the deep models using Transformer architecture and graph structure are computationally inefficient due to their quadratic complexity, which limits their scalability and applicability. Second, it is difficult to learn the generalized latent patterns from the limited but highly sensitive training data, which makes the models prone to overfitting. To address these challenges, we propose MambaAD, an efficient anomaly detection framework based on the linear-time state space model. Specifically, we segment and tokenize the time series to retain local semantic information in the embeddings. Then, we develop a bidirectional Mamba module to extract temporal dependencies and inter-signal correlations from different perspectives. Finally, the captured features are fused and projected for reconstruction and scoring. We also provide a multi-view token masking strategy and a contrastive learning mechanism to elevate both representation quality and generalization performance. Thorough experimentation with six real-world datasets across different fields indicates that the proposed method surpasses current state-of-the-art benchmarks in terms of both efficiency and accuracy.
ER  - 

TY  - JOUR
T1  - Joint relational triple extraction with enhanced representation and binary tagging framework in cybersecurity
AU  - Wang, Xiaodi
AU  - Liu, Zhonglin
AU  - Liu, Jiayong
JO  - Computers & Security
VL  - 144
SP  - 104001
PY  - 2024
DA  - 2024/09/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104001
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824003067
KW  - Cybersecurity
KW  - Open-source intelligence
KW  - Relation extraction
KW  - Joint extraction
KW  - Knowledge graph
AB  - The cyber threat intelligence (CTI) knowledge graph is a valuable tool for aiding security practitioners in the identification and analysis of cyberattacks. These graphs are constructed from CTI data, organized into relational triples, where each triple comprises two entities linked by a particular relation. However, as the volume of CTI data is expanding at a faster rate than predicted, existing technologies are unable to extract relational triples quickly and accurately. This work mainly focuses on the extraction of relational triples in CTI data, which is achieved by an enhanced representation and binary tagging framework (ERBTF). Firstly, we introduce embedding representations for relations and concatenate these with word embeddings to obtain the initial hidden representation. Subsequently, we employ a novel dilated convolutional encoder that consists of a dilated convolution neural network, gate mechanism and residual connection to enhance the learned contextual representation. Afterwards, we adopt an attention module that includes multi-head self-attention and position-wise feed-forward neural network to allocate greater attention to words that significantly influence the specific relation. Additionally, we utilize the straightforward yet efficient binary entity tagger to identify subject and object entities under different relations for constructing relational triples. We conduct massive experiments on relational triple extraction from CTI data, the results show that ERBTF is superior to the existing relation extraction models, and achieves state-of-the-art performance.
ER  - 

TY  - JOUR
T1  - A comparative analysis on using GPT and BERT for automated vulnerability scoring
AU  - Mirtaheri, Seyedeh Leili
AU  - Pugliese, Andrea
AU  - Movahed, Narges
AU  - Shahbazian, Reza
JO  - Intelligent Systems with Applications
VL  - 26
SP  - 200515
PY  - 2025
DA  - 2025/06/01/
SN  - 2667-3053
DO  - https://doi.org/10.1016/j.iswa.2025.200515
UR  - https://www.sciencedirect.com/science/article/pii/S2667305325000419
KW  - Vulnerability scoring
KW  - Large language model (LLM)
KW  - Transformers
KW  - Machine learning
AB  - Large language models and transformers such as GPT and BERT have shown great improvements in many domains including cybersecurity. A constantly increasing number of vulnerabilities necessitate automated vulnerability scoring systems. Therefore, a deeper understanding of GPT and BERT compatibility with the requirements of the cybersecurity domain seems inevitable for system designers. The BERT model’s family is known to be optimized in understanding the contextual relationships with a bidirectional approach, while the GPT models perform unidirectional processing with generative capabilities. Automated vulnerability scoring systems require both the features to analyze the vulnerability and to augment the vulnerability descriptions. On the other hand, powerful GPT models are often more “resource-intensive in comparison with the BERT family. This paper presents a comprehensive comparison analysis of GPT and BERT in terms of their text classification performance, utilizing the vulnerability description classification task. We outline a thorough theoretical and experimental comparison of the models, regarding their architectures, training objectives, and fine-tuning, as well as their text classification performance. We evaluate these models on the vulnerability description classification task and employ rigorous evaluation metrics to shed light on their relative strengths and shortcomings. We also evaluate the hybrid architectures that benefit from combining GPT and BERT at the same time. Our experiment results show that they can effectively leverage the complementary strengths of both GPT and BERT, namely generative and comprehension, leading to further improvements in classification performance.
ER  - 

TY  - JOUR
T1  - LLM4Game: Multi-agent reinforcement learning with knowledge injection for dynamic defense resource allocation in cloud storage
AU  - Peng, Yixiao
AU  - Hu, Hao
AU  - Li, Feiyang
AU  - Jiang, Yingchang
AU  - Tang, Jipeng
AU  - Liu, Yuling
JO  - Computer Networks
VL  - 273
SP  - 111748
PY  - 2025
DA  - 2025/12/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2025.111748
UR  - https://www.sciencedirect.com/science/article/pii/S1389128625007145
KW  - Cloud storage attack-defense
KW  - Defense resource allocation
KW  - Colonel Blotto game
KW  - Multi-agent RL
KW  - LLM-based knowledge injection
AB  - The non-cooperative and interdependent nature of network attack-defense links it closely to game theory. Current game-theoretic decision-making methods construct game models for attack-defense scenarios and use reinforcement learning (RL) to compute optimal strategies. However, RL relies on the “trial and error” exploration and is likely to fall into the local optimum in some cloud storage environment without game equilibrium. First, in cloud storage systems, the resource investment of attack and defense players has a “winner-takes-all” characteristic. Thus, we employ the Colonel Blotto game to model the attack-defense scenario in cloud storage systems, extending it to a multi-player, heterogeneous battlefield model with asymmetric resources. Second, RL’s reliance on trial-and-error exploration leads to suboptimal convergence in sparse-reward, non-equilibrium conditions. We leverage Large Language Models (LLMs) to inject attack-defense context knowledge, addressing the cold start problem of RL. Finally, we propose the RL-LLM-KI algorithm featuring a precomputation-retrieval mechanism that mitigates the inference speed discrepancy between LLMs and RL agents, enabling real-time defense decisions. Experiments show that our work increases utility by 140 % and 136.36 % compared to MADRL and DRS-DQN respectively in typical experimental scenarios. To our best knowledge, this study is the first to reveal the significant effect of knowledge injection in enhancing decision-making efficacy in highly adversarial cloud storage attack-defense scenarios.
ER  - 

TY  - JOUR
T1  - A novel framework for phishing attack detection using domain-adapted GloVe embeddings and attention-enhanced neural sequence model
AU  - Sruthi, K.
AU  - Manohar Naik, S.
JO  - Applied Soft Computing
VL  - 188
SP  - 114441
PY  - 2026
DA  - 2026/02/01/
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2025.114441
UR  - https://www.sciencedirect.com/science/article/pii/S1568494625017545
KW  - Cyber security
KW  - Deep learning
KW  - Phishing attack
KW  - GloVe Embeddings
KW  - Attention-Based BiLSTM
AB  - Phishing attacks have evolved into sophisticated cyber threats, causing catastrophic financial and reputational damage. Malicious URLs, often disguised as legitimate ones, are the primary vectors for these attacks. Current phishing detection systems suffer from two fundamental limitations: reliance on handcrafted features limits adaptability to evolving phishing techniques, while deep learning approaches exhibit inadequate semantic understanding of URL structures and produce sparse feature representations that degrade detection performance. This paper presents a novel phishing URL detection framework that integrates domain-adapted Global Vectors (GloVe) embeddings with attention-enhanced bidirectional sequence modeling. The framework contributes two key innovations: a cybersecurity-specific GloVe embedding model trained on specialized URL corpora to address sparse feature representations in malicious URL detection, and an attention-enhanced bidirectional LSTM architecture that dynamically identifies discriminative sequential patterns in URL structures. Comprehensive evaluation demonstrates superior performance, achieving 99.82 % accuracy and 99.84 % F1-score, significantly outperforming state-of-the-art methods. The K-fold cross-validation further demonstrates the consistent performance of the proposed model. This research establishes a new performance benchmark in automated phishing detection and advances natural language processing applications in cybersecurity.
ER  - 

TY  - JOUR
T1  - Innovative AI strategies for enhancing smart building operations through digital twins: A survey
AU  - Oulefki, Adel
AU  - Kheddar, Hamza
AU  - Amira, Abbes
AU  - Kurugollu, Fatih
AU  - Himeur, Yassine
AU  - Bounceur, Ahcene
JO  - Energy and Buildings
VL  - 335
SP  - 115567
PY  - 2025
DA  - 2025/05/15/
SN  - 0378-7788
DO  - https://doi.org/10.1016/j.enbuild.2025.115567
UR  - https://www.sciencedirect.com/science/article/pii/S037877882500297X
KW  - AI
KW  - Digital twin
KW  - Deep learning
KW  - Smart building
KW  - Transfer learning
KW  - Federated learning
KW  - Reinforcement learning
AB  - The Digital Twins (DT) have emerged as a digital transformation automation process with ubiquitous applications that span various domains, including buildings, manufacturing, and healthcare. These virtual clones of physical systems provide relevant insights, enhance decision-making processes, and optimize operations, along with allowing the prediction of future operations. Artificial intelligence (AI) has been instrumental in enhancing the functionalities of DT. This survey paper explores recent developments in advanced AI algorithms tailored for DT in building settings. Moreover, a wide spectrum of AI techniques designed to address the challenges posed by DT in buildings are categorized and reviewed, including convolution neural networks (CNN), recurrent neural networks (RNNs), and generative adversarial networks (GANs), among other cutting edge transformative technologies. Furthermore, the integration of reinforcement learning (RL) and transfer learning (TL) into the DT ecosystem is discussed. This survey explores practical use cases, such as predictive scenarios, anomaly detection, and optimization of DT models. The incorporation of multimodal AI sensor data and edge computing in enhancing the accuracy and efficiency of DT is analyzed. Additionally, challenges and future directions in the field are explored, including data privacy concerns using Blockchain (BC), scalability issues, and the potential impact of quantum computing (QC) and large language models (LLMs) on DT technology. This comprehensive survey serves as a valuable resource for researchers, practitioners, and decision makers looking to utilize cutting-edge techniques to harness the full potential of DT technology in smart buildings (SB).
ER  - 

TY  - JOUR
T1  - Generative AI for transportation safety and resilience: a comprehensive review from a lifecycle perspective
AU  - Liu, Jingling
AU  - Yu, Weiping
AU  - Yang, Mingming
AU  - Liu, Fan
JO  - Safety Science
VL  - 196
SP  - 107090
PY  - 2026
DA  - 2026/04/01/
SN  - 0925-7535
DO  - https://doi.org/10.1016/j.ssci.2025.107090
UR  - https://www.sciencedirect.com/science/article/pii/S0925753525003157
KW  - Generative AI
KW  - Transportation safety
KW  - Resilience
KW  - Lifecycle
AB  - Transportation systems face increasingly complex disruptions that challenge traditional safety and resilience frameworks reliant on historical stationarity. Generative Artificial Intelligence (GAI)—including generative adversarial networks, diffusion models, and large language models—offers novel capabilities for rare-event simulation, multimodal data augmentation, and proactive scenario generation. This paper conducts a systematic review of 170 peer-reviewed studies published between 2019 and 2025, integrating fragmented findings into a lifecycle perspective spanning accident prevention, accident prediction, accident response and recovery. Our analysis demonstrates that GAI enables significant advances in accident prevention through enhanced traffic flow and behavior prediction, improves accident forecasting via anomaly and collision detection, and supports real-time emergency response and post-disruption recovery through multimodal reasoning and decision support. We also identify critical challenges in interpretability, data quality, domain adaptation, and ethical governance, which constrain GAI’s safe deployment in transportation systems. Building on these insights, we outline future research directions emphasizing human–AI collaboration, bias mitigation, multimodal integration, and governance mechanisms for trustworthy and resilient applications. This review contributes to the operations and transportation management literature by providing comprehensive, lifecycle-oriented synthesis of GAI in transportation safety and resilience, and by highlighting pathways for aligning advanced AI technologies with the design of next-generation resilient infrastructure systems.
ER  - 

TY  - JOUR
T1  - DeepfakeCLIP: Semantic-Opposite prompt learning for generalizable deepfake detection
AU  - Chen, Xueying
AU  - Huang, Tianqiang
AU  - Liu, Wenyu
AU  - Wang, Zhenghong
AU  - Li, Wentong
AU  - Huang, Wei
AU  - Chen, Riqing
AU  - Luo, Haifeng
JO  - Knowledge-Based Systems
VL  - 330
SP  - 114681
PY  - 2025
DA  - 2025/11/25/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2025.114681
UR  - https://www.sciencedirect.com/science/article/pii/S0950705125017204
KW  - Deepfake detection
KW  - Prompt learning
KW  - Multi-modal learning
KW  - Contrastive learning
KW  - Vision-Language models
AB  - The proliferation of Generative Adversarial Networks and Diffusion Models has led to the widespread synthesis of hyper-realistic images, necessitating the development of robust deepfake detection mechanisms. This paper proposes DeepfakeCLIP, a novel framework employing the vision-language capabilities of the CLIP model to distinguish between real and deepfake images. Unlike previous methods that focus solely on image features, DeepfakeCLIP employs semantically opposite text prompts to represent the core characteristics of real and deepfake images, without dependence on particular object categories. By incorporating global and local context optimization, the model is effectively generalized to diverse synthetic images. Furthermore, a refinement module is introduced to fine-tune the textual space, improving text-image alignment. Extensive experiments across multiple datasets, including those generated by Generative Adversarial Networks and Diffusion Models, demonstrate that DeepfakeCLIP achieves competitive performance in deepfake detection, delivering significant improvements in both accuracy and average precision. The code will be publicly available.
ER  - 

TY  - JOUR
T1  - Blockchain-Enabled Mitigation Strategies for Distributed Denial of Service Attacks in IoT Sensor Networks: An Experimental Approach
AU  - Arachchige, Kithmini Godewatte
AU  - Murtaza, Mohsin
AU  - Cheng, Chi-Tsun
AU  - Albahlal, Bader M.
AU  - Lee, Cheng-Chi
JO  - Computers, Materials and Continua
VL  - 81
IS  - 3
SP  - 3679
EP  - 3705
PY  - 2024
DA  - 2024/12/19/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2024.059378
UR  - https://www.sciencedirect.com/science/article/pii/S1546221824008762
KW  - Blockchain
KW  - cyber intrusions
KW  - DDoS
KW  - IoT
KW  - low powered
KW  - sensors
KW  - vulnerabilities
KW  - wireless network
AB  - Information security has emerged as a crucial consideration over the past decade due to escalating cyber security threats, with Internet of Things (IoT) security gaining particular attention due to its role in data communication across various industries. However, IoT devices, typically low-powered, are susceptible to cyber threats. Conversely, blockchain has emerged as a robust solution to secure these devices due to its decentralised nature. Nevertheless, the fusion of blockchain and IoT technologies is challenging due to performance bottlenecks, network scalability limitations, and blockchain-specific security vulnerabilities. Blockchain, on the other hand, is a recently emerged information security solution that has great potential to secure low-powered IoT devices. This study aims to identify blockchain-specific vulnerabilities through changes in network behaviour, addressing a significant research gap and aiming to mitigate future cybersecurity threats. Integrating blockchain and IoT technologies presents challenges, including performance bottlenecks, network scalability issues, and unique security vulnerabilities. This paper analyses potential security weaknesses in blockchain and their impact on network operations. We developed a real IoT test system utilising three prevalent blockchain applications to conduct experiments. The results indicate that Distributed Denial of Service (DDoS) attacks on low-powered, blockchain-enabled IoT sensor networks cause measurable anomalies in network and device performance, specifically: (1) an average increase in CPU core usage to 34.32%, (2) a reduction in hash rates by up to 66%, (3) an increase in batch timeout by up to 14.28%, and (4) an increase in block latency by up to 11.1%. These findings suggest potential strategies to counter future DDoS attacks on IoT networks.
ER  - 

TY  - JOUR
T1  - When explainability turns into a threat - using xAI to fool a fake news detection method
AU  - Kozik, Rafał
AU  - Ficco, Massimo
AU  - Pawlicka, Aleksandra
AU  - Pawlicki, Marek
AU  - Palmieri, Francesco
AU  - Choraś, Michał
JO  - Computers & Security
VL  - 137
SP  - 103599
PY  - 2024
DA  - 2024/02/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2023.103599
UR  - https://www.sciencedirect.com/science/article/pii/S0167404823005096
KW  - Explainable AI
KW  - Adversarial attacks
KW  - NLP
KW  - Fake news
KW  - BERT
AB  - The inclusion of Explainability of Artificial Intelligence (xAI) has become a mandatory requirement for designing and implementing reliable, interpretable and ethical AI solutions in numerous domains. xAI is now the subject of extensive research, from both the technical and social science perspectives. It is being received enthusiastically by legislative bodies and regular users of machine-learning-boosted applications alike. However, opening the black box of AI comes at a cost. This paper presents the results of the first study proving that xAI can enable successful adversarial attacks in the domain of fake news detection and lead to a decrease in AI security. We postulate the novel concept that xAI and security should strike a balance, especially in critical applications, such as fake news detection. An attack scheme against fake news detection methods is presented that employs an explainable solution. The described experiment demonstrates that the well-established SHAP explainer can be used to reshape the structure of the original message in such a way that the value of the model's prediction could be arbitrarily forced, whilst the meaning of the message stays the same. The paper presents various examples for which the SHAP values are used to point the adversary to the words and phrases that have to be changed to flip the label on the model prediction. To the best of the authors' knowledge, it has been the first research work to experimentally demonstrate the sinister side of xAI. As the generation and spreading of fake news has become a tool of modern warfare and a grave threat to democracy, the potential impact of explainable AI should be addressed as soon as possible.
ER  - 

TY  - JOUR
T1  - Explainable artificial intelligence models in intrusion detection systems
AU  - AL, Samed
AU  - Sagiroglu, Seref
JO  - Engineering Applications of Artificial Intelligence
VL  - 144
SP  - 110145
PY  - 2025
DA  - 2025/03/15/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2025.110145
UR  - https://www.sciencedirect.com/science/article/pii/S0952197625001459
KW  - Explainable artificial intelligence
KW  - Interpretable artificial intelligence
KW  - Intrusion detection System
KW  - Local interpretable model-agnostic explanations
KW  - Shapley additive explanations
AB  - This study introduces the growing necessity of Explainable Artificial Intelligence (XAI) in the context of cybersecurity, particularly in Intrusion Detection Systems (IDSs). As Artificial Intelligence (AI) technologies, especially complex neural networks, become more prevalent and difficult to understand, the opacity of these models poses increasing risks in critical firald like cybersecurity. XAI aims to address these concerns by making AI models and their outputs more interpretable and transparent, thus fostering trust and secure use. Despite the rising interest and application of XAI in various domains, its integration into IDSs remains insufficient. This research provides a comprehensive overview of XAI, examining its definitions, terminologies, and the evolution of the field. It delves into the opportunities, challenges, and research needs within XAI, as well as the latest developments, tools, and technologies for implementing XAI in AI-based IDSs, alongside associated risks. The study also summarizes and demonstrates a gap in the literature regarding comprehensive reviews of IDS solutions that incorporate XAI, aiming to fill this gap by detailing the application of XAI in IDS research. The findings are expected to guide researchers, experts, users, and policymakers in the domains of AI, XAI, and IDS.
ER  - 
