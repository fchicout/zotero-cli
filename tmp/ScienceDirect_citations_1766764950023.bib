@article{QIN2025104038,
title = {Directed grey box fuzzy testing for power terminal device firmware with intermediate representation similarity comparison},
journal = {Journal of Information Security and Applications},
volume = {90},
pages = {104038},
year = {2025},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2025.104038},
url = {https://www.sciencedirect.com/science/article/pii/S2214212625000766},
author = {Zhongyuan Qin and Jiaqi Chen and Xin Sun and Yubo Song and Hua Dai and Weiwei Chen and Bang Lv and Kanghui Wang},
keywords = {Directed grey box fuzzing(DGF), Intermediate representation(IR), Binary code similarity, Target scheduling mechanism, Feature extraction, Graph auto-encoder},
abstract = {The proliferation of heterogeneous devices in power IoT terminals significantly increases security risks due to firmware vulnerabilities, thereby threatening the stability and reliability of power systems. However, existing Directed Greybox Fuzzing (DGF) methods face challenges, such as the need for manual identification of vulnerable code and limitations to specific architectures. This paper proposes a DGF approach, guided by intermediate representation similarity comparison, comprising two main components: objective function localization and directed greybox fuzzing. In the objective function localization phase, support for multiple architectures is achieved by lifting the binary code to LLVM Intermediate Representation (IR). Given that functions may vary in both structure and semantics, we represent functions using both structural and semantic features. We employ word embedding techniques based on Natural Language Processing (NLP) and graph neural network models to construct feature vectors. By calculating the feature similarity between each function and known vulnerable functions, we automatically identify highly similar functions as targets. In the directed greybox fuzzing phase, to address issues like high false positive rates and unreachable targets, we designed a target scheduling mechanism. This mechanism permanently blocks targets that have been sufficiently covered and periodically blocks those that have not been covered, thereby further improving the efficiency of fuzzing. Experimental results on two datasets demonstrate the effectiveness of this method in identifying vulnerabilities in power terminal equipment.}
}
@article{JIANG2026114048,
title = {Robotics for HVAC applications: A critical review and future perspectives},
journal = {Building and Environment},
volume = {289},
pages = {114048},
year = {2026},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2025.114048},
url = {https://www.sciencedirect.com/science/article/pii/S0360132325015148},
author = {Yilin Jiang and Han Li and Payam Delgoshaei and Zhangding Liu and Tianzhen Hong},
keywords = {AI, Robotics, HVAC, Technology readiness level (TRL), Building automation system (BAS), Building information modeling (BIM)},
abstract = {Recent advances in artificial intelligence (AI), enhanced computational capabilities, and innovations in sensors and hardware have driven the increasing development and application of robots in heating, ventilation, and air conditioning (HVAC) systems. We selected and reviewed 101 studies published between 2005 and 2025, sourced from IEEE Xplore, Scopus, Web of Science, and the ACM Digital Library. To analyze these works, we developed a five-dimensional analytical framework (morphology, sensing, navigation, task execution, and system integration), inspired by the Springer Handbook of Robotics and tailored specifically for robotic applications in HVAC. Based on the reviewed studies, six distinct tasks spanning the entire HVAC lifecycle have been identified. Among the six tasks, inspection and maintenance dominate (59 %), followed by indoor monitoring and auditing (21 %), whereas leakage detection, comfort support, and installation/retrofit remain less explored. To address the identified gaps, this review proposes future research directions including investigating robot-aware HVAC design principles, developing multimodal HVAC sensing and data fusion techniques, enhancing robot training and hardware capabilities, and expanding robotic applications beyond Maintenance and Operations (M&O). The findings from this review inform future robotics research for HVAC applications and ultimately enhance system affordability, energy efficiency, resilience or reliability, and occupant environmental comfort. Moreover, it seeks to inspire researchers to explore the intersections of robotics, computer science, building science, and HVAC engineering fostering advancements in this multidisciplinary field.}
}
@article{HASSANI2024102136,
title = {A systematic review of data fusion techniques for optimized structural health monitoring},
journal = {Information Fusion},
volume = {103},
pages = {102136},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.102136},
url = {https://www.sciencedirect.com/science/article/pii/S1566253523004529},
author = {Sahar Hassani and Ulrike Dackermann and Mohsen Mousavi and Jianchun Li},
keywords = {Structural health monitoring, Raw data fusion, Feature fusion, Decision fusion, Deep learning, Machine learning},
abstract = {Advancements in structural health monitoring (SHM) techniques have spiked in the past few decades due to the rapid evolution of novel sensing and data transfer technologies. This development has facilitated the simultaneous recording of a wide range of data, which could contain abundant damage-related features. Concurrently, the age of omnipresent data started with massive amounts of SHM data collected from large-size heterogeneous sensor networks. The abundance of information from diverse sources needs to be aggregated to enable robust decision-making strategies. Data fusion is the process of integrating various data from heterogeneous sources to produce more useful, accurate, and reliable information about system behavior. This paper reviews recent developments in data fusion techniques applied to SHM systems. The theoretical concepts, applications, benefits, and limitations of current methods and challenges in SHM are presented, and future trends in data fusion methods are discussed. Furthermore, a set of criteria is proposed to evaluate contents and information from original and review papers in this field, and a road map is provided discussing possible future work.}
}
@article{TEJAY2023103751,
title = {Cultivating security culture for information security success: A mixed-methods study based on anthropological perspective},
journal = {Information & Management},
volume = {60},
number = {3},
pages = {103751},
year = {2023},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2022.103751},
url = {https://www.sciencedirect.com/science/article/pii/S0378720622001598},
author = {Gurvirender P.S. Tejay and Zareef A. Mohammed},
keywords = {Information security culture, Security success, Security awareness, Group cohesiveness, Empowerment, Professional codes, Mixed-methods approach},
abstract = {The continuous information security failures in organizations have led focus toward organizational culture. It is argued that the development of culture of information security would subsequently lead to a secure organization. However, limited studies have been conducted to understand information security culture. This study aims to understand information security culture and its impact on success with information security efforts in an organization. The research model is based on the theory of primary message systems, which is an established theory from the anthropology discipline. We followed a mixed-methods research design involving two phases of the study. In the first phase, 25 semi-structured interviews with experienced cybersecurity practitioners were conducted to develop the research model. The second phase empirically validated the research model using survey data from 473 participants who completed a web-based survey in Southeast USA from multiple companies. For data analysis, we employed Partial Least Squares - Structural Equation Modeling using SmartPLS. Our findings indicate that group cohesiveness, professional code, information security awareness, and informal work practices have significant influence on information security culture. Further, the security culture has positive impact on information security success perception. The contribution of this research lies in establishing the role of security culture and information security awareness in contributing toward information security success.}
}
@article{KIM2025109266,
title = {Self-driving laboratories with artificial intelligence: An overview of process systems engineering perspective},
journal = {Computers & Chemical Engineering},
volume = {203},
pages = {109266},
year = {2025},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2025.109266},
url = {https://www.sciencedirect.com/science/article/pii/S0098135425002698},
author = {Youhyun Kim and Hayoung Doo and Daeun Shin and Seo Yoon Lee and Yugyeong Roh and Seongeun Park and Heejin Song and Yujin Jung and Hyuk Jun Yoo and Sang Soo Han and Jong Woo Kim and Maximilian O. Besenhard and Ye Seol Lee and Jonggeol Na},
keywords = {Self-driving laboratory, Process systems engineering, Artificial intelligence, Optimization, Autonomous discovery, Process and product design},
abstract = {Self-driving laboratories (SDLs), also known as autonomous laboratories, have recently gained in popularity due to their rapid advances in hardware for solving real-world problems and connectivity with various artificial intelligence (AI) embedded software. SDLs with autonomy have the potential to accelerate the development in chemistry and materials science, which leads to solving design problems that are difficult for human intuition. The concept of SDLs is quite similar to that of process automation and AI-enabled autonomy in chemical engineering, which are current focused research topics in process systems engineering (PSE). However, SDLs have lacked discussion from this perspective, although they require the artistic integration of technologies such as optimization, process monitoring, product and process design, control, and machine learning, which are traditionally studied by the PSE discipline. Here, we discuss the importance of PSE in improving key SDL technologies. We first provide an overview of process integration with various types of hardware for SDLs that each experimental hardware component in the laboratory must be automated to enable autonomy. Most importantly, this review conducts a deep dive into how software can be applied to enhance and actualize SDLs, which is highly related to the implications and opportunities for PSE researchers studying SDL-specific operating systems, optimization algorithms for SDLs-generated chemicals and materials, and use of AI to achieve system-wide autonomy.}
}
@article{TU2024965,
title = {Architecture for data-centric and semantic-enhanced industrial metaverse: Bridging physical factories and virtual landscape},
journal = {Journal of Manufacturing Systems},
volume = {74},
pages = {965-979},
year = {2024},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2024.05.016},
url = {https://www.sciencedirect.com/science/article/pii/S0278612524001134},
author = {Xinyi Tu and Riku Ala-Laurinaho and Chao Yang and Juuso Autiosalo and Kari Tammi},
keywords = {Industrial metaverse, Virtual–physical continuum, Digital twins, Extended reality, Architecture, Industry 5.0},
abstract = {The metaverse paradigm has recently captured increasing scholarly and industrial attention, particularly within the scope of human-centric Industry 5.0. In this context, the metaverse promises a transformative confluence of the physical and digital realms, offering unparalleled avenues for human augmentation in industrial applications. Yet, while several conceptual metaverse architectures and illustrative case studies have emerged, they scarcely delve deep into the nuanced practice of cultivating the industrial metaverse for factory-scale applications. Addressing this research gap, this work introduces a novel architecture for a data-centric and semantic-enhanced industrial metaverse. The architecture intricately weaves the physical factory domain with the metaverse, fortified by a suite of ten modules, facilitating data flow and knowledge synchronization with the integration of digital twins and semantic models. The practical application and relevance of this architecture are further accentuated through a case study focused on in-plant material flow tracking. Emerging results underline that our architecture encapsulates the essential components for constructing a factory-scale industrial metaverse. Future research will be geared towards a comprehensive validation of the proposed metaverse architecture, culminating in tangible implementations across diverse industrial contexts.}
}
@article{FANG2020300981,
title = {SankeyVis: Visualizing active relationship from emails based on multiple dimensions and topic classification methods},
journal = {Forensic Science International: Digital Investigation},
volume = {35},
pages = {300981},
year = {2020},
issn = {2666-2817},
doi = {https://doi.org/10.1016/j.fsidi.2020.300981},
url = {https://www.sciencedirect.com/science/article/pii/S2666281720300469},
author = {Yong Fang and Cuirong Zhao and Cheng Huang and Liang Liu},
keywords = {Digital email forensics, Social relationship, Visualization, LDA Model, Semantic analysis, Sankey diagram},
abstract = {The explosive growth of email has led to the rapid development of e-mail-based forensics, and at the same time, it has brought enormous challenges. As a special kind of data, email consists of structured metadata and unstructured email Body. Most attention is paid to visualization forensics of metadata at present, which is more focused on the mining of social network relationships between senders and recipients. These methods limit the range of email visualization forensics. Visual forensics of semantic analysis of the email body is relatively rare and difficult to connect semantic analysis with visualization. In recent years, the booming development of machine learning has extended the focus of forensics to the email body. This paper proposed SankeyVis: a visualization model for email forensics of active relation based on multiple dimensions and LDA topic classification methods, focusing on mining social relationships and semantic patterns in emails. SankeyVis conducts forensic work from the four data attributes of the email, “From,” “To,” “Date,” and “Body,” and the data is divided into two parts, the email header and email body according to the structure. The email header is used to get address pair with the working relationship after selecting and for the email body. Then introduced the Latent Dirichlet Allocation model to classify the topic of the email body discussed and adopt the adaption Sankey diagram to conduct forensic work from the topic semantic. It is proved that tested well by adapting to the Enron corpus. SankeyVis integrates structured and unstructured data in the visualization of email forensics, achieving visual forensics of email content. It breaks the limitations of dimensions and supports adding more than four attributes for forensics, extending the breadth of email forensics. SankeyVis reveals the topics of email senders and recipients with active relationships discussed at different time units and supports for forensics of email content to varying levels of relationships, extending the depth of email forensics.}
}
@article{FRANZIL2025111890,
title = {Sharpening Kubernetes Audit Logs with Context Awareness},
journal = {Computer Networks},
pages = {111890},
year = {2025},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2025.111890},
url = {https://www.sciencedirect.com/science/article/pii/S1389128625008564},
author = {Matteo Franzil and Valentino Armani and Luis Augusto {Dias Knob} and Domenico Siracusa},
keywords = {Kubernetes, Audit logs, Log analysis, Machine Learning},
abstract = {Kubernetes (K8s) has emerged as the de facto orchestrator of microservices, providing scalability and extensibility to a highly dynamic environment. It builds an intricate and deeply connected system that requires extensive monitoring capabilities to be properly managed. To this account, K8s natively offers audit logs, a powerful feature for tracking Application Programming Interface (API) interactions in the cluster. Audit logs provide a detailed and chronological record of all activities in the system. Unfortunately, K8s auditing suffers from several practical limitations: it generates large volumes of data continuously, as all components within the cluster interact and respond to user actions. Moreover, each action can trigger a cascade of secondary events dispersed across the log, with little to no explicit linkage, making it difficult to reconstruct the context behind user-initiated operations. In this paper, we introduce K8NTEXT, a novel approach for streamlining K8s audit logs by reconstructing contexts, i.e., grouping actions performed by actors on the cluster with the subsequent events these actions cause. Correlated API calls are automatically identified, labeled, and consistently grouped using a combination of inference rules and a Machine Learning (ML) model, largely simplifying data consumption. We evaluate K8NTEXT’s performance, scalability, and expressiveness both in systematic tests and with a series of use cases. We show that it consistently provides accurate context reconstruction, even for complex operations involving 50, 100 or more correlated actions, achieving over 95% accuracy across the entire spectrum, from simple to highly composite actions.}
}
@article{SINGH2022878,
title = {Big Data as a Service and Application for Indian Banking Sector},
journal = {Procedia Computer Science},
volume = {215},
pages = {878-887},
year = {2022},
note = {4th International Conference on Innovative Data Communication Technology and Application},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.12.090},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922021615},
author = {Jaspreet Singh and Gurpreet Singh and Muskan Gahlawat and Chander Prabha},
keywords = {Role of Big Data in Banking, Big Data Risk Management in Banking, Bibliometric Analysis for Big Data in Banking, Banking Related Technology Elements of Big Data, Big Data Tool in Banking},
abstract = {The financial world, money markets, and the growth of an economy are all powered by banks. In India's financial sector, where cashless and paperless transactions are expanding quickly, bank fraud is also rising quickly, and fraudsters are now turning to cutting-edge techniques. Fighting financial crimes has always been a priority for the banking industry. Banks’ fraud losses will diminish when they are able use analytics and emerging technologies for better fraud prevention. Data has evolved into more than simply an IT resource; it is a vital feature of the banking industry's digital transformation in the present world. The majority of contemporary risk monitoring systems, which are based on data science discipline such as big data, allow for surveillance and offer Early Warning Signals (EWS) about any kind of worsening. The study of this paper signifies that how big data as a service and application proven as a strong and innovative instrument that assists Indian banking sector not only in identifying security issues and fraudulent behavior, but also in their early prevention. The experimental results of bibliometric study conducted on Scopus and Web of Science databases using in Vos Viewer software, clearly discovered big data technology is a crucial approach to deploy in Indian banking system. Findings of this paper will contribute to knowledge and practice of researchers working in this filed by increasing their understanding related to numerous big data technologies and techniques deployment for handling banking financial risks and its role in operational banking workflow management.}
}
@article{PAN2023377,
title = {An automatic vulnerability classification framework based on BiGRU-TextCNN},
journal = {Procedia Computer Science},
volume = {222},
pages = {377-386},
year = {2023},
note = {International Neural Network Society Workshop on Deep Learning Innovations and Applications (INNS DLIA 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.08.176},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923009419},
author = {Mengyuan Pan and Po Wu and Yiwei Zou and Chong Ruan and Tao Zhang},
keywords = {vulnerability classification, text classification, deep learning, security advisory},
abstract = {Common Vulnerabilities and Exposures (CVE) records known vulnerabilities and provides standardized descriptions. By utilizing Common Weakness Enumeration (CWE) to classify vulnerabilities, it can provide richer background knowledge and more detailed mitigation measures for the vulnerability. However, due to the negligence on manual classification and the evolution of vulnerabilities, the accuracy of vulnerabilities classification needs urgent improvement. Additionally, the large and ever-increasing number of vulnerabilities poses a huge challenge to the efficiency and accuracy of vulnerabilities manual classification. To address that, we propose a vulnerability classification framework based on BiGRU-TextCNN, which processes, trains, predicts to automatically classify vulnerabilities into weaknesses based on the description of vulnerability. To verify the performance and feasibility of the proposed framework, we first conducting comparison experiments on different text classification models, and then predicting the corresponding weakness with the description of vulnerability utilizing the proposed framework.}
}
@article{WANI2021116,
title = {Sexual-predator Detection System based on Social Behavior Biometric (SSB) Features},
journal = {Procedia Computer Science},
volume = {189},
pages = {116-127},
year = {2021},
note = {AI in Computational Linguistics},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.05.075},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921011704},
author = {Mudasir Ahmad Wani and Nancy Agarwal and Patrick Bours},
keywords = {Online Sexual Predators, Emotion mining, Lexical analysis, Machine Learning},
abstract = {This study designs an online sexual predator detection system using Social Behavior Biometric (SSB) features. Social biometric focuses on extracting the pattern a user exhibits while interacting and communicating through social networks. The paper addresses the online sexual predator problem by mining the vocabulary and emotional behavior, which could assist in identifying if the user is a benign or predator. The feature-set consists of vocabulary terms that appear differently in predator and victim content. In order to strengthen the detection model, the paper also focuses on distinguishing the two classes of users based on emotions reflected in their conversation. The experiments are performed on the PAN 2012 corpus. Two datasets are created with respect to vocabulary-based and emotion-based features. The results obtained on the test set have proved that by integrating the vocabulary and emotion-based attributes, the performance of the system is significantly enhanced. While comparing, the proposed approach has outperformed top existing methods by obtaining F1, F2, and F0.5 values of 0.95, 0.94, and 0.96 respectively. Furthermore, we also recorded the best accuracy compared to state-of-the-art studies for our proposed SBB-based approach with 99.86%, 99.51%, and 99.88% for Decision Tree (DT), Support Vector Machine (SVM), and Random Forest (RF) respectively.}
}
@article{SAHIN2025102014,
title = {New blockchain consensus algorithm applied on healthcare industry: Proof of Visit- (POV)},
journal = {Engineering Science and Technology, an International Journal},
volume = {64},
pages = {102014},
year = {2025},
issn = {2215-0986},
doi = {https://doi.org/10.1016/j.jestch.2025.102014},
url = {https://www.sciencedirect.com/science/article/pii/S2215098625000692},
author = {Çetin Şahin and Muhammed Ali Aydin and Ahmet Sertbaş},
keywords = {Blockchain, Data security, Data privacy, Electronic Health Records (EHRs), Digital Health Wallet, Healthcare data security, Blockchain Consensus Algoritm},
abstract = {The increase in the world’s population, technological advancements, genetic research, digital health services, and medical devices are among the reasons that lead to the rapid growth of Electronic Health Record (EHR). Health services, clinical studies, public health studies, health insurance data, health research, and similar sources generate a large amount of EHR. One of today’s important issues is the storage of data in centralized database systems and the fact that data accuracy and security are only ensured through these centers. Due to communication and integration issues between these centers, vital data such as examinations and laboratory tests can be repeated due to difficulty accessing the EHR. As citizens do not have full control over sharing their own EHR, this situation can cause deficiencies and disruptions in the healthcare process. Sharing personal EHR without the citizen’s consent can lead to data privacy issues. In systems where patient data is centrally stored, software changes can cause problems such as loss of patient data. The fact that the patient’s potentially valuable EHR is secondary causes irregular maintenance of the data. With its decentralized architecture and verification mechanisms, blockchain technology can work more efficiently than centralized structures without data loss or security problems. In this study, it is proposed to share EHR using blockchain infrastructure and to prepare a consensus algorithm specifically for health data on the blockchain. This way, personal EHR is stored in the patient’s own control and their own health wallet.}
}
@article{DAVIS2024103896,
title = {Fostering security-related citizenship through the employee-supervisor relationship: An examination of supervisor security embodiment},
journal = {Computers & Security},
volume = {142},
pages = {103896},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.103896},
url = {https://www.sciencedirect.com/science/article/pii/S0167404824001986},
author = {Joshua M. Davis and Deepti Agrawal and Rebekah Austin},
keywords = {Supervisor security embodiment, Social identity theory of leadership, Leader-member exchange, Behavioral information security},
abstract = {Organizational information security performance is increasingly dependent on employees’ security-related citizenship behaviors that stretch beyond the scope of formal organizational prescription and control. Unfortunately, cultivating enactment of these valued behaviors has proven challenging for many companies. The literature has recognized workplace relationships as important determinants of behavioral security outcomes and extra-role security behaviors (ERBs) in particular. Taken further, an employee's relationship with the immediate supervisor is recognized as one of the most influential relational factors shaping a variety of workplace behaviors, including those related to security. Consistent with these notions, scholars have called for making the employee-supervisor relationship a more central component of behavioral security research and practice. Currently however, beyond recognition of this relationship's importance, the knowledge base is unclear about how it shapes ERB enactment. Because employees view supervisors as both organizational agents and as individuals in their own rights, this relationship has the potential to drive productive or counterproductive security behaviors, depending on how aligned the supervisor's security values are with those of the organization. Yet, the security literature has given surprisingly little consideration to the notion that employees can differ in the extent to which they perceive supervisors as embodying organizational information security values. Responding to this gap, the current study examines how employee-supervisor relations and perceived security-related value alignment between supervisors and the broader organization shape employees’ commitment to organizational information security and ultimately, ERB enactment. Grounded in the social identity theory of leadership (SITL), a research model is developed that positions high-quality employee-supervisor exchange as a direct antecedent of affective commitment to organizational information security, which then serves as a central intrinsic motivational mechanism driving ERB enactment. Further, rooted in SITL's principles on leader prototypicality and supervisor organizational embodiment, employee-perceived value alignment between the immediate supervisor and the organization as a whole—referred to here as supervisor security embodiment (SSE)—is introduced as a critical boundary condition influencing the extent to which employee-supervisor relations drive commitment. Results from model testing empirically demonstrate the value of SSE in explicating how this important relationship shapes workplace ERB enactment, through its influence on affective commitment to organizational information security performance.}
}
@article{SPRENKAMP2025101978,
title = {Data-driven intelligence in crisis: The case of Ukrainian refugee management},
journal = {Government Information Quarterly},
volume = {42},
number = {1},
pages = {101978},
year = {2025},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2024.101978},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X24000704},
author = {Kilian Sprenkamp and Mateusz Dolata and Gerhard Schwabe and Liudmila Zavolokina},
keywords = {Natural language processing, Topic modeling, Chatbot, Refugee management, Design science research},
abstract = {The ongoing conflict in Ukraine has triggered a humanitarian crisis, leading to a substantial increase in refugees. This situation presents a significant challenge for European countries, emphasizing the urgent need for effective refugee management strategies. Hence, effective decision-making is needed for the public sector to create a better livelihood for refugees. In this study, we propose using the concept of intelligence defined by Herbert Simon for effective refugee management. Following the Design Science Research Methodology, we utilize 58 semi-structured stakeholder interviews within Switzerland to identify problems and define design goals that facilitate intelligence in refugee management. Based on the design goals, we developed R2G – “Refugees to Government”, an application that utilizes community data and state-of-the-art NLP, including a chatbot interface, to offer an interactive dashboard for identifying refugee needs. The chatbot allows policymakers to interact with refugee data through dynamic, conversational queries, enabling real-time identification of refugee needs and providing data-driven intelligence. Our assessment of R2G, facilitated through 28 semi-structured interviews, resulted in four design principles for data-driven intelligence in refugee management: community-driven insight, spatial-temporal knowledge, multilingual data synthesis and visualization, and interactive data querying through chatbots. Additionally, we provide policy recommendations emphasizing the ethical use of community data, the integration of advanced NLP techniques in government processes, and the need for shifting governmental roles towards data analytics.}
}
@article{LIU2025111977,
title = {DRL-BM: Intelligent Buffer Management in Data Center Network},
journal = {Computer Networks},
pages = {111977},
year = {2025},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2025.111977},
url = {https://www.sciencedirect.com/science/article/pii/S1389128625009429},
author = {Wai-xi Liu and Xin-Jian Zhong and Zhen-xin Zhang and Jun Cai and Wen-Li Shang and Yong Ding and Zhiquan Liu and Chao-Xuan Zheng and Zhen-zheng Guo},
keywords = {Programmable data plane, Buffer management, Active queue management, Reinforcement learning, Queueing theory},
abstract = {Setting appropriate buffers size for switches in data center network (DCN) is important. In the DCN, the bottleneck links are unpredictably spatiotemporal-varying; various workloads demand different buffer management (BM) settings. However, existing works primarily focus on locally optimizing the buffer size of two switches connected on a fixed bottleneck link, suffering from poor performance because they employ either fixed buffer size or heuristically adjust the buffer size based on a fixed control logic. The challenge of globally optimizing the buffer size across all switches in a DCN has not yet been thoroughly explored. This article proposes an intelligent buffer management scheme, DRL-based Buffer Management (DRL-BM). Employing a strategy of “advancing by retreating”, DRL-BM uses Twin Delayed Deep Deterministic Policy Gradient (TD3) to spatiotemporally adaptive adjust the buffer size of all switches to minimizing flow completion time (FCT) for elephant flows & maximizing deadline meet rate (DMR) for mice flows simultaneously. We built a theoretical analysis model for BM. Furthermore, we design the action-granularity adaptive strategy to quickly find the optimal action for DRL, the prior-knowledge-based exploration mechanism to improve decision-making efficiency and robustness; the strategy of selecting key switches to overcome scalability issues. The experiment results under real-world DCN workloads (including Web-search, Data-mining, Hadoop, and Cache workload) demonstrate DRL-BM's effectiveness, reducing FCT by up to 29.8%, 20.3%, 17.7%, 20.6%, and 12.01%, compared to the typical fixed size BM (Fix (350)), ECN-based AQM (RED), delay-based AQM (CoDel), DRL-based BM(ABS), and end-host congestion control (NCC) scheme, respectively.}
}
@article{SYED2026127300,
title = {Next-generation control for electrolyzers: a review of GPT-based AI frameworks in renewable hydrogen systems},
journal = {Applied Energy},
volume = {406},
pages = {127300},
year = {2026},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2025.127300},
url = {https://www.sciencedirect.com/science/article/pii/S0306261925020306},
author = {Ahmad Syed and Xiaoqiang Guo and Ning Wang and Le sun and Shiqi Zhang and Changchun Hua and Abu Tayab},
keywords = {Green hydrogen, Electrolyzer control, Artificial intelligence, Power electronics, Hybrid energy systems, Generative pre-trained transformers (GPTs)},
abstract = {Hydrogen is increasingly recognized as a cornerstone of the clean energy transition, with renewable-powered electrolyzers enabling carbon-neutral hydrogen production. However, integrating variable renewable energy sources with electrolyzers remains technically challenging due to intermittency, dynamic load requirements, and efficiency losses. While conventional artificial intelligence (AI) techniques such as fuzzy logic, neural networks, and reinforcement learning have shown promise in optimization and control, they remain fragmented, data-intensive, and limited in scalability. This review introduces a novel perspective by providing the first dedicated analysis of Power Electronics–Generative Pre-trained Transformers (PE-GPT) for renewable hydrogen systems. Unlike existing surveys that address hydrogen technologies or AI applications in isolation, this paper systematically bridges both domains, demonstrating how domain-specific generative AI frameworks can optimize converter design, real-time modulation, and system-level energy management. The review further outlines hybrid architectures that integrate AI across power systems and power electronics, creating a unified pathway toward intelligent, reliable, and cost-effective hydrogen production. By synthesizing technical advances and highlighting open challenges, this work establishes a research roadmap that positions AI-driven frameworks as a transformative enabler for scalable green hydrogen deployment. To demonstrate practical feasibility, MATLAB/Simulink-based simulation results comparing a conventional PI-controller with a PE-GPT-assisted controller for a DC–DC converter feeding an electrolyzer are included, confirming the performance advantages of the proposed approach.}
}
@article{RAHMAN2023100822,
title = {Machine learning and internet of things in industry 4.0: A review},
journal = {Measurement: Sensors},
volume = {28},
pages = {100822},
year = {2023},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2023.100822},
url = {https://www.sciencedirect.com/science/article/pii/S2665917423001587},
author = {Md. Sazzadur Rahman and Tapotosh Ghosh and Nahid Ferdous Aurna and M. Shamim Kaiser and Mehrin Anannya and A.S.M. Sanwar Hosen},
keywords = {Industry 4.0, Internet of things, Machine learning, Smart system, Automation},
abstract = {Machine learning (ML), sensors networks, and Internet of Things (IoT) are the most important contributor in the newest revolution in the industry. It is going towards a fully automated industrial environment where all the components including post production, pre production, supply chain and quality control would be automatically managed. Human will work more with brain, where all the physical efforts would be replaced by ML enabled intelligent robots that will perform all the tasks, where sensor networks will collect live information from the environment. All the decision would be taken on the fly from the previous records. In this work, we have tried to shed some light on the current involvement of ML and IoT in industry 4.0 environment. 28 articles were reviewed in this work which were selected through a selection process and were published between 2017 and 2022. Different tools, protocols, algorithms and the latest technologies used in the industry 4.0 environment have been analytically discussed in this work. Research gaps were tried to found out and some recommendations were provided which can be a pathway to research advancement related to industry 4.0.}
}
@article{PLOSCA20251,
title = {Individual Software Expertise Formalization and Assessment from Project Management Tool Databases},
journal = {Computers, Materials and Continua},
volume = {86},
number = {1},
pages = {1-23},
year = {2025},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2025.069707},
url = {https://www.sciencedirect.com/science/article/pii/S1546221825010124},
author = {Traian-Radu Ploscă and Alexandru-Mihai Pescaru and Bianca-Valeria Rus and Daniel-Ioan Curiac},
keywords = {Expertise formalization, transformer-based models, natural language processing, augmented data, project management tool, skill classification},
abstract = {Objective expertise evaluation of individuals, as a prerequisite stage for team formation, has been a long-term desideratum in large software development companies. With the rapid advancements in machine learning methods, based on reliable existing data stored in project management tools’ datasets, automating this evaluation process becomes a natural step forward. In this context, our approach focuses on quantifying software developer expertise by using metadata from the task-tracking systems. For this, we mathematically formalize two categories of expertise: technology-specific expertise, which denotes the skills required for a particular technology, and general expertise, which encapsulates overall knowledge in the software industry. Afterward, we automatically classify the zones of expertise associated with each task a developer has worked on using Bidirectional Encoder Representations from Transformers (BERT)-like transformers to handle the unique characteristics of project tool datasets effectively. Finally, our method evaluates the proficiency of each software specialist across already completed projects from both technology-specific and general perspectives. The method was experimentally validated, yielding promising results.}
}
@article{XU2024100698,
title = {Towards autonomous supply chains: Definition, characteristics, conceptual framework, and autonomy levels},
journal = {Journal of Industrial Information Integration},
volume = {42},
pages = {100698},
year = {2024},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2024.100698},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X24001419},
author = {Liming Xu and Stephen Mak and Yaniv Proselkov and Alexandra Brintrup},
keywords = {Supply chain management, Autonomous supply chain, Autonomy levels, Conceptual framework, Multi-agent system},
abstract = {Recent global disruptions, such as the COVID-19 pandemic and the ongoing geopolitical conflicts, have profoundly exposed vulnerabilities in traditional supply chains, requiring exploration of more resilient alternatives. Among various solution offerings, Autonomous supply chains (ASCs) have emerged as key enablers of increased integration and visibility, enhancing flexibility and resilience in turbulent trade environments through the widespread automation of low level decision making. Although ASC solutions have been discussed and trialled over several years, they still lack well-established theoretical foundations. This paper addresses this research gap by presenting a formal definition of ASC along with its defining characteristics and auxiliary concepts. We propose a layered conceptual framework, called the MIISI model. An illustrative case study focusing on the meat supply chain demonstrates an initial ASC implementation based on this conceptual model. Furthermore, we introduce a seven-level supply chain autonomy reference model, delineating a trajectory towards achieving full supply chain autonomy. Recognising that this work represents an initial endeavour, we emphasise the need for continued exploration in this emerging domain. This work is designed to stimulate further research, both theoretical and technical, and contribute to the continual evolution of ASCs.}
}
@article{LEE20253050,
title = {ARPA-H for Radiologists: Novel Funding Opportunities and Results of a National Survey},
journal = {Academic Radiology},
volume = {32},
number = {5},
pages = {3050-3064},
year = {2025},
issn = {1076-6332},
doi = {https://doi.org/10.1016/j.acra.2024.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S1076633224008468},
author = {Yueh Z. Lee and Ichiro Ikuta and Anugayathri Jawahar and Josie Wilkinson and Casey Cappelletti and Renee L. Cruea and Mai-Lan Ho},
keywords = {Academy, ARPA-H, Funding, Grants, Research, RRA, Survey},
abstract = {The Advanced Research Projects Agency for Health (ARPA-H) is a new federal agency established by the Biden administration in March 2022 to accelerate US government-funded biomedical and health solutions. ARPA-H has a distinct operating model, leadership structure, and funds flow separate from the National Institutes of Health. In 2023, the Association of Academic Radiology formed a Radiology Research Alliance taskforce to better understand the mission, vision, and guiding principles of ARPA-H and relevance to radiology and biomedical imaging research. This white paper summarizes the findings of the taskforce with particular relevance to radiology & biomedical imaging researchers. The article begins with a background of ARPA-H history, principles, and organization. Next, we describe the application and review process, timelines, and tips for investigators. Subsequently, we summarize recent/upcoming programs and examples of successful awards, highlighting potential opportunities for radiology researchers. Because the agency is not disease or specialty-specific, it is incumbent upon investigators to brainstorm potential funding opportunities. Therefore, the taskforce conducted a national survey of radiology research leaders in collaboration with The Academy for Radiology & Biomedical Imaging Research, designed to identify cutting-edge developments and opportunities for the field, including suitable targets for ARPA-H funding.}
}
@article{CRAMER2025112322,
title = {Engineering patterns for Trust and Safety on social media platforms: A case study of Mastodon and Diaspora},
journal = {Journal of Systems and Software},
volume = {222},
pages = {112322},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112322},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224003662},
author = {Geoffrey Cramer and William P. {Maxam III} and James C. Davis},
keywords = {Empirical software engineering, Social media platforms, Trust & Safety engineering, Engineering decision-making, Risk},
abstract = {Context:
Trust & Safety (T&S) Engineering is an emerging area of software engineering that mitigates the risks of harmful interactions in online platforms. Numerous studies have explored T&S risks on social media platforms, taxonomizing threats and investigating individual issues. However, there is limited empirical knowledge about engineering efforts to promote T&S.
Methods:
This study examines T&S risks and the engineering patterns to resolve them. We conducted a case study of the two largest decentralized SMPs: Mastodon and Diaspora. These SMPs are open-source, so we analyzed T&S discussions within 60 GitHub issues. We analyzed T&S discussions that took place in their online repository and extracted T&S risks, T&S engineering patterns, and resolution rationales considered by the engineers. We integrate our findings by mapping T&S engineering patterns onto a general model of SMPs, to give SMP engineers a systematic understanding of their T&S risk treatment options.
Results:
T&S issues are a challenge throughout the feature set and lifespan of an SMP. A taxonomy of 12 solution patterns are developed, paving the way for academia and industry to standardize Trust & Safety solutions. We conclude with future directions to study and improve T&S Engineering, spanning software design, decision-making, and validation. We conclude with future directions to study and improve T&S Engineering, spanning software design, decision-making, and validation.}
}
@article{WANG2025104139,
title = {Can attention detect AI-generated text? A novel Benford's law-based approach},
journal = {Information Processing & Management},
volume = {62},
number = {4},
pages = {104139},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104139},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325000767},
author = {Zhenhua Wang and Guang Xu and Ming Ren},
keywords = {AI-generated text detection, Benford's law, Attention distribution, Adherence pattern},
abstract = {AI technologies, such as the GPT-series, have garnered worldwide attention and raised concerns regarding their potential for misuse, owing to their groundbreaking text-generating capabilities, particularly in AI-generated text (AIGT). In response to the urgent need for effective detection, this study proposes BENATTEN, a novel approach that exploits the attention between human-generated text (HGT) and AIGT. We reveal that the way humans think and the probabilistic nature of AI algorithms lead to discrepancies in how they pay attention to tokens within the text they produce, with AIGT exhibiting a higher adherence to Benford's law in attention distribution compared to HGT. Extensive experiments on three general-domain datasets demonstrate the advantage of BENATTEN compared with existing methods. For instance, on the HC3 dataset, BENATTEN achieved an impressive 99.24 % accuracy, 99.69 % F1 and 99.47 % AUC, surpassing the OpenAI detector by 3.05 %, 3.48 % and 2.39 %, respectively. Also, comprehensive evaluations on seven specialized-application domain datasets have confirmed BENATTEN's robustness and its cross-platform applicability, proving its ongoing efficacy even as AI technology evolves. Further, the experiments have shown that BENATTEN exhibits remarkable resilience, effectively handling adversarial attacks and interference from other AI systems.}
}
@article{LI2025,
title = {Trust or distrust? AIGC trustworthiness and an extended analysis within nomology framework},
journal = {Data Science and Management},
year = {2025},
issn = {2666-7649},
doi = {https://doi.org/10.1016/j.dsm.2025.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S2666764925000499},
author = {Mingqian Li and Rong Du and Shizhong Ai and Richard A. Hunt and Jianing Xie},
keywords = {artificial intelligence (AI), artificial intelligence generated content (AIGC), nomology framework, trust, trustworthiness, grounded theory, text mining, sentiment analysis},
abstract = {Given the dizzying advancements in artificial intelligence (AI) applications such as ChatGPT and DeepSeek, AI-generated content (AIGC) has attracted considerable attention from scholars, practitioners, and policymakers, each of whom is grappling with fundamental issues involving individual, organizational, and even societal impacts, which are exciting and daunting. Central to the process of identifying and assessing the benefits and detriments of AIGC are critical issues involving reliability, intelligibility, desirability, and, perhaps most of all, trustworthiness. Although humans have generally accepted the reality that AI is destined to play a prominent role in our lives, we are still in the very early stages of determining how we feel about the complex relationships that emerge between people and AI. Management and organizational scholars play a key role in developing theories that demarcate and predict the evolving structure and content of these relationships. Towards that end, this study adopts a mixed-methods design to systematically examine perceptions of AIGC trustworthiness. We begin by employing grounded theory to develop a nomology framework that integrates the extroverted and introverted dimensions of human cognition. We then subject the interview corpus to text mining and sentiment analysis to distill targeted, evidence-based strategies for strengthening AIGC trustworthiness.}
}
@article{FEDELE2024105986,
title = {The ALTAI checklist as a tool to assess ethical and legal implications for a trustworthy AI development in education},
journal = {Computer Law & Security Review},
volume = {53},
pages = {105986},
year = {2024},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2024.105986},
url = {https://www.sciencedirect.com/science/article/pii/S0267364924000530},
author = {Andrea Fedele and Clara Punzi and Stefano Tramacere},
keywords = {Trustworthy AI, Education, Vulnerability, AI regulation, AI accountability, eXplainable AI},
abstract = {The rapid proliferation of Artificial Intelligence (AI) applications in various domains of our lives has prompted a need for a shift towards a human-centered and trustworthy approach to AI. In this study we employ the Assessment List for Trustworthy Artificial Intelligence (ALTAI) checklist to evaluate the trustworthiness of Artificial Intelligence for Student Performance Prediction (AI4SPP), an AI-powered system designed to detect students at risk of school failure. We strongly support the ethical and legal development of AI and propose an implementation design where the user can choose to have access to each level of a three-tier outcome bundle: the AI prediction alone, the prediction along with its confidence level, and, lastly, local explanations for each grade prediction together with the previous two information. AI4SPP aims to raise awareness among educators and students regarding the factors contributing to low school performance, thereby facilitating the implementation of interventions not only to help students, but also to address biases within the school community. However, we also emphasize the ethical and legal concerns that could arise from a misuse of the AI4SPP tool. First of all, the collection and analysis of data, which is essential for the development of AI models, may lead to breaches of privacy, thus causing particularly adverse consequences in the case of vulnerable individuals. Furthermore, the system’s predictions may be influenced by unacceptable discrimination based on gender, ethnicity, or socio-economic background, leading to unfair actions. The ALTAI checklist serves as a valuable self-assessment tool during the design phase of AI systems, by means of which commonly overlooked weaknesses can be highlighted and addressed. In addition, the same checklist plays a crucial role throughout the AI system life cycle. Continuous monitoring of sensitive features within the dataset, alongside survey assessments to gauge users’ responses to the systems, is essential for gathering insights and intervening accordingly. We argue that adopting a critical approach to AI development is essential for societal progress, believing that it can evolve and accelerate over time without impeding openness to new technologies. By aligning with ethical principles and legal requirements, AI systems can make significant contributions to education while mitigating potential risks and ensuring a fair and inclusive learning environment.}
}
@article{BENYAHYA2025104451,
title = {Bayes-based word weighting for enhanced vulnerability classification in critical infrastructure systems},
journal = {Computers & Security},
volume = {154},
pages = {104451},
year = {2025},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2025.104451},
url = {https://www.sciencedirect.com/science/article/pii/S0167404825001403},
author = {Aissa {Ben Yahya} and Hicham {El Akhal} and El {Mehdi Ismaili Alaoui} and Abdelbaki El Belrhiti {El Alaoui}},
keywords = {Word weighting, Vulnerability classification, Critical infrastructure security, Deep learning, Word embedding, Text classification},
abstract = {The increasing number of vulnerabilities in embedded devices poses a significant threat to the critical infrastructure security where these devices are used. While deep learning approaches have advanced software vulnerability classification, they exhibit critical limitations regarding word weighting. Conventional methods like term frequency–inverse document frequency (TF–IDF) prioritize global term distributions but overlook intra-class distinctions. While improved variants of this technique have been proposed, they often fail to consider that a word’s importance can vary across categories and struggle to prioritize rare but distinctive words adequately. Additionally, high inter-class semantic overlap and terminological ambiguity in vulnerability descriptions hinder model performance by failing to separate intra-class keywords From background noise. to address these gaps, we propose a novel vulnerability classification and word vector weighting approach based on bayes theorem. our method dynamically adjusts term relevance by calculating posterior probabilities of word-category associations, emphasizing rare tokens with high intra-class specificity. we validate the approach on four test datasets derived from databases such as the national vulnerability database (NVD) and the chinese vulnerability database (CNNVD). rigorous ablation and comparative studies demonstrate that bayes-based word weighting outperformed other methods by achieving a performance of 97.63% accuracy, and 97.60% F1-score on the most challenging test data. all our models and code to produce our results are open-sourced.}
}
@article{WANG2024103503,
title = {Improved capsule networks based on Nash equilibrium for malicious code classification},
journal = {Computers & Security},
volume = {136},
pages = {103503},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2023.103503},
url = {https://www.sciencedirect.com/science/article/pii/S0167404823004133},
author = {Meng Wang and Yahao Zhang and WeiPing Wen},
keywords = {Malware detection, Capsule network, Nash equilibrium, Security model, Machine learning},
abstract = {With the cutting-edge technology and artificial intelligence, various types of malware have seriously attacked cyberspace, thus relying on the deep learning to maintain high accuracy on malware classification was the solution. After the malware binaries are changed into grayscale images as network inputs, most of the existing methods deal with the observed substantial visual similarities in image texture for malware as if they were from the same family. In addition, the patterns among the different families should include exclusive features, which are prerequisite for malicious code classification. However, the previous methods do not focus on the feature extraction. To solve this problem, we propose an improved capsule network based on the Nash equilibrium for malicious code classification. From the perspective of game theory, extracting of the exclusive features can be viewed as a noncooperative game through a novel dynamic routing embedded with the Nash equilibrium process in the proposed method. The three most recent datasets are used in the evaluation period. Five indicators are calculated to test the general performance and ability to distinguish the malware categories between the Nash capsule networks, traditional capsule network and CNN. Experiments show that the classification effect of the proposed method is better than that of the traditional machine learning methods. CCS CONCEPTS: Computing Methodologies, Malware Classification, Nash Equilibrium, Machine learning, Deep Learning, Capsule Network}
}
@article{CHEN2025114013,
title = {A lightweight embedding method for knowledge graph quality evaluation},
journal = {Knowledge-Based Systems},
volume = {326},
pages = {114013},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.114013},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125010585},
author = {Bin Chen and Hongyi Li and Di Zhao and Chengwei Pan},
keywords = {Quality evaluation, Low-dimensional embedding, Knowledge graph, Feature reduction},
abstract = {Knowledge graph (KG) quality evaluation seeks to assess the quality of triples in a KG. Existing approaches for KG quality evaluation often rely on high-dimensional embeddings to improve the model's evaluative performance. This reliance, however, not only increases the model's scale but also introduces feature redundancy, constraining its applicability to real-world problems. To tackle this challenge, this study proposes a Lightweight Embedding Method for KG Quality Evaluation (LEKGQE). This method performs kernel principal component analysis on each dimension of the triples, mapping multivariate data into univariate data, thereby effectively extracting the main features of the data. Furthermore, we quantify the contribution of each dimension on the target variable. Cross-entropy is used to identify the most discriminative features for KG quality evaluation, significantly reducing the model's embedding dimension and improving the KG quality evaluation performance under low-dimensional embeddings. Extensive experiments demonstrate the effectiveness of the LEKGQE model. With an embedding dimension of 32, the LEKGQE achieves a 14 % increase in F1 score on the FB15K dataset and a 12 % increase in F1 score on the WN18 dataset, markedly improving the model’s performance in low-dimensional embedding scenarios.}
}
@article{LASKIN2024102489,
title = {The Delphi Panel investigation of artificial intelligence in investor relations},
journal = {Public Relations Review},
volume = {50},
number = {4},
pages = {102489},
year = {2024},
issn = {0363-8111},
doi = {https://doi.org/10.1016/j.pubrev.2024.102489},
url = {https://www.sciencedirect.com/science/article/pii/S0363811124000687},
author = {Alexander V. Laskin and Giulia D’Agostino},
keywords = {Artificial Intelligence, Investor relations, Financial communication, Shareholder, Stockholder},
abstract = {In recent years, there has been a discernible upswing in the attention dedicated to artificial intelligence (AI) within the domains of public relations, advertising, and marketing. Notably, the subdomain of investor relations has maintained a significant historical engagement with AI, actively employing AI and AI-enabled tools for several decades, a practice traceable back to the 1980s. This protracted involvement presents a reservoir of invaluable insights germane to comprehending the broader integration of AI within the purview of public relations. This scholarly inquiry embarks on a Delphi panel examination to scrutinize the deployment of AI in investor relations, proffers a systematic classification of AI-enabled tools within this realm, and prognosticates the trajectory of AI's influence on investor relations and financial communications. The panel of Delphi participants comprises seasoned authorities in the field, boasting a cumulative professional experience spanning 161 years. Leveraging the depth of expertise inherent in investor relations, the study not only illuminates the current landscape but also posits conceivable trajectories for the evolution of AI across other subfields within the domain of public relations.}
}
@article{DAI2025131188,
title = {MVF-PointCLIP: Training-free multi-view fusion PointCLIP for zero-shot 3D classification},
journal = {Neurocomputing},
volume = {653},
pages = {131188},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.131188},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225018600},
author = {Jiuqian Dai and Zhenyan Ji and Zechang Xiong and Guiping Zhu and Hui Liu and Shen Yin and Jose Enrique Armendariz-Inigo},
keywords = {Point cloud, CLIP, Multi-view fusion, Zero-shot, Training-free},
abstract = {The remarkable success of Contrastive Language-Image Pretraining (CLIP) in zero-shot 2D vision classification inspires researchers to explore its potential application to zero-shot 3D classification. Some researchers project 3D point clouds into 2D images from multiple views to leverage CLIP. However, by doing experiments, we find that this method suffers from two critical drawbacks: (1) noise views existing in multiview depth maps, which provide limited information that may mislead classification; (2) covariance inconsistencies between sample views, which can lead to misclassification when using cosine similarity. To address these issues, we propose a training-free MultiView Fusion PointCLIP (MVF-PointCLIP). It contains a Spatial and Frequency Attention (SFA) module and a Mahalanobis Distance module designed by us. The SFA module automatically assigns importance weights to views, effectively filtering out noisy information. The Mahalanobis Distance module models the distribution of views to tackle covariance inconsistencies. Experimental results verify the superiority of MVF-PointCLIP to SOTA models in zero-shot classification across ModelNet10, ModelNet40, and ScanObjectNN.}
}
@article{CHO20251193,
title = {A study on Gen-AI technology development trends to enhance small-medium sized enterprise digital competence and management quality},
journal = {Journal of Entrepreneurship in Emerging Economies},
volume = {17},
number = {5},
pages = {1193-1218},
year = {2025},
issn = {2053-4604},
doi = {https://doi.org/10.1108/JEEE-10-2024-0485},
url = {https://www.sciencedirect.com/science/article/pii/S2053460425000209},
author = {Youngju Cho and Junsung Park and Junyoung Yoo and Soyoung Kim and Heejun Park},
keywords = {Digitalization, Gen-AI, SME, OS-Matrix, Patent analysis, Topic modelling, Scaling-up, Startup, Entrepreneurship},
abstract = {Purpose
The rapid advancement of Generative Artificial Intelligence (Gen-AI) offers transformative opportunities for enhancing digital competence and management quality in small and medium-sized enterprises (SMEs). Given the challenges of a Volatile, Uncertain, Complex and Ambiguous (VUCA) business environment, SMEs face risks of losing competitive advantages to larger corporations. This study aims to explore Gen-AI trends and identify strategies that can support SMEs in building digital resilience and operational efficiency.
Design/methodology/approach
Through text analysis of patent data and using Gen-AI technology, this research examines potential AI applications to address SME challenges, such as labor shortages, productivity declines and operational inefficiencies. The study uses topic modeling and an OS-matrix framework to analyze trends in Gen-AI patents, aligning technological developments with SME-specific needs.
Findings
The study finds that Gen-AI technologies, such as automated content creation and predictive analytics, provide targeted solutions for key SME challenges. The OS-matrix framework reveals that specific Gen-AI applications can enhance SMEs’ adaptability and competitive positioning in dynamic markets.
Research limitations/implications
While this research underscores the potential of Gen-AI for SME digital transformation, limitations include a reliance on patent data and a lack of consideration of various industrial features of SMEs. Future research should expand data sources and apply findings across diverse SME sectors.
Originality/value
This study contributes insights by mapping Gen-AI advancements to SME needs under VUCA conditions. Therefore, integrating topic modeling with OS-matrix for aligning Gen-AI technologies to SME operational challenges, offers a strategic framework for digital adoption.}
}
@article{AGARWAL2025535,
title = {A five-layer framework for AI governance: integrating regulation, standards, and certification},
journal = {Transforming Government: People, Process and Policy},
volume = {19},
number = {3},
pages = {535-555},
year = {2025},
issn = {1750-6166},
doi = {https://doi.org/10.1108/TG-03-2025-0065},
url = {https://www.sciencedirect.com/science/article/pii/S1750616625000046},
author = {Avinash Agarwal and Manisha J. Nene},
keywords = {AI governance, Responsible AI, Trustworthy AI, Framework, Standards, Assessment, Certification, Incidents},
abstract = {Purpose
The governance of artificial intelligence (AI) systems requires a structured approach that connects high-level regulatory principles with practical implementation. Existing frameworks lack clarity on how regulations translate into conformity mechanisms, leading to gaps in compliance and enforcement. This paper aims to address this critical gap in AI governance.
Design/methodology/approach
A five-layer AI governance framework is proposed, spanning from broad regulatory mandates to specific standards, assessment methodologies and certification processes. By narrowing its scope through progressively focused layers, the framework provides a structured pathway to meet technical, regulatory and ethical requirements. Its applicability is validated through two case studies on AI fairness and AI incident reporting.
Findings
The case studies demonstrate the framework’s ability to identify gaps in legal mandates, standardization and implementation. It adapts to both global and region-specific AI governance needs, mapping regulatory mandates with practical applications to improve compliance and risk management.
Practical implications
By offering a clear and actionable roadmap, this work contributes to global AI governance by equipping policymakers, regulators and industry stakeholders with a model to enhance compliance and risk management.
Social implications
The framework supports the development of policies that build public trust and promote the ethical use of AI for the benefit of society.
Originality/value
This study proposes a five-layer AI governance framework that bridges high-level regulatory mandates and implementation guidelines. Validated through case studies on AI fairness and incident reporting, it identifies gaps such as missing standardized assessment procedures and reporting mechanisms, providing a structured foundation for targeted governance measures.}
}
@article{OLERIBE2025,
title = {ETHICS of AI Adoption and Deployment in Health Care: Progress, Challenges, and Next Steps},
journal = {JMIR AI},
volume = {4},
year = {2025},
issn = {2817-1705},
doi = {https://doi.org/10.2196/67626},
url = {https://www.sciencedirect.com/science/article/pii/S2817170525000870},
author = {Obinna O Oleribe and Andrew W Taylor-Robinson and Christian C Chimezie and Simon D Taylor-Robinson},
keywords = {artificial intelligence, generative AI, ethics, equity, health care},
abstract = {Generative artificial intelligence (GenAI) is increasingly being integrated into health care, offering a wide array of benefits. Currently, GenAI applications are useful in disease risk prediction and preventive care, diagnostics via imaging, artificial intelligence (AI)–assisted devices and point-of-care tools, drug discovery and design, patient and disease monitoring, remote monitoring and wearables, integration of multimodal data and personalized medicine, on-site and remote patient and disease monitoring and device integration, robotic surgery, and health system efficiency and workflow optimization, among other aspects of disease prevention, control, diagnosis, and treatment. Recent breakthroughs have led to the development of reliable and safer GenAI systems capable of handling the complexity of health care data. The potential of GenAI to optimize resource use and enhance productivity underscores its critical role in patient care. However, the use of AI in health is not without critical gaps and challenges, including (but not limited to) AI-related environmental concerns, transparency and explainability, hallucinations, inclusiveness and inconsistencies, cost and clinical workflow integration, and safety and security of data (ETHICS). In addition, the governance and regulatory issues surrounding GenAI applications in health care highlight the importance of addressing these aspects for responsible and appropriate GenAI integration. Building on AI’s promising start necessitates striking a balance between technical advancements and ethical, equity, and environmental concerns. Here, we highlight several ways in which the transformative power of GenAI is revolutionizing public health practice and patient care, acknowledge gaps and challenges, and indicate future directions for AI adoption and deployment.}
}
@article{KOTILAINEN2025112333,
title = {Allocating distributed AI/ML applications to cloud–edge continuum based on privacy, regulatory, and ethical constraints},
journal = {Journal of Systems and Software},
volume = {222},
pages = {112333},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2025.112333},
url = {https://www.sciencedirect.com/science/article/pii/S0164121225000019},
author = {Pyry Kotilainen and Niko Mäkitalo and Kari Systä and Ali Mehraj and Muhammad Waseem and Tommi Mikkonen and Juan Manuel Murillo},
keywords = {Internet of Things, IoT, Cloud computing, Model cards, Ethical orchestration, Orchestration, Artificial Intelligence, AI, Ethics, Compliance, Privacy, AI regulation},
abstract = {There is an increasing need for practitioners to address legislative and ethical issues in both the development and deployment of data-driven applications with AI/ML due to growing concerns and regulations, such as GDPR and the EU AI Act. Thus, the field needs a systematic framework for assessing risks and helping to stay compliant with regulations in designing and deploying software systems. Clear and concise descriptions of risks associated with each model and data source are needed to guide the design without acquiring deep knowledge of the regulations. In this paper, we propose a reference architecture for an ethical orchestration system that manages distributed AI/ML applications on the cloud–edge continuum and present a proof-of-concept implementation of the main ideas of the architecture. Our starting point is the methods already in use in the industry, such as model cards, and we extend the idea of model cards to data source cards and software component cards, which provide practitioners and the automated system with relevant information in actionable form. With the metadata card based orchestration system and information about the risk levels of the target infrastructure, the users can create deployments of distributed AI/ML systems that fulfill the regulatory and other requirements.}
}
@article{LAVALLE2025102410,
title = {A methodology for the systematic design of storytelling dashboards applied to Industry 4.0},
journal = {Data & Knowledge Engineering},
volume = {156},
pages = {102410},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2025.102410},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X25000059},
author = {Ana Lavalle and Alejandro Maté and Maribel Yasmina Santos and Pedro Guimarães and Juan Trujillo and Antonina Santos},
keywords = {Analytical requirements, Big data, Data visualization, Storytelling dashboards, Industrial processes},
abstract = {Dashboards are popular tools for presenting key insights to decision-makers by translating large volumes of data into clear information. However, while individual visualizations may effectively answer specific questions, they often fail to connect in a way that conveys the overall narrative, leaving decision-makers without a cohesive understanding of the area under analysis. This paper presents a novel methodology for the systematic design of holistic dashboards, moving from analytical requirements to storytelling dashboards. Our approach ensures that all visualizations are aligned with the analytical goals of decision-makers. It includes several key steps: capturing analytical requirements through the i* framework; structuring and refining these requirements into a tree model to reflect the decision-maker’s mental analysis; identifying and preparing relevant data; capturing the key concepts and relationships for the composition of the cohesive storytelling dashboard through a novel storytelling conceptual model; finally, implementing and integrating the visualizations into the dashboard, ensuring coherence and alignment with the decision-maker’s needs. Our methodology has been applied in real-world industrial environments. We evaluated its impact through a controlled experiment. The findings show that storytelling dashboards significantly improve data interpretation, reduce misinterpretations, and enhance the overall user experience compared to traditional dashboards.}
}
@article{DAS2024111981,
title = {Extracting goal models from natural language requirement specifications},
journal = {Journal of Systems and Software},
volume = {211},
pages = {111981},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.111981},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224000244},
author = {Souvick Das and Novarun Deb and Agostino Cortesi and Nabendu Chaki},
keywords = {Natural language requirements, Natural language processing, Transformer model, Entity type recognition, Contextual vector, Synonymy vector},
abstract = {Unstructured (or, semi-structured) natural language is mostly used to capture the requirement specifications both for legacy software systems and for modern day software systems. The adoption of a formal approach to the specification of the requirements, using goal models, enables rigorous and formal inspections while analyzing the requirements for satisfiability, consistency, completeness, conflicts and ambiguities. However, such a formal approach is often considered burdening for the analysts’ activity as it requires additional skills, and is therefore, discarded a priori. This works aims to bridge the gap between natural language requirement specifications and efficient goal model analysis techniques. We propose a framework that uses extensive natural language processing techniques to transform a set of unstructured natural language requirement specifications to the corresponding goal model. We combine techniques such as parts-of-speech tagging, dependency parsing, contextual and synonymy vector generation with the FiBER transformer model. An extensive unbiased crowd-sourced evaluation of the proposed framework has been performed, showing an acceptability rate (total and partial combined) of 95%. Time and space analyses of our framework also demonstrate the scalability of the proposed solution.}
}
@article{REN2025106775,
title = {CMCPS: A model copyright protection scheme based on Cohen's Kappa statistic},
journal = {Results in Engineering},
volume = {27},
pages = {106775},
year = {2025},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2025.106775},
url = {https://www.sciencedirect.com/science/article/pii/S2590123025028403},
author = {Junling Ren and Zihao Niu},
keywords = {Model copyright protection, Adversarial samples, Cohen's Kappa, Classification consistency, Model vulnerability},
abstract = {Deep learning models perform well in many tasks; however, training a high-performance deep learning model requires significant computational resources, which contributes to its high value. Consequently, model theft is likely to occur. A copyright protection scheme based on Cohen's Kappa statistic, CMCPS, is proposed to address copyright protection issues faced by deep learning models. This approach overcomes the limitations of traditional black-box watermarking schemes that degrade the performance of the original task. It generates adversarial samples using the MI-FGSM algorithm with a momentum term, constructs a mixed evaluation set containing both original and adversarial samples, and introduces Cohen's Kappa statistic to quantify the classification consistency between the suspect model and the original model on the evaluation set, thereby assessing model consistency. Experiments demonstrate that CMCPS can effectively distinguish between models with different architectures and independently trained models. In fine-tuning and pruning experiments, κ>0.6, indicating that this approach can resist 20 rounds of fine-tuning attacks and pruning attacks involving 70% of parameters. In experiments with independently trained “twin” models, κ<0.2, indicating that no misclassification occurs in such cases. Compared with the white-box watermarking technique, the scheme only requires API access to verify the copyright, which provides a new type of intellectual property protection for the model-as-a-service scenario, while the scheme utilizes the vulnerability feature that models are susceptible to adversarial sample spoofing, which provides a new way of thinking about copyright protection.}
}
@article{ONETO2025132505,
title = {Informed machine learning for complex data},
journal = {Neurocomputing},
pages = {132505},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.132505},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225031777},
author = {Luca Oneto and Nicolò Navarin and Alessio Micheli and Luca Pasa and Claudio Gallicchio and Davide Bacciu and Davide Anguita},
keywords = {Artificial intelligence, Machine learning, Informed machine learning, Data structure informed, Technically informed, Environmentally informed, Physically informed, Ethically informed},
abstract = {Machine Learning (ML) has become a central force in Artificial Intelligence, driving major breakthroughs in applications that handle increasingly complex data, from images and text sequences to graph structures. While new architectures such as Transformers and Graph Neural Networks continue to redefine performance benchmarks in various domains, these predominantly data-driven methods often neglect critical domain knowledge, practical constraints, and broader contextual factors. This oversight diminishes their trustworthiness and restricts their impact in real-world settings. In this paper, we discuss the need for a more informed approach to ML for complex data. Specifically, we advocate for solutions that explicitly integrate structural awareness to capture underlying relationships in the data, incorporate key technical requirements to ensure safety and compliance with industry standards, embed environmental considerations to promote sustainability and resource efficiency, adhere to established physical principles, and uphold ethical and societal values. By weaving these dimensions together, informed ML can bridge the gap between purely data-centric methods and the nuanced demands of practical applications. We show how this integrated framework not only strengthens model performance but also ensures that ML solutions remain trustworthy, efficient, and sensitive to human ecological, ethical, and regulatory imperatives. Our discussion underscores the transformative potential of Informed ML to drive innovation across diverse domains, setting a new benchmark for responsible and high-impact ML system design.}
}
@article{LI2026127196,
title = {QSTAformer: A quantum-enhanced Transformer for robust short-term voltage stability assessment against adversarial attacks},
journal = {Applied Energy},
volume = {405},
pages = {127196},
year = {2026},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2025.127196},
url = {https://www.sciencedirect.com/science/article/pii/S0306261925019269},
author = {Yang Li and Chong Ma and Yuanzheng Li and Sen Li and Yanbo Chen and Zhaoyang Dong},
keywords = {Short-term voltage stability assessment (STVSA), Quantum machine learning (QML), Parameterized quantum circuits (PQCs), Quantum-enhanced attention mechanism, Hybrid quantum-classical neural networks, Adversarial attacks, Adversarial training, Cyber-physical power systems},
abstract = {Short-term voltage stability assessment (STVSA) is critical for secure power system operation. While classical machine learning-based methods have demonstrated strong performance, they still face challenges in robustness under adversarial conditions. This paper proposes QSTAformer—a tailored quantum-enhanced Transformer architecture that embeds parameterized quantum circuits (PQCs) into attention mechanisms—for robust and efficient STVSA. A dedicated adversarial training strategy is developed to defend against both white-box and gray-box attacks. Furthermore, diverse PQC architectures are benchmarked to explore trade-offs between expressiveness, convergence, and efficiency. To the best of our knowledge, this is the first work to systematically investigate the adversarial vulnerability of quantum machine learning-based STVSA. Case studies on the IEEE 39-bus system demonstrate that QSTAformer achieves competitive accuracy, reduced complexity, and stronger robustness, underscoring its potential for secure and scalable STVSA under adversarial conditions.}
}
@article{GAO2025111914,
title = {Resource-efficient automatic software vulnerability assessment via knowledge distillation and particle swarm optimization},
journal = {Engineering Applications of Artificial Intelligence},
volume = {160},
pages = {111914},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.111914},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625019165},
author = {Chaoyang Gao and Xiang Chen and Jiyu Wang and Jibin Wang and Guang Yang},
keywords = {Software vulnerability assessment, Knowledge distillation, Particle swarm optimization, Large language code model},
abstract = {The increasing complexity of software systems has led to a surge in cybersecurity vulnerabilities, necessitating efficient and scalable solutions for vulnerability assessment. However, the deployment of large pre-trained models in real-world scenarios is hindered by their substantial computational and storage demands. To address this challenge, we propose a novel resource-efficient framework that integrates knowledge distillation and particle swarm optimization to enable automated vulnerability assessment. Our framework employs a two-stage approach: First, particle swarm optimization is utilized to optimize the architecture of a compact student model, balancing computational efficiency and model capacity. Second, knowledge distillation is applied to transfer critical vulnerability assessment knowledge from a large teacher model to the optimized student model. This process significantly reduces the model size while maintaining high performance. Experimental results on an enhanced MegaVul dataset, comprising 12,071 CVSS (Common Vulnerability Scoring System) v3 annotated vulnerabilities, demonstrate the effectiveness of our approach. Our approach achieves a 99.4% reduction in model size while retaining 89.3% of the original model’s accuracy. Furthermore, it outperforms state-of-the-art baselines by 1.7% in accuracy with 60% fewer parameters. The framework also reduces training time by 72.1% and architecture search time by 34.88% compared to traditional genetic algorithms.}
}
@article{KANIJ2024112169,
title = {Enhancing understanding and addressing gender bias in IT/SE job advertisements},
journal = {Journal of Systems and Software},
volume = {217},
pages = {112169},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112169},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224002140},
author = {Tanjila Kanij and John Grundy and Jennifer McIntosh},
keywords = {Job advertisement, Gender bias},
abstract = {The majority of Information Technology (IT)/Software Engineering (SE) professionals are male. A potential reason for the low number of female IT/SE professionals might be that the roles and the way they are advertised are biased towards male candidates. The aim of this research is to collect information about the present state of practice of gender inclusiveness within IT/SE job advertisements and how, if needed, we might improve this. We conducted a survey of hiring managers and IT/SE professionals (who are employed in IT/SE roles). The survey collected their general views on gender bias within job advertisements. According to their opinions, job advertisements are often biased towards male candidates. Based on the review and suggestions from our participants we developed a set of recommendations to help hiring managers design more gender inclusive SE job advertisements. This will be a first step toward developing a gender balanced SE workforce.}
}
@article{LEENICH2023107220,
title = {Usefulness and usability of heuristic walkthroughs for evaluating domain-specific developer tools in industry: Evidence from four field simulations},
journal = {Information and Software Technology},
volume = {160},
pages = {107220},
year = {2023},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2023.107220},
url = {https://www.sciencedirect.com/science/article/pii/S0950584923000745},
author = {Olaf Leßenich and Stefan Sobernig},
keywords = {Domain-specific language, Integrated development environment, User experience, Programmer experience, Review, Heuristic walkthrough},
abstract = {Context:
The usage of domain-specific languages (DSLs) is an approach to reduce complexity in software development by expert developers for selected application domains. To support expert developers, a DSL is often combined with a tailored, domain-specific developer tool, offering similar functionality as general-purpose programming environments (IDEs like Eclipse for Java) while integrating with a domain-specific toolchain (e.g., code or documentation generators, simulators). General-purpose development environments have been successfully evaluated for the programmer experience (PX) and for anomalies using heuristic walkthroughs as a mixed review technique combining cognitive walkthroughs and a heuristic evaluation.
Objective:
In this paper, we report on the usefulness and acceptance of heuristic walkthroughs as an PX evaluation technique applied to domain-specific languages and IDEs in an industry context.
Methods:
Heuristic walkthroughs are used in four interventions (field simulations) to assess the programming experience and usability of domain-specific, Eclipse-based IDEs in a concrete industry setting. Data on the usefulness and acceptance (perceived satisfaction) of the walkthroughs themselves are collected and analysed.
Results:
Our studies show that, in practice, the instrument of walkthroughs is useful for revealing practically relevant PX anomalies, while maintaining acceptance by practitioners participating in the walkthroughs.
Conclusion:
The documented variant of heuristic walkthroughs is eligible to become adopted for future field studies in academic research and for evaluation projects in industry, in support of developing domain-specific developer tooling in an evidence-driven manner.}
}
@article{ARTEMCHUK2025e42802,
title = {Unified resilience model using deep learning for assessing power system performance},
journal = {Heliyon},
volume = {11},
number = {4},
pages = {e42802},
year = {2025},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2025.e42802},
url = {https://www.sciencedirect.com/science/article/pii/S2405844025011831},
author = {Volodymyr Artemchuk and Iurii Garbuz and Jamil Abedalrahim {Jamil Alsayaydeh} and Vadym Shkarupylo and Andrii Oliinyk and Mohd Faizal {Bin Yusof} and Safarudin Gazali Herawan},
keywords = {Deep learning, Energy resilience, Fidelity, Weather impact},
abstract = {Energy resilience in renewable energy sources dissemination components such as batteries and inverters is crucial for achieving high operational fidelity. Resilience factors play a vital role in determining the performance of power systems, regardless of their operating environment and interruptions. This article introduces a Unified Resilience Model (URM) using Deep Learning (DL) to enhance power system performance. The proposed model analyzes environmental factors impacting the resilience of batteries and energy storage devices. This deep learning approach trains performance-impacting factors using previously known low resilience drain data. The learning output is utilized to augment various strengthening factors, thereby improving resilience. Drain mitigation and performance improvements are combined for direct impact verification. This process validates the model's fidelity in enhancing power system performance, with a specific focus on the impact of weather factors.}
}
@article{HEYMANN2025104167,
title = {Digitalization, autonomy and the future of energy policy},
journal = {Energy Research & Social Science},
volume = {127},
pages = {104167},
year = {2025},
issn = {2214-6296},
doi = {https://doi.org/10.1016/j.erss.2025.104167},
url = {https://www.sciencedirect.com/science/article/pii/S2214629625002488},
author = {Fabian Heymann and Sinan Küfeoğlu and Matthias Galus},
keywords = {Artificial intelligence, Autonomous agents, Energy policy, Regulation, Innovation, Digitalization},
abstract = {Digital technologies and the increasing availability and use of data are transforming policymaking worldwide. While many studies have carved out the current effects, benefits and risks of data and digital technologies for policymaking, little attempts have been made to analyze the potential directions these trends will eventually lead to. Using a conceptual lens, we start by briefly describing the digitalization phenomena and how digital technologies are currently adopted along the policymaking cycle, with a special emphasis on energy policy. Building on these findings, and lending theoretical foundations from autonomous systems and control, we develop an outlook on the potential evolution of energy policymaking under further digitalization. Applying the elaborated 6-staged framework of autonomy in policymaking, we show that energy policymaking witnesses a mostly unnoted shift towards higher autonomy levels, being only halfway from what would be fully autonomous policymaking. The increasingly automated policymaking process, in energy policy and beyond, does raise important societal questions - on the technical design, societal trade-offs and ethical dilemmas that should become urgently addressed.}
}
@article{PR2025523,
title = {Algorithmic solutions, subjectivity and decision errors: a study of AI accountability},
journal = {Digital Policy, Regulation and Governance},
volume = {27},
number = {5},
pages = {523-552},
year = {2025},
issn = {2398-5038},
doi = {https://doi.org/10.1108/DPRG-05-2024-0090},
url = {https://www.sciencedirect.com/science/article/pii/S2398503824000018},
author = {Biju P.R. and Gayathri O.},
keywords = {India, Algorithms, AI accountability, Decision errors, Subjectivity},
abstract = {Purpose
The purpose of this paper is to explore the challenges of implementing accountable artificial intelligence (AI) systems in India, focusing on the need for algorithms to justify their decisions, especially in subjective and complex scenarios. By analyzing various government projects, documented biases and conducting empirical case studies and experiments, the study highlights the limitations of AI in recognizing the nuances of India’s unique social landscape. It aims to underscore the importance of integrating political philosophy to ensure that AI systems are held accountable within India’s sociopolitical context, urging policymakers to develop frameworks for responsible AI decision-making.
Design/methodology/approach
The research adopts a mixed-methods approach to address the five research questions. It begins with an extensive literature review, focusing on AI’s transformative potential, algorithmic bias and accountability in the Indian context. Data is collected from 15 AI use cases in health care, education and public safety, 13 government automated decision tools and five bias cases, including facial recognition and caste-based discrimination. Additionally, ten case studies and three experiments on ChatGPT are analyzed. Content analysis is used to interpret and categorize the data, identifying patterns and themes. Specific case studies and experiments on autocompletion in search engines further support the findings.
Findings
The study revealed significant limitations in current AI systems when applied to India’s complex socio-cultural landscape. Analyzing 15 AI applications and 13 government projects, the research identified multiple instances of algorithmic bias. Experiments with Google’s autocomplete and ChatGPT showed that these systems often reinforce social stereotypes and struggle with nuanced, subjective situations. The findings emphasize the accountability gap in AI-driven decisions, highlighting the need for rigorous oversight, particularly in welfare projects where errors could lead to severe consequences. The study recommends developing regulatory frameworks, improving AI design and raising public awareness to address these challenges.
Originality/value
In the context of complex societies like India, a pressing concern arises: who should assume responsibility for the repercussions stemming from algorithmic failures to comprehend subjective complexities? To this end, there exist no serious scholarly works toward which present paper tries to shed new insights. It draws upon insights from the corpus of political philosophy literature, encompassing both classical and contemporary notions of responsibility, and seeks to establish connections between these concepts and the unique sociopolitical structure of India. The work is unique in the focus of the paper and is original in the direction projected.}
}
@article{MINANI2025112408,
title = {IoT systems testing: Taxonomy, empirical findings, and recommendations},
journal = {Journal of Systems and Software},
volume = {226},
pages = {112408},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2025.112408},
url = {https://www.sciencedirect.com/science/article/pii/S0164121225000767},
author = {Jean Baptiste Minani and Yahia El Fellah and Fatima Sabir and Naouel Moha and Yann-Gaël Guéhéneuc and Martin Kuradusenge and Tomoaki Masuda},
keywords = {IoT testing taxonomy, IoT systems testing taxonomy, Software engineering taxonomy, Quality assurance taxonomy, Testing approaches, Testing techniques, Application testing, System testing},
abstract = {The Internet of Things (IoT) is reshaping our lives, increasing the need for thorough pre-deployment testing. However, traditional software testing may not address the testing requirements of IoT systems, leading to quality challenges. A specific testing taxonomy is crucial, yet no widely recognized taxonomy exists for IoT system testing. We introduced an IoT-specific testing taxonomy that categorizes aspects of IoT systems testing into seven distinct categories. We mined testing aspects from 83 primary studies in IoT systems testing and built an initial taxonomy. This taxonomy was refined and validated through two rounds of surveys involving 16 and then 204 IoT industry practitioners. We assessed its effectiveness by conducting an empirical evaluation on two separate IoT systems, each involving 12 testers. Our findings categorize seven testing aspects: (1) testing objectives, (2) testing tools and artifacts, (3) testers, (4) testing stage, (5) testing environment, (6) Object Under Test (OUT) and metrics, and (7) testing approaches. The evaluation showed that testers equipped with the taxonomy could more effectively identify diverse test cases and scenarios. Additionally, we recommend new research opportunities to enhance the testing of IoT systems.}
}
@article{COHEN2024545,
title = {Digital, Technological and AI Skills for Smart Production Work Environment},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {19},
pages = {545-550},
year = {2024},
note = {18th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.09.269},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324016987},
author = {Yuval Cohen and Hila Chalutz–Ben Gal},
keywords = {Skills, Collaborative Work, Smart Manufacturing, Industry 5.0, Human in the loop, Cobot},
abstract = {This paper analyses the past and anticipated developments in collaborative smart production work environment and points at the required skills to best utilize and flourish in this newly formed work environment. The paper identifies the new work requirements using the job type and its related required technologies and maps the work requirements to the set of skills that may fulfill these requirements. An important notion in this paper is that a shopfloor usually involves several different work environments, each with its unique set of work requirements and associated skills. Thus, tailoring a subset of skills to these set of requirements is the suggested strategy. We use a small example of assembly shopfloor for illustrating the proposed approach. Finally, we propose future research related to this study.}
}
@article{DENG2023103323,
title = {Enimanal: Augmented cross-architecture IoT malware analysis using graph neural networks},
journal = {Computers & Security},
volume = {132},
pages = {103323},
year = {2023},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2023.103323},
url = {https://www.sciencedirect.com/science/article/pii/S016740482300233X},
author = {Liting Deng and Hui Wen and Mingfeng Xin and Hong Li and Zhiwen Pan and Limin Sun},
keywords = {IoT malware, Malware analysis, Malware classification, System call graph, Deep learning, Graph neural network},
abstract = {IoT malware analysis is crucial for understanding the behavior and purpose of malware samples. While deep learning methods have been applied to IoT malware analysis using sequences or graphs to represent system calls, these approaches have limitations in their semantic representation of system call names. This paper presents Enimanal, a novel cross-architecture IoT malware analysis method based on graph neural networks. Enimanal leverages information from the Linux Programmer Manual to improve the semantic representation of dynamic system call information. By fusing semantic and structural information, Enimanal constructs a unique feature representation called an attributed system call graph (ASCG). We evaluated Enimanal on a dataset of 63k IoT malware samples with 9 CPU architectures and find that it outperforms comparison methods by up to 46% in macro precision and 38% in macro recall, achieving macro precision, macro recall and macro f1-score of over 98%. Furthermore, we verify the robustness of Enimanal against “zero-day” IoT malware.}
}
@article{MATELESS202149,
title = {Pkg2Vec: Hierarchical package embedding for code authorship attribution},
journal = {Future Generation Computer Systems},
volume = {116},
pages = {49-60},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.10.020},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X20329976},
author = {Roni Mateless and Oren Tsur and Robert Moskovitch},
keywords = {Source code authorship attribution, Code embedding, Hierarchical neural networks},
abstract = {Authorship attribution of software is the task of identifying the author of a given piece of code. Code attribution is of importance in multiple scenarios, ranging from software plagiarism to cybersecurity. In this paper, we introduce authorship attribution of software packages that better reflect real-world scenarios in which code is organized in packages and written by teams. We present a novel approach for software package authorship attribution called Pkg2Vec, based on a hierarchical deep neural network (DNN) architecture, corresponding to the hierarchical nature of software (code) packages. The hierarchical neural network model consists of a token level encoder and an attention mechanism for a function level encoder, together producing package embedding. Beyond package embedding, we use keywords and API calls as resilient features, which reflect the programmer’s intention and style. Pkg2Vec is evaluated on a large dataset of public packages and compared to a number of other source code authorship attribution state-of-the-art algorithms. We find that Pkg2Vec significantly outperforms other approaches, achieving a 13% improvement in accuracy}
}
@article{CAO2025112528,
title = {Enhancing vulnerability repair through the extraction and matching of repair patterns},
journal = {Journal of Systems and Software},
volume = {230},
pages = {112528},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2025.112528},
url = {https://www.sciencedirect.com/science/article/pii/S0164121225001967},
author = {Xiansheng Cao and Junfeng Wang and Peng Wu},
keywords = {Deep learning, Vulnerability repair, Repair patterns, Optimal matching},
abstract = {The application of deep learning models in software vulnerability repair is increasingly crucial. However, current deep learning-based vulnerability repair models primarily rely on implicit learning when generating patches, making it challenging to effectively reuse existing repair patterns for new vulnerabilities. Additionally, while introducing large-scale external data helps leverage historical experience, it often leads to information redundancy and increased computational complexity. This paper introduces VulMatch, an automated vulnerability repair framework based on a pre-trained code model, aimed at vulnerability repair in C/C++ code. VulMatch explicitly extracts repair patterns from real-world vulnerabilities and matches new vulnerabilities to the optimal repair pattern, addressing current limitations. We validated VulMatch on a real-world dataset of 6,104 vulnerability repair samples. The results show that VulMatch achieved the highest accuracy over baseline methods, with gains in Perfect Match Rate (PMR@1) ranging from 29.8% to 586.8%, and CodeBLEU score improvements ranging from 6.34% to 248.56%. VulMatch also successfully repaired 141 out of 758 Top-25 most dangerous CWE vulnerabilities, surpassing state-of-the-art methods by 38 repairs, demonstrating its strong potential for addressing complex, critical security vulnerabilities.}
}
@article{CABALLEROTESTON2026129259,
title = {The role of automated planning in battle management systems for military tactics},
journal = {Expert Systems with Applications},
volume = {297},
pages = {129259},
year = {2026},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.129259},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425028751},
author = {J. {Caballero Testón} and Olaya Pérez-Mon and María D. R-Moreno},
keywords = {Artificial intelligence, Automated planning, Wireless sensor networks, Data fusion, Battle management systems, Behavior trees},
abstract = {Urban warfare presents complex and dynamic challenges for modern military operations, demanding adaptive and responsive support systems. This study presents a Battle Management System (BMS) based on a Wireless Sensor Network (WSN) integrated with an Artificial Intelligence (AI)-powered planner to address key operational issues such as task coordination, resource allocation, mobility management, energy optimization, and communication resilience. Unlike prior works, our study introduces a tightly coupled integration where real-time sensor data dynamically influences AI-generated plans, allowing mission adaptation under battlefield constraints. Our study covers the practical implementation of this AI-enhanced BMS, a showcase of its capabilities through comprehensive urban warfare simulations, its real-world validation at a military facility demonstrating its effectiveness in an operational setting, and a performance benchmarking against state-of-the-art planners, showing superior results in mission success, risk reduction, and resource efficiency. Our findings confirm that AI-driven planning, in conjunction with WSNs, can generate operational plans that address the unique demands of urban combat scenarios with high precision and efficiency.}
}
@article{CAPACHO2025101067,
title = {Diagnostic analysis and performance optimization of scalable computing systems in the context of industry 4.0},
journal = {Sustainable Computing: Informatics and Systems},
volume = {45},
pages = {101067},
year = {2025},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2024.101067},
url = {https://www.sciencedirect.com/science/article/pii/S2210537924001124},
author = {John William Vásquez Capacho and G. Pérez-Zuñiga and L. Rodriguez-Urrego},
keywords = {Scalable computing systems - SCS, V-nets, HPC energy performance, Discrete-time systems diagnosis, Industry 4.0},
abstract = {Escalating energy costs and sustainability concerns in high-performance computing (HPC) and industrial-scale systems demand advanced models for energy-efficient operations. Traditional discrete event system (DES) models, while valuable tools, often struggle with the complexities of real-world systems, particularly when dealing with simultaneous events, partial sequences, and false positives. To address these limitations, this paper introduces V-nets, a novel formalism that offers a more robust approach to modeling and analyzing complex event sequences. V-nets excel at handling concurrent events, incorporating temporal constraints, and accurately detecting partial sequences, leading to improved system diagnostics and energy efficiency. By leveraging V-nets, we can gain deeper insights into the behavior of complex systems, identify potential bottlenecks, and optimize resource allocation. This can lead to significant energy savings and improved system performance. For example, in HPC systems, V-nets can be used to monitor the energy consumption of individual components, identify idle resources, and optimize workload scheduling. In industrial settings, V-nets can help detect anomalies in production processes, leading to timely interventions and reduced downtime. The potential applications of V-nets are vast, extending beyond HPC systems to various industrial domains. As AI-driven workloads continue to grow in complexity, V-nets can play a crucial role in monitoring and optimizing energy consumption in these systems. By bridging the gap between theoretical advancements and real-world applications, V-nets have the potential to revolutionize the field of DES modeling and contribute to the development of more sustainable and efficient systems.}
}
@article{SCHINK2026103368,
title = {Transforming B2B platforms through interconnected digital twins: Enhancing situation awareness for decision-making},
journal = {Technovation},
volume = {149},
pages = {103368},
year = {2026},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2025.103368},
url = {https://www.sciencedirect.com/science/article/pii/S0166497225002007},
author = {Alexander Schink and Tobias Gutmann and Sebastian Brenk},
keywords = {Interconnected digital twins, Decision-making, Situation awareness, B2B platform ecosystem, Digital transformation, Industry 4.0, Digital manufacturing, Digitalization},
abstract = {Business-to-business (B2B) platforms hold transformative potential for manufacturing by enabling firms to collaborate, share data, and coordinate decisions across interconnected cyber-physical networks. However, many firms struggle to fully leverage these platforms due to bounded rationality, as decision-makers face difficulties in processing fragmented, heterogeneous, and real-time data streams. Interconnected Digital Twins (IDTs) offer a promising technological response to this challenge. By integrating data from multiple sources and simulating dynamic manufacturing processes across organizational boundaries, IDTs create shared, real-time representations of operations that support decision-making in complex B2B ecosystems. Grounded in Endsley's Situation Awareness Theory, this study examines how IDTs support perception, comprehension, and projection in cross-organizational decision-making. We conducted an exploratory qualitative case study of a leading automotive manufacturer, drawing on ethnographic access to its IDT implementation. Our findings show that IDTs enhance situation awareness and support cross-organizational decision-making by consolidating fragmented data and reducing cognitive overload through simulation. The study contributes to B2B platform ecosystem research by identifying IDTs as a technological enabler of digital transformation and demonstrating their role in enhancing situation awareness in industrial ecosystems.}
}
@article{ZHENG2025112109,
title = {Causality-Enhanced System Reliability and Safety Analysis: An Overview},
journal = {Reliability Engineering & System Safety},
pages = {112109},
year = {2025},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2025.112109},
url = {https://www.sciencedirect.com/science/article/pii/S0951832025013080},
author = {Shuwen Zheng and Kai Pan and Yunxia Chen and Jie Liu and Enrico Zio},
keywords = {causality, artificial intelligence, machine learning, system reliability, system safety},
abstract = {Ensuring system reliability and safety is paramount for all industries, particularly critical ones like aerospace, nuclear, chemical where failures can lead to catastrophic consequences. Traditional causality-based methods, such as Fault Tree Analysis (FTA) and causal Bayesian networks, have long been employed but face limitations in scalability and adaptability. Recently, data-driven approaches have emerged as a powerful way of mapping complex and nonlinear relations, but these approaches often lack interpretability and struggle with accuracy under data distribution shifts occurring during system life. This paper systematically explores the integration of causality theory into system reliability and safety for bridging the gap between conventional techniques and modern advancements in causal inference and reasoning. We analyze three key approaches: causal discovery algorithms, causality-guided models and causal graph-based methods, covering their theoretical foundations and research applications. The review of the literatures highlights that causality-enhanced frameworks facilitate gaining deeper insights into system behavior, enabling improvements on model robustness, generalizability and transparency while mitigating spurious correlations. Furthermore, challenges like cross-scale and evolving causal dynamics motivate further dedication into causality-enhanced research. By embedding causality into system reliability and safety, this work underscores its potential in advancing system predictive maintenance, risk assessment and resilient design, paving the way towards trustworthy reliability and safety analysis.}
}
@article{ABADDI2025,
title = {Q-Omni: A quantum computing and GPT-4o solution for Camel-Vehicle Collisions},
journal = {International Journal of Transportation Science and Technology},
year = {2025},
issn = {2046-0430},
doi = {https://doi.org/10.1016/j.ijtst.2025.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S2046043025000334},
author = {Samer Abaddi},
keywords = {Camel-vehicle collisions, Autonomous vehicles, Quantum computing, GPT-4o, Transportation science},
abstract = {Camel-Vehicle Collisions (CVCs) have been a major cause of public safety hazards in the Gulf countries, in particular, the United Arab Emirates and Saudi Arabia. It is similar to deer-vehicle collisions in the United States and kangaroo-vehicle collisions in Australia. When it comes to road accidents, each millisecond of early warning/detection matters, potentially transforming a life-threatening situation into a manageable incident. Therefore, this study aims to mitigate CVCs by integrating quantum computing and Generative Pretrained Transformer-4Omni (GPT-4o) into autonomous vehicles (AVs). Environmental data was sourced through high-accuracy sensors in conjunction with quantum algorithms and GPT-4o modules handling the processing through a multi-phase approach. The integration allowed for enhanced detection, tracking, and decision-making regarding camel movements. Heatmaps revealed heightened camel activity during low-visibility nighttime conditions and seasonal peaks, particularly during the breeding season. The quantum-enhanced algorithms achieved a mean detection accuracy of 95% and tracking precision of 92%, with computational speeds 10x that of classical methods. GPT-4o vision modules further improved object detection accuracy to 98.7%, securing (ʈ=0.97) seconds as an early warning to the AV’s braking system. This innovative approach offers a novel paradigm in AV technology, setting new standards for safety and efficiency in transportation. Future GPT-5 models can be used in AVs and with sophisticated technologies for safer driving and wildlife protection. The results obtained from this study go beyond updating AV safety technology, opening avenues for application in urban planning and real-time hazard detection systems.}
}
@article{REICHENSTEIN2025837,
title = {Role-based manufacturing systems: A concept towards intelligent and adaptive automation in manufacturing},
journal = {Procedia CIRP},
volume = {134},
pages = {837-842},
year = {2025},
note = {58th CIRP Conference on Manufacturing Systems 2025},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2025.02.187},
url = {https://www.sciencedirect.com/science/article/pii/S2212827125005918},
author = {Tobias Reichenstein and Alexander Müller and Baris Eray Albayrak and Luca Werthmann and Till Sindel and Alexander Schneider and Jan Hinrich Krüger and Benjamin Gutwald and Martin Barth and Jörg Franke},
keywords = {manufacturing systems, self-organization, artificial intelligence, multi-agent systems},
abstract = {The advancement of technologies related to smart manufacturing has brought new potentials to manufacturing systems (MS). In particular, the use of artificial intelligence (AI) in MS facilitates their self-organization and self-optimization capabilities. However, companies are facing an increasing skills shortage, consequently relying on AI to solve this issue. Therefore, this paper introduces the concept of role-based MS (RBMS) capable of performing key tasks in manufacturing companies. Concepts for three roles in RBMS are presented, as well as possible realization approaches with an emphasis on the required technologies. An exemplary multi-agent reinforcement learning based energy management use cases illustrates the interplay between the three roles. Future research needs focus on evaluating the results of RBMS use cases.}
}
@article{RAMAN2024e24727,
title = {Fake news research trends, linkages to generative artificial intelligence and sustainable development goals},
journal = {Heliyon},
volume = {10},
number = {3},
pages = {e24727},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e24727},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024007588},
author = {Raghu Raman and Vinith {Kumar Nair} and Prema Nedungadi and Aditya {Kumar Sahu} and Robin Kowalski and Sasangan Ramanathan and Krishnashree Achuthan},
keywords = {Deep fake, Ethics, Fake news, Generative AI, Prominence percentile, Sustainable development goal},
abstract = {In the digital age, where information is a cornerstone for decision-making, social media's not-so-regulated environment has intensified the prevalence of fake news, with significant implications for both individuals and societies. This study employs a bibliometric analysis of a large corpus of 9678 publications spanning 2013–2022 to scrutinize the evolution of fake news research, identifying leading authors, institutions, and nations. Three thematic clusters emerge: Disinformation in social media, COVID-19-induced infodemics, and techno-scientific advancements in auto-detection. This work introduces three novel contributions: 1) a pioneering mapping of fake news research to Sustainable Development Goals (SDGs), indicating its influence on areas like health (SDG 3), peace (SDG 16), and industry (SDG 9); 2) the utilization of Prominence percentile metrics to discern critical and economically prioritized research areas, such as misinformation and object detection in deep learning; and 3) an evaluation of generative AI's role in the propagation and realism of fake news, raising pressing ethical concerns. These contributions collectively provide a comprehensive overview of the current state and future trajectories of fake news research, offering valuable insights for academia, policymakers, and industry.}
}
@article{WANG2026112709,
title = {Assessing UML diagrams by GPT: Implications for education},
journal = {Journal of Systems and Software},
volume = {234},
pages = {112709},
year = {2026},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2025.112709},
url = {https://www.sciencedirect.com/science/article/pii/S0164121225003784},
author = {Chong Wang and Beian Wang and Peng Liang and Jie Liang},
keywords = {UML Diagram, GPT, Model assessment, Software modeling education},
abstract = {In software engineering (SE) research and practice, UML is well known as an essential modeling methodology for requirements analysis and software modeling in both academia and industry. In particular, fundamental knowledge of UML modeling and practice in creating high-quality UML diagrams are included in SE-relevant courses in the undergraduate programs of many universities. This leads to a time-consuming and labor-intensive task for educators to review and grade a large number of UML diagrams created by the students. Recent advances in generative AI techniques, such as GPT, have paved new ways to automate many SE tasks. However, current research or tools seldom explore the capabilities of GPT in evaluating the quality of UML diagrams. This paper aims to investigate the feasibility and performance of GPT in assessing the quality of UML use case diagrams, class diagrams, and sequence diagrams. First, 11 evaluation criteria with grading details were proposed for these UML diagrams. Next, a series of experiments was designed and conducted on 40 students’ UML modeling reports to explore the performance of GPT in evaluating and grading these UML diagrams. The research findings reveal that GPT can complete this assessment task, but it cannot replace human experts yet. Meanwhile, there are five evaluation discrepancies between GPT and human experts. These discrepancies vary in the use of different evaluation criteria in different types of UML diagrams, presenting GPT’s strengths and weaknesses in this automatic evaluation task.}
}
@article{GONDA2026103199,
title = {Charting the ChatGPT landscape: Insights from academic discourse on Twitter},
journal = {Technology in Society},
volume = {85},
pages = {103199},
year = {2026},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.103199},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25003896},
author = {Raphael Gonda and Jaehun Park},
keywords = {ChatGPT, Sentiment analysis, Time-series analysis, Twitter(, , )},
abstract = {In the wake of the emergence of ChatGPT as a transformative tool, effective policies and regulations for its integration into research and education are vital. This paper addresses challenges in the rapidly evolving AI landscape by identifying key events and discussions. To that end, the current study extracted insights from the academic community that had come during the early stages of ChatGPT's adoption. A dataset of 84,706 sentences sourced from Twitter (X.com) users in the research and academic community and collected over the course of eight months between November 2022 and June 2023 were examined using topic modeling and aspect-based sentiment analysis to explore prevailing reactions and perceptions. Nine key themes such as academic writing, coding, and time-saving tasks were identified. Strong sentiments emerged around policy debates, the issue of data security, and evolving research practices. Further, a causal analysis was performed to identify discussions and events that had triggered shifts in public sentiment. Examples include temporary restrictions on generative AI, new institutional policies, and legislative efforts to ensure responsible AI integration. This paper provides a timeline-linked perspective on how the academic community, thus far, has responded to generative AI. The findings can inform pragmatic, context-sensitive policies that foster innovation while safeguarding academic values.}
}
@article{TAYOURI2025104296,
title = {CORAL: Container Online Risk Assessment with Logical attack graphs},
journal = {Computers & Security},
volume = {150},
pages = {104296},
year = {2025},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.104296},
url = {https://www.sciencedirect.com/science/article/pii/S0167404824006023},
author = {David Tayouri and Omri {Sgan Cohen} and Inbar Maimon and Dudu Mimran and Yuval Elovici and Asaf Shabtai},
keywords = {Container risk assessment, Attack graphs, Kubernetes, Vulnerability analysis, Risk exposure},
abstract = {Container-based architectures, with their highly volatile runtime configurations, rapid code changes, and dependence on third-party code, have raised security concerns. The first step in establishing solid security footing in a production application is understanding its risk exposure profile. Attack graphs (AGs), which organize the topology and identified vulnerabilities into possible attack paths as part of a larger graph, help organizations assess and prioritize risks and establish a baseline for countermeasure planning and remediation. Although AGs are valuable, their use in the container environment, where the AG must be repeatedly rebuilt due to frequent data changes, is challenging. In this paper, we present a novel approach for efficiently building container-based AGs that meets the needs of highly dynamic, real-life applications. We propose CORAL, a framework for identifying attack paths between containers, which does not require rebuilding the graph each time the underlying architecture (code or topology) changes. CORAL accomplishes this by intelligently disregarding changes that should not trigger AG build and reusing fragments of existing AGs. We propose a model to evaluate the attack paths’ risks and highlighting the riskiest path in any AG. We evaluate CORAL’s performance in maintaining an up-to-date AG for an environment with many containers. Our proposed framework demonstrated excellent performance for large topologies — searching similar topologies and reusing their AGs was two orders of magnitude faster than AG regeneration. We demonstrate how CORAL can assist in efficiently detecting lateral movement attacks in containerized environments using provenance graphs.}
}
@article{ALI2025100762,
title = {Comprehending the theoretical knowledge and practice around AI-enabled innovations in the finance sector},
journal = {Journal of Innovation & Knowledge},
volume = {10},
number = {5},
pages = {100762},
year = {2025},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2025.100762},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X25001076},
author = {Omar Ali and Peter A. Murray and Ahmad Al-Ahmad and Il Jeon and Yogesh K. Dwivedi},
keywords = {Artificial intelligence, Machine learning, Innovation, Comprehending theory},
abstract = {This study adopts a comprehending theory (CT) approach towards understanding machine learning (ML) for theory and practice within the finance sector. In building on prior research, the study explores the hidden meanings of ML phenomena and connects them to the underlying financial motivation behind the actions of financial firms to create greater intellectual insight for users in practice. At its most basic, the study explores why the meaning and conception of ML is confusing and ambivalent for users in the sector. Through a scoping review, only top-tier quartile one publications between the years of 2014 to 2024 were chosen for the review with 167 articles selected for analysis. In making a significant contribution to theory, a classification framework was developed to provide greater meaning and clarification of different ML criteria. The study matches relevant CT criteria with the opportunities and challenges of ML identifying significant differences between theory and practice. The study thus substantially contributes to broadening and extending existing knowledge related to ML in the financial sector by better explaining what these gaps look like and what to do about them for future research.}
}
@article{WOLF2024103993,
title = {Benchmarking of synthetic network data: Reviewing challenges and approaches},
journal = {Computers & Security},
volume = {145},
pages = {103993},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.103993},
url = {https://www.sciencedirect.com/science/article/pii/S0167404824002980},
author = {Maximilian Wolf and Julian Tritscher and Dieter Landes and Andreas Hotho and Daniel Schlör},
keywords = {NetFlow, Synthetic data, Generator, GPT, GAN, Benchmark, Evaluation},
abstract = {The development of Network Intrusion Detection Systems (NIDS) requires labeled network traffic, especially to train and evaluate machine learning approaches. Besides the recording of traffic, the generation of traffic via generative models is a promising approach to obtain vast amounts of labeled data. There exist various machine learning approaches for data generation, but the assessment of the data quality is complex and not standardized. The lack of common quality criteria complicates the comparison of synthetic data generation approaches and synthetic data. Our work addresses this gap in multiple steps. Firstly, we review and categorize existing approaches for evaluating synthetic data in the network traffic domain and other data domains as well. Secondly, based on our review, we compile a setup of metrics that are suitable for the NetFlow domain, which we aggregate into two metrics Data Dissimilarity Score and Domain Dissimilarity Score. Thirdly, we evaluate the proposed metrics on real world data sets, to demonstrate their ability to distinguish between samples from different data sets. As a final step, we conduct a case study to demonstrate the application of the metrics for the evaluation of synthetic data. We calculate the metrics on samples from real NetFlow data sets to define an upper and lower bound for inter- and intra-data set similarity scores. Afterward, we generate synthetic data via Generative Adversarial Network (GAN) and Generative Pre-trained Transformer 2 (GPT-2) and apply the metrics to these synthetic data and incorporate these lower bound baseline results to obtain an objective benchmark. The application of the benchmarking process is demonstrated on three NetFlow benchmark data sets, NF-CSE-CIC-IDS2018, NF-ToN-IoT and NF-UNSW-NB15. Our demonstration indicates that this benchmark framework captures the differences in similarity between real world data and synthetic data of varying quality well, and can therefore be used to assess the quality of generated synthetic data.}
}
@article{AKKEM2024107881,
title = {A comprehensive review of synthetic data generation in smart farming by using variational autoencoder and generative adversarial network},
journal = {Engineering Applications of Artificial Intelligence},
volume = {131},
pages = {107881},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.107881},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624000393},
author = {Yaganteeswarudu Akkem and Saroj Kumar Biswas and Aruna Varanasi},
keywords = {Variational autoencoders, Generative adversarial networks, Smart farming},
abstract = {In this study, we propose the use of Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) to generate synthetic data for crop recommendation (CR). CR is critical in agriculture, assisting farmers in making informed decisions about crop cultivation, considering factors like soil conditions, weather patterns etc. Unfortunately, the availability of labeled data for CR is often limited, posing a significant challenge in training accurate recommendation models. VAEs and GANs are employed to create synthetic data that closely mirrors real-world crop data. VAEs are utilized to extract latent representation from the input data, enabling the generation of new samples with similar characteristics. GANs play a crucial role in generating data by training a generator network to produce synthetic samples that closely resemble real data, while a discriminator network distinguishes between genuine and synthetic data. The generated synthetic data serves as a valuable resource to prepare datasets for CR, enhancing the performance of recommendation models. Our research explores the effectiveness of VAEs and GANs in producing high-quality synthetic CR data, facilitating improved training and evaluation of recommendation systems. This paper presents the architecture and training process of the proposed models and evaluates the quality and utility of the generated synthetic data using various experiments, including visualizations such as heatmaps, scatter plots, cumulative sum per feature plots, and distribution per feature plots. The results of this study hold the potential to make a significant contribution to the field of agriculture by providing a reliable and abundant source of training data for CR systems.}
}
@article{ADHIKARY2024101365,
title = {TinyWolf — Efficient on-device TinyML training for IoT using enhanced Grey Wolf Optimization},
journal = {Internet of Things},
volume = {28},
pages = {101365},
year = {2024},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2024.101365},
url = {https://www.sciencedirect.com/science/article/pii/S2542660524003068},
author = {Subhrangshu Adhikary and Subhayu Dutta and Ashutosh Dhar Dwivedi},
keywords = {Internet of Things, Evolutionary algorithms, Deep learning, Nature inspired algorithms, Embedded intelligence, Memory optimization},
abstract = {Training a deep learning model generally requires a huge amount of memory and processing power. Once trained, the learned model can make predictions very fast with very little resource consumption. The learned weights can be fitted into a microcontroller to build affordable embedded intelligence systems which is also known as TinyML. Although few attempts have been made, the limits of the state-of-the-art training of a deep learning model within a microcontroller can be pushed further. Generally deep learning models are trained with gradient optimizers which predict with high accuracy but require a very high amount of resources. On the other hand, nature-inspired meta-heuristic optimizers can be used to build a fast approximation of the model’s optimal solution with low resources. After a rigorous test, we have found that Grey Wolf Optimizer can be modified for enhanced uses of main memory, paging and swap space among α,β,δ and ω wolves. This modification saved up to 71% memory requirements compared to gradient optimizers. We have used this modification to train the TinyML model within a microcontroller of 256KB RAM. The performances of the proposed framework have been meticulously benchmarked on 13 open-sourced datasets.}
}
@article{KOUSTAS2024864,
title = {Uncovering the potential of chatbots during the development of industrial smart product-service systems},
journal = {Procedia CIRP},
volume = {128},
pages = {864-869},
year = {2024},
note = {34th CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.07.068},
url = {https://www.sciencedirect.com/science/article/pii/S221282712400790X},
author = {Spyridon Georg Koustas and Julius Kirschbaum and Kathrin M. Möslein},
keywords = {Industry chatbots, IoT sensors, Industrial Product-Service Systems (IPSS)},
abstract = {Digitalization of manufacturing processes led to the emergence of smart product-service systems (sPSS), the development of which requires expertise across multiple domains, while the Internet of Things (IoT) technology landscape poses challenges regarding hardware selection. This paper proposes an industry chatbot that employs GPT-4 and bge-base-en models to assist manufacturers during the IoT sensor search and selection process. The chatbot utilizes a vectorized knowledge base to provide technical insights and recommend compatible hardware. User tests conducted with both experts and novices revealed the chatbot’s accuracy and potential for improvement. Overall, this approach holds promise for expediting the development of sPSS.}
}
@article{CHEN202568,
title = {Future Manufacturing with AI-Driven Particle Vision Analysis in the Microscopic World},
journal = {Engineering},
volume = {52},
pages = {68-84},
year = {2025},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2025.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S2095809925004680},
author = {Guangyao Chen and Fengqi You},
keywords = {Particle vision analysis, AI-driven microscopic imaging, Smart manufacturing},
abstract = {Recent advances in artificial intelligence (AI) have led to the development of sophisticated algorithms that significantly improve image analysis capabilities. This combination of AI and microscopic imaging is transforming the way we interpret and analyze imaging data, simplifying complex tasks and enabling innovative experimental methods previously thought impossible. In smart manufacturing, these improvements are especially impactful, increasing precision and efficiency in production processes. This review examines the convergence of AI with particle image analysis, an area we refer to as “particle vision analysis (PVA).” We offer a detailed overview of how this technology integrates into and impacts various fields within the physical sciences and materials sectors, where it plays a crucial role in both innovation and operational improvements. We explore four key areas of advancement—namely, particle classification, detection, segmentation, and object tracking—along with a look into the emerging field of augmented microscopy. This paper also underscores the vital role of the existing datasets and implementations that support these applications, which provide essential insights and resources that drive continuous research and development in this fast-evolving field. Our thorough analysis aims to outline the transformative potential of AI-driven PVA in improving precision in future manufacturing at the microscopic scale and thereby preparing the ground for significant technological progress and broad industrial applications in nanomanufacturing, biomanufacturing, and pharmaceutical manufacturing. This exploration not only highlights the advantages of integrating AI into conventional manufacturing processes but also anticipates the rise of next-generation smart manufacturing, which is set to revolutionize industry standards and operational practices.}
}
@article{SIMJANOSKAMISHEVA2025,
title = {AI Act Compliance Within the MyHealth@EU Framework: Tutorial},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/81184},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125014657},
author = {Monika {Simjanoska Misheva} and Dragan Shahpaski and Jovana Dobreva and Djansel Bukovec and Blagojche Gjorgjioski and Marjan Nikolov and Dalibor Frtunikj and Petre Lameski and Azir Aliu and Kostadin Mishev and Matjaž Gams},
keywords = {AI Act, MyHealth@EU, OpenNCP, HL7 CDA, HL7 FHIR, Fast Healthcare Interoperability Resources, generative AI, interoperability, trustworthiness, reliability, compliance},
abstract = {The integration of artificial intelligence (AI) into clinical workflows is advancing even before full compliance with the European Union Cross-Border eHealth Network (MyHealth@EU) framework is achieved. While AI-based clinical decision support systems are automatically classified as high risk under the European Union’s AI Act, cross-border health data exchange must also satisfy MyHealth@EU interoperability requirements. This creates a dual-compliance challenge: vertical safety and ethics controls mandated by the AI Act and horizontal semantic transport requirements enforced through Open National Contact Point (OpenNCP) gateways, many of which are still maturing toward production readiness. This paper provides a practical, phase-oriented tutorial that enables developers and providers to embed AI Act safeguards before approaching MyHealth@EU interoperability tests. The goal is to show how AI-specific metadata can be included in the Health Level Seven International Clinical Document Architecture and Fast Healthcare Interoperability Resources messages without disrupting standard structures, ensuring both compliance and trustworthiness in AI-assisted clinical decisions. We systematically analyzed Regulation (EU) 2024/1689 (AI Act) and the OpenNCP technical specifications, extracting a harmonized set of overlapping obligations. The AI Act provisions on transparency, provenance, and robustness are mapped directly onto MyHealth@EU workflows, identifying the points where outgoing messages must record AI involvement, log provenance, and trigger validation. To operationalize this mapping, we propose a minimal extension set, covering AI contribution status, rationale, risk classification, and Annex IV documentation links, together with a phase-based compliance checklist that aligns AI Act controls with MyHealth@EU conformance steps. A simulated International Patient Summary transmission demonstrates how Clinical Document Architecture/Fast Healthcare Interoperability Resources extensions can annotate AI involvement, how OpenNCP processes such enriched payloads, and how clinicians in another member state view the result with backward compatibility preserved. We expand on security considerations (eg, Open Worldwide Application Security Project generative AI risks such as prompt injection and adversarial inputs), continuous postmarket risk assessment, monitoring, and alignment with MyHealth@EU’s incident aggregation system. Limitations reflect the immaturity of current infrastructures and regulations, with real-world validation pending the rollout of key dependencies. AI-enabled clinical software succeeds only when AI Act safeguards and MyHealth@EU interoperability rules are engineered together from day 0. This tutorial provides developers with a forward-looking blueprint that reduces duplication of effort, streamlines conformance testing, and embeds compliance early. While the concept is still in its early phases of practice, it represents a necessary and worthwhile direction for ensuring that future AI-enabled clinical systems can meet both European Union regulatory requirements from day 1.
risks such as prompt injection and adversarial inputs), continuous postmarket risk assessment, monitoring, and alignment with MyHealth@EU’s incident aggregation system. Limitations reflect the immaturity of current infrastructures and regulations, with real-world validation pending the rollout of key dependencies.}
}
@article{LING2026103088,
title = {Vision-based extraction of industrial information from legacy Programmable Logic Controllers},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {97},
pages = {103088},
year = {2026},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2025.103088},
url = {https://www.sciencedirect.com/science/article/pii/S0736584525001425},
author = {Zhengyang Ling and Sam Brooks and Duncan McFarlane and Alan Thorne and Gregory Hawkridge},
keywords = {Programmable Logic Controllers, Vision system, Retrofitting, Data extraction},
abstract = {Technological advancements in manufacturing are increasingly driven by connectivity and information that can be collected about manufacturing processes. Programmable Logic Controllers (PLCs) are a valuable source of process information which can help inform operations. However, many factories use legacy PLCs with restricted connection and data extraction capabilities. This paper presents a novel vision-based PLC monitoring method for extracting the input and output (I/O) states of a PLC in real time. Four case studies in industry and laboratory settings are presented; in each case study, vision-based PLC monitoring was used to extract I/O data successfully and provide data for applications such as operation monitoring, process monitoring, production counting and fault detection. Vision-based monitoring is evaluated and compared to other PLC monitoring methods using a set of key requirements. The vision-based monitoring method showed several improvements over existing PLC data extraction methods; these include no PLC control system interference, minimal disruption during installation, system security, and cost-effective design. This new vision-based PLC monitoring method has the potential to provide manufacturers with a method to retrofit PLCs to access new valuable sources of information that can be used to improve their operation or create a smart factory at a lower cost.}
}
@article{BORDALLOLOPEZ2025100952,
title = {A Cyberpunk 2077 perspective on the prediction and understanding of future technology},
journal = {Entertainment Computing},
volume = {54},
pages = {100952},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2025.100952},
url = {https://www.sciencedirect.com/science/article/pii/S1875952125000321},
author = {Miguel {Bordallo López} and Constantino {Álvarez Casado}},
keywords = {Future technology, Videogames, Cyberpunk, Predictions},
abstract = {Science fiction and video games have long served as valuable tools for envisioning and inspiring future technological advancements. This position paper investigates the potential of Cyberpunk 2077, a popular science fiction video game, to shed light on the future of technology, particularly in the areas of artificial intelligence, edge computing, augmented humans, and biotechnology. By analyzing the game’s portrayal of these technologies and their implications, we aim to understand the possibilities and challenges that lie ahead. We discuss key themes such as neural links and brain–computer interfaces, multimodal recording systems, virtual and simulated reality, digital representation of the physical world, augmented and AI-based home appliances, smart clothing, and autonomous vehicles. The paper highlights the importance of designing technologies that can coexist with existing preferences and systems, considering the uneven adoption of new technologies. Through this exploration, we emphasize the potential of science fiction and video games like Cyberpunk 2077 as tools for guiding future technological advancements and shaping public perception of emerging innovations.}
}
@article{FERREIRA20242521,
title = {Digital twinning for smart restoration of classic cars},
journal = {Procedia Computer Science},
volume = {232},
pages = {2521-2530},
year = {2024},
note = {5th International Conference on Industry 4.0 and Smart Manufacturing (ISM 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.02.070},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924002473},
author = {Frederico Ferreira and Vasco Amaral and Fernando {Brito e Abreu}},
keywords = {digital twin, classic cars, bodywork restoration, digital transformation, industry 4.0, IoT},
abstract = {Classic cars hold substantial value in the automotive industry, and the restoration process plays a pivotal role in increasing their worth. Ensuring the certification of these restoration processes is vital, as is keeping owners well-informed about the ongoing procedures taking place in their appreciated vehicles. By monitoring and controlling these restoration activities, the management of classic car workshops can effectively optimize their operations, empower owners with pertinent information, and preserve the authentic nature of these vintage automobiles. This study aims to develop a digital twin system for a classic car bodywork restoration shop workshop. The latter integrates multiple sensor technologies, including location tracking, humidity and temperature sensing, accelerometer monitoring, and smart plugs, to facilitate the identification of ongoing activities of classic car bodywork restoration process instances. By leveraging these sensors, the digital twin system may simulate and control workshop operations more effectively. We perform a systematic rapid review of related work and, based on state-of-the-art practices, we identify existing architectures and software applications used for creating digital twin systems. Then, we propose the architecture for our digital twin system, detailing its functionalities. We aim at contributing to advancing digital twin technology in classic car bodywork restoration, enhancing its authenticity, and fostering improved management practices, and overall experience for classic car owners.}
}
@article{CARAVEOCACEP2024103677,
title = {A review on security implementations in soft-processors for IoT applications},
journal = {Computers & Security},
volume = {139},
pages = {103677},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2023.103677},
url = {https://www.sciencedirect.com/science/article/pii/S0167404823005874},
author = {Miguel Antonio Caraveo-Cacep and Rubén Vázquez-Medina and Antonio {Hernández Zavala}},
keywords = {Internet of Things (IoT), Security in IoT, Soft-processor, Cybersecurity, Secure-processor},
abstract = {With the increase in the number of devices connected to the Internet, the need to maintain and harden information security in Internet systems has significantly increased. This has led to the development of hardware systems that implement security services. Therefore, from a taxonomy to sort and classify the key criteria to processor design, an overview and in-depth analysis of soft-processors that implement algorithms for Internet of Thing applications is presented highlighting their advantages and disadvantages to be used in larger systems. In order to perform a systematic review of the engineering literature related to the interest topic in this work, a bidirectional review methodology consisting of the following three phases has been proposed and applied: review planning, review conducting, and review reporting. Then, soft-processor architectures implementing security algorithms are compared considering computational cost, speed, bus size, number of pipeline stages, and performance. Finally, based on a feature analysis, the strengths and threats of soft-processors when implementing information security for Internet of Things applications are discussed, and the LORS design model is proposed to lead to recommendations for future designs.}
}
@article{KALIBATIENE2026104073,
title = {From manual to automated systematic review: Key attributes influencing the duration of systematic reviews in software engineering},
journal = {Computer Standards & Interfaces},
volume = {96},
pages = {104073},
year = {2026},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2025.104073},
url = {https://www.sciencedirect.com/science/article/pii/S0920548925001023},
author = {Diana Kalibatiene and Jolanta Miliauskaitė},
keywords = {Systematic literature review, Systematic review, Process modelling, Quality, Performance time, Duration, Software engineering research, Process performance measure, Digitalisation},
abstract = {Context
It is widely accepted that a systematic literature review (SLR) is an effective, comprehensive, repeatable, less biased, and transparent method for gathering and condensing knowledge from existing scientific publications. The SLR method facilitates the identification of gaps for new research opportunities, fostering decision-making based on evidence. At the same time, SLR is a time and effort-consuming task that is threatened by the increasing volume of publications. However, there is a lack of comprehension about which factors directly impact manually conducted SLR performance, limiting researchers to better plan and optimize their processes.
Objective
To enhance the understanding of the attributes that directly influence the SLR process in terms of time consumption.
Methods
We performed a tertiary study that (i) identified 138 secondary studies, (ii) mapped the possible influential attributes for SLR performance, (iii) extracted data from SLR reports and metadata, synthesized and analysed their influence, providing an overview of core trends related to those attributes over time.
Results
Our SLR mapped four main attributes influencing the performance time of the SLR process – number of authors, number of initially retrieved papers from databases, number of included papers for data synthesis, and usage of the snowballing techniques. We noticed a trend for smaller research groups (2–5 persons) using 4–6 different databases and processing to process a large number of studies, and an increasing adoption of the snowballing technique.
Conclusion
This paper reveals a bottleneck in manually conducted SLR, reinforcing the need for evolving automation. Mapping the attributes is only the first step to making the SLR process more measurable regarding its resource consumption. We contribute by providing recommendations to assist scientists and practitioners in planning their future SLRs and IT projects, including SLRs, particularly in the evolving landscape of digital transformation and innovations.}
}
@article{ZHENG2025106479,
title = {An overview of Unmanned Surface Vehicles: Methods, practices, and applications},
journal = {Control Engineering Practice},
volume = {164},
pages = {106479},
year = {2025},
issn = {0967-0661},
doi = {https://doi.org/10.1016/j.conengprac.2025.106479},
url = {https://www.sciencedirect.com/science/article/pii/S0967066125002412},
author = {Huarong Zheng and Chenguang Liu},
keywords = {Unmanned Surface Vehicles (USVs), Guidance navigation and control, Design and testing, Applications, Overview},
abstract = {Over the past few decades, Unmanned Surface Vehicles (USVs) have transitioned from concept to reality at an impressive pace. This rapid development is fueled by advances in technology and emerging demands in science, engineering, and military applications. The emphasis on USVs has evolved from purely research-focused activities to practical commercial and engineering applications. This paper presents insights gained from a decade of USV development, providing an overview of the latest methodologies, design practices, and applications. We review and compare various USVs currently in use, including those for research and field applications. In addition, we categorize and update the state-of-the-art navigation, guidance, and control methodologies that form the core capabilities of USVs, with a particular emphasis on the growing trend of learning-based and data-driven systems. As a crucial aspect, we also discuss the architectural design, implementation, and field testing of USVs. Finally, we explore their applications in three key areas: military operations, oceanographic observation, and intelligent waterborne transportation. Given that technological and practical challenges for USVs remain, we outline considerations and highlight relevant future directions.}
}
@article{CHOWDHURY2025109948,
title = {ENVQA: Improving Visual Question Answering model by enriching the visual feature},
journal = {Engineering Applications of Artificial Intelligence},
volume = {142},
pages = {109948},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.109948},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624021079},
author = {Souvik Chowdhury and Badal Soni},
keywords = {Visual Question Answering, Computer vision, Natural language processing, Visual and language},
abstract = {Visual Question Answering (VQA) is pivotal in various industries, including medicine. Current approaches typically rely on identifying patterns between image regions and questions, using attention-learning techniques to highlight essential information and suppress noise. However, existing VQA systems often overlook crucial foreground and background-related features in images, limiting their ability to tackle complex questions effectively. Most VQA models employ either spatial or channel attention mechanisms. Spatial attention localizes the region of interest (ROI) but may overlook global semantic relationships between salient objects. Conversely, channel attention enhances feature representation but disregards spatial dynamics within images. To address these limitations, we propose ”ENVQA” (Enriching V in VQA), a novel VQA model that integrates enriched visual features by leveraging both spatial and object-level features, alongside spatial and channel attention networks. Our model aims to enhance understanding by capturing both local and global contexts within images. Experimental evaluations on benchmark datasets such as VQA 2.0, TDIUC, and GQA demonstrate that ENVQA outperforms state-of-the-art (SOTA) models utilizing attention mechanisms.}
}
@article{RATH2025102024,
title = {IT-embedded dynamic capabilities for public institutions coping with disinformation – The case of financial fake news},
journal = {Government Information Quarterly},
volume = {42},
number = {2},
pages = {102024},
year = {2025},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2025.102024},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X25000188},
author = {Oliver Rath and Frederic Haase and Johannes Werner Melsbach and Jiarun Liu and Detlef Schoder},
keywords = {Disinformation, Fake news, Taxonomy, Dynamic capabilities, Detection, Deterrence, Education},
abstract = {Disinformation campaigns have become a significant concern for public institutions across various domains, including politics, healthcare, and financial markets. Consequently, authorities must develop effective strategies and measures to combat such campaigns while upholding their objectives of serving the public. In financial markets, institutions aim to ensure consumer protection and market integrity, both of which are at risk due to fraudulent activities driven by financial fake news (FFN). Drawing on a sample of FFN cases and institutional communications, our study contributes to the conceptualization of FFN schemes through a taxonomy, identifies IT-embedded dynamic capabilities (DCs) and the underlying microfoundations that institutions employ to address such schemes, and discusses open challenges for institutions. Our research provides practical value for institutions, regulators, and the public by informing them about FFN schemes and offering guidance applicable to other sectors affected by disinformation, such as healthcare and politics.}
}
@article{DING2025107868,
title = {POSVIA: Inconsistency analyzer for open-source Proof-of-Concept reports},
journal = {Information and Software Technology},
volume = {188},
pages = {107868},
year = {2025},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2025.107868},
url = {https://www.sciencedirect.com/science/article/pii/S0950584925002071},
author = {Lingyan Ding and Xingya Wang and Zhenyu Chen and Song Huang},
keywords = {Proof-of-Concept, Exploitability, Inconsistency, CVE},
abstract = {Context:
Proof-of-Concept (PoC) reports are indispensable for evaluating the exploitability of vulnerabilities. Various PoC data sources are responsible for collecting and sharing these reports. We have identified inconsistencies in the information pertaining to affected software versions across these data sources. These inconsistencies serve as red flags, alerting security experts to exercise caution during exploitability assessments and ensuring the effective allocation of resources.
Objective:
This paper analyzes software version inconsistencies in PoC reports and proposes “POSVIA” (PoC Oriented Software Version Inconsistency Analyzer), a deep learning tool designed to automatically detect and evaluate these inconsistencies across multiple PoC data sources, overcoming the impracticality of manual detection.
Methods:
A Named Entity Recognition (NER) model was developed with high performance: precision (93.76%) and recall (93.48%) for extracting CVE IDs, affected software names, and version data from PoC reports. Additionally, a Relation Extraction (RE) model was designed with metrics of 95.04% precision and 96.40% recall, to identify relationships between software and versions. These models analyzed 173,239 PoC reports from four data sources and assessed version inconsistencies using “POSVIA”.
Results:
Analysis revealed that Openwall had the lowest strict match rate (32.75%) for affected software versions, compared to other sources. The strict match rate for verified software versions ranged from 60.00% to 78.16%, indicating substantial inconsistencies. Over time, the match rate fluctuated, improving when using ExploitDB, Packet Storm Security, and CXSecurity as benchmarks. Openwall’s rate remained low, suggesting it should be considered alongside other sources for vulnerability exploitability assessments.
Conclusion:
This study introduces an automated tool named “POSVIA”, which is designed to address the challenge of detecting inconsistencies in software versions within PoC reports. By automating inconsistency detection across multiple data sources, POSVIA overcomes the limitations of manual methods and enhances the accuracy of exploitability assessments. This approach provides critical support for improving software security and resource allocation.}
}
@article{FATEMI2025101923,
title = {Anatomy of innovation biosphere in global AI landscape: Actors, interactions, and evolution},
journal = {Journal of Engineering and Technology Management},
volume = {78},
pages = {101923},
year = {2025},
issn = {0923-4748},
doi = {https://doi.org/10.1016/j.jengtecman.2025.101923},
url = {https://www.sciencedirect.com/science/article/pii/S0923474825000645},
author = {Mehdi Fatemi and Shohreh Nasri and Sepehr Ghazinoory},
keywords = {Global Innovation, Innovation Biosphere, Artificial Intelligence, Global AI},
abstract = {The rapid advancement of artificial intelligence (AI) reinforces the necessity of adopting global perspectives on innovation. Conventional frameworks (national innovation systems, global value chains, and ecosystem models) remain useful, yet they are limited in their ability to capture the complexity, dynamism, and asymmetrical interactions that characterize transnational AI ecosystems. This article introduces the innovation biosphere framework as a response to this theoretical gap, a conceptual approach that foregrounds the non-equilibrium dynamics, role fluidity, and co-evolutionary processes that characterize today's transnational AI landscape. Employing a metaphor research strategy, the article systematically maps key actors (leader, systemic intermediary, umbrella, and fundamental), interactions (cooperation, competition, prey/predator, and commensalism), and evolution mechanisms (environmental adaptation, innovation-driven evolution, performance improvement, and directional change) onto global innovation dynamics. Accordingly, leader actors (e.g., OpenAI and DeepMind) drive deep learning and language processing breakthroughs. Google and IBM, as systemic intermediary actors, spread AI across sectors, while umbrella actors, including Alphabet and Tencent, nurture AI startups and foster innovation at multiple scales. Fundamental actors contribute foundational research, regulation, and ethical frameworks. Furthermore, cooperative efforts (e.g., Partnership on AI) foster joint technological advancements, while competitive dynamics among tech giants stimulate rapid AI progress. Prey-predator and commensalism relationships illustrate interactions characterized by asymmetries in power or resources. Finally, evolution mechanisms include environmental adaptation, observed in AI's pandemic-driven growth, and innovation-driven evolution marked by leaps in NLP model capabilities. Performance improvement results from cross-sector contributions, like Nvidia's influence on autonomous vehicles, while geopolitical disruptions trigger directional changes.}
}
@article{OZDEMIRSONMEZ20248,
title = {ContractArmor: Attack Surface Generator for Smart Contracts},
journal = {Procedia Computer Science},
volume = {231},
pages = {8-15},
year = {2024},
note = {14th International Conference on Emerging Ubiquitous Systems and Pervasive Networks / 13th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (EUSPN/ICTH 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.12.151},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923021634},
author = {Ferda {Özdemir Sönmez} and William J. Knottenbelt},
keywords = {Attack Surface, Rule-Based Analysis, ChatGPT, GPT-3, DaVinci, Security Analysis, Smart Contract},
abstract = {This paper presents an ongoing study of a novel attack surface generator tool for smart contracts developed in Solidity. The tool leverages a rule-based engine and ChatGPT API for security analysis. The rule-based engine provides numerical values and key variables and functions for further analysis, while ChatGPT handles complex queries. However, ChatGPT may generate similar responses for more general questions, irrespective of the given contract code. The tool combines both approaches to identify and mitigate potential security vulnerabilities in Solidity-based smart contracts. The effectiveness of the tool is evaluated on real-world smart contracts, and its potential for detecting and preventing common attack vectors is demonstrated.}
}
@article{HUANG2025126922,
title = {Shaping the future of nuclear reactors with digital twins: Current developments and perspectives},
journal = {Applied Energy},
volume = {402},
pages = {126922},
year = {2025},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2025.126922},
url = {https://www.sciencedirect.com/science/article/pii/S0306261925016526},
author = {Qingyu Huang and Wei Zeng and Jia Liu and Zhuo Zhang and Jian Deng and Zhifang Qiu and Le Xu and Zonglan Wei and Qi Lu and Lanxin Gong and Chunsen Shi and Xianping Zhong},
keywords = {Digital twin, Artificial intelligence, Nuclear reactor, Maturity hierarchy},
abstract = {Digital Twin(DT) technology offers a transformative pathway to mitigate the fundamental trade-off in nuclear energy between uncompromising safety and economic competitiveness. This review synthesizes the state of the field, revealing a critical insight: despite progress, implementations of nuclear DTs globally remain nascent, predominantly confined to low-to-mid maturity levels. This developmental lag stems from unique, sector-specific challenges: severe data scarcity due to extreme in-vessel conditions, an irreconcilable trade-off between high-fidelity multi-physics model accuracy and real-time computational demands, and the “black-box” nature of data-driven artificial intelligence conflicting with nuclear safety demand for interpretability and verifiable trust. A comparative analysis against aerospace, power grid, maritime, and healthcare sectors confirms that nuclear applications face exceptionally stringent regulatory requirements and uniquely high technical barriers. To overcome these hurdles, this work establishes a comprehensive DT application framework and introduces a novel five-tier maturity hierarchy for nuclear reactors. This model provides a standardized, actionable roadmap for technological evolution—from basic simulation guidance to fully symbiotic autonomy—thereby positioning the DT as the indispensable engine for the future of safe, efficient, and intelligent nuclear power.}
}
@article{ANDRESINI2022100036,
title = {EUPHORIA: A neural multi-view approach to combine content and behavioral features in review spam detection},
journal = {Journal of Computational Mathematics and Data Science},
volume = {3},
pages = {100036},
year = {2022},
issn = {2772-4158},
doi = {https://doi.org/10.1016/j.jcmds.2022.100036},
url = {https://www.sciencedirect.com/science/article/pii/S2772415822000086},
author = {Giuseppina Andresini and Andrea Iovine and Roberto Gasbarro and Marco Lomolino and Marco {de Gemmis} and Annalisa Appice},
keywords = {Review spam detection, Deep learning, Multi-view learning, Feature extraction, Word embedding},
abstract = {Nowadays, online reviews are the main source to customer opinions. They are especially important in the realm of e-commerce, where reviews regarding products and services influence the purchase decisions of customers, as well as the reputation of the commerce websites. Unfortunately, not all the online reviews are truthful and trustworthy. Therefore, it is crucial to develop machine learning techniques to detect review spam. This study describes EUPHORIA — a novel classification approach to distinguish spam from truthful reviews. This approach couples multi-view learning to deep learning, in order to gain accuracy by accounting for the variety of information possibly associated with both the reviews’ content and the reviewers’ behavior. Experiments carried out on two real review datasets from Yelp.com – Hotel and Restaurant – show that the use of multi-view learning can improve the performance of a deep learning classifier trained for review spam detection. In particular, the proposed approach achieves AUC-ROC equal to 0.813 and 0.708 in Hotel and Restaurant, respectively.}
}
@article{ZHOU2024103795,
title = {Urban mobility foundation model: A literature review and hierarchical perspective},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {192},
pages = {103795},
year = {2024},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2024.103795},
url = {https://www.sciencedirect.com/science/article/pii/S1366554524003867},
author = {Zhen Zhou and Ziyuan Gu and Xiaobo Qu and Pan Liu and Zhiyuan Liu and Wenwu Yu},
keywords = {Multimodal Transportation, Foundation Model, Transportation Decision-making Tasks, Transformer, Multi-task Learning, Federated Learning},
abstract = {An urban mobility system serves as a highly intricate and nonlinear mega-system facilitating the movement of people, goods, and services across spatio-temporaldomains. This complexity stems from factors such as intricate interactions between transportation supply and demand, and the inherent stochastic nature of an open, heterogeneous, and adaptable system. Successfully comprehending and navigating this system presents a challenge. Yet, a remarkable opportunity emerges with the growing availability of multi-source data in urban mobility and various sectors, combined with the recent advancements in large-scale machine learning (ML) models. In this paper, we introduce a novel conceptual framework, the HUGE (Hierarchically Unified GEnerative) foundation model, to address multifaceted computational tasks and decision-making problems embedded in urban mobility systems. We delve into the core technologies and their seamless integration to realize this framework, highlighting its potential to harness substantial data analytics, hierarchical ML methodologies, and domain-specific knowledge. The conceived framework has the potential to revolutionize urban mobility system planning, design, construction, and management in a digital and intelligent manner.}
}
@article{SHUKLA2024100605,
title = {An overview of blockchain research and future agenda: Insights from structural topic modeling},
journal = {Journal of Innovation & Knowledge},
volume = {9},
number = {4},
pages = {100605},
year = {2024},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2024.100605},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X24001446},
author = {Anuja Shukla and Poornima Jirli and Anubhav Mishra and Alok Kumar Singh},
keywords = {Structural topic modeling, Blockchain, Scenario building, Datatopia, Natural language processing, Emerging technologies},
abstract = {As a disruptive technology, blockchain has become a strategic priority for many businesses. A vast amount of research exists on blockchain's innovative nature and immense potential for multiple industries. This study aims to synthesize the existing research to classify the findings into various themes and propose avenues for further research. A total of 2,360 academic articles were analyzed using the text-mining method of structural topic modeling. The identified fifteen topics were mapped to the four quadrants of the Datatopia model, leading to the development of the Datatopia-blockchain (DBlock) framework. The results present future scenarios that provide an understanding of what is known about blockchain, its characteristics, and potential research areas. The contributions to the theory and implications to the practitioners are discussed in detail.}
}
@article{JIANG2024120861,
title = {DSCAPS: A decentralized smart contract auditing platform based on sidechain},
journal = {Information Sciences},
volume = {677},
pages = {120861},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.120861},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524007758},
author = {Wenchao Jiang and Weiqi Dai and Jiamin Zheng and Zhipeng Liang and Quankeng Huang and Fanlong Zhang and Tao Wu},
keywords = {Blockchain, Smart contract, Vulnerability, Audit, Sidechain, Security},
abstract = {Successful attacks on smart contracts can result in loss of digital assets with potential financial and reputation implications. This reinforces the importance of auditing smart contracts prior to deployment. However, existing auditing approaches are generally non transparent, inefficient, limited to known bugs, and imprecise due to lack of real-world information in the blockchain. Therefore, we design a Decentralized Smart Contract Auditing Platform based on Sidechain (DSCAPS) in this paper. DSCAPS leverages the two-way peg sidechain technology to implement the interactions between the main chain and the sidechain which is used as the audit chain platform. Unlike conventional centralized audits, blockchain users can evaluate the security of contracts in a real-world smart contract execution environment by designing an appropriate incentive mechanism. Thus, detection results will be more comprehensive and precise. Moreover, to prevent multi-party collusion from manipulating the blockchain or audit process, we introduce a margin mechanism. Findings from our security analysis demonstrate that DSCAPS can mitigate potential threats. Evaluation findings based on the system implementation also show that DSCAPS is efficient in auditing a contract with performance overheads of less than 10%.}
}
@article{DIEULIIS2024361,
title = {Bolstering Biosecurity Amid the Biotechnology Revolution},
journal = {Orbis},
volume = {68},
number = {3},
pages = {361-382},
year = {2024},
issn = {0030-4387},
doi = {https://doi.org/10.1016/j.orbis.2024.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0030438724000255},
author = {Diane DiEuliis},
abstract = {The rapid pace of novel technological change, referred to as “emerging technologies,” is challenging our ability to devise policy and governance apace. This is particularly true in the life sciences and biotechnology, where the current tools used for promoting biosecurity via policy and governance are becoming outdated.}
}
@article{IMANDOJEMU2025875,
title = {Disruptor or enabler? AI and financial system stability},
journal = {Journal of Financial Economic Policy},
volume = {17},
number = {6},
pages = {875-903},
year = {2025},
issn = {1757-6385},
doi = {https://doi.org/10.1108/JFEP-10-2024-0306},
url = {https://www.sciencedirect.com/science/article/pii/S1757638525000082},
author = {Kinglsey Imandojemu and Segun E. Eniola Otokiti and Ademayowa M. Adebukunola and Romanus Osabohien and Mamdouh Abdulaziz Saleh Al-Faryan},
keywords = {Artificial intelligence, Financial system stability, Technology, Asymmetry panels, C33, E44, E58, G00, O33},
abstract = {Purpose
The advent of artificial intelligence (AI) tools signifies a major advancement in technology, poised to significantly influence the financial system. From a conceptual standpoint, AI introduces both advantages and challenges to the financial landscape. Thus, this study aims to examine the dynamics between AI and financial system stability through several distinct approaches. Initially, the authors investigate potential nonlinearities in this relationship to assess the asymmetric reactions of financial system stability to the application of AI, both positive and negative.
Design/methodology/approach
Subsequently, to address intra-country variations, the authors incorporate a heterogeneous effect within the cross-sections by using a nonlinear panel autoregressive distributed lag model, which serves as a panel data adaptation of the Shin et al. (2014) framework and is comparable to the nonstationary heterogeneous panel data model.
Findings
The findings indicate that final system stability exhibits asymmetric responses to AI, with the latter displaying a more pronounced reaction. The results remain consistent across various AI proxies. Ultimately, the findings emanating from the study carry significant implications for financial system regulators.
Originality/value
This paper addresses gaps in the AI–financial stability literature by empirically examining the relationship internationally, where existing studies are limited. While some prior research (e.g. Daud et al., 2022; Li, 2021; Khan et al., 2023a) explores this globally, they do not fully account for nonlinearities and heterogeneity effects. To the best of the authors’ knowledge, this study is the first to use panel data to incorporate both aspects, offering a more comprehensive understanding of AI’s impact on financial stability. Doing so advances empirical knowledge beyond the largely theoretical, country-specific focus of earlier work (e.g. Darangwa, 2021; Chen and Du, 2016).}
}
@article{LEALNETO2024,
title = {Digital Transformation of Public Health for Noncommunicable Diseases: Narrative Viewpoint of Challenges and Opportunities},
journal = {JMIR Public Health and Surveillance},
volume = {10},
year = {2024},
issn = {2369-2960},
doi = {https://doi.org/10.2196/49575},
url = {https://www.sciencedirect.com/science/article/pii/S2369296024000267},
author = {Onicio {Leal Neto} and Viktor {Von Wyl}},
keywords = {digital public health, artificial intelligence, non-communicable diseases, digital health, surveillance, well being, technological advancement, public health efficiency, digital innovation},
abstract = {The recent SARS-CoV-2 pandemic underscored the effectiveness and rapid deployment of digital public health interventions, notably the digital proximity tracing apps, leveraging Bluetooth capabilities to trace and notify users about potential infection exposures. Backed by renowned organizations such as the World Health Organization and the European Union, digital proximity tracings showcased the promise of digital public health. As the world pivots from pandemic responses, it becomes imperative to address noncommunicable diseases (NCDs) that account for a vast majority of health care expenses and premature disability-adjusted life years lost. The narrative of digital transformation in the realm of NCD public health is distinct from infectious diseases. Public health, with its multifaceted approach from disciplines such as medicine, epidemiology, and psychology, focuses on promoting healthy living and choices through functions categorized as “Assessment,” “Policy Development,” “Resource Allocation,” “Assurance,” and “Access.” The power of artificial intelligence (AI) in this digital transformation is noteworthy. AI can automate repetitive tasks, facilitating health care providers to prioritize personal interactions, especially those that cannot be digitalized like emotional support. Moreover, AI presents tools for individuals to be proactive in their health management. However, the human touch remains irreplaceable; AI serves as a companion guiding through the health care landscape. Digital evolution, while revolutionary, poses its own set of challenges. Issues of equity and access are at the forefront. Vulnerable populations, whether due to economic constraints, geographical barriers, or digital illiteracy, face the threat of being marginalized further. This transformation mandates an inclusive strategy, focusing on not amplifying existing health disparities but eliminating them. Population-level digital interventions in NCD prevention demand societal agreement. Policies, like smoking bans or sugar taxes, though effective, might affect those not directly benefiting. Hence, all involved parties, from policy makers to the public, should have a balanced perspective on the advantages, risks, and expenses of these digital shifts. For a successful digital shift in public health, especially concerning NCDs, AI’s potential to enhance efficiency, effectiveness, user experience, and equity—the “quadruple aim”—is undeniable. However, it is vital that AI-driven initiatives in public health domains remain purposeful, offering improvements without compromising other objectives. The broader success of digital public health hinges on transparent benchmarks and criteria, ensuring maximum benefits without sidelining minorities or vulnerable groups. Especially in population-centric decisions, like resource allocation, AI’s ability to avoid bias is paramount. Therefore, the continuous involvement of stakeholders, including patients and minority groups, remains pivotal in the progression of AI-integrated digital public health.}
}
@article{SUN2024103772,
title = {Malware2ATT&CK: A sophisticated model for mapping malware to ATT&CK techniques},
journal = {Computers & Security},
volume = {140},
pages = {103772},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.103772},
url = {https://www.sciencedirect.com/science/article/pii/S0167404824000737},
author = {Huaqi Sun and Hui Shu and Fei Kang and Yuntian Zhao and Yuyao Huang},
keywords = {ATT&CK techniques, Knowledge graph, Malicious behavior, Malware, Multi-label classification},
abstract = {MITER Corporation presents the ATT&CK Matrix, which maps malware behavior to different tactics, techniques, and procedures (TTPs) providing a comprehensive view to clarify the inner mechanism of malware more accurately. However, manual mapping methods are time-consuming, while rule-based feature-based mapping methods often under- or misreport many attacks. Inspired by the successful application of image multi-label classification techniques, we propose a method called Malware2ATT&CK to automatically map malware to ATT&CK techniques. The method applies pre-trained models to extract features from the two pieces of information — the static analysis information of assembly instruction and API calls from malware. The malicious techniques are identified by a multi-label classifier based on the graph neural network and knowledge graph. In the experiments over two test sets, Malware2ATT&CK shows excellent performance achieving an average F1 score of 83.6% in the technology mapping task. Further evaluation indicates that the high accuracy of the prediction is due to our ability to accurately capture the correlation between behaviors.}
}
@article{ALEXIOU2025110930,
title = {Kyrtos: A methodology for automatic deep analysis of graphic charts with curves in technical documents},
journal = {Pattern Recognition},
volume = {157},
pages = {110930},
year = {2025},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2024.110930},
url = {https://www.sciencedirect.com/science/article/pii/S0031320324006812},
author = {Michail S. Alexiou and Nikolaos G. Bourbakis},
keywords = {Chart analysis, Chart recognition, Chart reverse engineering, Data mining in charts, Document processing and analysis},
abstract = {Deep Understanding of Technical Documents (DUTD) has become a very attractive field with great potential due to large amounts of accumulated documents and the valuable knowledge contained in them. In addition, the holistic understanding of technical documents depends on the accurate analysis of its particular modalities, such as graphics, tables, diagrams, text, etc. and their associations. In this paper, we introduce the Kyrtos methodology for the automatic recognition and analysis of charts with curves in graphics images of technical documents. The recognition processing part adopts a clustering based approach to recognize middle-points that delimit the line-segments that construct the illustrated curves. The analysis processing part parses the extracted line-segments of curves to capture behavioral features such as direction, trend and etc. These associations assist the conversion of recognized segments’ relations into attributed graphs, for the preservation of the curves’ structural characteristics. The graph relations are also are expressed into natural language (NL) text sentences, enriching the document’s text and facilitating their conversion into Stochastic Petri-net (SPN) graphs, which depict the internal functionality represented in the chart image. Extensive evaluation results demonstrate the accuracy of Kyrtos’ recognition and analysis methods by measuring the structural similarity between input chart curves and the approximations generated by Kyrtos for charts with multiple functions.}
}
@article{CHEN2025104591,
title = {AutoSeg: Automatic micro-segmentation policy generation via configuration analysis},
journal = {Computers & Security},
volume = {157},
pages = {104591},
year = {2025},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2025.104591},
url = {https://www.sciencedirect.com/science/article/pii/S0167404825002809},
author = {Andong Chen and Zhaoxuan Jin and Zhenyuan Li and Yan Chen and Yu Ning and Ying Wang},
keywords = {Micro-segmentation, Policy generation, Service dependency, Cloud-native, Kubernetes},
abstract = {Micro-segmentation isolates network segments within different parts of an application, reducing potential attack surfaces. This technique has become increasingly common for enhancing security in cloud application infrastructures. Despite its benefits, the complexity of managing numerous service interactions can make defining and maintaining micro-segmentation policies challenging and prone to errors. Previous solutions have attempted to simplify policy creation, but gaps remain in their applicability, auditability, and response times. In this paper, we proposed the first configuration-based approach, AugoSeg, which automates the generation of micro-segmentation policies for cloud-native applications. By analyzing network configurations in service containers, AugoSeg identifies service dependencies and automatically creates corresponding policies. This system specifically targets commonly used, behavior-focused configurations, addressing the shortcomings of earlier systems through its design. We systematically evaluated AugoSeg, using the 184 services from 61 popular projects, covering 14 programming languages. The results illustrated that AugoSeg can completely model service dependencies for over 96.7% of projects and formulate restrictive policies in an average time of 7.13 s. It effectively restricts attackers’ lateral movements within networks. This evaluation not only underscores the efficiency of AugoSeg but also demonstrates its practical applicability in cloud environments, setting a new approach for micro-segmentation in cloud-native security.}
}
@article{GAETA2025100322,
title = {Computational analysis of Information Disorder in Cognitive Warfare},
journal = {Online Social Networks and Media},
volume = {48},
pages = {100322},
year = {2025},
issn = {2468-6964},
doi = {https://doi.org/10.1016/j.osnem.2025.100322},
url = {https://www.sciencedirect.com/science/article/pii/S2468696425000230},
author = {Angelo Gaeta and Vincenzo Loia and Angelo Lorusso and Francesco Orciuoli and Antonella Pascuzzo},
keywords = {Cognitive warfare, Information Disorder, Text-based features, Explainable AI},
abstract = {Cognitive Warfare represents the modern evolution of traditional conflict, where the human mind emerges as the primary battleground, and information serves as a weapon to influence people’s thoughts, perceptions, and behaviors. Adopting the Information Disorder perspective, this work meticulously explores the phenomena associated with Cognitive Warfare, particularly as they spread across online social networks and media, to better understand their textual nature. In particular, the work focuses on specific cognitive weapons predominantly used by malicious actors in this context, such as the dissemination of misleading political news, junk science, and conspiracy theories. Therefore, the paper proposes an approach to identify, extract, and assess text-based features able to characterize the forms of Information Disorder involved in Cognitive Warfare. The proposed approach starts with a literature review and ends by assessing the identified and selected features through comprehensive experimentation based on a well-known dataset and conducted through the application of machine learning methods. In particular, by applying the Rough Set Theory and explainable AI it is found that features belonging to readability, psychological, and linguistic categories demonstrate a significant contribution in classifying the aforementioned forms of disorder. The obtained results are highly valuable as they can be leveraged to analyze critical aspects of Information Disorder, such as identifying the intent behind manipulated content and its targeted audience.}
}
@article{JEDRZEJEWSKI2024103988,
title = {Adversarial Machine Learning in Industry: A Systematic Literature Review},
journal = {Computers & Security},
volume = {145},
pages = {103988},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.103988},
url = {https://www.sciencedirect.com/science/article/pii/S0167404824002931},
author = {Felix Viktor Jedrzejewski and Lukas Thode and Jannik Fischbach and Tony Gorschek and Daniel Mendez and Niklas Lavesson},
keywords = {Adversarial machine learning, Industry, Rigor, Relevance, State of evidence},
abstract = {Adversarial Machine Learning (AML) discusses the act of attacking and defending Machine Learning (ML) Models, an essential building block of Artificial Intelligence (AI). ML is applied in many software-intensive products and services and introduces new opportunities and security challenges. AI and ML will gain even more attention from the industry in the future, but threats caused by already-discovered attacks specifically targeting ML models are either overseen, ignored, or mishandled. Current AML research investigates attack and defense scenarios for ML in different industrial settings with a varying degree of maturity with regard to academic rigor and practical relevance. However, to the best of our knowledge, a synthesis of the state of academic rigor and practical relevance is missing. This literature study reviews studies in the area of AML in the context of industry, measuring and analyzing each study’s rigor and relevance scores. Overall, all studies scored a high rigor score and a low relevance score, indicating that the studies are thoroughly designed and documented but miss the opportunity to include touch points relatable for practitioners.}
}
@article{GOMEZCABRERA2024100567,
title = {ViLanIoT: A visual language for improving Internet of Things systems representation},
journal = {Journal of Industrial Information Integration},
volume = {38},
pages = {100567},
year = {2024},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2024.100567},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X24000116},
author = {Alain Gomez-Cabrera and Ponciano J. Escamilla-Ambrosio and Jassim Happa},
keywords = {Internet of Things, Visual language, Language design, Physics of notation},
abstract = {With the rapidly evolving and changing nature of Internet of Things (IoT) technologies, there is an absence of tools to support the IoT system design and development. For example, there is not a specialized tool for representing IoT systems. The common solution to this problem is to use general-purpose modeling tools, such as the Unified Modeling Language (UML) and its extensions, which have some disadvantages when representing IoT systems. This paper proposes a new visual language, called ViLanIoT, for making representations of IoT systems conceived as cyber–physical systems. We argue that diagrams obtained with ViLanIoT are more understandable and intuitive compared to improvised representations found in literature. To illustrate the use of ViLanIoT, we represent a smart campus system with visual elements according to our proposal. In addition, we also present a study of the application of ViLanIoT. In ViLanIoT, the inclusion of visual elements for each component reflecting semantic meaning improves the understandability, clarity, and simplicity of IoT system representations.}
}
@article{CUI20254939,
title = {Sensitive Target-Guided Directed Fuzzing for IoT Web Services},
journal = {Computers, Materials and Continua},
volume = {83},
number = {3},
pages = {4939-4959},
year = {2025},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2025.063592},
url = {https://www.sciencedirect.com/science/article/pii/S1546221825004783},
author = {Xiongwei Cui and Yunchao Wang and Qiang Wei},
keywords = {IoT, directed fuzzing, sensitive targets, vulnerabilities},
abstract = {The development of the Internet of Things (IoT) has brought convenience to people’s lives, but it also introduces significant security risks. Due to the limitations of IoT devices themselves and the challenges of re-hosting technology, existing fuzzing for IoT devices is mainly conducted through black-box methods, which lack effective execution feedback and are blind. Meanwhile, the existing static methods mainly rely on taint analysis, which has high overhead and high false alarm rates. We propose a new directed fuzz testing method for detecting bugs in web service programs of IoT devices, which can test IoT devices more quickly and efficiently. Specifically, we identify external input entry points using multiple features. Then we quickly find sensitive targets and paths affected by external input sources based on sensitive data flow analysis of decompiled code, treating them as testing objects. Finally, we perform a directed fuzzing test. We use debugging interfaces to collect execution feedback and guide the program to reach sensitive targets based on program pruning techniques. We have implemented a prototype system, AntDFuzz, and evaluated it on firmware from ten devices across five well-known manufacturers. We discovered twelve potential vulnerabilities, seven of which were confirmed and assigned bug id by China National Vulnerability Database (CNVD). The results show that our approach has the ability to find unknown bugs in real devices and is more efficient compared to existing tools.}
}
@article{HINA2025101654,
title = {Adversarial attacks on artificial Intelligence of Things-based operational technologies in theme parks},
journal = {Internet of Things},
volume = {32},
pages = {101654},
year = {2025},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2025.101654},
url = {https://www.sciencedirect.com/science/article/pii/S2542660525001684},
author = {Sadaf Hina and Qaiser Abbas and Kashan Ahmed},
keywords = {Artificial Intelligence of Things, Smart surveillance systems, Adversarial attacks, Operational technologies, Theme parks security},
abstract = {Theme parks represent a popular, yet vulnerable aspect of life, where large unsuspecting crowds gather and interact with technology. Artificial intelligence (AI), computer vision, and the Internet of Things (IoT) are transforming theme parks by revolutionizing various aspects. This research study is the first to identify critical components of theme parks that can be optimized, and comprehensively maps them onto emerging AI/IoT applications, often powered by machine learning or deep learning models. Additionally, the study sheds light on adversarial attacks targeting vulnerable smart surveillance systems, which generate a very large volume of video stream data. These systems serve as a prominent example of AIoT-based operational technologies (AIoT-OT) responsible for critical alerts and actions. Rigorous experimentation, involving a novel hybrid multi-pixel deception attack technique, demonstrates that advanced adversarial attack methods can significantly degrade the performance of detection systems. The performance metrics and attack success rate were measured by accuracy, precision, recall, F1-score, and AUC score. Before attack, the accuracy rates of 87. 45%, 83. 17% and 81. 40% were achieved for the EfficientNet, ResNet and MobileNet models, respectively. However, after applying the proposed MPD attack, the performance of each model declined significantly. The accuracy dropped to 61.23% for EfficientNet (with an attack success rate of 29.10%), 59.12% for ResNet (with success rate of 30.20%), and 55.17% for MobileNet (with success rate of 32.60%). This study signifies the need for a strategic plan of action and the development of robust methods for the proactive security of AIoT in theme parks.}
}
@article{CHRISTINA2025152040,
title = {Integrating the Caring Life Course Theory and Artificial Intelligence Applications to Enhance Cancer Care Across the Continuum},
journal = {Seminars in Oncology Nursing},
volume = {41},
number = {6},
pages = {152040},
year = {2025},
note = {Caring Life-Course Theory},
issn = {0749-2081},
doi = {https://doi.org/10.1016/j.soncn.2025.152040},
url = {https://www.sciencedirect.com/science/article/pii/S0749208125002335},
author = {Juliana Christina and Kelly Ford and Bradly Menz and Michael Sorich and Ashley Hopkins and Imogen Ramsey and Maree Duddle and Alison Kitson and Catherine Paterson},
keywords = {Cancer, Artificial intelligence, Caring life course theory, Person-centred care, Care networks, Survivorship, Equity},
abstract = {Objectives
With the escalating global burden of cancer, there is an increasing imperative to adopt holistic, person-centered approaches that address the complex and evolving care needs of individuals across the cancer continuum. Integrating advanced technologies such as artificial intelligence (AI) into conventional cancer care models offers significant potential to enhance the responsiveness, inclusivity, and sustainability of cancer care delivery. This paper aimed to explore how the Caring Life Course Theory (CLCT), a comprehensive multidisciplinary framework of care, can inform and enhance the integration of AI into cancer care delivery.
Methods
A conceptual synthesis and narrative synthesis were employed to explore and understand how CLCT constructs can inform AI applications across different levels of cancer care (individual, relational/network and structural).
Results
AI technologies are being used to support personalized care planning, real-time symptom monitoring, survivorship management, and coordinated service delivery. Guided by the CLCT, these technologies offer a structured and contextually grounded approach to delivering longitudinal, life-course-informed care. Nonetheless, significant challenges remain, including ethical concerns, algorithmic bias, and implementation barriers.
Conclusions
Aligning AI technologies with the CLCT framework can promote more personalized, equitable, and relationally responsive cancer care. Future research must prioritize ethical co-design, accountability, and sustained implementation.
Implications for Nursing Practice
: The integration of CLCT and AI can support nurses in identifying care needs, facilitating remote monitoring, and coordinating personalized care. However, the integration of AI must be approached with critical attention to ethics, equity, and the preservation of fundamental nursing values.}
}
@article{LOPES2026102939,
title = {Designing the future of flight: A socio-technical framework for single-pilot operations in commercial aviation},
journal = {Journal of Air Transport Management},
volume = {132},
pages = {102939},
year = {2026},
issn = {0969-6997},
doi = {https://doi.org/10.1016/j.jairtraman.2025.102939},
url = {https://www.sciencedirect.com/science/article/pii/S0969699725002029},
author = {Nuno Moura Lopes and Manuela Aparicio and Carlos J. Costa and Fátima Trindade Neves and Carlos Bernardino},
keywords = {Single-pilot operations (SPO), Human–autonomy teaming, Cognitive workload, Adaptive automation, Public perception},
abstract = {The transition to Single-Pilot Operations (SPO) represents a transformative evolution in commercial aviation, driven by advances in automation, human–autonomy teaming, and socio-economic imperatives. This study presents a comprehensive literature-informed investigation into SPO's technical, human, organizational, and societal dimensions, supported by a robust bibliometric analysis of over two decades of research. Through a multi-thematic review and framework development, the manuscript identifies eight critical dimensions shaping SPO implementation: human factors and cognitive workload, automation and human–autonomy teaming, the concept of operations and task redistribution, remote support and ground integration, safety and certification, interface and cockpit design, economic feasibility, and public perception. We also propose a new integrated socio-technical framework highlighting the interplay between these domains and the need for trust calibration, adaptive automation, and transparent certification processes. The framework emphasises stakeholder-centric design, highlighting the importance of aligning technological capability with human limitations, operational context, and societal expectations. The limitations of current SPO research, including gaps in real-world validation, interdisciplinary integration, and long-term public trust studies, are discussed. This work provides a roadmap for future research and a strategic orientation for regulators, airlines, and system designers seeking to deploy safe and publicly accepted SPOs.}
}
@article{WANG2022727,
title = {Online social network individual depression detection using a multitask heterogenous modality fusion approach},
journal = {Information Sciences},
volume = {609},
pages = {727-749},
year = {2022},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2022.07.109},
url = {https://www.sciencedirect.com/science/article/pii/S002002552200799X},
author = {Yiding Wang and Zhenyi Wang and Chenghao Li and Yilin Zhang and Haizhou Wang},
keywords = {Depression detection, Online social network, Deep learning, Multitask learning, Multimodal fusion},
abstract = {In recent years, the number of people who endanger their lives has been increasing rapidly due to the mental burden of depression. The online social network (OSN) provides researchers with another perspective for detecting individuals suffering from depression. However, existing machine learning-based depression detection studies still leave relatively low classification performance, suggesting that there is significant improvement potential in their feature engineering. In this paper, we manually build and publish a large dataset on Sina Weibo (a leading OSN with the largest number of active users in the Chinese community), namely the Weibo User Depression Detection Dataset (WU3D). It includes more than 20,000 normal users and more than 10,000 depressed users, both of which are labeled and rechecked following the DSM-5 official medical and psychological depression document by professionals. Then, we conclude and propose ten statistical features by analyzing the user’s text, social behavior, and posted pictures. In the meantime, text-based word features are extracted using the popular pretrained model XLNet. Moreover, we fuse these features from heterogeneous modalities and implement a multitask learning scheme to train our proposed deep neural network classification model, i.e. FusionNet (FN). The experimental results show that FN has excellent to recognize depressed users on the OSN, achieving the highest F1-Score of 0.9772 on the test set. Compared to existing studies, the proposed method has better classification performance and robustness for unbalanced training samples, as well as reasonable training and inference time. Our work provides a method to fuse multimodal information to detect individual-level depression and has reference significance for similar studies on other OSNs.}
}
@article{NARTENI2025110133,
title = {Explainable evaluation of generative adversarial networks for wearables data augmentation},
journal = {Engineering Applications of Artificial Intelligence},
volume = {145},
pages = {110133},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.110133},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625001332},
author = {Sara Narteni and Vanessa Orani and Enrico Ferrari and Damiano Verda and Enrico Cambiaso and Maurizio Mongelli},
keywords = {Data augmentation, Explainable artificial intelligence, Rule similarity, Reliable artificial intelligence},
abstract = {Data augmentation represents an opportunity for Artificial Intelligence (AI) applications, as it aims at creating new synthetic data based on an existing baseline. In this paper, we present a new evaluation framework for Generative Adversarial Networks (GANs), a data augmentation technique, in multivariate data classification contexts. The goal is not limited to assessing the performance variations obtained through GANs, but also to inspect results with explainable AI (XAI) tools, understanding how GANs work and, finally, exploiting them to discover new knowledge. To this aim, we adopt the Logic Learning Machine (LLM) for performance assessment and rule extraction, and introduce a new measure of rule similarity to compare different artificial datasets. We apply the methodology on two case studies, activity recognition and physical fatigue detection, confirming that GANs can help in overcoming limitations of original datasets and lead to new discoveries.}
}
@article{TARIQ2025107342,
title = {Edge-enabled smart agriculture framework: Integrating IoT, lightweight deep learning, and agentic AI for context-aware farming},
journal = {Results in Engineering},
volume = {28},
pages = {107342},
year = {2025},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2025.107342},
url = {https://www.sciencedirect.com/science/article/pii/S2590123025033973},
author = {Muhammad Usman Tariq and Sheikh Muhammad Saqib and Tehseen Mazhar and Muhammad Amir Khan and Tariq Shahzad and Habib Hamam},
keywords = {Agentic AI, Edge computing, Internet of things (IoT), Low-power deep learning, Precision farming, Smart agriculture, Weather and crop classification},
abstract = {Smart farming in connectivity-limited, energy-sensitive environments demands on-device perception and decision-making to reduce latency and cloud dependence. This article proposes an edge-enabled smart agriculture framework that integrates lightweight deep learning, rule-based agentic AI, and Internet of Things (IoT) devices for real-time, autonomous farming decisions. The system features two vision-based models—one for weather classification and one for crop identification—built on the MiT-B0 Vision Transformer architecture and optimized for low-resolution (128 × 128) image inputs. These models run on resource-constrained hardware suitable for rural deployment and support efficient, on-device processing. Weather prediction spans 11 classes (e.g., frost, lightning, rain, sandstorm), while crop classification covers 5 major crops. The system achieves an accuracy of 88 % for weather and 93 % for crops, with high F1-scores and low MAE, Kappa, and Hamming loss values. Predictions are interpreted by a rule-based agentic AI layer that triggers actions across multiple IoT actuators, such as smart irrigation, NDVI sensors, frost alarms, drones, and pest detectors. The decision engine supports both joint rule logic (e.g., activating hail protectors when hail is detected in maize fields) and fallback single-condition rules. Python-implemented case studies show seamless model–AI–IoT interaction in combined and separate scenarios. By minimizing cloud dependency, reducing communication overhead, and enabling low-power operation, the proposed framework addresses critical challenges in connectivity-limited, energy-sensitive agricultural contexts. It demonstrates the potential for scalable and intelligent smart farming, aligning with the goals of sustainable Agriculture 4.0.}
}
@article{HADJAMEUR2021232,
title = {AraCOVID19-MFH: Arabic COVID-19 Multi-label Fake News & Hate Speech Detection Dataset},
journal = {Procedia Computer Science},
volume = {189},
pages = {232-241},
year = {2021},
note = {AI in Computational Linguistics},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.05.086},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921012059},
author = {Mohamed Seghir {Hadj Ameur} and Hassina Aliane},
keywords = {Arabic COVID-19 Multi-label Dataset, Annotated Dataset, Fake News Detection, Hate Speech Detection, Misinformation, Social Media, Arabic Language},
abstract = {Along with the COVID-19 pandemic, an "infodemic" of false and misleading information has emerged and has complicated the COVID-19 response efforts. Social networking sites such as Facebook and Twitter have contributed largely to the spread of rumors, conspiracy theories, hate, xenophobia, racism, and prejudice. To combat the spread of fake news, researchers around the world have and are still making considerable efforts to build and share COVID-19 related research articles, models, and datasets. This paper releases "AraCOVID19-MFH"1 a manually annotated multi-label Arabic COVID-19 fake news and hate speech detection dataset. Our dataset contains 10,828 Arabic tweets annotated with 10 different labels. The labels have been designed to consider some aspects relevant to the fact-checking task, such as the tweet’s check worthiness, positivity/negativity, and factuality. To confirm our annotated dataset’s practical utility, we used it to train and evaluate several classification models and reported the obtained results. Though the dataset is mainly designed for fake news detection, it can also be used for hate speech detection, opinion/news classification, dialect identification, and many other tasks.}
}
@article{YAMAMOTO20242626,
title = {Practical Aspects of Designing a Human-centred AI System in Manufacturing},
journal = {Procedia Computer Science},
volume = {232},
pages = {2626-2638},
year = {2024},
note = {5th International Conference on Industry 4.0 and Smart Manufacturing (ISM 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.02.081},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924002588},
author = {Yuji Yamamoto and Alvaro Aranda Muñoz and Kristian Sandström},
keywords = {Human-centred AI, Manufacturing, AI system design, Machine Learning, Socio-technical systems},
abstract = {An increasing number of manufacturing companies have initiated designing and implementing AI systems in manufacturing, however, with limited success. Within our overarching research objective of establishing a methodology for the development of AI systems in manufacturing with socio-technical system consideration, this paper focuses on the early design phase of the development life cycle and aims to identify factors that are essential in the phase but whose importance has been less addressed in the manufacturing literature. To this aim, a case study was conducted adopting a design science approach. The case company was developing an ML-based anomaly detection system for a casting process. The researcher organised an AI system design workshop where participants from the company used the Human-AI design guidelines created by a leading large software company. The workshop enabled the participants to explore a wide range of design concerns. It, however, caused the confusing experience that they had to deal with too many questions simultaneously without clear guidance. Analysing this negative experience has led to identifying four design issues requiring further attention in the research. An example of these issues is that the interdependency of design decisions on operational procedures, human-machine interfaces, ML models, pre-processing, and input data makes it challenging to design these elements in isolation. The study found that a structured approach to dealing with the identified issues was currently lacking. This paper contributes to the manufacturing research community by addressing key unresolved issues in the research through highlighting practical details of designing AI systems in manufacturing.}
}