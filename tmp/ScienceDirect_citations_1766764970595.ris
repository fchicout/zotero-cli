TY  - JOUR
T1  - Advancing fault diagnosis in industrial systems: The power of V-nets for managing complex event sequences
AU  - Vásquez-Capacho, John William
JO  - Engineering Applications of Artificial Intelligence
VL  - 142
SP  - 109781
PY  - 2025
DA  - 2025/02/15/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2024.109781
UR  - https://www.sciencedirect.com/science/article/pii/S0952197624019407
KW  - V-nets theory
KW  - Fault diagnosis
KW  - Discrete-time systems
KW  - Event sequence recognition
KW  - Industrial applications
AB  - This paper introduces V-nets, an innovative formal model developed to enhance fault diagnosis and management of complex Discrete Event Systems (DES), particularly in industrial applications. The V-net model addresses key challenges in traditional models such as Petri nets and automata, including the management of simultaneous events, minimizing false positives, and improving the recognition of partial event sequences. Methods: This study builds upon a comparative analysis of existing fault diagnosis techniques, integrating V-nets with automata to form a robust framework for supervising and diagnosing industrial systems. Through a case study of the Reactor Startup Sequence of a Pressurized Water Reactor (PWR), the research highlights the practical utility of V-nets in real-time fault detection and system monitoring. Findings: The experimental results demonstrate that V-nets significantly reduce false positives and enhance system flexibility when dealing with complex event sequences. By evaluating over 100,000 event sequences using Monte Carlo methods, the study confirms the accuracy and scalability of the V-net model in industrial settings. Novelty: This research pioneers the development of V-nets as a superior alternative to traditional models for fault diagnosis in DES, offering a framework capable of handling simultaneous events and complex time constraints. The proposed model’s potential for real-world implementation opens new avenues for advancing industrial process supervision. The flexibility and scalability of V-nets represent a critical advancement in the formal methods for industrial systems, positioning this model as a promising tool for future industrial applications and automatic V-net generation in real-time scenarios.
ER  - 

TY  - JOUR
T1  - Evaluating quality of ontology-driven conceptual models abstractions
AU  - Romanenko, Elena
AU  - Calvanese, Diego
AU  - Guizzardi, Giancarlo
JO  - Data & Knowledge Engineering
VL  - 153
SP  - 102342
PY  - 2024
DA  - 2024/09/01/
SN  - 0169-023X
DO  - https://doi.org/10.1016/j.datak.2024.102342
UR  - https://www.sciencedirect.com/science/article/pii/S0169023X24000661
KW  - Conceptual model abstraction
KW  - Ontology-driven conceptual models
KW  - Quality evaluation of abstractions
KW  - Unified foundational ontology (UFO)
KW  - FAIR model catalog
KW  - User studies in conceptual modeling
AB  - The complexity of an (ontology-driven) conceptual model highly correlates with the complexity of the domain and software for which it is designed. With that in mind, an algorithm for producing ontology-driven conceptual model abstractions was previously proposed. In this paper, we empirically evaluate the quality of the abstractions produced by it. First, we have implemented and tested the last version of the algorithm over a FAIR catalog of models represented in the ontology-driven conceptual modeling language OntoUML. Second, we performed three user studies to evaluate the usefulness of the resulting abstractions as perceived by modelers. This paper reports on the findings of these experiments and reflects on how they can be exploited to improve the existing algorithm.
ER  - 

TY  - JOUR
T1  - Impact of ChatGPT and generative AI on lifelong learning and upskilling learners in higher education: unveiling the challenges and opportunities globally
AU  - Asad, Muhammad Mujtaba
AU  - Ajaz, Aqsa
JO  - International Journal of Information and Learning Technology
VL  - 41
IS  - 5
SP  - 507
EP  - 523
PY  - 2024
DA  - 2024/10/31/
SN  - 2056-4880
DO  - https://doi.org/10.1108/IJILT-06-2024-0103
UR  - https://www.sciencedirect.com/science/article/pii/S205648802400009X
KW  - ChatGPT
KW  - Generative AI
KW  - Lifelong learning
KW  - Competency-based personalized learning
AB  - Purpose
A gripping keyword emerged in the dynamic world of 2022: GPT or the advent of Generative Artificial Intelligence (GAI), at its forefront, embodied by the mysterious ChatGPT. This technological marvel had been silently lurking in the background for just over five years. However, all of a sudden, it emerged onto the scene, capturing the public’s attention and quickly becoming one of the most widely adopted inventions in history. Therefore, this narrative review is conducted in order to explore the impact of generative AI and ChatGPT on lifelong learning and upskilling of students in higher education and address opportunities and challenges proposed by Artificial Intelligence from a global perspective.
Design/methodology/approach
This review has been conducted using a narrative literature review approach. For in-depth identification of research gaps, 105 relevant articles were included from scholarly databases such as Scopus, Web of Science, ERIC and Google Scholar. Seven major themes emerged from the literature to answer the targeted research questions that describe the use of AI, the impact of generative AI and ChatGPT on students, the challenges and opportunities of using AI in education and mitigating strategies to cope with the challenges associated with the integration of ChatGPT and generative AI in education.
Findings
The review of the literature presents that generative AI and ChatGPT have gained a lot of recognition among students and have revolutionized educational settings. The findings suggest that there are some contexts in which adult education research and teaching can benefit from the use of chatbots and generative AI technologies like ChatGPT. The literature does, however, also highlight the necessity of carefully considering the benefits and drawbacks of these technologies in order to prevent restricting or distorting the educational process or endangering academic integrity. In addition, the literature raises ethical questions about data security, privacy and cheating by students or researchers. To these, we add our own ethical concerns about intellectual property, such as the fact that, once we enter ideas or research results into a generative chatbot, we no longer have control over how it is used.
Practical implications
This review is helpful for educators and policymakers to design the curriculum and policies that encourage students to use generative AI ethically while taking academic integrity into account. Also, this review article identifies the major gaps that are associated with the impact of AI and ChatGPT on the lifelong learning skills of students.
Originality/value
This review of the literature is unique because it explains the challenges and opportunities of using generative AI and ChatGPT, also defining its impact on lifelong learning and upskilling of students.
ER  - 

TY  - JOUR
T1  - Evaluating European Maritime Infrastructure Resilience through Constructive Simulation and Infrastructure Models
AU  - Niemi, Arto
AU  - Rosseck, Niklas
AU  - Stockfisch, Niklas
AU  - Stockbrügger, Jan
AU  - Wrede, Carl
AU  - Torres, Frank Sill
JO  - Procedia Computer Science
VL  - 274
SP  - 973
EP  - 982
PY  - 2025
DA  - 2025/01/01/
T2  - 22nd International Multidisciplinary Modeling & Simulation Multiconference (I3M)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2025.12.095
UR  - https://www.sciencedirect.com/science/article/pii/S1877050925038165
KW  - Maritime Security
KW  - Constructive Simulations
KW  - Infrastructure Models
AB  - The European maritime security is challenged by geopolitical tensions. This development necessitates robust protection strategies for critical infrastructure. Recent events, including suspected attacks on subsea cables and drone sightings near energy terminals, underscore the infrastructure vulnerability. We propose the application of constructive simulation models to evaluate the protection and resilience of maritime infrastructures. Constructive simulation offers an analytical tool for assessing the effectiveness of security measures. These simulations are today used in the defense field, e.g. for informing procurement decisions, optimizing ways on how well these systems are used for countering such threats, and for training practitioners. We see advantages in using this approach also in the civil security field. A simulation to replicate potential threat scenarios enables the evaluation of system capabilities and the development of effective countermeasures. This paper describes a variety of frameworks for the creation of constructive simulations. Each framework offers different advantages. A single simulation often proves insufficient in addressing the complexity of such scenarios. Thus, the use of co-simulations has become a prevalent approach. This concept requires diverse distribution standards, which in turn can be employed to establish a connection between potential simulations and infrastructure models. These standards are further described in this paper. Moreover, integrating detailed infrastructure models, exemplified by a recently developed offshore wind farm model, allows the simulation of infrastructure failures and the assessment of repair logistics. We discuss how this approach allows testing of infrastructure resilience against attacks, in terms of preventing and recovering from them.
ER  - 

TY  - JOUR
T1  - A Comprehensive Survey of Artificial Intelligence Applications in UAV-Enabled Wireless Networks
AU  - Zhou, Li
AU  - Yin, Hao
AU  - Zhao, Haitao
AU  - Wei, Jibo
AU  - Hu, Dewen
AU  - Leung, Victor C.M.
JO  - Digital Communications and Networks
PY  - 2024
DA  - 2024/11/20/
SN  - 2352-8648
DO  - https://doi.org/10.1016/j.dcan.2024.11.005
UR  - https://www.sciencedirect.com/science/article/pii/S2352864824001536
KW  - Artificial intelligence (AI)
KW  - Machine learning (ML)
KW  - Unmanned aerial vehicle (UAV)
KW  - Wireless network
AB  - This comprehensive survey paper examines the applications of artificial intelligence (AI) in unmanned aerial vehicle (UAV)-enabled wireless networks. With the increasing demand for efficient and adaptive communication systems, the integration of AI with UAV networks promises to revolutionize various aspects of wireless communication. The paper first outlines the background and motivation behind AI integration, highlighting the potential for enhanced network performance, autonomy, and adaptability. It then delves into the key AI applications across different network layers, including data sensing and collection, placement and trajectory optimization, radio resource management, routing and topology control, edge computing and caching, as well as security and privacy enhancement. For each application, the paper discusses relevant AI techniques, main findings, optimization objects, and the potential benefits and challenges. The survey also identifies open issues, such as the practical implementation gap, standardization issues, and real-world application barriers, and proposes future directions to address these challenges and further advance the field. In conclusion, the integration of AI with UAV-enabled wireless networks (UWNs) holds tremendous potential for transforming wireless communication, enabling new applications and services with unprecedented capabilities.
ER  - 

TY  - JOUR
T1  - A/B testing: A systematic literature review
AU  - Quin, Federico
AU  - Weyns, Danny
AU  - Galster, Matthias
AU  - Silva, Camila Costa
JO  - Journal of Systems and Software
VL  - 211
SP  - 112011
PY  - 2024
DA  - 2024/05/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2024.112011
UR  - https://www.sciencedirect.com/science/article/pii/S0164121224000542
KW  - A/B testing
KW  - Systematic literature review
KW  - A/B test engineering
AB  - A/B testing, also referred to as online controlled experimentation or continuous experimentation, is a form of hypothesis testing where two variants of a piece of software are compared in the field from an end user’s point of view. A/B testing is widely used in practice to enable data-driven decision making for software development. While a few studies have explored different facets of research on A/B testing, no comprehensive study has been conducted on the state-of-the-art in A/B testing. Such a study is crucial to provide a systematic overview of the field of A/B testing driving future research forward. To address this gap and provide an overview of the state-of-the-art in A/B testing, this paper reports the results of a systematic literature review that analyzed primary studies. The research questions focused on the subject of A/B testing, how A/B tests are designed and executed, what roles stakeholders have in this process, and the open challenges in the area. Analysis of the extracted data shows that the main targets of A/B testing are algorithms, visual elements, and workflow and processes. Single classic A/B tests are the dominating type of tests, primarily based in hypothesis tests. Stakeholders have three main roles in the design of A/B tests: concept designer, experiment architect, and setup technician. The primary types of data collected during the execution of A/B tests are product/system data, user-centric data, and spatio-temporal data. The dominating use of the test results are feature selection, feature rollout, continued feature development, and subsequent A/B test design. Stakeholders have two main roles during A/B test execution: experiment coordinator and experiment assessor. The main reported open problems are related to the enhancement of proposed approaches and their usability. From our study we derived three interesting lines for future research: strengthen the adoption of statistical methods in A/B testing, improving the process of A/B testing, and enhancing the automation of A/B testing.
ER  - 

TY  - JOUR
T1  - A novel hybrid liquid neural network with time dependent neuromorphic and transformer encoder based reservoir dynamics for respiratory sound classification
AU  - Aslan, Narin
JO  - Engineering Applications of Artificial Intelligence
VL  - 162
SP  - 112728
PY  - 2025
DA  - 2025/12/26/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2025.112728
UR  - https://www.sciencedirect.com/science/article/pii/S0952197625027599
KW  - Respiratory sound
KW  - Liquid neural network
KW  - Transformer encoder
KW  - Neuromorphic structure
KW  - Machine learning
AB  - Chronic obstructive pulmonary disease is often misdiagnosed due to its similarity to other respiratory disorders, which delays early intervention. In liquid neural network reservoirs, leaky and spiking neurons enhance sensitivity to low-frequency variations while preserving the continuity of respiratory sounds. Time-dependent activation coefficients and adaptive leakage rates improve computational efficiency, stability, and memory retention. To further enhance the discrimination between normal and chronic obstructive pulmonary disease respiratory signals by capturing long-range dependencies and temporal dynamics, a transformer encoder module is integrated. In this study, respiratory sound recordings obtained from individuals with chronic obstructive pulmonary disease and healthy controls are subjected to Z-score normalization. The liquid neural network reservoir is configured to include both leaky and spiking neurons. To improve performance metrics, a time-dependent activation coefficient is assigned to the leaky neurons, while a time-dependent leakage coefficient is added to the spiking neurons. To enhance the modeling capabilities, a transformer encoder block is integrated into the reservoir architecture. The accuracy values of the liquid neural network reservoir with leaky and spiking neurons are 97.70 % and 91.63 %, respectively. When a time-dependent activation coefficient is applied to the leaky neurons and a time-dependent leakage coefficient to the spiking neurons, the accuracy values increase to 99.84 % and 94.25 %, respectively. When the transformer encoder is integrated into the liquid neural network reservoir, the prediction accuracy values for the leaky and spiking neuron architectures are 98.19 % and 93.43 %, respectively. Furthermore, the robustness analysis revealed that the differences in accuracy values ranged from −0.94 to −4.83.
ER  - 

TY  - JOUR
T1  - A design framework for operationalizing trustworthy artificial intelligence in healthcare: Requirements, tradeoffs and challenges for its clinical adoption
AU  - Moreno-Sánchez, Pedro A.
AU  - Del Ser, Javier
AU  - van Gils, Mark
AU  - Hernesniemi, Jussi
JO  - Information Fusion
VL  - 127
SP  - 103812
PY  - 2026
DA  - 2026/03/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2025.103812
UR  - https://www.sciencedirect.com/science/article/pii/S1566253525008747
KW  - Trustworthy AI
KW  - Design framework
KW  - Health stakeholders
KW  - Medical AI
KW  - Healthcare
KW  - Explainable AI
KW  - Human agency and oversight
KW  - AI safety
KW  - Privacy
KW  - AI fairness
AB  - Artificial Intelligence (AI) holds great promise for transforming healthcare, particularly in disease diagnosis, prognosis, and patient care. The increasing availability of digital medical data, such as images, omics data, biosignals, and electronic health records, combined with advances in computing, has enabled AI models to approach expert-level performance. However, widespread clinical adoption remains limited, primarily due to challenges beyond technical performance, including ethical concerns, regulatory barriers, and lack of trust. To address these issues, medical AI systems must align with the principles of Trustworthy AI (TAI), which emphasize human agency and oversight, algorithmic robustness, privacy and data governance, transparency, bias and discrimination avoidance, and accountability. Yet, the complexity of healthcare processes (e.g., screening, diagnosis, prognosis, and treatment) and the diversity of stakeholders (clinicians, patients, providers, regulators) complicate the integration of TAI principles. To bridge the gap between TAI theory and practical implementation, this paper proposes a design framework to support developers in embedding TAI principles into medical AI systems. Thus, for each stakeholder identified across various healthcare processes, we propose a disease-agnostic collection of requirements that medical AI systems should incorporate to adhere to the principles of TAI. Additionally, we examine the challenges and tradeoffs that may arise when applying these principles in practice. To illustrate the discussion, we focus on cardiovascular diseases, which is a field marked by both high prevalence and active AI innovation, and demonstrate how TAI principles have been applied and where key obstacles persist.
ER  - 

TY  - JOUR
T1  - Defeating CSI obfuscation mechanisms: A study on unauthorized Wi-Fi Sensing in wireless sensor network
AU  - Chu, Zhiming
AU  - Li, Guyue
AU  - Meng, Qingchun
AU  - Li, Haobo
AU  - Zeng, Yuwei
JO  - Computer Networks
VL  - 263
SP  - 111208
PY  - 2025
DA  - 2025/05/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2025.111208
UR  - https://www.sciencedirect.com/science/article/pii/S1389128625001768
KW  - Wi-Fi sensing
KW  - Privacy concerns
KW  - Channel obfuscation
KW  - Unauthorized sensing
KW  - Wireless security
AB  - The proliferation of Wi-Fi sensing technology has raised significant privacy concerns due to potential unauthorized environmental monitoring. As a typical countermeasure, the Channel State Information (CSI) fuzzer uses a time-varying filter at the transmitter to obfuscate CSI, allowing only legitimate receiver who has the pre-shared filter parameters as keys to restore the original CSI. In this work, we present SnoopFi, a framework enabling unauthorized reconstruction of environment-matching sensing signals from obfuscated CSI, even with limited training samples. SnoopFi acquires accurate raw CSI when attackers exploit security vulnerabilities to obtain keys. It can also generate a new base signal that reflect the physical environment for sensing when the attackers’ capabilities are limited. SnoopFi employs two strategies to negate the filter’s effects: (1) The attacker first attempts to guess the keys, and then it inverts the filter by modeling the nonlinear relationship between the filter’s response and the keys; (2) With multiple receiving antennas, the attacker utilizes the ratio of CSIs between different antennas to wipe off the filter effect. Once the obfuscation is removed, SnoopFi uses a few-shot learning technique for precise sensing of user localization with constrained training samples. The experimental results show that SnoopFi achieves localization accuracies of 91.79% and 92.05% under the two strategies, respectively, with an average of only 18 samples per class.
ER  - 

TY  - JOUR
T1  - CodeSearchAttack: Enhancing soft-label black-box adversarial attacks on code
AU  - Pu, Xin
AU  - Xiong, Xi
AU  - Li, Yuanyuan
AU  - Liu, Zhaorong
AU  - Yu, Yan
JO  - Journal of Information Security and Applications
VL  - 94
SP  - 104258
PY  - 2025
DA  - 2025/11/01/
SN  - 2214-2126
DO  - https://doi.org/10.1016/j.jisa.2025.104258
UR  - https://www.sciencedirect.com/science/article/pii/S2214212625002959
KW  - Code adversarial attack
KW  - Robustness
KW  - Black-box
KW  - Soft-label
AB  - Adversarial attacks on code data face significant challenges due to its discrete and non-differentiable nature. Soft-label black-box code adversarial attacks, in particular, are a highly complex task, with research in this area still in its early stages. Existing methods leave room for improvement in performance. For instance, greedy search-based attacks often get trapped in local optima, resulting in excessive perturbations. To tackle these challenges, we propose a novel framework, CodeSearchAttack, for crafting high-quality adversarial examples. CodeSearchAttack leverages constrained K-means to identify diverse substitutions in the variable embedding space and employs an improved beam search to craft adversarial examples. Additionally, it calculates variable importance using information derived from soft labels. Experiments on four code classification tasks demonstrate that CodeSearchAttack significantly outperforms state-of-the-art baseline methods. Under a query budget of 100, CodeSearchAttack achieves superior attack efficacy compared to existing soft-label attacks.
ER  - 

TY  - JOUR
T1  - Fluid Computing & Digital Twins for intelligent interoperability in the IoT ecosystem
AU  - Bedogni, Luca
AU  - Mamei, Marco
AU  - Picone, Marco
AU  - Pietri, Marcello
AU  - Zambonelli, Franco
JO  - Future Generation Computer Systems
VL  - 171
SP  - 107855
PY  - 2025
DA  - 2025/10/01/
SN  - 0167-739X
DO  - https://doi.org/10.1016/j.future.2025.107855
UR  - https://www.sciencedirect.com/science/article/pii/S0167739X25001505
KW  - Digital twins
KW  - Intelligence
KW  - Fluid Computing
KW  - Interoperability
AB  - The integration of physical and digital systems is fundamental to enabling intelligent, adaptive, and scalable solutions in modern IoT environments. This paper explores Fluid Digital Twins (FDTs), a novel framework combining Fluid Computing (FC) principles with Digital Twin (DT) technology, to address challenges related to interoperability, dynamic functionality, and adaptability in IoT ecosystems. FC introduces a paradigm shift, enabling seamless data and computational task flow across heterogeneous environments, dynamically adjusting to resource availability and system needs. This paper focuses on embedding intelligence within FDTs to enhance interoperability and enable IoT applications to adapt to changes across both physical and digital domains. By integrating intelligent interoperability mechanisms, FDTs ensure smooth data alignment and compatibility across platforms, adapting to both physical and digital changes. The proposed framework has been implemented, prototyped, and evaluated in the Modena Automotive Smart Area (MASA), a smart city testbed. The evaluation demonstrates FDTs’ ability to enhance smart mobility, optimize transportation systems, and provide actionable insights, highlighting their transformative potential in dynamic, data-rich environments. The results emphasize the practical applicability of FDTs in addressing real-world challenges and advancing the capabilities of IoT-driven smart cities.
ER  - 

TY  - JOUR
T1  - AI-driven business model innovation: A systematic review and research agenda
AU  - Jorzik, Philip
AU  - Klein, Sascha P.
AU  - Kanbach, Dominik K.
AU  - Kraus, Sascha
JO  - Journal of Business Research
VL  - 182
SP  - 114764
PY  - 2024
DA  - 2024/09/01/
SN  - 0148-2963
DO  - https://doi.org/10.1016/j.jbusres.2024.114764
UR  - https://www.sciencedirect.com/science/article/pii/S0148296324002686
KW  - Business model innovation
KW  - Artificial intelligence
KW  - Value proposition
KW  - AI-driven BMI
KW  - Systematic literature review
AB  - Recent years have seen a surge in research on artificial intelligence (AI)-driven business model innovation (BMI), reflecting its profound impact across industries. However, the field’s current state remains fragmented due to varied conceptual lenses and units of analysis. Existing literature predominantly emphasizes the technological aspects of AI implementation in business models (BMs), treating BMI as a byproduct. Additionally, there is a lack of coherent understanding regarding the scope of BMI propelled by AI. To address these gaps, our study systematically reviews 180 articles, offering two key contributions: (1) a structured analysis of evolving research dimensions in AI-driven BMI, differentiating between static and dynamic views of BMI, and (2) a framework presenting distinct research perspectives on AI-driven BMI, each addressing specific managerial focuses. This synthesis facilitates a comprehensive understanding of the field, enabling the identification of research gaps and proposing future avenues for advancing knowledge on the management of AI-driven BMI.
ER  - 

TY  - JOUR
T1  - CASMS: Combining clustering with attention semantic model for identifying security bug reports
AU  - Ma, Xiaoxue
AU  - Keung, Jacky
AU  - Yang, Zhen
AU  - Yu, Xiao
AU  - Li, Yishu
AU  - Zhang, Hao
JO  - Information and Software Technology
VL  - 147
SP  - 106906
PY  - 2022
DA  - 2022/07/01/
SN  - 0950-5849
DO  - https://doi.org/10.1016/j.infsof.2022.106906
UR  - https://www.sciencedirect.com/science/article/pii/S0950584922000647
KW  - Security bug report
KW  - Clustering
KW  - Hybrid neural networks
AB  - Context:
Inappropriate public disclosure of security bug reports (SBRs) is likely to attract malicious attackers to invade software systems; hence being able to detect SBRs has become increasingly important for software maintenance. Due to the class imbalance problem that the number of non-security bug reports (NSBRs) exceeds the number of SBRs, insufficient training information, and weak performance robustness, the existing techniques for identifying SBRs are still less than desirable.
Objective:
This prompted us to overcome the challenges of the most advanced SBR detection methods.
Method:
In this work, we propose the CASMS approach to efficiently alleviate the imbalance problem and predict bug reports. CASMS first converts bug reports into weighted word embeddings based on tf−idf and word2vec techniques. Unlike the previous studies selecting the NSBRs that are the most dissimilar to SBRs, CASMS then automatically finds a certain number of diverse NSBRs via the Elbow method and k-means clustering algorithm. Finally, the selected NSBRs and all SBRs train an effective Attention CNN–BLSTM model to extract contextual and sequential information.
Results:
The experimental results have shown that CASMS is superior to the three baselines (i.e., FARSEC, SMOTUNED, and LTRWES) in assessing the overall performance (g-measure) and correctly identifying SBRs (recall), with improvements of 4.09%–24.26% and 10.33%–36.24%, respectively. The best results are easily obtained under the limited ratio ranges of the two-class training set (1:1 to 3:1), with around 20 experiments for each project. By evaluating the robustness of CASMS via the standard deviation indicator, CASMS is more stable than LTRWES.
Conclusion:
Overall, CASMS can alleviate the data imbalance problem and extract more semantic information to improve performance and robustness. Therefore, CASMS is recommended as a practical approach for identifying SBRs.
ER  - 

TY  - JOUR
T1  - RaxCS: Towards cross-language code summarization with contrastive pre-training and retrieval augmentation
AU  - Yang, Kaiyuan
AU  - Wang, Junfeng
AU  - Song, Zihua
JO  - Information and Software Technology
VL  - 183
SP  - 107741
PY  - 2025
DA  - 2025/07/01/
SN  - 0950-5849
DO  - https://doi.org/10.1016/j.infsof.2025.107741
UR  - https://www.sciencedirect.com/science/article/pii/S0950584925000801
KW  - Code summarization
KW  - Cross-language
KW  - Retrieval augmentation
KW  - Contrastive learning
AB  - Context:
Code summarization is the task of generating a concise natural language description of the code snippet. Recent efforts have been made to boost the performance of code summarization language from various perspectives, e.g., retrieving external information or introducing large transformer-based models, and thus has achieved promising performance for one specific programming language. While dealing with rapidly expanded cross-language source code datasets, existing approaches suffer from two issues, (1) the difficulty of building a universe code representation for multiple languages; (2) less-well performance for low-resource language.
Objective:
To cope with these issues, we propose a novel code summarization approach named RaxCS, which aims to perform code summarization across multiple languages and improve accuracy for low-resource languages by leveraging cross-language knowledge.
Methods:
We exploit the pre-trained models with the contrastive learning objective to build a unified code representation towards multiple languages. To fully mine the external knowledge across programming languages, we design a hybrid retrieval module to search functionally equivalent code and its corresponding comment to serve as preliminary information. Finally, we employ a decode-only transformer model to fuse contextual information, which guides the process of generating summaries.
Results:
Extensive experiments demonstrate (1) RaxCS outperforms the state-of-the-art on cross-language code summarization (i.e., RaxCS scores 4.39% higher in terms of BLEU metric and 8.65% in terms of BERTScore). (2) For low-resource languages, RaxCS can boost the code summarization performance by a significant magnification (e.g., 6.93% in terms of BLEU for ruby) with cross-language retrieval.
Conclusion:
This paper introduces a cross-language code summarization model, which utilizes contrastive pre-training and cross-language retrieval. Both are beneficial for incorporating cross-language knowledge to advance code summarization performance. The experimental results demonstrate that RaxCS is effective in generating accurate code summaries, particularly for low-resource languages.
ER  - 

TY  - JOUR
T1  - Towards understanding the role of content-based and contextualized features in detecting abuse on Twitter
AU  - Hussain, Kamal
AU  - Saeed, Zafar
AU  - Abbasi, Rabeeh
AU  - Sindhu, Muddassar
AU  - Khattak, Akmal
AU  - Arafat, Sachi
AU  - Daud, Ali
AU  - Mushtaq, Mubashar
JO  - Heliyon
VL  - 10
IS  - 8
SP  - e29593
PY  - 2024
DA  - 2024/04/30/
SN  - 2405-8440
DO  - https://doi.org/10.1016/j.heliyon.2024.e29593
UR  - https://www.sciencedirect.com/science/article/pii/S240584402405624X
KW  - Abuse
KW  - Context
KW  - Machine learning
KW  - Social media
KW  - Twitter
AB  - This paper presents a novel approach for detecting abuse on Twitter. Abusive posts have become a major problem for social media platforms like Twitter. It is important to identify abuse to mitigate its potential harm. Many researchers have proposed methods to detect abuse on Twitter. However, most of the existing approaches for detecting abuse look only at the content of the abusive tweet in isolation and do not consider its contextual information, particularly the tweets posted before the abusive tweet. In this paper, we propose a new method for detecting abuse that uses contextual information from the tweets that precede and follow the abusive tweet. We hypothesize that this contextual information can be used to better understand the intent of the abusive tweet and to identify abuse that content-based methods would otherwise miss. We performed extensive experiments to identify the best combination of features and machine learning algorithms to detect abuse on Twitter. We test eight different machine learning classifiers on content- and context-based features for the experiments. The proposed method is compared with existing abuse detection methods and achieves an absolute improvement of around 7%. The best results are obtained by combining the content and context-based features. The highest accuracy of the proposed method is 86%, whereas the existing methods used for comparison have highest accuracy of 79.2%.
ER  - 

TY  - JOUR
T1  - A cross-continental analysis of how regional cues shape top stack overflow contributors
AU  - Zolduoarrati, Elijah
AU  - Licorish, Sherlock A.
AU  - Grundy, John
JO  - Journal of Systems and Software
VL  - 223
SP  - 112338
PY  - 2025
DA  - 2025/05/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2025.112338
UR  - https://www.sciencedirect.com/science/article/pii/S0164121225000068
KW  - Contribution
KW  - Cross-regional behaviour
KW  - Repository mining
KW  - Social network analysis
KW  - Topic modelling
KW  - Stack overflow
KW  - User/contributor interactions
AB  - Stack Overflow offers valuable knowledge for software developers, but studies suggest digital information tends to cluster geographically, limiting access to necessary knowledge for innovation. This study explores posts of top contributors on Stack Overflow across the United States, Brazil, India, Egypt, the United Kingdom, and Australia. We analyse platform activities, conduct social network analysis, employ topic modelling paired with thematic analysis, before dissecting their knowledge sharing patterns via directed content analysis. Results indicate that cultural factors, entrepreneurial activities, tech ecosystem maturity, as well as workforce diversity in a region were found to shape how top contributors contribute. For instance, individualistic users communicate directly whilst collectivistic users prefer subtle communication and socio-emotional cues. Moreover, top contributors in nascent technology ecosystems were more likely to discuss fundamental concepts, while those in mature ecosystems focus on specialised niches. This study sheds light on how diversity in human aspects may influence the dynamics of CQA settings, where future researchers can explicate the extent of which latent contextual factors affect user contributions and community structure.
ER  - 

TY  - JOUR
T1  - BFS2Adv: Black-box adversarial attack towards hard-to-attack short texts
AU  - Han, Xu
AU  - Li, Qiang
AU  - Cao, Hongbo
AU  - Han, Lei
AU  - Wang, Bin
AU  - Bao, Xuhua
AU  - Han, Yufei
AU  - Wang, Wei
JO  - Computers & Security
VL  - 141
SP  - 103817
PY  - 2024
DA  - 2024/06/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.103817
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824001184
KW  - Text classification
KW  - Adversarial attack
KW  - Score-based adversarial attack
KW  - Hard-to-attack examples
AB  - The advent of Machine Learning as a Service (MLaaS) and deep learning applications has increased the susceptibility of models to adversarial textual attacks, particularly in black-box settings. Prior work on black-box adversarial textual attacks generally follows a stable strategy that involves leveraging char-level, world-level, and sentence-level perturbations, as well as using queries to the target model to find adversarial examples in the search space. However, existing approaches prioritize query efficiency by reducing the search space, thereby overlooking hard-to-attack textual instances. To address this issue, we propose BFS2Adv, a brute force algorithm that generates adversarial examples for both easy-to-attack and hard-to-attack textual inputs. BFS2Adv, starting with an original text, employs word-level perturbations and synonym substitution to construct a comprehensive search space, with each node representing a potential adversarial example. The algorithm systematically explores this space through a breadth-first search, combined with queries to the target model, to effectively identify qualified adversarial examples. We implemented and evaluated a prototype of BFS2Adv against renowned models such as ALBERT and BERT, utilizing the SNLI and MR datasets. Our results demonstrate that BFS2Adv outperforms state-of-the-art algorithms and effectively improves the success rate of short-text adversarial attacks. Furthermore, we provide detailed insights into the robustness of BFS2Adv by analyzing those hard-to-attack examples.
ER  - 

TY  - JOUR
T1  - Identifying contextual content-based risk drivers for advanced risk management strategies
AU  - Huang, Shirley Hsueh-Li
AU  - Hu, Guo-Hsin
AU  - Hsu, Ming-Fu
JO  - Research in International Business and Finance
VL  - 73
SP  - 102643
PY  - 2025
DA  - 2025/01/01/
SN  - 0275-5319
DO  - https://doi.org/10.1016/j.ribaf.2024.102643
UR  - https://www.sciencedirect.com/science/article/pii/S0275531924004367
KW  - Artificial intelligence
KW  - Risk management
KW  - Decision making
KW  - Text mining
KW  - Word embedding
AB  - This research proposes a profound contextual topic identifier that incorporates topic modelling and a word embedding technique to discover and quantify corporate risks from its self-identified risk disclosures and examines the association between each risk type and operating performance via artificial intelligence (AI) technique. Via topic modelling adoption, we are able to discover the most essential risks confronted by corporates in the near future and evaluate how they respond to these risks. To gain deeper insight, the study performs a bidirectional encoder representation from transformers (BERT) (one type of word embedding approach) to extract and quantify the semantic features embedded into each risk disclosure. The results show that operating performance significantly and positively relates to corporate-specific risks. This study offers solid and direct support for authorities that set accounting principles to encourage firm managers to add a new section on risk factors in annual reports.
ER  - 

TY  - JOUR
T1  - Beyond replacement: How project managers perceive the transformative role of AI in project work
AU  - Mariani, Costanza
AU  - Mancini, Mauro
JO  - Journal of Engineering and Technology Management
VL  - 78
SP  - 101927
PY  - 2025
DA  - 2025/10/01/
SN  - 0923-4748
DO  - https://doi.org/10.1016/j.jengtecman.2025.101927
UR  - https://www.sciencedirect.com/science/article/pii/S0923474825000682
KW  - Artificial intelligence
KW  - Project management
KW  - Transformation
AB  - Recent advancements in Artificial Intelligence (AI) have intensified discussions about job transformation, with growing evidence that many professional roles will be significantly affected. This paper examines the impact of analytical AI systems on project management, focusing on how data-driven, algorithmic tools influence both the quantitative and qualitative dimensions of project management activities. While existing studies often highlight the potential of AI in this domain, they frequently concentrate on generative AI or overlook project managers’ own expectations regarding whether analytical AI will replace or augment their work. Using the Nominal Group Technique, this study investigates which project management activities practitioners expect to be replaced, supported, or remain unaffected by analytical AI. The findings reveal that although analytical AI is not anticipated to replace project managers, it is likely to reshape how tasks are executed. As a result, project managers will increasingly need to develop new skills and competencies to remain competitive in an AI-enhanced project environment.
ER  - 

TY  - JOUR
T1  - A few-shot malware classification approach for unknown family recognition using malware feature visualization
AU  - Conti, Mauro
AU  - Khandhar, Shubham
AU  - Vinod, P.
JO  - Computers & Security
VL  - 122
SP  - 102887
PY  - 2022
DA  - 2022/11/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2022.102887
UR  - https://www.sciencedirect.com/science/article/pii/S0167404822002814
KW  - Malware classification
KW  - Few-shot learning
KW  - Siamese neural networks
KW  - Deep neural networks
KW  - GEM Image
KW  - Malware visualization
AB  - With the ever-increasing threat of malware attacks, building an effective malware classifier to detect malware promptly is of utmost importance. Malware visualization approaches and deep learning techniques have proven effective in classifying sophisticated malware from benchmark datasets. A major problem with traditional deep learning classifier is the need to re-train the classifier when a new malware family emerges. In this paper, we propose few-shot classification techniques which allows us to classify malware based on a few instances and without the need for re-training the classifier for novel malware families. We also propose a novel malware visualization technique that can represent a malware binary as a 3-channel image. We experiment with two distinct few-shot learning architectures namely CSNN (Convolutional Siamese Neural Network) and Shallow-FS (Shallow Few-Shot). CSNN is more suitable when scarce data is available for training, otherwise Shallow-FS can be used to achieve better performance. Our architectures outperforms state of the art few-shot learning approaches and achieves high accuracy in traditional malware classification. Our experiments show our models’ ability to classify recent and novel malware families from just a few instances with high accuracy.
ER  - 

TY  - JOUR
T1  - Bias and ethics of AI systems applied in auditing - A systematic review
AU  - Murikah, Wilberforce
AU  - Nthenge, Jeff Kimanga
AU  - Musyoka, Faith Mueni
JO  - Scientific African
VL  - 25
SP  - e02281
PY  - 2024
DA  - 2024/09/01/
SN  - 2468-2276
DO  - https://doi.org/10.1016/j.sciaf.2024.e02281
UR  - https://www.sciencedirect.com/science/article/pii/S2468227624002266
KW  - Artificial intelligence
KW  - Audit
KW  - Bias
KW  - Ethics
KW  - Machine learning
KW  - AI
AB  - The integration of artificial intelligence into auditing shows great potential in enhancing automation and gaining insights from complex data. However, it also presents significant ethical challenges, including algorithmic biases, transparency, accountability, and fairness. This study aimed to investigate the sources of bias and risks posed by AI systems applied in auditing and the complex downstream interactions and effects they have. The study also explored the technical and ethical guardrails proposed and recommendations for translating principles into auditing practice. A systematic methodology was employed to acquire relevant studies across scientific databases. This involved a three-step process, including a targeted search query using Boolean operators and snowballing to yield 310 preliminary publications. A systematic review process was then conducted to identify 123 relevant articles focused on AI's implications for auditing, accounting, finance, or assurance contexts. Finally, screening and filtering on research quality distilled 83 high-quality publications from the year 2018 to 2023 spanning computer science, accounting, management science, and ethics disciplines. The analysis revealed five primary sources driving technical and human biases: data deficiencies, demographic homogeneity, spurious correlations, improper comparators, and cognitive biases. It also highlighted wider issues, such as trade-offs between efficiency and diligence, erosion of human skills and judgement, data dependence risks, and privacy violations from uncontrolled personal data exploitation. The study found promising remedies, including causal modeling to enable auditors to uncover subtle biases, representative algorithmic testing to evaluate fairness, periodic auditing of AI systems, human oversight alongside automation, and embedding ethical values like fairness and accountability into system design. The study concludes that auditors play a crucial role in assessing and ensuring AI's reliable and socially beneficial integration. It recommends governance, risk assessment before deployment, ongoing performance monitoring, and policies fostering trust and collaboration to responsibly translate principles into auditing practice.
ER  - 

TY  - JOUR
T1  - Artificial intelligence for human flourishing – Beyond principles for machine learning
AU  - Stahl, B.C.
AU  - Andreou, A.
AU  - Brey, P.
AU  - Hatzakis, T.
AU  - Kirichenko, A.
AU  - Macnish, K.
AU  - Laulhé Shaelou, S.
AU  - Patel, A.
AU  - Ryan, M.
AU  - Wright, D.
JO  - Journal of Business Research
VL  - 124
SP  - 374
EP  - 388
PY  - 2021
DA  - 2021/01/01/
SN  - 0148-2963
DO  - https://doi.org/10.1016/j.jbusres.2020.11.030
UR  - https://www.sciencedirect.com/science/article/pii/S0148296320307839
KW  - Ethics
KW  - Artificial intelligence
KW  - Big data
KW  - Human rights
KW  - Governance
AB  - The technical and economic benefits of artificial intelligence (AI) are counterbalanced by legal, social and ethical issues. It is challenging to conceptually capture and empirically measure both benefits and downsides. We therefore provide an account of the findings and implications of a multi-dimensional study of AI, comprising 10 case studies, five scenarios, an ethical impact analysis of AI, a human rights analysis of AI and a technical analysis of known and potential threats and vulnerabilities. Based on our findings, we separate AI ethics discourse into three streams: (1) specific issues related to the application of machine learning, (2) social and political questions arising in a digitally enabled society and (3) metaphysical questions about the nature of reality and humanity. Human rights principles and legislation have a key role to play in addressing the ethics of AI. This work helps to steer AI to contribute to human flourishing.
ER  - 

TY  - JOUR
T1  - Envyr: Instant Execution with Smart Inference
AU  - Chaudhry, Tanmay
AU  - Garg, Abhay
AU  - Pathak, Yogesh
JO  - Procedia Computer Science
VL  - 238
SP  - 1068
EP  - 1073
PY  - 2024
DA  - 2024/01/01/
T2  - The 15th International Conference on Ambient Systems, Networks and Technologies Networks (ANT) / The 7th International Conference on Emerging Data and Industry 4.0 (EDI40), April 23-25, 2024, Hasselt University, Belgium
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.06.136
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924013723
KW  - devops
KW  - packaging
KW  - docker
KW  - inference
KW  - containers
KW  - sandboxes
KW  - reuse
KW  - python
AB  - This paper introduces a novel framework that eliminates the often cumbersome "build and install" step when running software. Our framework packages a collection of techniques to automatically infer and generate sandboxes, specifically Linux containers, for running applications directly from their source code. This approach significantly simplifies software execution, improving developer productivity and promoting reuse. We demonstrate the framework’s effectiveness through real-world examples and use cases implemented in Python, NodeJS, and Bash.
ER  - 

TY  - JOUR
T1  - A machine learning approach for detecting customs fraud through unstructured data analysis in social media
AU  - Dangsawang, Bundidth
AU  - Nuchitprasitchai, Siranee
JO  - Decision Analytics Journal
VL  - 10
SP  - 100408
PY  - 2024
DA  - 2024/03/01/
SN  - 2772-6622
DO  - https://doi.org/10.1016/j.dajour.2024.100408
UR  - https://www.sciencedirect.com/science/article/pii/S2772662224000122
KW  - Logistic Regression
KW  - Long short-term memory
KW  - Gated Recurrent Unit
KW  - Unstructured data
KW  - Customs duties
KW  - Commercial goods
AB  - Goods and services are sold through social media by individuals not authorized as legitimate dealers, resulting in lost taxes and customs duties to governments. This study proposes a model called SHIELD for detecting these violations through unstructured data in social media. The process involves collecting 2,373,570 records of commercial goods from social media platforms such as Twitter and Facebook in three phases. In Phase 1, keywords for labeling are collected for text classification. Three categories of results are defined: Red Line for smuggled goods, unpaid duty, prohibited goods, and restricted goods; Green Line for non-commercial goods; and Inspect for goods that cannot be identified from the text and require further investigation. Phase 2 and Phase 3 use keywords to detect smugglers from unstructured social media data for labeling grouped by three algorithms of Logistic Regression (LR), Gated Recurrent Unit (GRU), and Long Short-Term Memory (LSTM), employed to classify imported illegal products. The results of all tests show that the LSTM technique had the best accuracy of 99.44% and the best average F1 score of 90.55%. Using algorithms and techniques such as LR, GRU, and LSTM demonstrates the potential of machine learning and natural language processing in detecting illegal activities and promoting economic security.
ER  - 

TY  - JOUR
T1  - Laws of encryption: An emerging legal framework
AU  - Dizon, Michael Anthony C.
AU  - Upson, Peter John
JO  - Computer Law & Security Review
VL  - 43
SP  - 105635
PY  - 2021
DA  - 2021/11/01/
SN  - 2212-473X
DO  - https://doi.org/10.1016/j.clsr.2021.105635
UR  - https://www.sciencedirect.com/science/article/pii/S0267364921001084
KW  - Encryption laws
KW  - Cybercrime
KW  - Export control
KW  - Criminal procedure
KW  - Human rights
KW  - Cybersecurity
AB  - This article examines the emerging legal framework of encryption. It reviews the different categories of law that make up this legal framework, namely: export control laws, substantive cybercrime laws, criminal procedure laws, human rights laws, and cybersecurity laws. These laws are analysed according to which of the three regulatory subjects or targets they specifically address: the technology of encryption, the parties to encryption, or encrypted data and communications. For each category of law, illustrative examples of international and national laws are discussed. This article argues that understanding the legal framework of encryption is essential to determining how this technology is currently regulated and how these regulations can be improved. It concludes that the legal framework is the key to discerning the present state and future direction of encryption laws and policies.
ER  - 

TY  - JOUR
T1  - Business and human rights in Industry 4.0: A blueprint for collaborative human rights due diligence in the Factories of the Future
AU  - Emanuilov, Ivo
AU  - Yordanova, Katerina
JO  - Journal of Responsible Technology
VL  - 10
SP  - 100028
PY  - 2022
DA  - 2022/07/01/
SN  - 2666-6596
DO  - https://doi.org/10.1016/j.jrt.2022.100028
UR  - https://www.sciencedirect.com/science/article/pii/S2666659622000051
KW  - Industry 4.0
KW  - Smart manufacturing
KW  - Human rights
KW  - Collaborative due diligence
AB  - The digitalisation of production driven by new paradigms such as Industry 4.0, factories of the future and smart manufacturing, create new challenges as to how manufacturers and other supply chain actors would discharge their corporate responsibility to respect human rights. These new paradigms enable novel approaches like distributed and collaborative manufacturing. Manufacturers increasingly leverage digital technologies, such as 3D printing, cloud manufacturing and artificial intelligence, to provide customised products. Digital technologies also improve predictive and preventive maintenance on the shop floor and across the supply chain, increasing the overall resilience of manufacturing industries in times of crisis. This article proposes a blueprint of a collaborative, decentralised approach to human rights due diligence in digital supply chains. It argues that the pooling of human rights due diligence efforts in manufacturing industries could have network-wide effects of incentivising value chain actors to also collaborate on providing collective remedy.
ER  - 

TY  - JOUR
T1  - How does misinformation influence the digital agri-food advisory service? Multi-stakeholder Perspectives from Sri Lanka
AU  - Chowdhury, Ataharul
AU  - Kabir, Khondokar H.
AU  - Khan, Nasir Abbas
AU  - Gow, Gordon
JO  - Sustainable Futures
VL  - 10
SP  - 101093
PY  - 2025
DA  - 2025/12/01/
SN  - 2666-1888
DO  - https://doi.org/10.1016/j.sftr.2025.101093
UR  - https://www.sciencedirect.com/science/article/pii/S2666188825006574
KW  - Agriculture
KW  - Food
KW  - Misinformation
KW  - Digital advisory service
KW  - Q methodology
KW  - Sri Lanka
AB  - Misinformation can be a significant issue in the agri-food sector, just as it is in health and politics. The rise of social media has changed the way agri-food actors communicate, making it easier for them to connect and overcome the challenges of limited resources and slow service. However, while social media’s ease of access and rapid dissemination of information has benefits, it also creates a fertile ground for spreading misinformation. Understanding misinformation and its related issues can help inform strategies to address it. This study analyzed the perspectives of farmers, researchers, advisors, and input dealers on misinformation and its influence on agri-food advisory services in the virtual realms of social and online media in Sri Lanka. Using Q-methodology, we found three distinct perspectives on the issue. The first perspective sees social media as a great tool for connecting people but also a significant source of misinformation. The second perspective shows that the main motivation for spreading misinformation in the agri-food sector is the profit generated by those unfamiliar with farmers’ challenges. The third perspective sees misinformation as spreading quickly and difficult to counteract but acknowledges that it can be posted and shared by mistake. All three perspectives emphasize the need to improve digital literacy skills, develop an effective moderation strategy, and adopt a political economy of agri-food misinformation, and cultivate a multi-stakeholder collaboration to combat it. This study is the first of its kind and helps improve our understanding of this pressing issue. It provides valuable insights and impetus for future research, as we anticipate that agricultural advisory services will continue to embrace various digital tools.
ER  - 

TY  - JOUR
T1  - Neural networks based domain name generation
AU  - Wang, Zheng
AU  - Guo, Yang
JO  - Journal of Information Security and Applications
VL  - 61
SP  - 102948
PY  - 2021
DA  - 2021/09/01/
SN  - 2214-2126
DO  - https://doi.org/10.1016/j.jisa.2021.102948
UR  - https://www.sciencedirect.com/science/article/pii/S2214212621001629
KW  - Domain generation algorithm
KW  - Malicious domain name
KW  - Classification
KW  - Variational autoencoder
KW  - Deep learning
AB  - Domain generation algorithm (DGA) is used by botnets to build a stealthy command and control (C&C) communication channel between the C&C server and the bots. A DGA can periodically produce a large number of pseudo-random algorithmically generated domains (AGDs), a few of which direct the bots to the C&C server. AGD detection algorithms provide a lightweight, promising solution in response to the existing DGA techniques. In the constantly evolving attacker–defender game, attackers may seek more advanced DGA techniques to gain a better chance of evading detection by defenders. In this paper, we propose a new DGA, namely a neural networks-based domain name generation (NDG) architecture. NDG is based on a variational autoencoder (VAE), where the encoder and decoder networks use stacked gated convolutional neural networks (GCNNs) to learn the contextual structure hierarchically. NDG is experimentally validated using a set of state-of-the-art AGD detection algorithms. The existing DGAs of different classes following a DGA taxonomy are used to benchmark NDG. NDG shows the best overall anti-detection performance among all tested DGAs. We also demonstrate that NDG is effective in benchmarking AGD detection algorithms.
ER  - 

TY  - JOUR
T1  - Digital Sustainable Growth Model (DSGM): Achieving synergy between economy and technology to mitigate AGI risks and address global debt challenges
AU  - Shalaby, Ahmed
JO  - Journal of Economy and Technology
VL  - 3
SP  - 314
EP  - 332
PY  - 2025
DA  - 2025/11/01/
SN  - 2949-9488
DO  - https://doi.org/10.1016/j.ject.2024.08.003
UR  - https://www.sciencedirect.com/science/article/pii/S2949948824000350
KW  - Digital Sustainable Growth Model (DSGM)
KW  - Artificial Humanity (AH)
KW  - BankRabbna
KW  - Ethical AI Development
KW  - Global debt
KW  - Sustainable economic growth
AB  - The emergence of Artificial General Intelligence (AGI) as Artificial Humanity (AH) marks a crucial turning point in human history, influencing both the digital economy and sustainable development. AGI has the potential to either drive unprecedented progress or threaten sustainability. This perspective study critiques existing capitalist systems and proposes a shift towards sustainable digital strategies to address the uncertain future role of AGI. It aims to encourage further research and collaboration for a smooth transition to a society that integrates AGI, highlighting AGI's potential to contribute to sustainable development. The study employs a multi-step methodology, including interviews with AI models such as ChatGPT-4 and Gemini, validation of insights, and comparisons with expert reports. It introduces the Digital Sustainable Growth Model (DSGM) as a framework for harmonizing humanity with AH, providing new opportunities for growth and ethical governance. The DSGM addresses both human vulnerabilities and AH’s potential. Additionally, the study highlights the BankRabbna application as an innovative digital tool, intended to be the first of its kind—a global company primarily owned by people worldwide. Its main function is to automate AI regulation, ensuring AGI safety while also tackling global debt.
ER  - 

TY  - JOUR
T1  - Measuring privacy policy compliance in the Alexa ecosystem: In-depth analysis
AU  - Shafei, Hassan A.
AU  - Gao, Hongchang
AU  - Tan, Chiu C.
JO  - Computers & Security
VL  - 144
SP  - 103963
PY  - 2024
DA  - 2024/09/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.103963
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824002682
KW  - Smart speakers
KW  - Virtual personal assistants
KW  - Amazon Alexa
KW  - Skills
KW  - Privacy practices
KW  - Policy comparison
KW  - Data extraction
KW  - Account linking
AB  - Virtual Personal Assistant (VPA) services such as Amazon Alexa are quickly and seamlessly integrating into people’s daily lives. The Alexa ecosystem allows third-party developers to build new skills and publish them to the skill market. These skills can be either standalone skills, operating independently without external linking, or skills with account linking, necessitating the user connect to external services to access the skill’s functionality. Skill developers are required to provide privacy policies to disclose their skills’ data practices. The popularity of these skills raises privacy concerns in data handling practices. Privacy policy documents play an important role in addressing users’ privacy concerns and informing them about the data practices. These documents are complex for users to comprehend, and skill developers may intentionally or unintentionally fail to comply. Previous investigations have predominantly focused on scrutinizing the privacy policies of standalone skills, overlooking those associated with companion services and developers with multiple skills. This study aims to bridge this gap by examining the privacy policies of both the skills and their companion services, along with multiple skills published by the same developer, to explore potential differences in data practices. We conduct the first study on the Alexa ecosystem for skills with account linking, where we compare the policy of the skills and their companion services. We automatically extract the data types from both privacy policies for comparison using a machine learning technique. Mismatches between skill and companion service privacy practices were unveiled, with 975 instances of data type collection mismatches between skills and their companion services, along with 692 instances of data type sharing mismatches. We uncover differences in privacy practices among developers; 13 developers publish skills in different categories and three of them employ different privacy policies on their published skills. Among 35 developers who publish skills in the same category ten provide different privacy policies.
ER  - 

TY  - JOUR
T1  - Towards trustworthy and interpretable prediction of school bullying: A NAS-driven framework with Shapley value explanation
AU  - Qu, Wei
AU  - Chen, Cong
AU  - Lu, Wei
AU  - Chen, Haodong
AU  - Li, Tao
JO  - Neurocomputing
VL  - 659
SP  - 131744
PY  - 2026
DA  - 2026/01/01/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2025.131744
UR  - https://www.sciencedirect.com/science/article/pii/S0925231225024166
KW  - School bullying prediction
KW  - Neural architecture search
KW  - Shapley values
KW  - Interpretable machine learning
KW  - Educational data mining
KW  - Class imbalance learning
AB  - School bullying represents a critical societal challenge with lasting psychological and academic consequences for affected students. Despite recent advances in machine learning for predicting bullying behaviors, conventional models struggle to capture the complex, non-linear relationships among contributing factors, especially under the imbalanced data distributions typical of real-world bullying cases. Furthermore, the inherent opacity of Deep Neural Networks (DNNs) restricts their application in educational contexts where interpretability and actionable insights are essential. In this paper, we propose a novel automated framework that integrates Neural Architecture Search (NAS) with Shapley value-based explanation methods to jointly address performance and interpretability challenges. Our framework automatically identifies optimal DNN architectures tailored for bullying prediction, incorporating mechanisms to handle class imbalance without extensive manual tuning. To address model transparency, we employ a Shapley value analysis pipeline that systematically attributes predictions to key risk factors, offering educators and policymakers principled and quantitative insights. Extensive experiments on publicly available datasets demonstrate that our method significantly outperforms state-of-the-art baselines, achieving notable improvements in Accuracy (+2.58 %), F1-Score (+34.52 %), and AUC (+6.47 %). Importantly, the feature importance rankings from our Shapley analysis closely align with established sociological and educational theories on bullying, affirming the model’s interpretability and practical relevance. Cross-dataset validation further verifies the framework’s generalizability to broader youth behavioral risk prediction tasks. Our code is submitted at https://github.com/clsyc/Bullyingshapley.
ER  - 

TY  - JOUR
T1  - Membership inference attacks via spatial projection-based relative information loss in MLaaS
AU  - Ding, Zehua
AU  - Tian, Youliang
AU  - Wang, Guorong
AU  - Xiong, Jinbo
AU  - Tang, Jinchuan
AU  - Ma, Jianfeng
JO  - Information Processing & Management
VL  - 62
IS  - 1
SP  - 103947
PY  - 2025
DA  - 2025/01/01/
SN  - 0306-4573
DO  - https://doi.org/10.1016/j.ipm.2024.103947
UR  - https://www.sciencedirect.com/science/article/pii/S0306457324003066
KW  - Membership inference attack
KW  - Adversarial perturbation
KW  - Adversarial attack
KW  - Deep neural network
KW  - KL-divergence
AB  - Machine Learning as a Service (MLaaS) has significantly advanced data-driven decision-making and the development of intelligent applications. However, the privacy risks posed by membership inference attacks (MIAs) remain a critical concern. MIAs are primarily classified into score-based and perturbation-based attacks. The former relies on shadow data and models, which are difficult to obtain in practical applications, while the latter depends solely on perturbation distance, resulting in insufficient identification performance. To this end, we propose a Spatial Projection-based Relative Information Loss (SPRIL) MIA to ascertain the sample membership by flexibly controlling the size of perturbations in the noise space and integrating relative information loss. Firstly, we analyze the alterations in predicted probability distributions induced by adversarial perturbations and leverage these changes as pivotal features for membership identification. Secondly, we introduce a spatial projection technique that flexibly modulates the perturbation amplitude to accentuate the difference in probability distributions between member and non-member data. Thirdly, this quantifies the distribution difference by calculating relative information loss based on KL divergence to identify membership. SPRIL provides a solid method to assess the potential risks of DNN models in MLaaS and demonstrates its efficacy and precision in black-box and white-box settings. Finally, experimental results demonstrate the effectiveness of SPRIL across various datasets and model architectures. Notably, on the CIFAR-100 dataset, SPRIL achieves the highest attack accuracy and AUC, reaching 99.27% and 99.73%, respectively.
ER  - 

TY  - JOUR
T1  - On signal encryption at MapReduce and collaborative attribute-based access with ECAs for a preprocessed data set with ML in a privacy-preserving health 4.0
AU  - Mitra, Arnab
AU  - Pal, Anabik
JO  - e-Prime - Advances in Electrical Engineering, Electronics and Energy
VL  - 12
SP  - 100983
PY  - 2025
DA  - 2025/06/01/
SN  - 2772-6711
DO  - https://doi.org/10.1016/j.prime.2025.100983
UR  - https://www.sciencedirect.com/science/article/pii/S2772671125000907
KW  - Healthcare 4.0
KW  - Privacy-preserving health 4.0 (PPH 4.0)
KW  - Big data
KW  - Data security and privacy
KW  - Data preprocessing
KW  - Data dimension reduction
KW  - Machine learning (ML)
KW  - Signal encryption
KW  - MapReduce (MR)
KW  - Cooperative attribute-based access control
KW  - Elementary cellular automata (ECAs)
AB  - Latest Industry 4.0 developments and data science advances have transformed traditional hospital-centric patient care into a Healthcare 4.0 system that uses advanced technology-driven decision-making involving several low resource constraints electronic devices such as Personal Digital Assistants (PDAs), Smartphones, Tablets, etc. In a healthcare system, the data is the key fuel for such improved technology, which presently is an instance of big data. However, due to several data protection laws and regulations, the confidentiality and security of healthcare data are a big concern. To support the cost-effectiveness modeling of data security and privacy in Healthcare 4.0 scenarios, the Privacy-Preserving Health 4.0 (PPH 4.0) framework was proposed by integrating Machine Learning (ML) and Elementary Cellular Automata (ECAs). The ML techniques were proposed to offer effective data pre-processing and dimensionality reduction. In contrast, ECAs were proposed to offer an integral parallelism and very-large-scale-integration (VLSI) capability at a low cost for its physical implementation and low power consumption towards data security and privacy of such big data in PPH 4.0. The presented research presents signal encryption at MapReduce with ECAs generated pseudo-random noise signal and collaborative attribute-based access with ECAs for a preprocessed data set with ML in PPH 4.0. Experimental results and analysis of the proposed approach reveal its true nature and suitability are for an enhanced Healthcare 4.0 system, i.e., PPH 4.0.
ER  - 

TY  - JOUR
T1  - Toward Quality 5.0: Integrating Industry 4.0, Human-Centricity, and Quality Management
AU  - Antomarioni, Sara
AU  - Fani, Virginia
AU  - Bandinelli, Romeo
AU  - Ciarapica, Filippo Emanuele
AU  - Bevilacqua, Maurizio
JO  - IFAC-PapersOnLine
VL  - 59
IS  - 10
SP  - 1414
EP  - 1419
PY  - 2025
DA  - 2025/01/01/
T2  - 11th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2025
SN  - 2405-8963
DO  - https://doi.org/10.1016/j.ifacol.2025.09.238
UR  - https://www.sciencedirect.com/science/article/pii/S2405896325009991
KW  - Quality 4.0
KW  - Quality 5.0
KW  - Industry 5.0
KW  - Human-Centric Manufacturing
KW  - Human operator support
KW  - Human-centered systems engineering
KW  - Quality assurance
KW  - maintenance
AB  - The convergence of Industry 4.0 technologies, human-centric approaches, and quality management is shaping the emerging paradigm of Quality 5.0. This study develops a conceptual framework for Quality 5.0, illustrating the potential pathways industries can follow to effectively transition to this paradigm. Specifically, the framework identifies three distinct starting points: Human-Centric Industry 5.0 (HC I5.0), Quality 4.0, and Human-Centric Quality (HC Quality). Industries occupy distinct positions in this framework based on automation and digitalization levels. Identifying their starting point helps determine the strategic assets for a successful transition. Drawing on a comprehensive literature review and relevant case studies, this study examines the framework within the context of the fashion industry, to assess its positioning and examine the most covered areas among the intersections. The results reveal a focus on HC Quality approaches, with limited practical implementation of Quality 4.0, particularly in the luxury segment. The paper highlights the importance of leveraging existing frameworks for a strategic progression towards Quality 5.0, offering theoretical and managerial perspectives alongside practical insights for fashion companies navigating the shift toward a more sustainable, efficient, and HC production environment.
ER  - 

TY  - JOUR
T1  - AlexNet architecture based convolutional neural network for toxic comments classification
AU  - Singh, Inderpreet
AU  - Goyal, Gulshan
AU  - Chandel, Anmol
JO  - Journal of King Saud University - Computer and Information Sciences
VL  - 34
IS  - 9
SP  - 7547
EP  - 7558
PY  - 2022
DA  - 2022/10/01/
SN  - 1319-1578
DO  - https://doi.org/10.1016/j.jksuci.2022.06.007
UR  - https://www.sciencedirect.com/science/article/pii/S1319157822002026
KW  - Toxic comments
KW  - AlexNet
KW  - Fasttext
KW  - Deep learning
KW  - CNNs
KW  - Word embedding
KW  - ROC-AUC
AB  - Today online networking has become an indispensable part of life for people all over the world. It is difficult for users to reduce their internet/online communications, as the flow of information increases everyday. While the free flow of information benefits online communications, the high toxicity of online communication is a drawback. Toxic texts are described as disrespectful or insulting messages that make the recipient feel uncomfortable. Deep Learning based Convolutional Neural Networks (CNN) have given exceptional outcomes in Computer Vision Domain, and AlexNet has proven to be the leading architecture in image classification and object detection problems. This article presents a 3-tier CNN architecture that is inspired by the AlexNet model to classify the toxic comments on the Wikipedia forum available in the Google Jigsaw dataset. Fast text-crawl-300d-2 m is used to formulate the pre-trained word embeddings matrix. The Exponential Linear Unit (ELU) activation function is applied in the Convolutional blocks for faster convergence. Dropout is used sufficiently along with different layers of the network to prevent overfitting. From the simulation and subsequent comparative analysis, it is found that the proposed model achieved a decent average accuracy of 98.505% and an average F1 score of 0.79. ROC-AUC score is used as an evaluation parameter. The value of ROC-AUC for the proposed model is approximately 0.9854, which shows that the said model differentiates between the comment classes more accurately.
ER  - 

TY  - JOUR
T1  - Interdependence in information practices: differences matter when caring for immigration data in Canada
AU  - Shankar, Saguna
AU  - Nathan, Lisa P.
JO  - Journal of Documentation
VL  - 82
IS  - 7
SP  - 1
EP  - 18
PY  - 2025
DA  - 2025/12/11/
SN  - 0022-0418
DO  - https://doi.org/10.1108/JD-05-2025-0148
UR  - https://www.sciencedirect.com/science/article/pii/S0022041825000815
KW  - Information practice
KW  - Information studies
KW  - Migration
KW  - Care ethics
KW  - Data
KW  - Narrative analysis
AB  - Purpose
Service providers, government agencies and other entities gather data on immigration and settlement for myriad reasons. In Canada, newcomers to the country are required to provide personal information to access essential services from community-based organizations and government agencies. Individuals who handle immigration data hold valuable yet under-examined perspectives on these data collection and sharing activities. This study therefore seeks to answer the overarching question: What information practices are prominent in the work of different groups who collect, analyze and steward newcomers' data?
Design/methodology/approach
Our interview-based study reports on the practices of individuals supporting immigration and settlement (i.e. settlement service providers, migrant justice activists, immigration researchers, government staff and designers of digital systems and services oriented toward newcomers) through their use of newcomers' data.
Findings
A dual narrative and thematic analysis interprets participants' reflections on their information practices and responsibilities, showcasing variation despite their interdependence and shared priorities for newcomers' well-being. We propose the concept of “data care” to draw attention to experiences and tensions inherent in stewarding newcomers' data. This inquiry reveals conflicts over responsibilities, differences in ethical reasoning and the need for multi-stakeholder negotiation.
Originality/value
Findings bring greater clarity to the intricacies of respecting migrants and their privacy. The study contributes to a theoretical lens on information practices in care work by drawing from feminist care ethics and sociotechnical scholarship.
ER  - 

TY  - JOUR
T1  - Understanding the impact of ChatGPT on tourism and hospitality: Trends, prospects and research agenda
AU  - Sigala, Marianna
AU  - Ooi, Keng-Boon
AU  - Tan, Garry Wei-Han
AU  - Aw, Eugene Cheng-Xi
AU  - Buhalis, Dimitrios
AU  - Cham, Tat-Huei
AU  - Chen, Meng-Mei
AU  - Dwivedi, Yogesh K.
AU  - Gretzel, Ulrike
AU  - Inversini, Alessandro
AU  - Jung, Timothy
AU  - Law, Rob
AU  - Ye, Ivy Huiyue
JO  - Journal of Hospitality and Tourism Management
VL  - 60
SP  - 384
EP  - 390
PY  - 2024
DA  - 2024/09/01/
SN  - 1447-6770
DO  - https://doi.org/10.1016/j.jhtm.2024.08.004
UR  - https://www.sciencedirect.com/science/article/pii/S144767702400086X
KW  - Generative artificial intelligence
KW  - ChatGPT
KW  - Tourism
KW  - Hospitality management
KW  - Destination management
KW  - Research agenda
KW  - Sustainable tourism
AB  - The prevalence of ChatGPT (and generative artificial intelligence in general) has precipitated a paradigm shift in diverse industries, including tourism and hospitality. ChatGPT revolutionalises all business functions (from marketing to operations), empowering tourism and hospitality organisations to transform and innovate their business models. This study seeks to comprehensively examine the use and implications of ChatGPT in tourism and hospitality by discussing the current and future state of the technology, while also suggesting an agenda for future research. To that end, six areas, namely, business intelligence and tourism analytics, tourism marketing and experience, hospitality services, cultural and heritage tourism, travel services, and destination management, are elaborated on in depth. By compiling views solicited from international experts, this groundbreaking opinion piece unveils profound insights into the evolutionary journey of an emerging technology that is shaping tourism and hospitality. The paper provides useful implications for tourism scholars and professionals alike.
ER  - 

TY  - JOUR
T1  - Ethical, Legal and Social Aspects (ELSA) for AI: An assessment tool for Agri-food
AU  - van Hilten, Mireille
AU  - Ryan, Mark
AU  - Blok, Vincent
AU  - de Roo, Nina
JO  - Smart Agricultural Technology
VL  - 10
SP  - 100710
PY  - 2025
DA  - 2025/03/01/
SN  - 2772-3755
DO  - https://doi.org/10.1016/j.atech.2024.100710
UR  - https://www.sciencedirect.com/science/article/pii/S2772375524003149
KW  - Ethical legal social aspects
KW  - ELSA
KW  - Artificial intelligence
KW  - AI
KW  - responsible AI
KW  - Agrifood
KW  - Agriculture
KW  - Assessment
AB  - As Artificial Intelligence (AI) continues to emerge in various sectors, ethical frameworks and guidelines aim to contribute to responsible AI development. While AI ethics has gained prominence in addressing broader societal concerns, existing regulations and guidelines often lack specificity for certain domain-specific applications (e.g. agri-food). AI is rapidly developed and deployed throughout the agri-food sector, but there is little practical guidance on how to do this responsibly. This study examines if the agri-food sector needs domain-specific guidance for the development and use of responsible AI and, if so, what it could look like. This research proposes it does and aims to fill this gap by introducing a novel approach for responsible AI in agri-food: the ethical, legal, and social aspects (ELSA) Scan. This assessment comprises 25 targeted questions aimed at identifying ELSA considerations. These questions were developed and based on 23 ELSA aspects of AI in agri-food literature and from testing in two case studies (arable and dairy farming). The ELSA Scan provides a clear and implementable approach for identifying ELSA in the development and use of AI in agri-food with AI developers and organisations.
ER  - 

TY  - JOUR
T1  - Technical solution to counter potential crime: Text analysis to detect fake news and disinformation
AU  - Kozik, Rafał
AU  - Kula, Sebastian
AU  - Choraś, Michał
AU  - Woźniak, Michał
JO  - Journal of Computational Science
VL  - 60
SP  - 101576
PY  - 2022
DA  - 2022/04/01/
SN  - 1877-7503
DO  - https://doi.org/10.1016/j.jocs.2022.101576
UR  - https://www.sciencedirect.com/science/article/pii/S187775032200014X
KW  - Fake news detection
KW  - Transformers
KW  - Natural Language Processing
KW  - Deep learning
KW  - SocialTruth
AB  - Fake news detection is a challenging and complex task. Yet, several approaches to deal with this problem have already been proposed. The majority of solutions employ the NLP-based approach, where various architectures of a deep artificial neural network are proposed. However, as the experiments show, different NLP-based solutions have great performance in a single domain, but transferring them to another one is tedious. Therefore, in this paper, we propose a hybrid approach to dealing with this problem. Instead of retraining one big model on different types of data, we bundle several smaller models using meta-learning techniques. This paper is an extension of our previous research presented in Kula et al. (2021).
ER  - 

TY  - JOUR
T1  - Responsible smart home technology adoption: exploring public perceptions and key adoption factors
AU  - Li, Wenda
AU  - Yigitcanlar, Tan
AU  - Nili, Alireza
AU  - Browne, Will
AU  - Li, Fei
JO  - Internet of Things
VL  - 32
SP  - 101622
PY  - 2025
DA  - 2025/07/01/
SN  - 2542-6605
DO  - https://doi.org/10.1016/j.iot.2025.101622
UR  - https://www.sciencedirect.com/science/article/pii/S2542660525001362
KW  - Smart home
KW  - Smart living
KW  - Smart technology
KW  - Home automation
KW  - Technology adoption
KW  - Responsible innovation
AB  - Initially, smart home technology gained traction for its aesthetic appeal, functionality, and allure to early tech enthusiasts. Today, it plays a crucial role in enhancing security, healthcare, and energy management. As AI becomes more integrated into daily life, smart homes offer increased convenience and automation. Yet, concerns over privacy, data security, and ethical use have grown. This study leverages social media analytics to analyze a longitudinal dataset of over 150,000 tweets from Australia between 2016 and 2023, using quantitative, sentiment, and content analysis. The goal is to investigate the evolving public discourse around smart home technologies, focusing on user key concerns. A novel insight from the study reveals a rising awareness and demand for responsible practices in the development and deployment of smart home technologies, which may influence user adoption intentions and behaviors. This suggests a potential shift in user priorities from seeking functionality and convenience to becoming more concerned with ethical standards and responsible use. The study makes a novel contribution as it identifies a new trend in public discourse that extends beyond the traditional drivers of smart home technology adoption. By capturing these dynamics, this paper provides critical insights for stakeholders—particularly in the smart home industry and regulatory sectors—to inform the development of more responsible, user-centered products and policies.
ER  - 

TY  - JOUR
T1  - Knowledge graph and mitigation measures recommendation for safety hazards in large-scale hydropower projects using diverse heterogeneous inspection data
AU  - Yang, Yingliu
AU  - Xiang, Pengcheng
AU  - Wang, Dianxue
JO  - Automation in Construction
VL  - 178
SP  - 106419
PY  - 2025
DA  - 2025/10/01/
SN  - 0926-5805
DO  - https://doi.org/10.1016/j.autcon.2025.106419
UR  - https://www.sciencedirect.com/science/article/pii/S0926580525004595
KW  - Large-scale hydropower project (LHP)
KW  - Construction safety hazards (CSHs)
KW  - Knowledge graph
KW  - Sentence-BERT (SBERT)
KW  - Mitigation measures
KW  - Safety management standards
AB  - Large-scale hydropower project (LHP) sites are fraught with numerous construction safety hazards (CSHs). When the efficiency of addressing these CSHs falls to meet safety management requirements, accidents may occur. Existing inspection records of CSHs contain a wealth of useful information, yet these unstructured texts hinder their efficient utilization. Furthermore, current mitigation measures for CSHs largely depend on human experience, leading to low efficiency. To address these issues, this paper proposes a BERT-Att-BiLSTM-CRF model based on massive daily inspection data, achieving precise extraction of CSHs entities (F1 > 95 %); construction a multi-dimensional knowledge graph with nine entity types and eight relationships; a mitigation measures recommendation based on Sentence-BERT (SBERT) model demonstrates superior performance (Pearson = 0.92, Spearman = 0.85) through semantic similarity; for novel CSHs, a safety management standards-based semantic model recommends compliant solutions. Validation confirms the research results capability to automate safety knowledge extraction from unstructured texts, establishing a replicable paradigm for infrastructure risk management.
ER  - 

TY  - JOUR
T1  - Using Sentiment Analysis to Detect Disruptive Events in Supply Chains
AU  - Vishnuthilak, Kiran Katoor
AU  - Rolf, Benjamin
AU  - Reggelin, Tobias
AU  - Lang, Sebastian
JO  - IFAC-PapersOnLine
VL  - 58
IS  - 19
SP  - 864
EP  - 869
PY  - 2024
DA  - 2024/01/01/
T2  - 18th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2024
SN  - 2405-8963
DO  - https://doi.org/10.1016/j.ifacol.2024.09.178
UR  - https://www.sciencedirect.com/science/article/pii/S2405896324015933
KW  - Supply chain management
KW  - Sentiment analysis
KW  - Sourcing
KW  - Reconfigurable supply chains
KW  - Risk management
KW  - Natural language processing
KW  - Machine learning
KW  - Transfer learning
AB  - Contemporary supply chain operations operate on a global scale connecting multiple organizations. Beyond internal processes, supply chain performance is influenced by external events, which can lead to disruptive scenarios. Sourcing activities are particularly susceptible to disruptions. Classifying an event as disruptive or non-disruptive depending based on the perspective of a focal company can serve as a trigger system for sourcing decision-making. We propose a framework for classifying supply chain events based on risk type, geographical impact, occurrence frequency, and sentiment. Leveraging transfer learning, we train a sentiment analysis model to assess the relevance of news headlines related to supply chain events.
ER  - 

TY  - JOUR
T1  - FMG-locator: Fusion SegFormer with facial mask guidance for multi-person forgery localization
AU  - Liu, Jiatong
AU  - Wang, Lina
AU  - Wang, Run
AU  - Ye, Xi
JO  - Expert Systems with Applications
VL  - 293
SP  - 128687
PY  - 2025
DA  - 2025/12/01/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2025.128687
UR  - https://www.sciencedirect.com/science/article/pii/S095741742502305X
KW  - DeepFakes
KW  - Multi-person forgery localization
KW  - Fusion SegFormer
KW  - Facial mask guidance
AB  - The growing prevalence of AI-generated images has intensified the risk of malicious forgeries, posing serious threats to personal identity security. While previous researches have achieved reasonable performance in detecting prominent forgeries in single-face images without backgrounds, their accuracy significantly degrades when identifying small tampered areas in multi-person scene images. To address this limitation, we propose FMG-Locator, a novel forgery localization model based on fusion Segformer architecture. Our method incorporates a facial mask guidance module to suppress background interference and emphasize facial regions. It also employs a three-channel feature extraction module and a dual attention mechanism for robust feature fusion. The superiority of our FMG-Locator is verified by extensive experiments with existing baselines in three multi-person scene datasets and two emerging forgery datasets. The results demonstrate that FMG-Locator is effective in localizing multi-person scene images, especially in the small region facial forgeries. Furthermore, it remains strong robustness under six post-processing attacks and six social media platforms.
ER  - 

TY  - JOUR
T1  - The European AI liability directives – Critique of a half-hearted approach and lessons for the future
AU  - Hacker, Philipp
JO  - Computer Law & Security Review
VL  - 51
SP  - 105871
PY  - 2023
DA  - 2023/11/01/
SN  - 2212-473X
DO  - https://doi.org/10.1016/j.clsr.2023.105871
UR  - https://www.sciencedirect.com/science/article/pii/S026736492300081X
KW  - Artificial intelligence
KW  - ChatGPT
KW  - Product liability
KW  - EU law
KW  - AI act
KW  - Sustainability
KW  - Innovation
KW  - Large generative AI models
AB  - The optimal liability framework for AI systems remains an unsolved problem across the globe. With ChatGPT and other large generative models taking the technology to the next level, solutions are urgently needed. In a much-anticipated move, the European Commission advanced two proposals outlining the European approach to AI liability in September 2022: a novel AI Liability Directive (AILD) and a revision of the Product Liability Directive (PLD). They constitute the final cornerstone of AI regulation in the EU. Crucially, the liability proposals and the proposed EU AI Act are inherently intertwined: the latter does not contain any individual rights of affected persons, and the former lack specific, substantive rules on AI development and deployment. Taken together, these acts may well trigger a “Brussels effect” in AI regulation, with significant consequences for the US and other countries. Against this background, this paper makes three novel contributions. First, it examines in detail the liability proposals and shows that, while making steps in the right direction, they ultimately represent a half-hearted approach: if enacted as foreseen, AI liability in the EU will primarily rest on disclosure of evidence mechanisms and a set of narrowly defined presumptions concerning fault, defectiveness and causality. Hence, second, the article suggests amendments to the proposed AI liability framework. They are collected in a concise Annex at the end of the paper. I argue, inter alia, that the dichotomy between the fault-based AILD Proposal and the supposedly strict liability PLD Proposal is fictional and should be abandoned; that an EU framework for AI liability should comprise one fully harmonizing regulation instead of two insufficiently coordinated directives; and that the current proposals unjustifiably collapse fundamental distinctions between social and individual risk by equating high-risk AI systems in the AI Act with those under the liability framework. Third, based on an analysis of the key risks AI poses, the final part of the paper maps out a road for the future of AI liability and regulation, in the EU and beyond. More specifically, I make four key proposals. Effective compensation should be ensured by combining truly strict liability for certain high-risk AI systems with general presumptions of defectiveness, fault and causality in cases involving SMEs or non-high-risk AI systems. The paper introduces a novel distinction between illegitimate- and legitimate-harm models to delineate strict liability's scope. Truly strict liability should be reserved for high-risk AI systems that, from a social perspective, should not cause harm (illegitimate-harm models, e.g., autonomous vehicles or medical AI). Models meant to cause some unavoidable harm by ranking and rejecting individuals (legitimate-harm models, e.g., credit scoring or insurance scoring) may merely face rebuttable presumptions of defectiveness and causality. General-purpose AI systems and Foundation Models should only be subjected to high-risk regulation, including liability for high-risk AI systems, in specific high-risk use cases for which they are deployed. Consumers, in turn, ought to be liable based on regular fault, in general. Furthermore, innovation and legal certainty should be fostered through a comprehensive regime of safe harbours, defined quantitatively to the best extent possible. Moreover, trustworthy AI remains an important goal for AI regulation. Hence, the liability framework must specifically extend to non-discrimination cases and provide for clear rules concerning explainability (XAI). Finally, awareness for the climate effects of AI, and digital technology more broadly, is rapidly growing in computer science. In diametrical opposition to this shift in discourse and understanding, however, EU legislators have long neglected environmental sustainability in both the draft AI Act and the proposed liability regime. To counter this, I propose to jump-start sustainable AI regulation via sustainability impact assessments in the AI Act and sustainable design defects in the liability regime. In this way, the law may help spur not only fair AI and XAI, but also sustainable AI (SAI).
ER  - 

TY  - JOUR
T1  - APBAM: Adversarial perturbation-driven backdoor attack in multimodal learning
AU  - Zhang, Shaobo
AU  - Chen, Wenli
AU  - Li, Xiong
AU  - Liu, Qin
AU  - Wang, Guojun
JO  - Information Sciences
VL  - 700
SP  - 121847
PY  - 2025
DA  - 2025/05/01/
SN  - 0020-0255
DO  - https://doi.org/10.1016/j.ins.2024.121847
UR  - https://www.sciencedirect.com/science/article/pii/S0020025524017614
KW  - Multimodal learning
KW  - Backdoor attack
KW  - Adversarial perturbation
KW  - Dual trigger words
KW  - Sample-specific triggers
AB  - Due to the reliance on the cloud for training, multimodal learning models are vulnerable to multimodal backdoor attacks. However, such attacks often use static trigger patterns, which leads to two significant challenges: (1) the visibility of patches creates a trade-off between backdoor effectiveness and stealthiness, and (2) the use of fixed text triggers leads to a high probability of false backdoor activation. To address the above challenges, this paper proposes an adversarial perturbation-driven backdoor attack in multimodal learning (APBAM). First, we propose a visual perturbation trigger generation strategy to get the triggers that are easier to learn than a patch. This strategy modifies the image feature to bring it closer to the target output. Second, we consider using trigger words specific to the text and propose an improved semantically preserving dual triggers generation strategy. Next, we add negative samples to the training to keep the model working when only one modal trigger is detected and to change its decision when both modal triggers are present. Finally, extensive experiments demonstrate that compared to the state-of-the-art (SoTA) baseline, the false trigger rate decreases by 21.6%, and the attack success rate increases by 4.32%.
ER  - 

TY  - JOUR
T1  - Method and models for sentiment analysis and hidden propaganda finding
AU  - Strubytskyi, R.
AU  - Shakhovska, N.
JO  - Computers in Human Behavior Reports
VL  - 12
SP  - 100328
PY  - 2023
DA  - 2023/12/01/
SN  - 2451-9588
DO  - https://doi.org/10.1016/j.chbr.2023.100328
UR  - https://www.sciencedirect.com/science/article/pii/S2451958823000611
KW  - Natural language processing
KW  - Big data
KW  - Public opinion
KW  - Emotional recognition
KW  - Content filtering
KW  - Media content
AB  - The paper describes the method and system architecture for the intellectual analysis of text and emotions to support decision-making in the field of national security and defense. Considering the latest events in the world, mass media are becoming a powerful tool for manipulating public consciousness and promoting the interests of one country over another. The article describes the methodology of collecting historical articles from a website, analyzing peak news outbreaks, and analyzing each article's text. The morphological tagging and named-entity recognition as the core of natural language processing was described. A hybrid method based on learning rules and an ensemble of machine learning methods has been developed for sentiment analysis and covert propaganda. The proposed rule-based model allows choosing the class-based lexical approach or on collected dictionaries. The combination of the methods based on dictionaries and rules with the ensemble of machine learning models are developed. The developed stacking model combines weak classifiers and deformed meta-attributes based on the results of pairwise multiplication. Finally, the distorted features are used together with the training dataset in the meta-model. This combination avoids the correlation of the results of weak classifiers and increases the generalizability of the model. The proposed approach demonstrates high accuracy and usage for Russian and Ukrainian languages. The developed method is built on Chambers's proposal. As a result of the analysis, the manipulation of public consciousness and the number of negative articles about the two countries are determined. The results of the check give us reason to consider the information spread by the media to be manipulative.
ER  - 

TY  - JOUR
T1  - Machine learning at the edge to improve in-field safeguards inspections
AU  - Shoman, Nathan
AU  - Williams, Kyle
AU  - Balsara, Burzin
AU  - Ramakrishnan, Adithya
AU  - Kakish, Zahi
AU  - Coram, Jamie
AU  - Honnold, Philip
AU  - Rivas, Tania
AU  - Smartt, Heidi
JO  - Annals of Nuclear Energy
VL  - 200
SP  - 110398
PY  - 2024
DA  - 2024/06/01/
SN  - 0306-4549
DO  - https://doi.org/10.1016/j.anucene.2024.110398
UR  - https://www.sciencedirect.com/science/article/pii/S0306454924000604
KW  - Nonproliferation
KW  - International Nuclear Safeguards
KW  - Machine learning
KW  - 
AB  - Artificial intelligence (AI) and machine learning (ML) are near-ubiquitous in day-to-day life; from cars with automated driver-assistance, recommender systems, generative content platforms, and large language chatbots. Implementing AI as a tool for international safeguards could significantly decrease the burden on safeguards inspectors and nuclear facility operators. The use of AI would allow inspectors to complete their in-field activities quicker, while identifying patterns and anomalies and freeing inspectors to focus on the uniquely human component of inspections. Sandia National Laboratories has spent the past two and a half years developing on-device machine learning to develop both a digital and robotic assistant. This combined platform, which we term inspecta, has numerous on-device machine learning capabilities that have been demonstrated at the laboratory scale. This work describes early successes implementing AI/ML capabilities to reduce the burden of tedious inspector tasks such as seal examination, information recall, note taking, and more.
ER  - 

TY  - JOUR
T1  - Data-Driven construction project risk causal Network: Integration of ensemble causal discovery and PLS-SEM validation
AU  - Liu, Nan
AU  - Goh, Yang Miang
AU  - Du, Shuang
AU  - Chua, David KH.
JO  - Advanced Engineering Informatics
VL  - 69
SP  - 104121
PY  - 2026
DA  - 2026/01/01/
SN  - 1474-0346
DO  - https://doi.org/10.1016/j.aei.2025.104121
UR  - https://www.sciencedirect.com/science/article/pii/S1474034625010146
KW  - Causal discovery
KW  - Ensemble method
KW  - Directed acyclic graphs
KW  - Risk networks
KW  - Data analytics
KW  - Construction project risk management
KW  - PLS-SEM
AB  - Current construction project risk analysis depends heavily on manual processes and subjective expertise. This approach produces risk knowledge that is inherently subjective, inconsistent, and difficult to verify or scale. From an engineering informatics perspective, this represents a critical gap in the computational formalisation of domain knowledge. Besides, existing analytical methods are inadequate as they examine discrete risks or correlations without capturing causal mechanisms. This leads to fragmented interventions that address symptoms rather than root causes. To bridge these gaps, this study develops an automated, data-driven causal analysis framework, which integrates ensemble causal discovery (ECD) with PLS-SEM validation to uncover underlying causal mechanisms directly from data. This process effectively transforms tacit risk knowledge, previously confined to expert intuition, into an explicit and verifiable computational structure. The proposed ECD method addresses the inherent instability of individual causal discovery algorithms and mitigates overfitting risks. The subsequent PLS-SEM validation provides rigorous statistical testing, ensuring the final model is both robust and interpretable. Applied to data from 229 participants in Singapore, the framework automatically established a Project Risk Causal Network (PRCN). The PRCN explained 51% of project performance variation, outperformed individual algorithms, and revealed critical risk propagation pathways. This study advances engineering informatics by: (1) automating causal knowledge extraction from project data; (2) providing robust validation for discovered causal structures; and (3) enabling targeted interventions through quantified causal mechanisms.
ER  - 

TY  - JOUR
T1  - Deep clustering framework review using multicriteria evaluation
AU  - Ros, Frédéric
AU  - Riad, Rabia
AU  - Guillaume, Serge
JO  - Knowledge-Based Systems
VL  - 285
SP  - 111315
PY  - 2024
DA  - 2024/02/15/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2023.111315
UR  - https://www.sciencedirect.com/science/article/pii/S0950705123010638
KW  - Clustering
KW  - Domain representation
KW  - Unsupervised learning
KW  - Supervised learning
KW  - Deep learning
AB  - The application of clustering has always been an important method for problem-solving. In the era of big data, most classical clustering methods suffer from the curse of dimensionality and scalability issues. Recently, deep clustering models have garnered more attention due to their capabilities in dealing with complex, high-dimensional, and large-scale datasets. They offer intriguing perspectives owing to their outstanding representative capacity and fast inference speed. The remaining major problem in clustering scenarios with high-dimensional data revolves around determining an appropriately compressed representation that semantically preserves cluster structures. Without labels, defining an objective function to encourage a suitable representation becomes a critical question. After several years of stagnation, impressive results have been achieved in the last two years. This paper proposes a comprehensive and up-to-date review of deep clustering methods. We first introduce the basic concepts shared by several deep clustering algorithms, available network architectures, and optimization strategies. Then, a detailed review is presented for each family by analyzing their most representative algorithms. These algorithms are then assessed based on their classification accuracy and from a multi-criteria perspective to aid investigators in selecting the most appropriate solution. Finally, an overview of the diversity of tasks and application domains is provided, and current issues and challenges are discussed.
ER  - 

TY  - JOUR
T1  - LiDAR localization using position-encoded landmarks without point cloud maps
AU  - Xie, Wenjing
AU  - Ren, Tianchi
AU  - Xue, Chun Jason
AU  - Wu, Jen-Ming
AU  - Guan, Nan
JO  - Journal of Systems Architecture
VL  - 168
SP  - 103556
PY  - 2025
DA  - 2025/11/01/
SN  - 1383-7621
DO  - https://doi.org/10.1016/j.sysarc.2025.103556
UR  - https://www.sciencedirect.com/science/article/pii/S1383762125002280
KW  - LiDAR
KW  - Position-encoded landmarks
KW  - Vehicle localization
KW  - Point cloud map-free
AB  - LiDAR-based localization plays a critical role in autonomous driving and robotic navigation. However, traditional methods rely heavily on constructing high-precision point cloud maps, which is both time-consuming and labor-intensive. To address this, we propose an innovative localization approach that eliminates the need for point cloud maps by leveraging LiDAR and position-encoded landmarks. Our method encodes positional information into the shape of specially designed landmarks, strategically deployed in the environment. Subsequently, we fully leverage the advantages of LiDAR in accurately measuring distances and capturing the spatial structures of objects to detect and recognize the landmarks in the environment. By decoding the positional information embedded in the landmarks, precise vehicle localization is achieved. To overcome the limited information capacity of individual landmarks due to LiDAR’s reduced accuracy at long distances, we integrate multiple landmarks in a collaborative manner. By combining their encoded information and spatial relationships, we achieve high-precision localization without relying on point cloud maps. Experiments in CARLA and Autoware.AI simulators validate the effectiveness of our approach, offering a novel solution for LiDAR-based localization.
ER  - 

TY  - JOUR
T1  - GNPSum: A code summarization enhancement framework based on Graph Node Position
AU  - Cheng, Haogang
AU  - Xu, Ling
AU  - Huangfu, Luwen
AU  - Liu, Chao
AU  - Yan, Meng
AU  - Lei, Yan
JO  - Information and Software Technology
VL  - 187
SP  - 107837
PY  - 2025
DA  - 2025/11/01/
SN  - 0950-5849
DO  - https://doi.org/10.1016/j.infsof.2025.107837
UR  - https://www.sciencedirect.com/science/article/pii/S0950584925001764
KW  - Code summarization
KW  - Code structural feature
KW  - Graph Attention Network
KW  - Exposure bias
AB  - Code summarization is essential for effectively communicating a code’s core functionality and logic, enhancing software development efficiency, collaboration, and code quality. Traditional work has focused on generating summaries from textual information extracted from the source code. However, these approaches often fail to capture the hierarchical structure critical for effective summarization. To effectively capture the hierarchical structure of the code, which is crucial for accurate summarization, researchers often integrate structural elements such as Syntax Trees (AST) into their models. However, conventional embedding methods struggle to accurately discern the semantic nuances within the code, particularly for nodes with similar content but distinct structural roles. The relative positional information of these nodes, which often conveys semantics absent from the source code itself, is frequently overlooked, limiting the model’s ability to fully exploit the hierarchical and contextual richness inherent in the code structure. To overcome these limitations, we propose GNPSum, a code summarization enhancement framework based on the position of the graph node. GNPSum employs a structural combinatorial graph approach (SCG), which extends the AST edges with CFG and DFG to aggregate multimodal information. We introduce a novel positional embedding technique that leverages distances between nodes to reduce semantic ambiguity and guide effective summary generation. Evaluations on extensive Java and Python datasets demonstrate that GNPSum improves 3.30% and 1.82% in the BLEU score, compared to the highest performance baseline. Furthermore, our validation shows that GNPSum significantly enhances the structural comprehension for pre-trained models, resulting in a 1.93% performance boost over models fine-tuned without our framework.
ER  - 

TY  - JOUR
T1  - HyperLAC: Hypergraph-based Large-scale Alert Classification with spatial-temporal context enhancement
AU  - Zhang, Shilong
AU  - Luo, Zian
AU  - Ren, Zehua
AU  - Zhu, Yumeng
AU  - Zhang, Haichuan
AU  - Liu, Yang
JO  - Knowledge-Based Systems
VL  - 330
SP  - 114712
PY  - 2025
DA  - 2025/11/25/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2025.114712
UR  - https://www.sciencedirect.com/science/article/pii/S0950705125017514
KW  - Hypergraph clustering
KW  - Alert correlation
KW  - Alert classification
KW  - Spatial-temporal context
AB  - Alert fatigue is a persistent problem in security operation centers. Machine learning (ML)-based algorithms are widely adopted to help dispose alerts automatically. However, security analysts find it difficult to comprehend security events owing to the complicated relationship between alerts. Moreover, the performance of ML-based algorithms heavily relies on large amounts of labeled data, which are hard to obtain in a real network environment. Herein, we propose HyperLAC, a hypergraph-based large-scale alert classification method, to dispose massive alerts using context-enhanced features. We represent the nonlinear and multivariate relationships between alerts by constructing an alert hypergraph based on the alerts’ attribute correlation. Subsequently, we propose an adaptive incremental hypergraph clustering algorithm to efficiently extract potential security events from alert clusters. By enhancing the features of each alert using its spatial-temporal contextual features obtained from security events, we can train an effective alert classifier based on few lightweight, conventional classifiers. Results from public and real datasets show that HyperLAC can classify massive alerts accurately and cost-effectively.
ER  - 

TY  - JOUR
T1  - Architectural patterns for designing quantum artificial intelligence systems
AU  - Klymenko, Mykhailo
AU  - Hoang, Thong
AU  - Xu, Xiwei
AU  - Xing, Zhenchang
AU  - Usman, Muhammad
AU  - Lu, Qinghua
AU  - Zhu, Liming
JO  - Journal of Systems and Software
VL  - 227
SP  - 112456
PY  - 2025
DA  - 2025/09/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2025.112456
UR  - https://www.sciencedirect.com/science/article/pii/S0164121225001244
KW  - Quantum AI
KW  - Software architecture
KW  - Quantum machine learning
KW  - Architectural patterns
KW  - Quantum software engineering
KW  - Systematic mapping study
AB  - Utilising quantum computing technology to enhance artificial intelligence systems is expected to improve training and inference times, increase robustness against noise and adversarial attacks, and reduce the number of parameters without compromising accuracy. However, moving beyond proof-of-concept or simulations to develop practical applications of these systems while ensuring high software quality faces significant challenges due to the limitations of quantum hardware and the underdeveloped knowledge base in software engineering for such systems. In this work, we have conducted a systematic mapping study to identify the challenges and solutions associated with the software architecture of quantum-enhanced artificial intelligence systems. The results of the systematic mapping study reveal several architectural patterns that describe how quantum components can be integrated into inference engines, as well as middleware patterns that facilitate communication between classical and quantum components. Each pattern realises a trade-off between various software quality attributes, such as efficiency, scalability, trainability, simplicity, portability, and deployability. The outcomes of this work have been compiled into a catalogue of architectural patterns. Editor’s note: Open Science material was validated by the Journal of Systems and Software Open Science Board.
ER  - 

TY  - JOUR
T1  - Secure data communication for wireless mobile nodes in intelligent transportation systems
AU  - Qureshi, Kashif Naseer
AU  - Alhudhaif, Adi
AU  - Haidar, Syed Wasim
AU  - Majeed, Saqib
AU  - Jeon, Gwanggil
JO  - Microprocessors and Microsystems
VL  - 90
SP  - 104501
PY  - 2022
DA  - 2022/04/01/
SN  - 0141-9331
DO  - https://doi.org/10.1016/j.micpro.2022.104501
UR  - https://www.sciencedirect.com/science/article/pii/S0141933122000618
KW  - Internet of vehicles
KW  - Authentication
KW  - Drones
KW  - Transmission
KW  - Security
KW  - ITS
AB  - Intelligent Transportation Systems (ITS) is one of the demanding area of research based on fast communication services. However, these networks are suffered with some congestion, routing and security issues especially in urban areas and cause of delay and computational complexities issues and lead to late messages delivery or data congestion. The Unmanned Ariel Vehicles (UAV) or drones and Internet of Vehicles (IoV) are facilitating ITS networks by collecting the data from road nodes and forward to the Road Side Units (RSU) or to the backbone architecture for decision making. This strategy will open new threats and challenges in the form of security, user privacy and other malicious activities. The traditional security and authentication mechanisms have not been feasible due to their complex and heavy computational processing. This study presents a novel Secure Data Communication in Drone Enables Internet of Vehicle (SDCD-IoV), solution for authentication among vehicle nodes, RSU and trust authority database in ITS networks. The proposed system is based on three main phases including initialization, registration, and authentication. The proposed solution provides the authentication mechanism to fulfill the security requirements to intelligent mobile nodes and provides node anonymity where vehicle nodes and drones are protected the identity during data transmission. The second important contribution of proposed solution is unlinkability where the network prevents them from adversary. Traceability and mutual authentication are also considered where nodes check malicious action and real identity of nodes recovery and verifying the messages from other entities. The proposed solution is tested in terms of time cost, computational cost, overhead in the presence of different number of nodes and velocities. The proposed solution achieved the high performance as compared to existing solutions.
ER  - 

TY  - JOUR
T1  - Developing SPIM-TA: a maturity-level framework for systematic process improvement in software testing automation
AU  - Abrar, Muhammad Faisal
AU  - Alharbi, Yasser
AU  - Alsaffar, Muhammad
AU  - Hussain, Shah
AU  - Saqib, Muhammad
AU  - Khan, Jawad
AU  - Lee, Youngmoon
JO  - Ain Shams Engineering Journal
VL  - 16
IS  - 8
SP  - 103472
PY  - 2025
DA  - 2025/08/01/
SN  - 2090-4479
DO  - https://doi.org/10.1016/j.asej.2025.103472
UR  - https://www.sciencedirect.com/science/article/pii/S2090447925002138
KW  - Automated Software Testing
KW  - SPIM-TA framework
KW  - Systematic Process Improvement
AB  - The growing complexity and demands for high-quality software underlined the need for robust automated software testing frameworks. However, lack of skilled personnel, cost of testing automation, and maintenance of script along with others oppose the widespread adoption of automation in testing. The work proposed by this study is in line with the development of Systematic Process Improvement Model for Testing Automation, abbreviated as SPIM-TA. The model is inspired from Capability Maturity Model Integration (CMMI) and Software Outsourcing Vendor Readiness Model (SOVRM) maturity-level-based framework. The research was done based on a four-phased methodology. In the first phase, a systematic literature review identified 14 critical challenges in software testing automation with practices or solutions for each of these challenges. In the second round, a survey questionnaire is used to validate these findings in industrial context and extract more practical insights from case studies. This dual approach had ensured both academic rigor and the relevance of the practices with industry. The third one involved developing SPIM-TA by incorporating insights that come from the SLR and those results of the survey as well. The framework defines five maturity levels, systematically addressing the identified challenges and providing a structured pathway for organizations to enhance their automation processes. In the fourth phase, case studies of industrial applications were carried out to evaluate SPIM-TA’s efficiency. The applicability, scalability, and impact of the framework on testing automation in the real world were assessed using the Motorola Assessment Tool. The findings illustrate the systematic way SPIM-TA will help overcome the automation challenge, so that organizations can reach more advanced levels of maturity and efficiency in their testing processes. In the first place, the present study closes the gap between academia and industry but at the same time paves the foundation for future research into the automation of software testing.
ER  - 

TY  - JOUR
T1  - The privacy cost of fun: A measurement study of user data exposure in tiktok mini-games
AU  - Bello, Sideeq
AU  - Noureddine, Lamine
AU  - Bappah, Babangida
AU  - Ali-Gombe, Aisha
JO  - Computers & Security
VL  - 160
SP  - 104728
PY  - 2026
DA  - 2026/01/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104728
UR  - https://www.sciencedirect.com/science/article/pii/S0167404825004171
KW  - Tiktok minigames
KW  - Augmented reality
KW  - Privacy risks
KW  - Informed consent
AB  - TikTok Mini Games represent a growing class of interactive, embedded experiences within social media platforms. Delivered through filters and effects, these games offer high engagement, but raise underexplored privacy concerns. Unlike standalone mobile games, TikTok Mini Games operate entirely within the app’s ecosystem-blurring the lines between entertainment, content creation, and data collection. Despite their popularity, little is known about how these features collect, process, and expose user data. This paper presents the first comprehensive privacy analysis of TikTok Mini Games using a mixed-method framework. We combine documentation review and experimental development, developmental toolkit analysis, interface and behavioral heuristic evaluation, network traffic and code analysis, data synthesis for privacy sensitivity, and comparative analysis to examine how privacy risks are architected, operationalized, and experienced. Our analysis reveals systemic privacy gaps: AR functionalities and motion sensors operate without granular consent mechanisms, UI designs lack transparency, and sensitive data streams (facial landmarks, geolocation, behavioral telemetry) are extensively collected, often without explicit interface-level disclosures. We also identify misalignments between TikTok’s runtime data practices and disclosed privacy policies, raising concerns about informed consent and accountability. A comparative analysis with Facebook Instant Games highlights structural differences in developer access, API use, and data governance. To address these concerns, we recommend platform-level reforms, including per-feature consent and embedded transparency mechanisms for interactive content. Our findings inform both the platform design and the regulatory discourse as gamified content embedded becomes a dominant mode of digital interaction.
ER  - 

TY  - JOUR
T1  - DESIGN and be SMART: Eleven engineering challenges to achieve sustainable air transportation under safety assurance in the year 2050
AU  - Wandelt, Sebastian
AU  - Blom, Henk
AU  - Krömer, Marius Magnus
AU  - Li, Daochun
AU  - Mitici, Mihaela
AU  - Ryley, Tim
AU  - Stumpf, Eike
AU  - Wang, Kun
AU  - Yang, Bin
AU  - Zanin, Massimiliano
AU  - Sun, Xiaoqian
JO  - Journal of the Air Transport Research Society
VL  - 4
SP  - 100045
PY  - 2025
DA  - 2025/06/01/
SN  - 2941-198X
DO  - https://doi.org/10.1016/j.jatrs.2024.100045
UR  - https://www.sciencedirect.com/science/article/pii/S2941198X24000563
KW  - Air transportation
KW  - Sustainability
KW  - Engineering
KW  - Challenges
AB  - The aviation industry faces various challenges in meeting long-term sustainability goals amidst surging demand for air travel and growing environmental concerns of the general public. The year 2050 is set as an ambitious goal for net zero emissions, a substantial reduction in carbon dioxide emissions per passenger kilometer flown, major improvements in aircraft energy efficiency, and a development towards autonomous, intelligent operations. This review explores the pivotal role of advancements in engineering for achieving sustainability in aviation. Through a comprehensive review of existing literature and case studies, our work highlights how innovations in all aspects of aircraft engineering coupled with operations-related technologies, offer promising solutions to mitigate environmental impact, enhance efficiency, and ensure long-term sustainability in aviation operations. To discuss the necessary advances, we promote the so-called ‘DESIGN and be SMART’ framework, consisting of eleven complementary engineering challenges towards reaching sustainability. To address the high safety levels reached in air transportation, our DESIGN and be SMART framework also addresses the safety assurance challenge that is overarching each of the eleven engineering challenges. We believe that through an orchestrated integration of hardware advancements with innovative software solutions, and novel safety assurance methods, the aviation industry can realize synergistic benefits that drive sustainable growth of air transportation. Our review contributes to such an orchestration by describing the status quo and research challenges ahead.
ER  - 

TY  - JOUR
T1  - Patent litigation and narrative R&D disclosures: Evidence from the adoption of anti-troll legislation
AU  - Huang, Rui
AU  - Kim, Jeong-Bon
AU  - Lu, Louise Yi
AU  - Wang, Dongyue
AU  - Yu, Yangxin
JO  - Research Policy
VL  - 54
IS  - 1
SP  - 105127
PY  - 2025
DA  - 2025/01/01/
SN  - 0048-7333
DO  - https://doi.org/10.1016/j.respol.2024.105127
UR  - https://www.sciencedirect.com/science/article/pii/S0048733324001768
KW  - Patent trolls
KW  - Anti-troll legislation
KW  - Proprietary costs
KW  - R&D disclosures
AB  - The last two decades have witnessed a sharp increase in patent litigation in the United States (U.S.), mainly driven by patent trolls. By exploiting the staggered adoption of Anti-Troll laws across 34 states as a plausible exogenous shock that reduces the risk of patent litigation by these trolls, we show that firms significantly increase their narrative R&D disclosures following the enactment of Anti-Troll laws. This effect is less pronounced in firms facing higher competitive pressure, and more pronounced in firms that are more exposed to threats from patent trolls. Further analyses alleviate the concern that the impact of Anti-Troll laws on disclosures is attributable to state-level economic or policy changes. Our results highlight the significant role of patent troll litigation in influencing the dissemination of narrative R&D information.
ER  - 

TY  - JOUR
T1  - Few-shot cyberviolence intent classification with Meta-learning AutoEncoder based on adversarial domain adaptation
AU  - Yang, Shun
AU  - Du, YaJun
AU  - Du, ShangYi
AU  - Li, XianYong
AU  - Chen, XiaoLiang
AU  - Li, YanLi
AU  - Xie, ChunZhi
AU  - Liu, Jia
JO  - Neurocomputing
VL  - 620
SP  - 129089
PY  - 2025
DA  - 2025/03/01/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2024.129089
UR  - https://www.sciencedirect.com/science/article/pii/S0925231224018605
KW  - Few-shot learning
KW  - Meta-learning
KW  - Intent classification
KW  - Cyberviolence
KW  - AutoEncoder
AB  - The phenomenon of cyberviolence has become a critical issue in online security, drawing attention from various stakeholders. A major shortcoming in the previous works is the limitation of using simple methods like ”yes” or ”no” to evaluate cyberviolence utterances, which can significantly restrict netizens’ free speech. Therefore, we provide a novel strategy for detecting cyberviolence utterances based on the user’s real intent. Fine-grained cyberviolence intents are complex, leading to texts that share similar syntactic structures and semantics but differ in intent category. The previous method did not consider this issue. To address this, in this paper, we propose a Meta-learning AutoEncoder (MetaAE) based on adversarial domain adaptation. The goal is to comprehend and learn the inherent logical rules and important semantic knowledge of cyberviolence utterances, specifically targeting fine-grained cyberviolence intent problems. Specifically, we use the autoencoder structure to help the model implement self-supervised learning. This enables the model to comprehend the inherent logical structure of texts with different intent categories and helps the model learn important semantic knowledge of the text during the encoder compression process. At the same time, to solve the problem of overfitting in small samples and multidomain cyberviolence utterance, we introduce domain adversarial learning to align domain features and enhance model robustness. Experimental results on both a real cyberviolence intent classification dataset and a public dataset demonstrate significant improvements. On 5-way 1-shot and 5-shot Chinese and English cyberviolence datasets, MetaAE improved the accuracy by approximately 7.23%, 8.27%, 7.22%, and 5%, respectively. In the public dataset, MetaAE improved accuracy by approximately 2.53% on 5-way 5-shot.11Our code is available at https://github.com/YS19999/Meta-learning-AutoEncoder.
ER  - 

TY  - JOUR
T1  - A survey on versatile embedded Machine Learning hardware acceleration
AU  - Garreau, Pierre
AU  - Cotret, Pascal
AU  - Francq, Julien
AU  - Cexus, Jean-Christophe
AU  - Lagadec, Loïc
JO  - Journal of Systems Architecture
VL  - 167
SP  - 103501
PY  - 2025
DA  - 2025/10/01/
SN  - 1383-7621
DO  - https://doi.org/10.1016/j.sysarc.2025.103501
UR  - https://www.sciencedirect.com/science/article/pii/S1383762125001730
KW  - Hardware acceleration
KW  - Machine Learning
KW  - Multi-application
KW  - Embedded devices
AB  - This survey investigates recent developments in versatile embedded Machine Learning (ML) hardware acceleration. Various architectural approaches for efficient implementation of ML algorithms on resource-constrained devices are analyzed, focusing on three key aspects: performance optimization, embedded system considerations (throughput, latency, energy efficiency) and multi-application support. Nevertheless, it does not take into account attacks and defenses of ML architectures themselves. The survey then explores different hardware acceleration strategies, from custom RISC-V instructions to specialized Processing Elements (PEs), Processing-in-Memory (PiM) architectures and co-design approaches. Notable innovations include flexible bit-precision support, reconfigurable PEs, and optimal memory management techniques for reducing weights and (hyper)-parameters movements overhead. Subsequently, these architectures are evaluated based on the aforementioned key aspects. Our analysis shows that relevant and robust embedded ML acceleration requires careful consideration of the trade-offs between computational capability, power consumption, and architecture flexibility, depending on the application.
ER  - 

TY  - JOUR
T1  - Deep learning based emotion analysis of microblog texts
AU  - Xu, Dongliang
AU  - Tian, Zhihong
AU  - Lai, Rufeng
AU  - Kong, Xiangtao
AU  - Tan, Zhiyuan
AU  - Shi, Wei
JO  - Information Fusion
VL  - 64
SP  - 1
EP  - 11
PY  - 2020
DA  - 2020/12/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2020.06.002
UR  - https://www.sciencedirect.com/science/article/pii/S156625352030302X
KW  - Microblog short text
KW  - Emotional analysis
KW  - Convolutional neural network
KW  - Word2vec
AB  - Traditional text emotion analysis methods are primarily devoted to studying extended texts, such as news reports and full-length documents. Microblogs are considered short texts that are often characterized by large noises, new words, and abbreviations. Previous emotion classification methods usually fail to extract significant features and achieve poor classification effect when applied to processing of short texts or micro-texts. This study proposes a microblog emotion classification model, namely, CNN_Text_Word2vec, on the basis of convolutional neural network (CNN) to solve the above-mentioned problems. CNN_Text_Word2vec introduces a word2vec neural network model to train distributed word embeddings on every single word. The trained word vectors are used as input features for the model to learn microblog text features through parallel convolution layers with multiple convolution kernels of different sizes. Experiment results show that the overall accuracy rate of CNN_Text_Word2vec is 7.0% higher than that achieved by current mainstream methods, such as SVM, LSTM and RNN. Moreover, this study explores the impact of different semantic units on the accuracy of CNN_Text_Word2vec, specifically in processing of Chinese texts. The experimental results show that comparing to using feature vectors obtained from training words, feature vector obtained from training Chinese characters yields a better performance.
ER  - 

TY  - JOUR
T1  - Artificial intelligence auditability and auditor readiness for auditing artificial intelligence systems
AU  - Li, Yueqi
AU  - Goel, Sanjay
JO  - International Journal of Accounting Information Systems
VL  - 56
SP  - 100739
PY  - 2025
DA  - 2025/12/01/
SN  - 1467-0895
DO  - https://doi.org/10.1016/j.accinf.2025.100739
UR  - https://www.sciencedirect.com/science/article/pii/S1467089525000156
KW  - AI audits
KW  - Auditability
KW  - Auditors
KW  - Competency
KW  - AI auditability framework
AB  - As the business community races to implement artificial intelligence (AI), there are several challenges that need to be addressed such as fairness and biases, transparency, denial of individual rights, and dilution of privacy. AI audits are expected to ensure that AI systems function lawfully, robustly, and follow ethical standards (e.g., fairness). While the auditability for financial audits and information system audits has been well addressed in the literature, auditability of AI systems has not been sufficiently addressed. AI auditability and auditors’ competencies are crucial for ensuring AI audits are conducted with high quality. Research on the auditability of AI and the competencies of AI auditors is gravely lacking leaving risks in AI systems unmitigated. The primary reason is that the field is nascent and the rapid growth has left the audit profession struggling to catch up. Foundational work on establishing parameters for such research would help advance this research. In this paper, we explore AI auditability measures and competencies required for conducting AI audits. We conducted semi‐structured interviews with 23 experienced AI professionals who have direct involvement or indirect exposure to AI audits. Based on our findings, we propose a framework of AI auditability and identify the competencies required to conduct AI audits. Our study serves as the first formal attempt to systematically identify and classify auditability measures and auditors’ expertise demanded for AI audits based on practitioners’ perspectives. Our findings contribute to the AI audit literature, inform AI developers about implementing auditability, guide the training of new AI auditors, and establish a foundation for further research in the field.
ER  - 

TY  - JOUR
T1  - ChatGPT’s infusion advantage: The moderating role of strategic agility
AU  - Luo, Jiangwei
AU  - Mohd Shafiei, Mohd Wira
AU  - Ismail, Radzi
AU  - Liu, Qinghua
AU  - Chen, Lixian
AU  - Duan, Yingying
JO  - Journal of Strategy & Innovation
VL  - 36
IS  - 1
SP  - 200541
PY  - 2025
DA  - 2025/05/01/
SN  - 3050-7901
DO  - https://doi.org/10.1016/j.jsinno.2025.200541
UR  - https://www.sciencedirect.com/science/article/pii/S3050790125000117
KW  - ChatGPT
KW  - Infusion
KW  - Strategic agility
KW  - Competitive advantage
KW  - Firm system
AB  - With the development of Artificial Intelligence (AI) technology, the competitive role of ChatGPT in enterprise integration has become increasingly prominent. However, AI faces three significant strategic challenges in the enterprise integration process: universality, replicability, and narrowness, which limit its contribution to the competitive advantage of enterprises. Based on literature analysis and quantitative research, this study used the PLS-SEM (Partial Least Squares Structural Equation Modeling) method to analyze the data of 219 Chinese construction industry practitioners to explore the impact of ChatGPT deep integration (infusion) on the competitive advantage of enterprises. The results show that ChatGPT infusion promotes competitive advantage by improving information analysis capabilities, optimizing competitive intelligence, and enhancing intelligent decision-making support, thereby improving the market responsiveness of enterprises. In addition, strategic agility reinforces ChatGPT infusion and corporate competitive advantage and helps to cope with the three significant strategic challenges of AI in enterprise integration. This study demonstrates the importance of ChatGPT's integration advantages and strategic agility in the process of enterprise integration, provides reference and insights for various industries and enterprises, and proposes practical measures for AI enterprise integration and the necessity of further research.
ER  - 

TY  - JOUR
T1  - Generative AI in banking: empirical insights on integration, challenges and opportunities in a regulated industry
AU  - Moharrak, Moayad
AU  - Mogaji, Emmanuel
JO  - International Journal of Bank Marketing
VL  - 43
IS  - 4
SP  - 871
EP  - 896
PY  - 2024
DA  - 2024/11/25/
SN  - 0265-2323
DO  - https://doi.org/10.1108/IJBM-08-2024-0490
UR  - https://www.sciencedirect.com/science/article/pii/S0265232324000309
KW  - Generative AI
KW  - Banking innovation
KW  - Managerial preparedness
KW  - Regulatory compliance
KW  - Data privacy
AB  - Purpose
This study aims to fill critical research gaps by providing empirical evidence on the practical application of generative AI in the banking sector. It explores managerial preparedness, regulatory compliance and data privacy challenges in implementing this technology, offering insights into its operational effectiveness and potential in financial services.
Design/methodology/approach
The research employs a qualitative approach, conducting in-depth interviews with bank managers and industry experts. These interviews are analysed to identify key factors influencing the integration of generative AI in financial institutions.
Findings
The study identifies five critical factors – recognition, requirement, reliability, regulatory and responsiveness – that collectively impact the adoption and operational effectiveness of generative AI in banking. These factors highlight the challenges and opportunities of integrating this technology within the highly regulated financial industry.
Practical implications
The findings have significant theoretical and managerial implications. Theoretically, the research contributes to understanding AI integration in regulated industries, particularly financial services. Managerially, it provides a roadmap for financial institutions to adopt generative AI responsibly, balancing innovation with regulatory compliance and ethical considerations.
Originality/value
This study is among the first to provide empirical data on generative AI’s practical application in the banking sector, addressing the lack of real-world evidence and offering a comprehensive analysis of the factors influencing its successful implementation in a highly regulated environment.
ER  - 

TY  - JOUR
T1  - A Multi-Module Explainable Artificial Intelligence Framework for Project Risk Management: Enhancing Transparency in Decision-making
AU  - Badhon, Bodrunnessa
AU  - Chakrabortty, Ripon K.
AU  - Anavatti, Sreenatha G.
AU  - Vanhoucke, Mario
JO  - Engineering Applications of Artificial Intelligence
VL  - 148
SP  - 110427
PY  - 2025
DA  - 2025/05/15/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2025.110427
UR  - https://www.sciencedirect.com/science/article/pii/S0952197625004270
KW  - Explainable Artificial Intelligence
KW  - Knowledge Graph
KW  - Conditional Tabular Generative Adversarial Networks
KW  - Local Interpretable Model-Agnostic Explanations
KW  - Project Risk Management
AB  - The remarkable advancements in machine learning (ML) have led to its extensive adoption in Project Risk Management (PRM), leveraging its powerful predictive capabilities and data-driven insights that support proactive decision-making. Nevertheless, the “black-box” nature of ML models obscures the reasoning behind predictions, undermining transparency and trust. To address this, existing explainable artificial intelligence (XAI) techniques, such as Local Interpretable Model-agnostic Explanations (LIME), Global Priors-based LIME (G-LIME), and SHapley Additive exPlanations (SHAP), have been applied to interpret black-box models. Yet, they face considerable limitations in PRM, including their inability to model cascading effects and multi-level dependencies among risk factors, suffering from inconsistencies due to random sampling, and failure to capture non-linear interactions in high-dimensional risk data. In response to these shortcomings, this paper proposes the Multi-Module eXplainable Artificial Intelligence framework for Project Risk Management (MMXAI-PRM), a novel approach designed to address the unique demands of PRM. The framework consists of three modules: the Risk Relationship Insight Module (RRIM), which models risk dependencies using a Knowledge Graph (KG); the Risk Factor Influence Analysis Module (RFIAM), which introduces a Conditional Tabular Generative Adversarial Network-aided Local Interpretable Model-agnostic Explanations using Kernel Ridge Regression (CTGAN-LIME-KR) to ensure explanation consistency and handle non-linearity; and the Visualization and Interpretation Module (VIM), which synthesizes these insights into an interpretable, chain-based representation. Extensive experiments demonstrate that MMXAI-PRM delivers more consistent, stable, and accurate explanations than existing XAI methods. By improving interpretability, it enhances trust in AI-driven risk predictions and equips project managers with actionable insights, advancing decision-making in PRM.
ER  - 

TY  - JOUR
T1  - A data-driven hybrid framework for analyzing vessel detentions in Australia
AU  - Sheriff, Abubakar Mahmud
AU  - Anantharaman, Mohan
AU  - Islam, Rabiul
AU  - Nguyen, Hong-Oanh
JO  - Marine Policy
VL  - 184
SP  - 106933
PY  - 2026
DA  - 2026/02/01/
SN  - 0308-597X
DO  - https://doi.org/10.1016/j.marpol.2025.106933
UR  - https://www.sciencedirect.com/science/article/pii/S0308597X25003495
KW  - Port State Control
KW  - Maritime Safety
KW  - Vessel Detention
KW  - Entropy-Weighted Grey Relational Analysis
KW  - Association Rule Mining
KW  - Risk-Based Inspection Strategy
AB  - Port State Control (PSC) plays a critical role in safeguarding maritime safety and environmental protection by identifying and detaining substandard vessels. Given the complexity of detention decisions and the diversity of vessel profiles, there is a growing need for interpretable, data-driven approaches that reflect regional enforcement contexts. This study proposes a hybrid analytical framework that integrates Entropy-Weighted Grey Relational Analysis (EW-GRA) and Association Rule Mining (ARM) to evaluate vessel detentions in Australia. EW-GRA ranks deficiency categories by their influence on detentions, while ARM reveals frequent co-occurrence patterns, uncovering relational structures among deficiencies. Using ten years of detention records from the Australian Maritime Safety Authority (AMSA), the analysis identifies International Safety Management (IntSafeMan), Emergency Systems (EmSys), and Water/Weathertight Conditions (WatWeath) as the most influential deficiencies. Stratified analysis by vessel type and age reveals increased risks among bulk carriers and older vessels, supporting targeted inspection strategies. The ARM results show that IntSafeMan-related deficiencies frequently co-occur with crew welfare and operational deficiencies, indicating compound risk factors. These findings align with AMSA’s compliance priorities, particularly in relations to planned maintenance, emergency preparedness, and working conditions under the IntSafeMan Code and the Maritime Labour Convention (MLC). The proposed framework enhances interpretability and visualisation, offering practical utility for inspection planning and regulatory oversight, thereby contributing to more effective, risk-informed PSC enforcement in the Australian maritime domain.
ER  - 

TY  - JOUR
T1  - Do names echo semantics? A large-scale study of identifiers used in C++’s named casts
AU  - Petrescu, Constantin Cezar
AU  - Smith, Sam
AU  - Giavrimis, Rafail
AU  - Dash, Santanu Kumar
JO  - Journal of Systems and Software
VL  - 202
SP  - 111693
PY  - 2023
DA  - 2023/08/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2023.111693
UR  - https://www.sciencedirect.com/science/article/pii/S0164121223000882
KW  - C++ type conversions
KW  - Languages
KW  - Programme analysis
AB  - Developers relax restrictions on a type to reuse methods with other types. While type casts are prevalent, in weakly typed languages such as C++, they are also extremely permissive. Assignments where a source expression is cast into a new type and assigned to a target variable of the new type, can lead to software bugs if performed without care. In this paper, we propose an information-theoretic approach to identify poor implementations of explicit cast operations. Our approach measures accord between the source expression and the target variable using conditional entropy. We collect casts from 34 components of the Chromium project, which collectively account for 27MLOC and random-uniformly sample this dataset to create a manually labelled dataset of 271 casts. Information-theoretic vetting of these 271 casts achieves a peak precision of 81% and a recall of 90%. We additionally present the findings of an in-depth investigation of notable explicit casts, two of which were fixed in recent releases of the Chromium project.
ER  - 

TY  - JOUR
T1  - Piloting a maturity model for responsible artificial intelligence: A portuguese case study
AU  - Ferreira, Rui Miguel Frazão Dias
AU  - GRILO, António
AU  - MAIA, Maria
JO  - Journal of Responsible Technology
VL  - 22
SP  - 100117
PY  - 2025
DA  - 2025/06/01/
SN  - 2666-6596
DO  - https://doi.org/10.1016/j.jrt.2025.100117
UR  - https://www.sciencedirect.com/science/article/pii/S2666659625000137
KW  - Responsible artificial intelligence
KW  - Artificial intelligence regulation
KW  - Maturity model
KW  - Ethical
KW  - Legal and social issues
KW  - Responsible research and innovation
AB  - Recently, frameworks and guidelines aiming to assist trustworthiness in organizations and assess ethical issues related to the development and use of Artificial Intelligence (AI) have been translated into self-assessment checklists and other instruments. However, such tools can be very time consuming to apply. Aiming to develop a more practical tool, an Industry-Wide Maturity Model for Responsible AI was piloted in 3 companies and 2 research centres, in Portugal. Results show that organizations are aware of requirements (44 %) to deploy a responsible AI approach and have a reactive response to its implementation, as they are willing to integrate other requirements (33 %) into their business processes. The proposed Model was welcomed and showed openness from companies to consistently use it, since it helped to identify gaps and needs when it comes to foster a more trustworthy approach to the development and deployment of AI.
ER  - 

TY  - JOUR
T1  - Sentiment and time-series analysis of direct-message conversations
AU  - Harris, Martyn
AU  - Jacobson, Jessica
AU  - Provetti, Alessandro
JO  - Forensic Science International: Digital Investigation
VL  - 49
SP  - 301753
PY  - 2024
DA  - 2024/06/01/
SN  - 2666-2817
DO  - https://doi.org/10.1016/j.fsidi.2024.301753
UR  - https://www.sciencedirect.com/science/article/pii/S2666281724000726
KW  - Text analysis
KW  - Sentiment analysis
KW  - Access to mobile data
KW  - Digital forensics
AB  - Social media and mobile communications in general are an extremely rich source of digital forensic information. We present our new framework for analysing this resource with an innovative combination of time series and text mining methods. The framework is intended to create a tool to analyse and operationally summarise extended trails of social media messages, thus enabling investigators for the first time to drill down into specific moments at which sentiment analysis has detected a change of tone indicative of a particularly strong and significant response. Crucially, the method will give investigators an opportunity to reduce the time and resource commitment required for ongoing and hands-on analysis of digital communications on media such as Texts/SMS, WhatsApp and Messenger.
ER  - 

TY  - JOUR
T1  - BCBA: An IIoT encrypted traffic classifier based on a serial network model
AU  - Wang, Maoli
AU  - Chen, Chuanxin
AU  - Zhang, Xinchang
AU  - Qiu, Haitao
JO  - Future Generation Computer Systems
VL  - 164
SP  - 107603
PY  - 2025
DA  - 2025/03/01/
SN  - 0167-739X
DO  - https://doi.org/10.1016/j.future.2024.107603
UR  - https://www.sciencedirect.com/science/article/pii/S0167739X24005673
KW  - Encrypted traffic classification
KW  - Industrial Internet of Things
KW  - BERT
KW  - Pretraining
AB  - With the rapid development of the Industrial Internet of Things (IIoT), ensuring the security and privacy of network traffic has become particularly important. Classifying and identifying encrypted traffic is a critical step in enhancing network security, but traditional traffic classification methods often struggle to handle the complexities of the IIoT environment. In this paper, we propose the BCBA model, a bidirectional encoder representation from transformers (BERT)-based serial network model, which significantly improves the encrypted traffic classification performance and can be trained more than four times faster than the original BERT classifier. The BCBA method obtains word vector representations from the embedding layer of the pretrained BERT model, uses convolutional neural networks (CNNs) to extract local features, employs bidirectional long short-term memory (BiLSTM) networks to capture temporal dependencies in traffic data, and leverages a multihead self-attention mechanism to improve global dependency understanding. In experiments on six types of regular encrypted traffic from the ISCXVPN2016 dataset, the BCBA model achieved an F1 score of 99.10%, outperforming traditional traffic classification techniques across multiple performance metrics. This study demonstrates the effectiveness of deep learning in enhancing the security of the IIoT. It also provides new perspectives and technical routes for future research, particularly in encrypted traffic processing and classification applications.
ER  - 

TY  - JOUR
T1  - Transforming towards AI-augmented Healthcare: Experiences of physicians in Sweden
AU  - Ismail, Muhammad
AU  - Barth, Henrik
AU  - Holmén, Magnus
AU  - Petersson, Lena
AU  - Irgang, Luís
JO  - Technovation
VL  - 148
SP  - 103333
PY  - 2025
DA  - 2025/12/01/
SN  - 0166-4972
DO  - https://doi.org/10.1016/j.technovation.2025.103333
UR  - https://www.sciencedirect.com/science/article/pii/S0166497225001658
KW  - Artificial intelligence
KW  - Technology adoption
KW  - Drivers
KW  - Barriers
KW  - Paradox
KW  - Physicians
KW  - AI strategy
KW  - Swedish healthcare system
KW  - Sweden
AB  - Recent advancements in connectivity and automation driven by artificial intelligence (AI) is leading to transformative changes in the healthcare sector. This study investigates physicians' experience of AI-based technologies in healthcare. To achieve this objective, we gathered responses through open-ended essays from 326 physicians working in Swedish healthcare. These respondents have experience in using AI technologies for distinct tasks, which include prediction, diagnosis, medical image analysis, text generation, analysis, chatbots, wearable devices, telemedicine and robot assistance. The data was analyzed by thematic coding. The findings show that the physicians’ perception towards use of AI in healthcare is influenced by drivers and barriers that are present at macro, organizational, system and personal level. The identified drivers include work task changes, functional aspects, organizational aspects, system characteristics and personal motivators. The barriers include legal and ethical dilemma, organizational readiness, system limitations and personal demotivators. This study leverages paradox theory as a framework to deepen the understanding of the complexities and interconnections between perceived barriers and potential solutions related to AI in healthcare as a contribution to the literature.
ER  - 

TY  - JOUR
T1  - Differences between human and artificial/augmented intelligence in medicine
AU  - Monteith, Scott
AU  - Glenn, Tasha
AU  - Geddes, John R.
AU  - Achtyes, Eric D.
AU  - Whybrow, Peter C.
AU  - Bauer, Michael
JO  - Computers in Human Behavior: Artificial Humans
VL  - 2
IS  - 2
SP  - 100084
PY  - 2024
DA  - 2024/08/01/
SN  - 2949-8821
DO  - https://doi.org/10.1016/j.chbah.2024.100084
UR  - https://www.sciencedirect.com/science/article/pii/S2949882124000446
KW  - Artificial intelligence
KW  - Human intelligence
KW  - High-risk situations
AB  - The emphasis on artificial intelligence (AI) is rapidly increasing across many diverse aspects of society. This manuscript discusses some of the key topics related to the expansion of AI. These include a comparison of the unique cognitive capabilities of human intelligence with AI, and the potential risks of using AI in clinical medicine. The general public attitudes towards AI are also discussed, including patient perspectives. As the promotion of AI in high-risk situations such as clinical medicine expands, the limitations, risks and benefits of AI need to be better understood.
ER  - 

TY  - JOUR
T1  - Balancing Innovation, Responsibility, and Ethical Consideration in AI Adoption
AU  - Taherdoost, Hamed
AU  - Madanchian, Mitra
AU  - Castanho, Giovana
JO  - Procedia Computer Science
VL  - 258
SP  - 3284
EP  - 3293
PY  - 2025
DA  - 2025/01/01/
T2  - International Conference on Machine Learning and Data Engineering
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2025.04.586
UR  - https://www.sciencedirect.com/science/article/pii/S1877050925016904
KW  - Artificial intelligence
KW  - AI adoption
KW  - Innovation
KW  - Responsibility
KW  - Ethics
KW  - Bias
AB  - This paper looks at the complex balance in the acceptance of artificial intelligence (AI) between ethics, accountability, and invention. It investigates the several aspects of artificial intelligence acceptance, including the ethical issues influencing society influence as well as the developments fostering technical progress. By means of an extensive analysis of approaches for including ethical issues into artificial intelligence research, the paper underlines the need of encouraging openness, responsibility, and inclusiveness in AI systems. Leveraging multidisciplinary knowledge and cooperative efforts, stakeholders are urged to negotiate the complexity of artificial intelligence adoption with an eye on ethical standards and social benefit.
ER  - 

TY  - JOUR
T1  - Enabling innovation with big data analytics capabilities: the moderating role of organizational learning culture
AU  - Horani, Omar Mohammed
AU  - Al-Adwan, Ahmad Samed
AU  - Al-Rahmi, Waleed Mugahed
AU  - Alkhalifah, Ali
JO  - Data Science and Management
PY  - 2025
DA  - 2025/07/05/
SN  - 2666-7649
DO  - https://doi.org/10.1016/j.dsm.2025.06.006
UR  - https://www.sciencedirect.com/science/article/pii/S2666764925000335
KW  - Big data analytics
KW  - Dynamic capabilities
KW  - Innovation outcomes
KW  - Organizational learning culture
KW  - Manufacturing firms
AB  - Big data analytics (BDA) capabilities for innovation are an area of growing interest; however, empirical results on this pivotal relationship remain inconclusive. This study investigates how BDA capabilities influence product, process, and business model innovation while examining the moderating role of organizational learning culture (OLC). Drawing on the dynamic capabilities perspective, we conceptualize BDA capabilities in four dimensions: data-driven culture, technological infrastructure, human analytical skills, and data governance. Using survey data from 298 manufacturing firms in Jordan and employing partial least squares structural equation modeling, we find that these competencies significantly enhance all three types of innovation, with their effects further amplified by a strong learning culture. Our findings extend prior research by revealing the specific mechanisms through which data-driven strategies foster innovation and highlighting OLC as a critical social integration mechanism. This study contributes to the understanding of how data-centric approaches reshape industry dynamics and offers actionable insights for firms seeking innovation-led competitiveness.
ER  - 

TY  - JOUR
T1  - Impact of artificial intelligence on project management (PM): Multi-expert perspectives on advancing knowledge and driving innovation toward PM2030
AU  - Hughes, Laurie
AU  - Mavi, Reza Kiani
AU  - Aghajani, Masoud
AU  - Fitzpatrick, Keith
AU  - Gunaratnege, Senali Madugoda
AU  - Shekarabi, Seyed Ashkan Hosseini
AU  - Hughes, Richard
AU  - Khanfar, Ahmad
AU  - Khatavakhotan, Ahdieh
AU  - Mavi, Neda Kiani
AU  - Li, Keyao
AU  - Mahmoud, Moataz
AU  - Malik, Tegwen
AU  - Mutasa, Sashah
AU  - Nafar, Farzaneh
AU  - Yates, Ross
AU  - Alahmad, Rasha
AU  - Jeon, Il
AU  - Dwivedi, Yogesh K.
JO  - Journal of Innovation & Knowledge
VL  - 10
IS  - 5
SP  - 100772
PY  - 2025
DA  - 2025/09/01/
SN  - 2444-569X
DO  - https://doi.org/10.1016/j.jik.2025.100772
UR  - https://www.sciencedirect.com/science/article/pii/S2444569X25001179
KW  - Project management
KW  - Artificial intelligence
KW  - Sustainability
KW  - Resilience
KW  - Ethics
AB  - The project management profession is undergoing transformative change with the integration of Artificial Intelligence (AI), redefining core methodologies and decision-making processes. As societal expectations rise and technological complexity intensifies, project managers face unprecedented challenges. By 2030, AI-driven predictive insights and modelling capabilities are expected to significantly enhance efficiency, raising critical questions about the evolving role of human project managers. Will AI take the lead in key decisions, or will human attributes such as creativity, ethical judgment, and emotional intelligence remain essential? Framed as PM2030, this study explores future scenarios through expert insights from academia and industry. Using an opinion-based approach, we introduce two conceptual models: the AI-Augmented Ethics-Centric Model and the Predictive Model for AI Adoption and Human Trust. These models offer a forward-looking vision of project management shaped by automation, ethics, and human-AI collaboration. This study contributes to the growing discourse on the human-centric evolution of AI-enabled project management.
ER  - 

TY  - JOUR
T1  - MLPro 2.0 - Online machine learning in Python
AU  - Arend, Detlef
AU  - Baheti, Laxmikant Shrikant
AU  - Yuwono, Steve
AU  - Kumar, Syamraj Purushamparambil Satheesh
AU  - Schwung, Andreas
JO  - Machine Learning with Applications
VL  - 21
SP  - 100715
PY  - 2025
DA  - 2025/09/01/
SN  - 2666-8270
DO  - https://doi.org/10.1016/j.mlwa.2025.100715
UR  - https://www.sciencedirect.com/science/article/pii/S2666827025000982
KW  - Online machine learning
KW  - Cascaded adaptation
KW  - Reverse adaptation
KW  - Software engineering
KW  - MLPro
KW  - Python
AB  - In this paper, we present version 2.0 of the open-source middleware MLPro for applied machine learning in Python. Notably, it introduces the new sub-framework MLPro-OA for online machine learning, focusing on standards and templates for classic and online-adaptive data stream processing (DSP/OADSP). As part of this, we provide three novel adaptation mechanisms:The first, event-oriented adaptation, enables localized, event-driven parameter updates within individual tasks. The second, cascaded adaptation, allows adaptation events to propagate across multiple dependent tasks, creating task-spanning adjustment cascades decoupled from the forward-facing DSP. The third, reverse adaptation, allows tasks to revise prior adjustments by explicitly processing obsolete instances discarded from a preceding sliding window. Furthermore, we provide insights into the underlying design criteria of MLPro-OA, which were developed through extensive requirements engineering. In the practical part of this work, we demonstrate the essential functionalities of MLPro-OA using reproducible examples.
ER  - 

TY  - JOUR
T1  - Artificial intelligence in knowledge management: Identifying and addressing the key implementation challenges
AU  - Rezaei, Mojtaba
JO  - Technological Forecasting and Social Change
VL  - 217
SP  - 124183
PY  - 2025
DA  - 2025/08/01/
SN  - 0040-1625
DO  - https://doi.org/10.1016/j.techfore.2025.124183
UR  - https://www.sciencedirect.com/science/article/pii/S0040162525002148
KW  - Artificial intelligence (AI)
KW  - Knowledge management (KM)
KW  - Knowledge creation (KC)
KW  - Knowledge storage (KTS)
KW  - Knowledge sharing (KS)
KW  - Knowledge application (KA)
KW  - Delphi method
KW  - Technological challenges
KW  - Organisational challenges
KW  - Ethical challenges
KW  - CFA
AB  - In today's digital landscape, Knowledge Management (KM) is crucial for organisational competitiveness. Artificial Intelligence (AI) offers transformative potential for KM practices, yet its integration presents multifaceted challenges. This study addresses significant gaps in the literature by identifying and prioritising critical challenges associated with AI integration in KM. Employing a tripartite methodological approach, this research combines a literature review on KM and AI’s challenges, a Delphi study with domain experts, and confirmatory factor analysis (CFA) across four KM processes. Data from retail sector professionals validate the challenges identified by experts. Findings reveal a comprehensive landscape of challenges, categorised into technological, organisational, and ethical domains, with variations across different KM processes. The study contributes to the field by comprehensively exploring AI-related challenges in KM, offering a quantitative ranking, and enhancing understanding of the AI-KM interplay. This research provides valuable insights for business leaders, facilitating the development of strategies to foster robust knowledge ecosystems. By addressing these challenges proactively, organisations can enhance their KM practices, leveraging AI to maintain competitiveness in an increasingly digital business environment. The study contributes to theoretical discourse and offers practical implications for organisations navigating AI integration in their KM practices.
ER  - 

TY  - JOUR
T1  - Challenges and opportunities for artificial intelligence in auditing: Evidence from the field
AU  - Kokina, Julia
AU  - Blanchette, Shay
AU  - Davenport, Thomas H.
AU  - Pachamanova, Dessislava
JO  - International Journal of Accounting Information Systems
VL  - 56
SP  - 100734
PY  - 2025
DA  - 2025/12/01/
SN  - 1467-0895
DO  - https://doi.org/10.1016/j.accinf.2025.100734
UR  - https://www.sciencedirect.com/science/article/pii/S1467089525000107
KW  - Artificial intelligence
KW  - AI
KW  - AI challenges
KW  - Robotic Process Automation
KW  - Machine Learning
KW  - Natural Language Processing
AB  - In this study we research the adoption of artificial intelligence (AI) in auditing by large public accounting firms, with emphasis on its challenges and opportunities. Some previous studies point to delayed adoption of AI in auditing due to regulations and the need for additional safeguards while others document extensive AI implementation. To address this dissensus, we conducted 22 interviews with experienced audit professionals. We find that “simple AI” technologies such as key data extraction from documents and optical character recognition are used widely in audits while “complex AI” tools are only being developed. We find RPA is used to automate repetitive administrative processes while the use of RPA for audit tasks is not as common. We also find that the main AI adoption challenges are related to transparency and explainability, AI bias, data privacy, robustness and reliability, fear of auditor overreliance on AI, and the need for AI guidance. We present ideas for addressing these challenges based on our research and lessons from other fields.
ER  - 

TY  - JOUR
T1  - EncryptoVision: A dual-modal fusion-based multi-classification model for encrypted traffic recognition
AU  - Li, Zhiyuan
AU  - Jin, Yujie
JO  - Computer Networks
VL  - 270
SP  - 111499
PY  - 2025
DA  - 2025/10/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2025.111499
UR  - https://www.sciencedirect.com/science/article/pii/S1389128625004669
KW  - Encrypted traffic recognition
KW  - Feature extraction
KW  - Spatial–temporal fusion
KW  - Vision transformer
KW  - Channel attention
AB  - With the development of security, confidentiality, and data privacy technologies, the classification of fine-grained encrypted traffic has become increasingly important. Nowadays, existing deep learning methods, including CNN, LSTM, and transformer, have shown impressive classification performance. However, many of these methods merely utilize the raw packet bytes to generate traffic representations, resulting in the potential loss of crucial information, such as dynamic traffic patterns and changes in protocols. In this paper, we propose a dual-modal fusion-based multi-classification model for encrypted traffic recognition, called EncryptoVision. Firstly, we transform the encrypted traffic data into three-channel images and incorporate a triplet attention mechanism to enhance the interaction among the three channels. Then, we use the multi-head self-attention mechanism to expand the model’s global receptive field, allowing it to capture more detailed spatial feature information. Additionally, we also leverage the learning abilities of the transformer encoder to extract temporal feature information from the traffic for long-term time series prediction. Next, we use the spatial–temporal fusion features to obtain the fine-grained features for multi-classification. Experimental results show that our model outperforms state-of-the-art models in classification performance across four real-world encrypted traffic datasets.
ER  - 

TY  - JOUR
T1  - Human–Robot collaboration in construction: Robot design, perception and Interaction, and task allocation and execution
AU  - Liu, Jiajing
AU  - Luo, Hanbin
AU  - Wu, Dongrui
JO  - Advanced Engineering Informatics
VL  - 65
SP  - 103109
PY  - 2025
DA  - 2025/05/01/
SN  - 1474-0346
DO  - https://doi.org/10.1016/j.aei.2025.103109
UR  - https://www.sciencedirect.com/science/article/pii/S1474034625000023
KW  - Human–robot collaboration
KW  - Construction
KW  - Collaborative robots
KW  - Human–robot interaction
KW  - Digital twin
AB  - Human–robot collaboration (HRC) is a vital area for enhancing safety and productivity in the construction industry. Despite its growing importance, current literature lacks comprehensive reviews on the technological and methodological advancements supporting the design and deployment of HRC systems in construction industry. This review aims to fill this gap by providing a detailed examination of recent progress in HRC technologies and methods within the construction industry, with a focus on three main areas: (1) collaborative robot design, (2) perception and interaction, and (3) task allocation and execution of HRC systems. The review highlights significant challenges in current construction research and underscores the necessity for future research to prioritize the development of: (1) exoskeleton robots designed for construction trades and non-exoskeleton collaborative robots with rigid-flexible-soft configurations; (2) multimodal perception and interactive methods; and (3) digital twin-based HRC systems. This review study not only addresses the existing gap but also identifies promising research avenues to promote the development of safe and efficient HRC systems in the construction industry.
ER  - 

TY  - JOUR
T1  - Disruptive Technologies for e-Diasporas: Blockchain, DAOs, Data Cooperatives, Metaverse, and ChatGPT
AU  - Calzada, Igor
JO  - Futures
VL  - 154
SP  - 103258
PY  - 2023
DA  - 2023/12/01/
SN  - 0016-3287
DO  - https://doi.org/10.1016/j.futures.2023.103258
UR  - https://www.sciencedirect.com/science/article/pii/S0016328723001623
KW  - Hyperconnected diasporas
KW  - Blockchain
KW  - DAOs
KW  - Data cooperatives
KW  - Metaverse
KW  - ChatGPT
AB  - E-diasporas are networks driven by human agency, connecting digital citizens to their home countries and diasporic fellows through digital tools. In contrast, Hyperconnected Diasporas (HD) are data-driven networks engaged in extractive activities, often employed for government (para)diplomacy, heavily relying on social media extractivist data-opolies or Big Tech platforms. This article examines the impact of disruptive technologies on e-diasporas in the context of data extractivism, particularly stemming from HD. The article pursues a dual objective: (i) reviewing existing literature and comparing five disruptive technologies—Blockchain, Decentralized Autonomous Organizations (DAOs), Data Cooperatives, Metaverse, and ChatGPT—in sustaining e-diasporas as networks driven by human agency, and (ii) scrutinizing associated opportunities and risks, including challenges to institutional trust and data privacy arising from HD. The study seeks to elucidate how these technologies may either hinder or exacerbate the impacts of HD on e-diasporas, characterized by their human-driven nature. The article begins with an introduction to HD, followed by a literature review on e-diasporas. Methodologically, it presents a comparative analysis of the five disruptive technologies concerning the research question and discusses their implications for e-diasporic communities, concluding with final remarks.
ER  - 

TY  - JOUR
T1  - Modification and use of a machine learning algorithm to the Z-SEP clustering in WSNs
AU  - Alsubaei, Faisal S.
AU  - H. El-Sayed, Hamdy
JO  - Alexandria Engineering Journal
VL  - 123
SP  - 637
EP  - 650
PY  - 2025
DA  - 2025/06/01/
SN  - 1110-0168
DO  - https://doi.org/10.1016/j.aej.2025.03.104
UR  - https://www.sciencedirect.com/science/article/pii/S1110016825004120
KW  - Wireless sensor network
KW  - Cluster head
KW  - Heterogeneity
KW  - Routing protocol
KW  - Energy efficiency
KW  - Machine Learning
AB  - Wireless Sensor Networks (WSNs) consist of thousands of sensor nodes randomly placed to monitor and observe the state of the physical environment. The limited power of batteries, which are often non-replaceable or non-rechargeable, is crucial to the operation of WSNs. To extend the lifespan of WSNs, researchers focus on reducing the energy consumption of sensor nodes and developing energy-efficient routing protocols. Research has shown that threshold-based cluster head (CH) selection approaches in hierarchical routing protocols are effective in prolonging network lifetime. For heterogeneous WSNs, where some sensor nodes interact directly with the base station (BS) while others rely on clustering mechanisms, the Modified Zonal Stable Election Protocol (MZ-SEP) and Machine Learning Zonal Stable Election Protocol (MLZ-SEP) are proposed. These algorithms start with strategic node initialization, positioning nodes throughout the network and configuring their energy levels based on predefined parameters. Nodes are classified as 'Advanced' or 'Normal' to reflect inherent energy disparities within the network. A distance-based cluster head selection approach is used to assign nodes a probability of becoming cluster heads, considering their proximity to the sink node and the network's dimensions. Results indicate that MZ-SEP and MLZ-SEP are more energy-efficient than the existing protocols, showing improvements in throughput, average residual energy, network lifetime, and packet delivery to the base station. Specifically, MZ-SEP and MLZ-SEP achieve a 13 % increase in network lifetime, a 15 % boost in packet transmission to the base station, and a 12 % enhancement in average residual energy compared to existing protocols. These improvements demonstrate the potential of MZ-SEP and MLZ-SEP to significantly extend the lifespan of WSNs while optimizing data transmission and energy consumption.
ER  - 

TY  - JOUR
T1  - Predicting learners' engagement and help-seeking behaviors in an e-learning environment by using facial and head pose features
AU  - Wang, Guan-Yun
AU  - Hatori, Yasuhiro
AU  - Sato, Yoshiyuki
AU  - Tseng, Chia-Huei
AU  - Shioiri, Satoshi
JO  - Computers and Education: Artificial Intelligence
VL  - 8
SP  - 100387
PY  - 2025
DA  - 2025/06/01/
SN  - 2666-920X
DO  - https://doi.org/10.1016/j.caeai.2025.100387
UR  - https://www.sciencedirect.com/science/article/pii/S2666920X2500027X
KW  - Machine learning
KW  - Facial expression
KW  - Hint processing
KW  - Action units
KW  - Engagement
KW  - Help-seeking
AB  - In an e-learning environment, it is difficult for teachers to track learners’ engagement or detect when they need help. The current study estimates two mental states: the engagement state and the help-seeking state. We asked participants to solve a problem on an intelligent tutoring system (ITS) and recorded their facial videos, clicks of hint buttons, and answers. Action Units (AUs) and head pose features were extracted from OpenFace to consist of three feature sets: Basic AUs, Head Pose, and Co-occurring AUs feature sets. LightGBM (Light Gradient Boosting Machine) and SVM (support vector machine) classifiers showed 0.69 to 0.93 accuracy in estimating the two mental states. The classification performance revealed that LightGBM is better than SVM. We used SHAP (Shapley Additive exPlanations) analysis to evaluate the importance of Basic AUs and Head Pose features. The results showed that AU02 (outer brow raiser), AU23 (lip tightener), and AU04 (brow lowerer) are important for estimating the engagement states; AU04, AU23, and AU14 (dimpler) are important for estimating the help-seeking states. The current study succeeded in estimating when participants are engaging in solving a problem and when they need help. Features obtained from facial videos are useful in improving e-learning education.
ER  - 

TY  - JOUR
T1  - Enhancing Healthcare in Africa using Statistical Learning: Applications and Opportunities
AU  - Muchapa, Pierre T.
AU  - Kasereka, Selain K.
AU  - Pinto, Jonathan K.
AU  - Mandiya, Reagan E.
AU  - Mulomba, Christian M.
AU  - Ngoie, Ruffin-Benoît M.
AU  - Slavov, Vladislav
AU  - Tashev, Tasho
AU  - Kyamakya, Kyandoghere
JO  - Procedia Computer Science
VL  - 265
SP  - 268
EP  - 275
PY  - 2025
DA  - 2025/01/01/
T2  - 20th International Conference on Future Networks and Communications/ 22nd International Conference on Mobile Systems and Pervasive Computing/15th International Conference on Sustainable Energy Information Technology (FNC/MobiSPC/SEIT 2025)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2025.07.181
UR  - https://www.sciencedirect.com/science/article/pii/S1877050925022318
KW  - Statistical learning
KW  - Healthcare
KW  - Decision-making
KW  - Disease prediction
KW  - Artificial intelligence
KW  - Epidemiology
KW  - Africa
AB  - This review examines its role in African healthcare and its application in advancing medical imaging, epidemiological surveillance, and resource management. A review of 40 recent studies highlights key challenges, including data scarcity, inequity, inadequate infrastructure, and a shortage of qualified professionals, which hinder the large-scale implementation of these technologies. For responsible and effective integration, we suggest addressing several considerations – legal, ethical, and governance – beyond technical barriers. Although focused on Africa, this review incorporates studies from non-African countries to enrich the analysis and identify transferable strategies, given the limited number of African publications in the field. It proposes innovative pathways tailored to the continent’s healthcare systems.
ER  - 

TY  - JOUR
T1  - The effects of artificial intelligence applications in educational settings: Challenges and strategies
AU  - Ali, Omar
AU  - Murray, Peter A.
AU  - Momin, Mujtaba
AU  - Dwivedi, Yogesh K.
AU  - Malik, Tegwen
JO  - Technological Forecasting and Social Change
VL  - 199
SP  - 123076
PY  - 2024
DA  - 2024/02/01/
SN  - 0040-1625
DO  - https://doi.org/10.1016/j.techfore.2023.123076
UR  - https://www.sciencedirect.com/science/article/pii/S0040162523007618
KW  - ChatGPT
KW  - Artificial intelligence
KW  - Challenges
KW  - Strategies
KW  - Education sector
AB  - With the continuous intervention of AI tools in the education sector, new research is required to evaluate the viability and feasibility of extant AI platforms to inform various pedagogical methods of instruction. The current manuscript explores the cumulative published literature to date in order to evaluate the key challenges that influence the implications of adopting AI models in the Education Sector. The researchers' present works both in favour and against AI-based applications within the Academic milieu. A total of 69 articles from a 618-article population was selected from diverse academic journals between 2018 and 2023. After a careful review of selected articles, the manuscript presents a classification structure based on five distinct dimensions: user, operational, environmental, technological, and ethical challenges. The current review recommends the use of ChatGPT as a complementary teaching-learning aid including the need to afford customized and optimized versions of the tool for the teaching fraternity. The study addresses an important knowledge gap as to how AI models enhance knowledge within educational settings. For instance, the review discusses interalia a range of AI-related effects on learning from the need for creative prompts, training on diverse datasets and genres, incorporation of human input and data confidentiality and elimination of bias. The study concludes by recommending strategic solutions to the emerging challenges identified while summarizing ways to encourage wider adoption of ChatGPT and other AI tools within the education sector. The insights presented in this review can act as a reference for policymakers, teachers, technology experts and stakeholders, and facilitate the means for wider adoption of ChatGPT in the Education sector more generally. Moreover, the review provides an important foundation for future research.
ER  - 

TY  - JOUR
T1  - Regulation and innovation: Unveiling the quadruple-helix-innovation ecosystem of generative AI
AU  - Zhu, Yu Peng
AU  - Liang, Si Qi
AU  - Zou, Ya Fang
AU  - Park, Han Woo
JO  - Information Processing & Management
VL  - 63
IS  - 3
SP  - 104549
PY  - 2026
DA  - 2026/04/01/
SN  - 0306-4573
DO  - https://doi.org/10.1016/j.ipm.2025.104549
UR  - https://www.sciencedirect.com/science/article/pii/S030645732500490X
KW  - Generative artificial intelligence (Gen-AI)
KW  - The Quadruple Helix
KW  - Network analysis
KW  - Knowledge innovation
AB  - The collaboration between generative artificial intelligence (Gen-AI) innovation and regulation is a new trend. How can different regions and subjects balance knowledge innovation in Gen-AI between regulation and innovation? This study introduced an innovative Quadruple Helix model. By analyzing over 6000 pieces of data from five different fields–policy documents, industry patents, academic papers, media news, and posts from X–we obtained knowledge output and collaborative relationships between different Quadruple Helix subjects. We find​ that governments, industries, and universities play different but interrelated roles in the innovation and regulation of Gen-AI. The participation of civil society has broken through the limitations of the Triple Helix in knowledge innovation, effectively balancing innovation and regulation of Gen-AI knowledge production. This study seeks to provide a new perspective and method for gaining an in-depth understanding of Gen-AI development. We recommend that the government and corporate sector collaboratively construct an innovation and governance system that harmonizes specialized expertise with public consensus, aiming to achieve democratic governance and technological sustainability.
ER  - 

TY  - JOUR
T1  - Trust, transparency, and adoption in generative AI for software engineering: Insights from Twitter discourse
AU  - Basha, Manaal
AU  - Rodríguez-Pérez, Gema
JO  - Information and Software Technology
VL  - 186
SP  - 107804
PY  - 2025
DA  - 2025/10/01/
SN  - 0950-5849
DO  - https://doi.org/10.1016/j.infsof.2025.107804
UR  - https://www.sciencedirect.com/science/article/pii/S0950584925001430
KW  - Generative AI
KW  - Code generation tools
KW  - AI adoption
KW  - Human-AI interaction
AB  - Context:
The rise of AI-driven coding assistants, such as GitHub Copilot and ChatGPT, are transforming software development practices. Despite their growing impact, informal user feedback on these tools is often neglected.
Objective:
This study aims to analyze Twitter/X conversations to understand user opinions on the benefits, challenges, and barriers associated with Code Generation Tools (CGTs) in software engineering. By incorporating diverse perspectives from developers, hobbyists, students, and critics, this research provides a comprehensive view of public sentiment.
Methods:
We employed a hybrid approach using BERTopic and open coding to collect and analyze data from approximately 90,000 tweets. The focus was on identifying themes and sentiments related to various CGTs. The study sought to determine the most frequently discussed topics and their related sentiment, followed by highlighting the reoccurring feedback or criticisms that could influence generative AI (GenAI) adoption in software engineering.
Results:
Our analysis identified several significant themes, including productivity enhancements, shifts in developer practices, regulatory uncertainty, and a demand for neutral GenAI content. While some users praised the efficiency benefits of CGTs, others raised concerns regarding intellectual property, transparency, and potential biases.
Conclusion:
The findings highlight that addressing issues of trust, accountability, and legal clarity is essential for the successful integration of CGTs in software development. These insights underscore the need for ongoing dialogue and refinement of CGTs to better align with user expectations and mitigate concerns.
ER  - 

TY  - JOUR
T1  - Overview: Application status and prospects of digital twin technology in mechanical cutting processing
AU  - Xin, Li
AU  - Hanjun, Gao
AU  - Xiaoman, Chen
AU  - Nianpu, Xue
AU  - Qiong, Wu
JO  - Journal of Industrial Information Integration
VL  - 45
SP  - 100822
PY  - 2025
DA  - 2025/05/01/
SN  - 2452-414X
DO  - https://doi.org/10.1016/j.jii.2025.100822
UR  - https://www.sciencedirect.com/science/article/pii/S2452414X25000469
KW  - Digital twin
KW  - Cutting processing
KW  - Data collection
KW  - Modeling and simulation
KW  - Dynamic parameter optimization
AB  - With the advancement of digitalization and intelligence, the demand for improving processing quality and efficiency is becoming increasingly urgent. Digital twin technology, a key supporting technology for intelligent manufacturing, can accurately simulate and predict the machining process in virtual space. This is achieved through data fusion analysis and iterative optimization, effectively ensuring the shape and quality of key components. The article provides a detailed review of the development history of digital twin technology, introduces the progress of its theoretical system construction and technical standard formulation, and explores its broad application prospects in the field of intelligent manufacturing. Through the analysis of relevant research and engineering cases, this article summarizes the current research status of relevant technologies, analyzes the future development directions, provides an application paradigm of digital twin in machining cutting processing, and reveals the important role and enormous potential of digital twin technology in promoting the transformation and upgrading of the manufacturing industry.
ER  - 

TY  - JOUR
T1  - FedMVA: Enhancing software vulnerability assessment via federated multimodal learning
AU  - Liu, Qingyun
AU  - Ju, Xiaolin
AU  - Chen, Xiang
AU  - Gong, Lina
JO  - Journal of Systems and Software
VL  - 228
SP  - 112469
PY  - 2025
DA  - 2025/10/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2025.112469
UR  - https://www.sciencedirect.com/science/article/pii/S0164121225001372
KW  - Software vulnerability assessment
KW  - Federated learning
KW  - Multimodal fusion
KW  - Privacy-preserving
AB  - Software Vulnerability Assessment plays a crucial role in identifying and evaluating security vulnerabilities in software systems and prioritizing their resolution. However, as concerns about data privacy and security continue to grow, traditional vulnerability assessment methods struggle to balance effectiveness with privacy protection, particularly in heterogeneous data environments. To address this challenge, we propose a novel federated multimodal vulnerability assessment framework (FedMVA), designed with privacy preservation at its core. FedMVA leverages federated learning, enabling local model training without sharing data, thereby protecting sensitive information while ensuring efficient vulnerability evaluation. Our framework also incorporates multimodal data, including code structure, lexical features, and developer comments, fully utilizing the complementary nature of these modalities. We introduce a weighted variance minimization loss function to improve the alignment between local and global models and adopt a momentum-based weight allocation strategy with a dynamic learning rate mechanism to enhance the model’s robustness and adaptability across diverse data environments. Extensive ablation studies demonstrate that FedMVA outperforms existing methods in multiple performance metrics, significantly improving the precision of vulnerability assessment. This work highlights the advantages of integrating multimodal data within a federated learning framework, providing an innovative and promising solution for effective and privacy-preserving vulnerability assessment in complex software systems. Editor’s note: Open Science material was validated by the Journal of Systems and Software Open Science Board.
ER  - 

TY  - JOUR
T1  - FederatedTrust: A solution for trustworthy federated learning
AU  - Sánchez Sánchez, Pedro Miguel
AU  - Huertas Celdrán, Alberto
AU  - Xie, Ning
AU  - Bovet, Gérôme
AU  - Martínez Pérez, Gregorio
AU  - Stiller, Burkhard
JO  - Future Generation Computer Systems
VL  - 152
SP  - 83
EP  - 98
PY  - 2024
DA  - 2024/03/01/
SN  - 0167-739X
DO  - https://doi.org/10.1016/j.future.2023.10.013
UR  - https://www.sciencedirect.com/science/article/pii/S0167739X23003886
KW  - Trustworthy federated learning
KW  - Trust assessment
KW  - AI governance
KW  - Privacy
KW  - Robustness
KW  - Fairness
KW  - Explainability
KW  - Accountability
AB  - The rapid expansion of the Internet of Things (IoT) and Edge Computing has presented challenges for centralized Machine and Deep Learning (ML/DL) methods due to the presence of distributed data silos that hold sensitive information. To address concerns regarding data privacy, collaborative and privacy-preserving ML/DL techniques like Federated Learning (FL) have emerged. FL ensures data privacy by design, as the local data of participants remains undisclosed during the creation of a global and collaborative model. However, data privacy and performance are insufficient since a growing need demands trust in model predictions. Existing literature has proposed various approaches dealing with trustworthy ML/DL (excluding data privacy), identifying robustness, fairness, explainability, and accountability as important pillars. Nevertheless, further research is required to identify trustworthiness pillars and evaluation metrics specifically relevant to FL models, as well as to develop solutions that can compute the trustworthiness level of FL models. This work examines the existing requirements for evaluating trustworthiness in FL and introduces a comprehensive taxonomy consisting of six pillars (privacy, robustness, fairness, explainability, accountability, and federation), along with over 30 metrics for computing the trustworthiness of FL models. Subsequently, an algorithm named FederatedTrust is designed based on the pillars and metrics identified in the taxonomy to compute the trustworthiness score of FL models. A prototype of FederatedTrust is implemented and integrated into the learning process of FederatedScope, a well-established FL framework. Finally, five experiments are conducted using different configurations of FederatedScope (with different participants, selection rates, training rounds, and differential privacy) to demonstrate the utility of FederatedTrust in computing the trustworthiness of FL models. Three experiments employ the FEMNIST dataset, and two utilize the N-BaIoT dataset, considering a real-world IoT security use case.
ER  - 

TY  - JOUR
T1  - Multi-objective optimization collaborating with deep reinforcement learning: Adversarial audio attacks
AU  - Wang, Pengchuan
AU  - Cui, Wen
AU  - Li, Deqiang
AU  - Li, Qianmu
JO  - Neurocomputing
VL  - 653
SP  - 131124
PY  - 2025
DA  - 2025/11/07/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2025.131124
UR  - https://www.sciencedirect.com/science/article/pii/S0925231225017965
KW  - Adversarial audio attack
KW  - Automatic speech recognition
KW  - DQN
KW  - Multi-objective genetic algorithm
AB  - With the increasing prevalence of human-computer speech interaction, the security of Automatic Speech Recognition (ASR) models in Speech-to-Text (STT) systems has become a critical concern. Generating targeted and concealed adversarial speech examples poses significant challenges due to noise disturbances, inefficient querying processes, and limited consideration of speech timing characteristics. This paper introduces a novel black-box generative audio attack method, Deep Q-Network-Driven Multi-objective Optimization in Adversarial Audio Attack (DQMOA). For the first time, deep reinforcement learning is integrated into adversarial audio attacks. By leveraging deep Q-network capabilities to map solution spaces to attack behaviors, along with a reward and punishment mechanism and experience pool, DQMOA delivers optimal decision-making for multi-objective genetic algorithm. This approach substantially reduces query counts, achieves high attack success rates, and ensures low word error rates with superior speech naturalness. Extensive evaluations are conducted on the Mozilla Common Voice and LibriSpeech datasets across three commercial ASR platforms, where DQMOA consistently outperforms five state-of-the-art baselines. Further experiments on Whisper large-v2/v3 and real-world over-the-air scenarios demonstrate its strong generalization ability and practical applicability. DQMOA achieves high attack success rates with over 10 % fewer queries, while preserving low word error rates and high perceptual audio quality. These findings highlight the potential of reinforcement learning-guided evolutionary optimization for robust and stealthy adversarial audio attack generation.
ER  - 

TY  - JOUR
T1  - Whom to pity, whom to scold? Effects of empathetic and normative AI-assisted interventions on aggressive Reddit users with different activity profiles
AU  - Tempska, Patrycja
AU  - Urbaniak, Rafał
AU  - Dowgiałło, Maria
AU  - Ptaszynski, Michal
AU  - Zajączkowski, Alan
AU  - Milewska, Maja
AU  - Leliwa, Gniewosz
AU  - Marcińczuk, Michał
AU  - Brochocki, Maciej
AU  - Wroczyński, Michał
JO  - Information Processing & Management
VL  - 63
IS  - 2, Part A
SP  - 104316
PY  - 2026
DA  - 2026/03/01/
SN  - 0306-4573
DO  - https://doi.org/10.1016/j.ipm.2025.104316
UR  - https://www.sciencedirect.com/science/article/pii/S0306457325002572
KW  - Counter-speech
KW  - Artificial intelligence
KW  - Collective intelligence
KW  - Peaceful interventions
KW  - Reddit
KW  - Online aggression
KW  - Online abuse
KW  - Personal attacks
AB  - During a six-month experiment conducted on Reddit, we studied the impact of counter-speech interventions against personal attacks sent by 440 users regularly attacking others. We used two types of interventions, normative—which referred to social norms, and empathetic—which referred to emotions and encouraged perspective-taking. We employed a collective intelligence approach—the collaboration between human and machine intelligence. Artificial Intelligence was used to detect verbal aggression and notify human volunteers, who then performed the interventions, providing a level of context understanding and realistic human involvement not achieved by potentially automated responses. We analyzed the data from three perspectives. We used time series models of (1) the short-term impact of individual interventions, (2) of the cumulative impact of interventions received as the experiment progressed. We also (3) used aggregated data for a long-term before/after analysis. The short-term effect of interventions is damaging: users tend to be on average around 26% more aggressive the next day, but the effect does not last beyond two days. The cumulative effect of interventions is helpful: each intervention (up to around 8–10 total, the effectiveness of more interventions tends to be lower) decreases daily aggression by 4% on average, and the effects accumulate and balance out the short-term effect in the long run. The effectiveness of normative interventions seems overall higher, except for the less aggressive offenders, for whom empathetic interventions might be equally or more useful.
ER  - 

TY  - JOUR
T1  - Regulating Artificial Intelligence for CANDU Software Qualifications
AU  - Dahaweer, Samer
AU  - Hammad, Issam
AU  - Thiyagarajan, Karthik
JO  - Nuclear Engineering and Design
VL  - 443
SP  - 114322
PY  - 2025
DA  - 2025/11/01/
SN  - 0029-5493
DO  - https://doi.org/10.1016/j.nucengdes.2025.114322
UR  - https://www.sciencedirect.com/science/article/pii/S0029549325004996
KW  - Artificial intelligence
KW  - Regulatory framework
KW  - Canadian standards association
KW  - CSA N290.14-15 standard
KW  - CANDU
KW  - Software qualification
KW  - SMR
AB  - This paper examines the inadequacies in qualifying Artificial Intelligence (AI) software for the Canadian nuclear energy sector. The nuclear energy sector is a high-risk environment with strict regulations to ensure safety. Despite the rising popularity of new technologies like AI, a compliance assessment would be needed against nuclear qualification procedures. First, the paper analyzes the existing regulatory framework within the Canadian nuclear sector. This analysis reveals potential gaps that traditional software qualification methods fail to address when applied to AI. The risks of AI, primarily linked to the complexity and opacity of decision-making processes, show the need for a new approach to AI regulation in nuclear. Next, a review of the Canadian regulatory framework focusing on the Canadian Standards Association (CSA) N290.14 with case studies of qualifying commercial software is presented to showcase the software qualification lifecycle. Through these detailed case studies, gaps are identified when applying the software qualifications methods to AI software. The paper presents three proposed methodologies for future AI qualification: model interpretability, feature importance, and data variety. These methodologies are investigated in order to improve the transparency, reliability, and safety of AI applications in high-risk contexts such as nuclear power plants. Finally, the paper proposes incorporating these three methodologies of evaluating AI complexity and reliability into the software qualification framework to significantly mitigate the risks and support safe deployment and operations of AI based software in the nuclear sector.
ER  - 

TY  - JOUR
T1  - GreenDFL: A framework for assessing the sustainability of Decentralized Federated Learning systems
AU  - Feng, Chao
AU  - Huertas Celdrán, Alberto
AU  - Cheng, Xi
AU  - Bovet, Gérôme
AU  - Stiller, Burkhard
JO  - Information and Software Technology
VL  - 190
SP  - 107937
PY  - 2026
DA  - 2026/02/01/
SN  - 0950-5849
DO  - https://doi.org/10.1016/j.infsof.2025.107937
UR  - https://www.sciencedirect.com/science/article/pii/S0950584925002769
KW  - Federated Learning
KW  - Sustainability
KW  - Software engineering
KW  - Decentralized Machine Learning
AB  - Context:
Decentralized Federated Learning (DFL) is an emerging paradigm that enables collaborative model training without centralized data and model aggregation, enhancing privacy and resilience. However, its sustainability remains underexplored, as energy consumption and carbon emissions vary across different system configurations. Understanding the environmental impact of DFL is crucial for optimizing its design and deployment.
Objective:
This work aims to develop a comprehensive and operational framework for assessing the sustainability of DFL systems. To address it, this work provides a systematic method for quantifying energy consumption and carbon emissions, offering insights into improving the sustainability of DFL.
Methods:
This work proposes GreenDFL, a fully implementable framework that has been integrated into a real-world DFL platform. GreenDFL systematically analyzes the impact of various factors, including hardware accelerators, model architecture, communication medium, data distribution, network topology, and federation size, on the sustainability of DFL systems. Besides, a sustainability-aware aggregation algorithm (GreenDFL-SA) and a node selection algorithm (GreenDFL-SN) are developed to optimize energy efficiency and reduce carbon emissions in DFL training.
Results:
Empirical experiments are conducted on multiple datasets, measuring energy consumption and carbon emissions at different phases of the DFL lifecycle. Results indicate that local training dominates energy consumption and carbon emissions, while communication has a relatively minor impact. Optimizing model complexity, using GPUs instead of CPUs, and strategically selecting participating nodes significantly improve sustainability. Additionally, using wired communication, particularly optical fiber, effectively reduces energy consumption during the communication phase, while integrating early stopping mechanisms further minimizes overall emissions.
Conclusion:
The proposed GreenDFL provides a comprehensive and practical approach for assessing the sustainability of DFL systems. Furthermore, it offers best practices for improving environmental efficiency in DFL, making sustainability considerations more actionable in real-world deployments.
ER  - 

TY  - JOUR
T1  - The Metaverse: Innovations and generative AI
AU  - Jauhiainen, Jussi S.
JO  - International Journal of Innovation Studies
VL  - 8
IS  - 3
SP  - 262
EP  - 272
PY  - 2024
DA  - 2024/09/01/
SN  - 2096-2487
DO  - https://doi.org/10.1016/j.ijis.2024.04.004
UR  - https://www.sciencedirect.com/science/article/pii/S2096248724000183
KW  - Metaverse
KW  - Innovation
KW  - Generative AI
KW  - Collaboration
KW  - Sustainability
KW  - Creativity
KW  - ChatGPT
AB  - Today, the Metaverse consists of various platforms, including digital twins of the physical world as well as virtual and blended digital-material environments that offer immersive experiences for individual users. By going beyond solely physical or virtual realms, these platforms unlock new possibilities for exploration, experimentation, and interaction. This makes it possible to transcend the limitations of innovation processes confined to physical locations, so the Metaverse is thus poised to drive groundbreaking innovations. This article explores the Metaverse as an innovation platform, its opportunities and challenges, including the role of generative AI in it. It discusses how the Metaverse, as a collaboration, creativity, and technological platform, supports innovation potential. By embracing the possibilities and challenges offered by the Metaverse and leveraging the capabilities of generative AI within it, a future in which individuals can truly explore novel synergies between the physical and digital realms, thriving various kinds of innovations. It is crucial to achieve holistic sustainability impacts both within the Metaverse innovation platform and as its outputs.
ER  - 

TY  - JOUR
T1  - DFPulse: The 2024 digital forensic practitioner survey
AU  - Hargreaves, Christopher
AU  - Breitinger, Frank
AU  - Dowthwaite, Liz
AU  - Webb, Helena
AU  - Scanlon, Mark
JO  - Forensic Science International: Digital Investigation
VL  - 51
SP  - 301844
PY  - 2024
DA  - 2024/12/01/
SN  - 2666-2817
DO  - https://doi.org/10.1016/j.fsidi.2024.301844
UR  - https://www.sciencedirect.com/science/article/pii/S2666281724001719
KW  - Digital forensics
KW  - Practitioner survey
KW  - Challenges
KW  - Future directions
KW  - Artificial intelligence
AB  - This paper reports on the largest survey of digital forensic practitioners to date (DFPulse) conducted from March to May 2024 resulting in 122 responses. The survey collected information about practitioners' operating environments, the technologies they encounter, investigative techniques they use, the challenges they face, the degree to which academic research is accessed and useful to the practitioner community, and their suggested future research directions. The paper includes quantitative and qualitative results from the survey and a discussion of the implications for academia, the improvements that can be made, and future research directions.
ER  - 

TY  - JOUR
T1  - Artificial intelligence in consumer preferences: implications for health and well-being
AU  - Bigliardi, Barbara
AU  - Bottani, Eleonora
AU  - Dolci, Virginia
AU  - Monferdini, Laura
AU  - Pini, Benedetta
JO  - Procedia Computer Science
VL  - 253
SP  - 2869
EP  - 2878
PY  - 2025
DA  - 2025/01/01/
T2  - 6th International Conference on Industry 4.0 and Smart Manufacturing
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2025.02.011
UR  - https://www.sciencedirect.com/science/article/pii/S1877050925003540
KW  - Artificial Intelligence
KW  - Consumers experience
KW  - health
KW  - well-being
AB  - The article explores how AI influences consumer behavior and wellbeing, addressing both the opportunities and challenges posed by AI technologies. It acknowledges the exponential growth of AI capabilities facilitated by advancements in computing power, IoT, and big data, which have revolutionized industries such as manufacturing and services. This evolution underscores the necessity for understanding AI’s impacts on consumer experiences, ethical dimensions, and societal implications. The research’s timely focus on AI’s role in enhancing or hindering consumer health and wellbeing directly responds to current economic contexts shaped by technological advancements.
ER  - 

TY  - JOUR
T1  - Understanding Danmaku and Comment Interactions Through Content Features and Video Popularity
AU  - Wang, Qiao
AU  - Liu, Liang
AU  - Omote, Kazumasa
AU  - Yoshida, Mitsuo
JO  - Procedia Computer Science
VL  - 270
SP  - 4253
EP  - 4262
PY  - 2025
DA  - 2025/01/01/
T2  - 29th International Conference on Knowledge-Based and Intelligent Information & Engineering Systems (KES 2025)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2025.09.550
UR  - https://www.sciencedirect.com/science/article/pii/S1877050925032235
KW  - Video Popularity
KW  - Content-Level Expression
KW  - Danmaku Interaction
KW  - User-Generated Content
KW  - Multilingual Text Analysis
AB  - This study explores how user interaction with content relates to video popularity on Bilibili, a video-sharing platform. We focus on two primary forms of interaction, danmaku and traditional comment sections, to examine how different content-level characteristics may influence user engagement outcomes. Using an exploratory content analysis framework, we assess six dimensions of potentially controversial expression, quantified through the Perspective API and cross-validated with ChatGPT-4o to address language limitations. A composite popularity index is constructed by integrating views, likes, favorites, danmaku density, and comment density. Hierarchical regression results suggest that interaction volume is the strongest predictor of video popularity, while content-related signals contribute additional explanatory power. Specifically, the fluctuation of overall toxicity in danmaku is positively associated with video popularity, whereas fluctuations in identity attacks show a negative association. In traditional comments, higher average levels of identity attacks and insults are significantly negatively correlated with video popularity. This study contributes by: (1) introducing a multidimensional exploratory framework to assess content-level expression in user interactions; (2) identifying distinct patterns between danmaku and comments in their associations with popularity; and (3) offering implications for content moderation and interaction design in video-sharing environments.
ER  - 

TY  - JOUR
T1  - PQCAIE: Post quantum cryptographic authentication scheme for IoT-based e-health systems
AU  - Mansoor, Khwaja
AU  - Afzal, Mehreen
AU  - Iqbal, Waseem
AU  - Abbas, Yawar
AU  - Mussiraliyeva, Shynar
AU  - Chehri, Abdellah
JO  - Internet of Things
VL  - 27
SP  - 101228
PY  - 2024
DA  - 2024/10/01/
SN  - 2542-6605
DO  - https://doi.org/10.1016/j.iot.2024.101228
UR  - https://www.sciencedirect.com/science/article/pii/S2542660524001690
KW  - Post-quantum cryptography
KW  - Internet of Things (IoT) security
KW  - Journal
KW  - Medical device security
AB  - The increasing integration of Internet of Things (IoT) technologies in consumer electronics has revolutionized various sectors, including healthcare. This evolution has led to the development of IoT-enabled consumer health devices and systems, offering benefits such as enhanced remote health monitoring and more efficient health data management. However, these advancements also pose significant security challenges, especially regarding data privacy and secure access. A critical concern is the vulnerability of current cryptographic methods to potential future quantum computing capabilities. This paper focuses on addressing these challenges by exploring the implementation of Post-Quantum Cryptography (PQC) in IoT-based consumer health electronics. Specifically, it evaluates the application of PQC methods in conjunction with Transport Layer Security 1.3 (TLS 1.3) for robust authentication in these systems. The study analyzes the performance and security efficacy of these schemes, comparing them to existing cryptographic approaches. Additionally, it delves into the practical hurdles and prospective solutions related to the deployment of post-quantum cryptographic techniques in the context of consumer health electronics, paving the way for more secure and reliable healthcare technology in the era of advanced consumer electronics.
ER  - 

TY  - JOUR
T1  - Visually inspired power quality disturbances recognition via Gramian Angular Difference Field, swin transformer and temporal–frequency–symmetry attention
AU  - Lin, Jiajian
AU  - Tavalaei, Jalal
AU  - Ektesabi, Mehran Motamed
AU  - Afrouzi, Hadi Nabipour
JO  - Electric Power Systems Research
VL  - 252
SP  - 112352
PY  - 2026
DA  - 2026/01/01/
SN  - 0378-7796
DO  - https://doi.org/10.1016/j.epsr.2025.112352
UR  - https://www.sciencedirect.com/science/article/pii/S0378779625009393
KW  - Power quality disturbance
KW  - Deep learning
KW  - Gram matrix
KW  - Swin transformer
KW  - Attention mechanism
AB  - Accurate and real-time identification of power quality disturbances (PQDs) remains a pressing challenge in modern power systems, especially with the increased penetration of renewable energy sources and the resulting complexity of electrical networks. This study proposed a novel hybrid framework for PQD recognition, integrating Gramian Angular Difference Field (GADF) image encoding, the Swin Transformer for hierarchical local feature extraction, and a Temporal-Frequency-Symmetry Enhanced Global Attention Mechanism (TFSGAM) for capturing global and domain-specific features. The one-dimensional PQD signals are first converted into two-dimensional images using GADF, effectively preserving temporal dependencies. The Swin Transformer exploits local contextual information, while TFSGAM further enhances feature representation by incorporating temporal position encoding, frequency-domain awareness, and symmetry-based spatial attention. Experimental results on synthetic and real-world datasets demonstrated that the proposed framework achieved classification accuracy exceeding 98 % under most noise conditions, while maintaining strong robustness across 25 PQD types and ensuring real-time applicability with an average inference time of 169 ms/sample. Comparative studies with state-of-the-art methods and extensive ablation analyses confirmed that this approach exhibits strong robustness in noise scenarios with SNR = 20/30/40 dB.
ER  - 
