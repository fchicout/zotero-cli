TY  - JOUR
T1  - Self-diagnosis service to support analysis of production performance, monitoring and optimisation activities
AU  - Peralta Abadía, José Joaquín
AU  - Monetti, Fabio Marco
AU  - Rea Minango, Sylvia Nathaly
AU  - Carrera-Rivera, Angela
AU  - Ugarte Querejeta, Miriam
AU  - Cuesta Zabaljauregui, Mikel
AU  - Larrinaga Barrenechea, Felix
AU  - Illarramendi Rezabal, Miren
AU  - Maffei, Antonio
JO  - Journal of Manufacturing Systems
VL  - 83
SP  - 800
EP  - 821
PY  - 2025
DA  - 2025/12/01/
SN  - 0278-6125
DO  - https://doi.org/10.1016/j.jmsy.2025.11.010
UR  - https://www.sciencedirect.com/science/article/pii/S0278612525002717
KW  - Self-diagnosis
KW  - Cyber–physical systems
KW  - Tool condition monitoring
KW  - Cloud computing
KW  - Predictive maintenance
KW  - Case study
AB  - Self-diagnosis functionalities, as integral components of advanced manufacturing services within cyber–physical systems (CPSs), are made possible through cloud computing technologies and machine learning techniques. These services play a crucial role in enhancing the autonomy of CPSs and introducing cost-efficient and scalable solutions. Despite the promising outlook, a gap exists in the literature regarding the lack of clear architectural frameworks and requirements for implementing self-diagnosis services in industrial settings. This paper addresses this gap by presenting a comprehensive requirement set and developing a high-level architecture tailored for self-diagnosis services. The proposed approach is validated through a detailed case study of a cloud-based self-diagnosis service, demonstrating alignment with the established architecture and requirements. The anticipated outcome of this research is to offer concrete implementation guidelines to support researchers, engineers, and practitioners in deploying CPS-based self-diagnosis services and improving production processes and system performance.
ER  - 

TY  - JOUR
T1  - Zero day ransomware detection with Pulse: Function classification with Transformer models and assembly language
AU  - Gaber, Matthew
AU  - Ahmed, Mohiuddin
AU  - Janicke, Helge
JO  - Computers & Security
VL  - 148
SP  - 104167
PY  - 2025
DA  - 2025/01/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104167
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824004723
KW  - Dynamic binary instrumentation
KW  - Malware analysis
KW  - Feature extraction
KW  - Ransomware
KW  - Transformers
KW  - LLM
KW  - AI
KW  - Assembly
AB  - Finding automated AI techniques to proactively defend against malware has become increasingly critical. The ability of an AI model to correctly classify novel malware is dependent on the quality of the features it is trained with and the authenticity of the features is dependent on the analysis tool. Peekaboo, a Dynamic Binary Instrumentation tool defeats evasive malware to capture its genuine behaviour. The ransomware Assembly instructions captured by Peekaboo, follow Zipf’s law, a principle also observed in natural languages, indicating Transformer models are particularly well-suited to binary classification. We propose Pulse, a novel framework for zero day ransomware detection with Transformer models and Assembly language. Pulse, trained with the Peekaboo ransomware and benign software data, uniquely identify truly new samples with high accuracy. Pulse eliminates any familiar functionality across the test and training samples, forcing the Transformer model to detect malicious behaviour based solely on context and novel Assembly instruction combinations.
ER  - 

TY  - JOUR
T1  - A Systematic Literature Review of Software Engineering Research on Jupyter Notebook
AU  - Siddik, Md Saeed
AU  - Li, Hao
AU  - Bezemer, Cor-Paul
JO  - Journal of Systems and Software
SP  - 112758
PY  - 2025
DA  - 2025/12/25/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2025.112758
UR  - https://www.sciencedirect.com/science/article/pii/S0164121225004273
KW  - Jupyter Notebook
KW  - Software Engineering
KW  - Data Analysis
AB  - Context: Jupyter Notebook has emerged as a versatile tool that transforms how researchers, developers, and data scientists conduct and communicate their work. As the adoption of Jupyter notebooks continues to rise, so does the interest from the software engineering research community in improving the software engineering practices for Jupyter notebooks. Objective: The purpose of this study is to analyze trends, gaps, and methodologies used in software engineering research on Jupyter notebooks. Method: We selected 199 relevant publications up to September 2025, following established systematic literature review guidelines. We explored publication trends, categorized them based on software engineering topics, and reported findings based on those topics. Results: The most popular venues for publishing software engineering research on Jupyter notebooks are related to human-computer interaction instead of traditional software engineering venues. Researchers have addressed a wide range of software engineering topics on notebooks, such as code reuse, readability, and execution environment. Although reusability is one of the research topics for Jupyter notebooks, only 82 of the 199 studies can be reused based on their provided URLs. Additionally, most replication packages are not hosted on permanent repositories for long-term availability and adherence to open science principles. Conclusion: Solutions specific to notebooks for software engineering issues, including testing, refactoring, and documentation, are underexplored. Future research opportunities exist in automatic testing frameworks, refactoring clones between notebooks, and generating group documentation for coherent code cells.
ER  - 

TY  - JOUR
T1  - Overview of key power system state estimation methods with a focus on artificial intelligence-based approaches
AU  - Ranjbar, Mohammad Amin
AU  - Azad, Sasan
AU  - Nazari-Heris, Morteza
AU  - Mohammadpourfard, Mostafa
JO  - e-Prime - Advances in Electrical Engineering, Electronics and Energy
VL  - 14
SP  - 101125
PY  - 2025
DA  - 2025/12/01/
SN  - 2772-6711
DO  - https://doi.org/10.1016/j.prime.2025.101125
UR  - https://www.sciencedirect.com/science/article/pii/S2772671125002311
KW  - State estimation
KW  - Artificial intelligence
KW  - Machine learning
KW  - Deep learning
KW  - Transfer learning
AB  - State estimation (SE) is the most critical part of power systems management and control centers because correct data from the equipment in the network is needed before any operation. Power systems in the past were less complex than today's systems, so simple methods were sufficient to solve the SE problem. As power systems have developed and distribution systems have become more interconnected to enhance reliability and handle growing loads and uncertainties, the methods for solving the SE problem have evolved over time. Many methods have been employed so far to address the state estimate problem; each of these techniques has the potential to be helpful in particular situations; therefore, identifying the strategies and getting familiar with their features can be crucial. Based on this issue, SE methods are divided into two categories. In one category, their dynamic and static characteristics are specified, and another category is based on the application of methods. Most of the methods have been studied, and the advantages and disadvantages of each have been thoroughly investigated to identify their strengths and weaknesses. The methods based on artificial intelligence (AI) can have good potential in solving SE problems, so they have been specifically investigated. This category of SE methods can be beneficial in solving future problems. Based on this, the existing challenges for the future of SE have been discussed. As a case study, we demonstrate how AI techniques, such as transfer learning (TL), can address one of these challenges—specifically in handling network reconfiguration in a 118-bus system. This example can guide those interested in the field to tackle similar challenges and provide direction for future research.
ER  - 

TY  - JOUR
T1  - The metaverse: Privacy and information security risks
AU  - Laiz-Ibanez, Héctor
AU  - Mendaña-Cuervo, Cristina
AU  - Carus Candas, Juan Luis
JO  - International Journal of Information Management Data Insights
VL  - 5
IS  - 2
SP  - 100373
PY  - 2025
DA  - 2025/12/01/
SN  - 2667-0968
DO  - https://doi.org/10.1016/j.jjimei.2025.100373
UR  - https://www.sciencedirect.com/science/article/pii/S2667096825000552
KW  - Metaverse
KW  - Security
KW  - Privacy
KW  - Risks
KW  - Countermeasures
KW  - Cybersecurity
KW  - Emerging technologies
AB  - The advent of the metaverse—a convergence of physical and virtual realities catalyzed by a spectrum of emerging technologies—heralds a new epoch in the digital era. As the metaverse unfolds its immense potential, it simultaneously reveals unprecedented privacy and information security risks. Understanding these risks is paramount, as the pose significant implications for user safety, data integrity, and the overall trustworthiness of the metaverse. Consequently, this paper conducts a Systematic Literature Review (SLR) to meticulously analyze these emerging risks. Utilizing the Population, Intervention, Comparison, Outcomes, Context (PICOC) method, the review examines 735 articles from four databases, distilling essential insights from 35 key studies. The review identifies major challenges, including vulnerabilities in AI and IoT integration, threats from surveillance capitalism, and insufficient user education on privacy risks. To address these issues, the study proposes strategies such as holistic security frameworks, privacy-first design principles, and multi-stakeholder collaboration. These findings provide actionable insights for navigating the intricate dynamics of the metaverse, fostering a secure and privacy-conscious digital ecosystem. The study’s contributions aim to guide academic discourse, inform industry practices, and influence future policy development. The contributions from this research are intended to stimulate further academic discourse and influence future practices and policy in the context of the metaverse.
ER  - 

TY  - JOUR
T1  - Detecting APT-Exploited Processes through Semantic Fusion and Interaction Prediction
AU  - Luo, Bin
AU  - Chen, Liangguo
AU  - Ruan, Shuhua
AU  - Luo, Yonggang
JO  - Computers, Materials and Continua
VL  - 78
IS  - 2
SP  - 1731
EP  - 1754
PY  - 2024
DA  - 2024/02/27/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2023.045739
UR  - https://www.sciencedirect.com/science/article/pii/S1546221824000900
KW  - Advanced persistent threat
KW  - provenance graph
KW  - multi-head self-attention
KW  - graph neural network
AB  - Considering the stealthiness and persistence of Advanced Persistent Threats (APTs), system audit logs are leveraged in recent studies to construct system entity interaction provenance graphs to unveil threats in a host. Rule-based provenance graph APT detection approaches require elaborate rules and cannot detect unknown attacks, and existing learning-based approaches are limited by the lack of available APT attack samples or generally only perform graph-level anomaly detection, which requires lots of manual efforts to locate attack entities. This paper proposes an APT-exploited process detection approach called ThreatSniffer, which constructs the benign provenance graph from attack-free audit logs, fits normal system entity interactions and then detects APT-exploited processes by predicting the rationality of entity interactions. Firstly, ThreatSniffer understands system entities in terms of their file paths, interaction sequences, and the number distribution of interaction types and uses the multi-head self-attention mechanism to fuse these semantics. Then, based on the insight that APT-exploited processes interact with system entities they should not invoke, ThreatSniffer performs negative sampling on the benign provenance graph to generate non-existent edges, thus characterizing irrational entity interactions without requiring APT attack samples. At last, it employs a heterogeneous graph neural network as the interaction prediction model to aggregate the contextual information of entity interactions, and locate processes exploited by attackers, thereby achieving fine-grained APT detection. Evaluation results demonstrate that anomaly-based detection enables ThreatSniffer to identify all attack activities. Compared to the node-level APT detection method APT-KGL, ThreatSniffer achieves a 6.1% precision improvement because of its comprehensive understanding of entity semantics.
ER  - 

TY  - JOUR
T1  - Industry 6.0: Vision, technical landscape, and opportunities
AU  - Verma, Ashwin
AU  - Prasad, Vivek Kumar
AU  - Kumari, Aparna
AU  - Bhattacharya, Pronaya
AU  - Srivastava, Gautam
AU  - Fang, Kai
AU  - Wang, Wei
AU  - Gadekallu, Thippa Reddy
JO  - Alexandria Engineering Journal
VL  - 130
SP  - 139
EP  - 174
PY  - 2025
DA  - 2025/10/01/
SN  - 1110-0168
DO  - https://doi.org/10.1016/j.aej.2025.08.040
UR  - https://www.sciencedirect.com/science/article/pii/S1110016825009354
KW  - Industry 6.0
KW  - Explainable AI
KW  - 6G
KW  - Dew computing
KW  - Quantum computing
KW  - Internet-of-Anything
AB  - Industry 5.0 is designed with the objective of leveraging collaboration between human intelligence and cyber-driven processes. It aims to present customized manufacturing solutions to the end users as per demand. Despite its promising benefits in the current production landscape, Industry 5.0 faces critical challenges in scalability, workforce transition to collaborate with advanced technologies, high production costs, and privacy and security challenges in the post-quantum era. Thus, necessitates a shift towards more advanced Industrial paradigm that modernize and reinvent operations to synergize with high end sustainable and scalable machineries, products and processes. Industry 6.0 is defined as ubiquitous, hyper-customer driven, virtualized, and sustainable manufacturing, where focus is towards hyper-connected factories and dynamic supply chains. Industry 6.0 is expected to connect cross-vertical applications, and in this paper, we present a tutorial-based survey on the vision, technical landscape, and advancements which would drive the Industry 6.0. New concepts are introduced over Industry 5.0 processes to support industrial applications like supply-chain based productions, human–robotic industrial pipelines, green computing, and generative artificial intelligence (GAI) induction in control processes. We highlight the key enablers to support the 6.0 vision-automated digital twins, metaverse-assisted virtual production, 6G, dew computing, GAI Cobots Networks (GOBOTs), Internet-of-Anything (IoX), quantum-assisted nano production, and other technologies. We highlight the reference architecture, Industry 6.0 vision, features, components, and the threats surrounding Industry 6.0, and solutions. We also present the sustainability aspects of Industry 6.0, and finally discuss future challenges and directions. The article is presented to assist researchers, industry practitioners, and allied stakeholders to design cost-effective, customized, and process driven Industrial operations.
ER  - 

TY  - JOUR
T1  - WMPA-ConvBERT-BM: A hybrid deep learning model optimized by whale-marine predator algorithm for IoT-enabled malicious URL detection
AU  - Zhao, Zihan
AU  - Zhu, Yulin
AU  - Zhang, Shilong
AU  - Tolba, Amr
AU  - Alfarraj, Osama
AU  - Yu, Keping
JO  - Internet of Things
VL  - 33
SP  - 101683
PY  - 2025
DA  - 2025/09/01/
SN  - 2542-6605
DO  - https://doi.org/10.1016/j.iot.2025.101683
UR  - https://www.sciencedirect.com/science/article/pii/S2542660525001970
KW  - Deep learning in cybersecurity
KW  - Malicious URLs detection
KW  - Hybrid deep learning
KW  - Cybersecurity in Internet of Things (IoT)
KW  - Intelligent Optimization Algorithms (IOAs)
AB  - The increasing prevalence of malicious Uniform Resource Locators (URLs) in Internet of Things (IoT) environments poses a significant threat to network security. To address this challenge, we propose WMPA-ConvBERT-BM, a novel hybrid deep learning architecture that integrates ConvBERT and a multi-head attention-enhanced bidirectional Gated Recurrent Unit to effectively capture both semantic and structural features from URLs. The model utilizes a dual embedding strategy combining word-level and character-level representations for enriched multi-granular input. Furthermore, we introduce a Whale-Marine Predator Algorithm (WMPA), a hybrid intelligent optimization algorithm designed to adaptively search for optimal learning rates during training, enhancing convergence and generalization. Comprehensive experiments conducted on a large-scale multi-class malicious URL dataset demonstrate that our model achieves state-of-the-art performance, attaining an accuracy of 97.6%, precision of 96.769%, recall of 97.344% and F1-score of 97.032%, outperforming existing baselines and optimization methods. Ablation studies validate the critical contributions of each component, and further comparisons show the superiority of WMPA over conventional intelligent optimization algorithms. Additionally, SHAP-based interpretability analysis reveals how integrated embeddings contribute to prediction decisions, offering transparency and insights into model behavior. Results show that our WMPA-ConvBERT-BM provides an effective and interpretable solution for robust malicious URL detection in IoT scenarios.
ER  - 

TY  - JOUR
T1  - DBWE-Corbat: Background network traffic generation using dynamic word embedding and contrastive learning for cyber range
AU  - Du, Linfeng
AU  - He, Junjiang
AU  - Li, Tao
AU  - Wang, Yunpeng
AU  - Lan, Xiaolong
AU  - Huang, Yunhua
JO  - Computers & Security
VL  - 129
SP  - 103202
PY  - 2023
DA  - 2023/06/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2023.103202
UR  - https://www.sciencedirect.com/science/article/pii/S0167404823001128
KW  - Background network traffic
KW  - Dynamic word embedding
KW  - Network traffic generation
KW  - Cyber range
KW  - Contrastive learning
AB  - Background network traffic generation is critical to replicating the real network environment in Cyber Range. But how to sufficiently extract the spatio-temporal features of traffic and generate superior background network traffic are still problems for the Cyber Range. In this paper, we propose a background network traffic generative model, DBWE-Corbat. Our solution relies on intelligent feature extraction based on the DB-WE dynamic word embedding method. Which consists of Doc2Vec and two Bidirectional Long Short-Term Memory (Bi-LSTM) layers. Specifically, first we convert the traffic feature tuple data into a static word vector. Then, we capture the spatio-temporal features of the traffic for characterization. Finally, we generate high-quality and numerous background network traffic by learning the feature distribution of small samples based on the contrastive learning model SimCSE. Extensive experiments show that our approach can generate high-quality traffic data. It meets the requirements of cyber range construction compared to other traffic generation methods.
ER  - 

TY  - JOUR
T1  - CVE Severity Prediction From Vulnerability Description - A Deep Learning Approach
AU  - A, Manjunatha
AU  - Kota, Kethan
AU  - Babu, Anoop S.
AU  - S, Sree Vivek
JO  - Procedia Computer Science
VL  - 235
SP  - 3105
EP  - 3117
PY  - 2024
DA  - 2024/01/01/
T2  - International Conference on Machine Learning and Data Engineering (ICMLDE 2023)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.04.294
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924009748
KW  - Common Vulnerabilities
KW  - Exposures (CVE)
KW  - National Vulnerability Database (NVD)
KW  - Common Vulnerability Scoring System (CVSS)
KW  - GPT-2 large language model
KW  - Natural Language Processing (NLP)
KW  - Vulnerability Severity Prediction
AB  - The Common Vulnerabilities and Exposures (CVE) system is a widely used standard for identifying and tracking known vulnerabilities in software systems. The severity of these vulnerabilities must be determined in order to prioritize mitigation efforts. However, assigning severity to a vulnerability is a challenging task that requires careful analysis of its characteristics and potential impact. Considering the vast number of vulnerabilities identified every year, it is vital to automate the severity assignment, thereby reducing manual effort. This paper proposes a novel approach for predicting the severity of vulnerabilities based on their CVE description using GPT-2, a state-of-the-art language model. The CVSS severity values distribution imbalance is addressed using oversampling and contextual data augmentation techniques. This approach leverages the large-scale language modeling capabilities of GPT-2 to automatically extract relevant features from CVE descriptions and predict the severity level of the vulnerability. The model is evaluated on a test data set of 7,765 CVEs and achieves a high accuracy of 84.2% and an F1 score of 0.82 in predicting the severity of the vulnerabilities on the test data. A comparative analysis of this approach was done against state-of-the-art methods, demonstrating the superior performance of the proposed approach. Based on the results, the proposed approach could be considered a valuable tool for quickly and accurately identifying high-severity vulnerabilities, facilitating more efficient and effective vulnerability management practices. Furthermore, this approach could be extended to other natural language processing tasks related to vulnerability analysis and management.
ER  - 

TY  - JOUR
T1  - A novel self-adaptive interval Type-3 Fuzzy Logic System for X spam detection
AU  - Al Zeyadi, Haidar
AU  - Yatak, Meral Özarslan
AU  - Teke, Mustafa
AU  - Mohammadzadeh, Ardashir
AU  - Duran, Fecir
JO  - Egyptian Informatics Journal
VL  - 32
SP  - 100819
PY  - 2025
DA  - 2025/12/01/
SN  - 1110-8665
DO  - https://doi.org/10.1016/j.eij.2025.100819
UR  - https://www.sciencedirect.com/science/article/pii/S1110866525002129
KW  - Type-3 fuzzy system
KW  - Enhanced Kalman Filter
KW  - Square Root Cubature Kalman Filter
KW  - Particle Swarm Optimization
KW  - Online social networks
KW  - X spam detection
AB  - Online Social Network spam detection has gained importance as malicious content abuses platform purity and user experience. Especially for the X platform, spam detection requires more effort due to its character limitations, multilingual content, and diverse symbol usage. The inherent uncertainty in spam characteristics and the dynamic properties of X content require advanced computational approaches with proper modeling of uncertainties while keeping up high accuracy under complex cybersecurity threats. This study presents a Self-Adaptive Interval Type-3 Fuzzy Logic System (SA-IT3FLS) with new hybrid learning approaches, integrating Square Root Cubature Kalman Filter (SCKF) and Extended Kalman Filter (EKF), to enhance spam detection accuracy for X platform against high levels of uncertainties. The proposed approach specifically targets the modeling of uncertainty challenges that appear because of the boundary between spam and non-spam. A type-3 fuzzy system is suitable for managing uncertainty at the membership function level, rule evaluation level, and within the data itself. The new adaptive approach is implemented to tune the rule weights and the membership functions (MFs) centers in this study. Along with the optimized covariance matrices, the initial values of MF centers and rule weights are optimized with Particle Swarm Optimization. The optimized parameters are learned by SCKF and EKF. The proposed method’s effectiveness is revealed through four scenarios with real-world data sets. The experimental results of the proposed method showed robust performance, achieving an accuracy of (96.74%),a recall of 0.98, an F-score of 0.96, and an AUC value of 0.98, showing a conspicuous increase in the performance. Additionally, the proposed method outperformed a recent study that employed the same dataset with type-1 and type-2 fuzzy systems, demonstrating improvements in all the parameters and the same for the F-score. This proves the effectiveness and competitiveness of the proposed approach under complex and uncertain conditions in the X platform.
ER  - 

TY  - JOUR
T1  - Zero-shot learning for requirements classification: An exploratory study
AU  - Alhoshan, Waad
AU  - Ferrari, Alessio
AU  - Zhao, Liping
JO  - Information and Software Technology
VL  - 159
SP  - 107202
PY  - 2023
DA  - 2023/07/01/
SN  - 0950-5849
DO  - https://doi.org/10.1016/j.infsof.2023.107202
UR  - https://www.sciencedirect.com/science/article/pii/S0950584923000563
KW  - Zero-shot learning
KW  - Language models
KW  - Contextual word-embeddings
KW  - Requirements classification
KW  - Zero-shot text classification
KW  - Unsupervised learning
KW  - Multi-label classification
KW  - Transfer learning
KW  - Deep learning
KW  - Requirements engineering
KW  - AI for requirements engineering
KW  - AI for software engineering
AB  - Context:
Requirements engineering (RE) researchers have been experimenting with machine learning (ML) and deep learning (DL) approaches for a range of RE tasks, such as requirements classification, requirements tracing, ambiguity detection, and modelling. However, most of today’s ML/DL approaches are based on supervised learning techniques, meaning that they need to be trained using a large amount of task-specific labelled training data. This constraint poses an enormous challenge to RE researchers, as the lack of labelled data makes it difficult for them to fully exploit the benefit of advanced ML/DL technologies.
Objective:
This paper addresses this problem by showing how a zero-shot learning (ZSL) approach can be used for requirements classification without using any labelled training data. We focus on the classification task because many RE tasks can be framed as classification problems.
Methods:
The ZSL approach used in our study employs contextual word-embeddings and transformer-based language models (LMs). We demonstrate this approach through a series of experiments to perform three classification tasks: (1) FR/NFR — classification functional requirements vs non-functional requirements; (2) NFR — identification of NFR classes; (3) Security — classification of security vs non-security requirements.
Results:
The study shows that the ZSL approach achieves an F1 score of 0.66 for the FR/NFR task. For the NFR task, the approach yields F1∼0.72−0.80, considering the most frequent classes. For the Security task, F1 ∼0.66. All of the aforementioned F1 scores are achieved with zero-training efforts.
Conclusion:
This study demonstrates the potential of ZSL for requirements classification. An important implication is that it is possible to have very little or no training data to perform classification tasks. The proposed approach thus contributes to the solution of the long-standing problem of data shortage in RE.
ER  - 

TY  - JOUR
T1  - VehicleLang: A probabilistic modeling and simulation language for modern vehicle IT infrastructures
AU  - Katsikeas, Sotirios
AU  - Johnsson, Pontus
AU  - Hacks, Simon
AU  - Lagerström, Robert
JO  - Computers & Security
VL  - 117
SP  - 102705
PY  - 2022
DA  - 2022/06/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2022.102705
UR  - https://www.sciencedirect.com/science/article/pii/S0167404822001031
KW  - Domain-specific language
KW  - Cyber security
KW  - Threat modeling
KW  - Attack graphs
KW  - Vehicular security
AB  - Attack simulations are a feasible means of assessing the cyber security of various systems. Simulations can replicate the steps taken by an attacker to compromise sensitive system assets, and the time required for the acquisition of assets of interests can be calculated. One widely accepted approach to such simulations is the modelling of attack steps and their dependencies in a formal manner using attack graphs. To reduce the effort of creating new attack graphs for each system in a given domain, one can employ domain-specific attack-modeling languages to codify common attack logic. The Meta Attack Language has been proposed as a framework for developing domain-specific attack languages. In this article, we propose vehicleLang as a domain-specific language for modeling vehicles in the context of corresponding information technology infrastructures and analyzing weaknesses related to known attacks. To model domain-specific attributes, we reviewed existing literature to develop a comprehensive language, which was then verified through a series of interviews with domain experts from the automotive industry. Specifically, a systematic literature review was performed to identify possible attacks against vehicles. The identified attacks served as a blueprint for the evaluation of vehicleLang’s simulation capabilities. Finally, the language was validated using the Feigenbaum test methodology.
ER  - 

TY  - JOUR
T1  - Anomaly detection in electronic invoice systems based on machine learning
AU  - Tang, Peng
AU  - Qiu, Weidong
AU  - Huang, Zheng
AU  - Chen, Shuang
AU  - Yan, Min
AU  - Lian, Huijuan
AU  - Li, Zhe
JO  - Information Sciences
VL  - 535
SP  - 172
EP  - 186
PY  - 2020
DA  - 2020/10/01/
SN  - 0020-0255
DO  - https://doi.org/10.1016/j.ins.2020.03.089
UR  - https://www.sciencedirect.com/science/article/pii/S0020025520302693
KW  - Electronic invoice
KW  - Abnormal behaviors
KW  - Machine learning
KW  - Fusion analysis
AB  - Electronic invoice(E-invoice) has become the product of the information age, its issue will greatly save the cost of enterprises and achieve the goal of financial process automation. Hence, the generalization of electronic invoice is imperative. However, there exists the risk of malicious attacks in electronic invoice systems, such as sudden invoice of large invoice, invoice at abnormal time, etc. These malicious attacks are difficult to detect through the system itself or manually. To provide a secure service platform for the generalization of electronic invoice, this paper studies the attack detection technology of electronic invoice systems which is mainly based on machine learning to complete two aspects of research. The first is to propose a machine learning-based e-invoice anomaly detection method, which can accurately determine the anomalies occurring in the e-invoice systems. The second is to conduct deep fusion analysis on abnormal behaviors, mining potential threats in the electronic invoice systems, and designing and implementing the electronic invoice depth fusion analysis method based on k-means and Skip-gram. The experimental results indicate that the method we proposed can not only detect the malicious attacks effectively, and also capable of mining the potential threats in the electronic invoice systems.
ER  - 

TY  - JOUR
T1  - A community-centric intelligent cyberinfrastructure for addressing nitrogen pollution using web systems and conversational AI
AU  - Shrestha, Samrat
AU  - Mount, Jerry
AU  - Vald, Gabriel
AU  - Sermet, Yusuf
AU  - Samuel, Dinesh Jackson
AU  - Bryant, Chelsea
AU  - Peralta, Ana C.
AU  - Beck, Marcus W.
AU  - Meyers, Steven D.
AU  - Muller-Karger, Frank E.
AU  - Cwiertny, David
AU  - Demir, Ibrahim
JO  - Environmental Science & Policy
VL  - 167
SP  - 104055
PY  - 2025
DA  - 2025/05/01/
SN  - 1462-9011
DO  - https://doi.org/10.1016/j.envsci.2025.104055
UR  - https://www.sciencedirect.com/science/article/pii/S1462901125000711
KW  - Web systems
KW  - Information systems
KW  - AI agents
KW  - Nitrogen pollution management
KW  - Water quality
KW  - Large language model
KW  - Conversational AI
AB  - The Blue-Green Action Platform (BlueGAP) information system (IS) is an intelligent cyberinfrastructure framework designed to support large-scale water quality assessments in the context of demographic statistics and community stories about water issues. The system prioritizes collaboration with interested parties in three pilot watersheds with test cases implemented in US locations including Iowa, Tampa, and the U.S. Virgin Islands. The BlueGAP IS leverages Artificial Intelligence (AI) technologies with large language models based on regional nutrient management issues and community knowledge to provide access to water quality information. The current focus of the system is on nitrate in drinking water, rivers, and waterways, and can be expanded to incorporate other water quality information. BlueGAP identifies possible partnerships and promotes collaborations among diverse stakeholders to facilitate effective evaluation of nitrogen-related analytes, guide action to address possible pollution, and outline sustainable water management practices. The BlueGAP IS also emphasizes its educational mission by connecting water quality data with inclusive and accessible educational content through AI technology. By integrating nitrogen data and water quality issues into educational resources, BlueGAP fosters a deeper understanding of water quality issues across diverse communities, empowering users to make informed decisions and contribute to sustainable water management practices.
ER  - 

TY  - JOUR
T1  - Improving deep learning with prior knowledge and cognitive models: A survey on enhancing explainability, adversarial robustness and zero-shot learning
AU  - Mumuni, Fuseini
AU  - Mumuni, Alhassan
JO  - Cognitive Systems Research
VL  - 84
SP  - 101188
PY  - 2024
DA  - 2024/03/01/
SN  - 1389-0417
DO  - https://doi.org/10.1016/j.cogsys.2023.101188
UR  - https://www.sciencedirect.com/science/article/pii/S1389041723001225
KW  - Domain knowledge
KW  - Cognitive architecture
KW  - Brain-inspired neural network
KW  - Explainable AI
KW  - Adversarial attack
KW  - Zero-shot generalization
AB  - We review current and emerging knowledge-informed and brain-inspired cognitive systems for realizing adversarial defenses, eXplainable Artificial Intelligence (XAI), and zero-shot or few-shot learning. Data-driven machine learning models have achieved remarkable performance and demonstrated capabilities surpassing humans in many applications. Yet, their inability to exploit domain knowledge leads to serious performance limitations in practical applications. In particular, deep learning systems are exposed to adversarial attacks, which can trick them into making glaringly incorrect decisions. Moreover, complex data-driven models typically lack interpretability or explainability, i.e., their decisions cannot be understood by human subjects. Furthermore, models are usually trained on standard datasets with a closed-world assumption. Hence, they struggle to generalize to unseen cases during inference in practical open-world environments, thus, raising the zero- or few-shot generalization problem. Although many conventional solutions exist, explicit domain knowledge, brain-inspired neural networks and cognitive architectures offer powerful new dimensions towards alleviating these problems. Prior knowledge is represented in appropriate forms like mathematical relations, logic rules, knowledge graphs, and large language models (LLMs). and incorporated in deep learning frameworks to improve performance. Brain-inspired cognition methods use computational models that mimic the human brain to enhance intelligent behavior in artificial agents and autonomous robots. Ultimately, these models achieve better explainability, higher adversarial robustness and data-efficient learning, and can, in turn, provide insights for cognitive science and neuroscience—that is, to deepen human understanding on how the brain works in general, and how it handles these problems.
ER  - 

TY  - JOUR
T1  - Images of AI: How AI practitioners view the impact of Artificial Intelligence on society, now and in the future
AU  - Spiegler, Simone
AU  - Hoda, Rashina
AU  - Pant, Aastha
JO  - Technology in Society
VL  - 84
SP  - 103109
PY  - 2026
DA  - 2026/03/01/
SN  - 0160-791X
DO  - https://doi.org/10.1016/j.techsoc.2025.103109
UR  - https://www.sciencedirect.com/science/article/pii/S0160791X25002994
KW  - Artificial intelligence
KW  - AI
KW  - Societal impact
KW  - Human control
KW  - Future
KW  - Responsible AI
KW  - Large language models
KW  - LLMs
KW  - AI practitioners
KW  - Images
KW  - AI psychosis
KW  - Generative AI
KW  - Agentic AI
AB  - Despite unprecedented technological advancement, intense commercial investment, international agreements, and growing societal concerns with Artificial Intelligence (AI), there is little insight into how those driving the field – the everyday AI practitioners – perceive AI and its impact on society, now and in the future. We address this critical gap by conducting a broad-based survey with 100 AI practitioners, followed by in-depth interviews with 20 AI practitioners, including developers, managers, and consultants. Using socio-technical grounded theory (STGT) for data analysis, we inductively identified six images of AI which capture six ways in which AI practitioners view AI, now and in the future, and their implications for impact on society and human control: Parrot captures AI that mimics human behaviour, including biases; Companion surrounds humans in daily life and supports decision making with empathy-like traits; Wolf in Sheep’s Clothing highlights AI misused by humans, causing societal harms; Saviour envisions AI solving complex problems beyond human capacity; Wizard portrays AI as powerful, yet, unpredictable and inexplicable; and Pinocchio imagines AI as gaining free will, learning from mistakes, and possibly harming humans. These images of AI provide a novel framework for understanding how AI practitioners perceive and shape AI solutions. Our findings and recommendations will assist AI practitioners, companies, and users with a shared vocabulary and understanding to explicitly and critically examine the intended and unintended impacts of AI solutions on human society, contributing to more responsible and human controlled AI design and use.
ER  - 

TY  - JOUR
T1  - Detecting and visualizing hate speech in social media: A cyber Watchdog for surveillance
AU  - Modha, Sandip
AU  - Majumder, Prasenjit
AU  - Mandl, Thomas
AU  - Mandalia, Chintak
JO  - Expert Systems with Applications
VL  - 161
SP  - 113725
PY  - 2020
DA  - 2020/12/15/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2020.113725
UR  - https://www.sciencedirect.com/science/article/pii/S0957417420305492
KW  - Natural language processing
KW  - Deep learning
KW  - Hate speech
KW  - Aggression detection
KW  - Text classification
KW  - Social media visualization
AB  - The multi-fold growth of the social media user-base fuelled a substantial increase in the amount of hate speech posts on social media platforms. The enormous data volume makes it hard to capture such cases and either moderate or delete them. This paper presents an approach to detect and visualize online aggression, a special case of hate speech, over social media. Aggression is categorized into overtly aggressive (OAG), covertly aggressive (CAG), and non-aggressive labels (NAG). We have designed a user interface based on a web browser plugin over Facebook and Twitter to visualize the aggressive comments posted on the Social media user’s timelines. This plugin interface might help to the security agency to keep a tab on the social media stream. It also provides citizens with a tool that is typically only available for large enterprises. The availability of such a tool alleviates the technological imbalance between industry and citizens. Besides, the system might be helpful to the research community to create further tools and prepare weakly labeled training data in a few minutes using comments posted by users on celebrity’s Facebook, Twitter timeline. We have reported the results on a newly created dataset of user comments posted on Facebook and Twitter using our proposed plugins and the standard Trolling Aggression Cyberbullying 2018 (TRAC) dataset in English and code-mixed Hindi. Various classifiers like Support Vector Machine (SVM), Logistic regression, deep learning model based on Convolution Neural Network (CNN), Attention-based model, and the recently proposed BERT pre-trained language model by Google AI, have been used for aggression classification. The weighted F1-score of around 0.64 and 0.62 is achieved on TRAC Facebook English and Hindi datasets while on Twitter English and Hindi datasets, the weighted F1-score is 0.58 and 0.50, respectively.
ER  - 

TY  - JOUR
T1  - Optimising blockchain security: Computational analysis of adaptive AI coaching
AU  - Lakhdim, Rahma
AU  - Treur, Jan
AU  - Roelofsma, Peter H.M.P.
JO  - Cognitive Systems Research
VL  - 95
SP  - 101430
PY  - 2026
DA  - 2026/01/01/
SN  - 1389-0417
DO  - https://doi.org/10.1016/j.cogsys.2025.101430
UR  - https://www.sciencedirect.com/science/article/pii/S1389041725001093
KW  - Adaptive network model
KW  - AI coaching
KW  - Blockchain security
KW  - Cyber security
KW  - Risk assessment
AB  - Blockchain networks face evolving security risks that require rapid and consistent responses from employees. This study presents an AI Coach that mirrors human reasoning through stages of context detection, world modeling, belief updating, preparation, execution, and feedback. In doing so, the AI Coach provides cognitive support. The architecture is defined by six types of matrices that include state connectivity, connectivity weights, combination functions, combination function parameters, speed factors, and initial values. In simulations of anomalous transactions, smart contract breaches, consensus delays, and unauthorized access, the AI Coach effectively prioritized critical events and guided response actions, demonstrating its ability to support more structured and efficient security workflows. These results underscore the effectiveness of the AI Coach in improving reliability and responsiveness in blockchain security monitoring.
ER  - 

TY  - JOUR
T1  - Adaptive edge security framework for dynamic IoT security policies in diverse environments
AU  - Halgamuge, Malka N.
AU  - Niyato, Dusit
JO  - Computers & Security
VL  - 148
SP  - 104128
PY  - 2025
DA  - 2025/01/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104128
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824004334
KW  - Cybersecurity
KW  - Edge security
KW  - IoT security
KW  - Regulatory and compliance
KW  - Policy
AB  - The rapid expansion of Internet of Things (IoT) technologies has introduced significant cybersecurity challenges, particularly at the network edge where IoT devices operate. Traditional security policies designed for static environments fall short of addressing the dynamic, heterogeneous, and resource-constrained nature of IoT ecosystems. Existing dynamic security policy models lack versatility and fail to fully integrate comprehensive risk assessments, regulatory compliance, and AI/ML (artificial intelligence/machine learning)-driven adaptability. We develop a novel adaptive edge security framework that dynamically generates and adjusts security policies for IoT edge devices. Our framework integrates a dynamic security policy generator, a conflict detection and resolution in policy generator, a bias-aware risk assessment system, a regulatory compliance analysis system, and an AI-driven adaptability integration system. This approach produces tailored security policies that adapt to changes in the threat landscape, regulatory requirements, and device statuses. Our study identifies critical security challenges in diverse IoT environments and demonstrates the effectiveness of our framework through simulations and real-world scenarios. We found that our framework significantly enhances the adaptability and resilience of IoT security policies. Our results demonstrate the potential of AI/ML integration in creating responsive and robust security measures for IoT ecosystems. The implications of our findings suggest that dynamic and adaptive security frameworks are essential for protecting IoT devices against evolving cyber threats, ensuring compliance with regulatory standards, and maintaining the integrity and availability of IoT services across various applications.
ER  - 

TY  - JOUR
T1  - Detection of violence incitation expressions in Urdu tweets using convolutional neural network
AU  - Khan, Muhammad Shahid
AU  - Malik, Muhammad Shahid Iqbal
AU  - Nadeem, Aamer
JO  - Expert Systems with Applications
VL  - 245
SP  - 123174
PY  - 2024
DA  - 2024/07/01/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2024.123174
UR  - https://www.sciencedirect.com/science/article/pii/S0957417424000393
KW  - Violence incitation
KW  - Urdu language
KW  - Twitter
KW  - Uni-gram
KW  - Convolutional neural network
AB  - The popularity and widespread use of social media are constantly generating unmonitored data, spreading unwanted content such as hate speech and expressions that incite violence. Automatic detection of violence incitation is a challenging task and to the best of our knowledge, Urdu language has been completely neglected. Therefore, a robust framework is proposed for identifying expressions exhibiting violence incitation in Urdu tweets. The potentials of the semantic, word embeddings, and language models are explored to learn contextualized representations of the violence incitation in Urdu tweets. In addition, the strength of the 1-Dimensional Convolutional Neural Network (1D-CNN) is exploited by tunning its parameters on the newly proposed annotated Urdu corpus. The annotated dataset consists of 4808 tweets manually collected from Pakistani Twitter accounts. The performance of 1D-CNN with word uni-gram, Urdu Bidirectional Encoder Representations from Transformer (Urdu-BERT), and Urdu- Robustly Optimized BERT Approach (Urdu-RoBERTa) models is compared to fine-tuned Urdu-RoBERTa, Bidirectional Long short-term memory (BiLSTM), Convolutional BiLSTM (CBi-LSTM), and six state-of-the-art Machine Learning (ML) models. The results reveal that the 1D-CNN with word uni-gram model shows benchmark performance by demonstrating 89.84% accuracy and 89.80% macro f1-score. Furthermore, it outperforms all comparable models and achieves 89.76% f1-score for the violence class, and 89.84% f1-score for not-violence class identification. The uniqueness of the proposed model is evaluated using MARS shine-through and MARS occlusion metrics and the CNN model outperformed the others. The MARS metrics facilitate evaluation and visualization of the classifier performance in terms of capturing unique true positive samples that are not predicted by other models. The findings of the proposed framework are very supportive for further investigation in this domain.
ER  - 

TY  - JOUR
T1  - Augmenting IoT Intrusion Detection System Performance Using Deep Neural Network
AU  - Sayed, Nasir
AU  - Shoaib, Muhammad
AU  - Ahmed, Waqas
AU  - Qasem, Sultan Noman
AU  - Albarrak, Abdullah M.
AU  - Saeed, Faisal
JO  - Computers, Materials and Continua
VL  - 74
IS  - 1
SP  - 1351
EP  - 1374
PY  - 2022
DA  - 2022/08/16/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2023.030831
UR  - https://www.sciencedirect.com/science/article/pii/S1546221822001655
KW  - Internet of things
KW  - intrusion detection system
KW  - deep learning
KW  - convolutional neural network
KW  - supervised learning
AB  - Due to their low power consumption and limited computing power, Internet of Things (IoT) devices are difficult to secure. Moreover, the rapid growth of IoT devices in homes increases the risk of cyber-attacks. Intrusion detection systems (IDS) are commonly employed to prevent cyberattacks. These systems detect incoming attacks and instantly notify users to allow for the implementation of appropriate countermeasures. Attempts have been made in the past to detect new attacks using machine learning and deep learning techniques, however, these efforts have been unsuccessful. In this paper, we propose two deep learning models to automatically detect various types of intrusion attacks in IoT networks. Specifically, we experimentally evaluate the use of two Convolutional Neural Networks (CNN) to detect nine distinct types of attacks listed in the NF-UNSW-NB15-v2 dataset. To accomplish this goal, the network stream data were initially converted to two-dimensional images, which were then used to train the neural network models. We also propose two baseline models to demonstrate the performance of the proposed models. Generally, both models achieve high accuracy in detecting the majority of these nine attacks.
ER  - 

TY  - JOUR
T1  - Botnet DGA Domain Name Classification Using Transformer Network with Hybrid Embedding
AU  - Ding, Ling
AU  - Du, Peng
AU  - Hou, Haiwei
AU  - Zhang, Jian
AU  - Jin, Di
AU  - Ding, Shifei
JO  - Big Data Research
VL  - 33
SP  - 100395
PY  - 2023
DA  - 2023/08/28/
SN  - 2214-5796
DO  - https://doi.org/10.1016/j.bdr.2023.100395
UR  - https://www.sciencedirect.com/science/article/pii/S221457962300028X
KW  - Botnet detection
KW  - Domain generation algorithm (DGA)
KW  - Hybrid word embedding
KW  - Deep learning architecture
AB  - One of the severest threats to cyber security is botnet, which typically uses domain names generated by Domain Generation Algorithms (DGAs) to communicate with their Command and Control (C&C) infrastructure. DGA detection and classification play an important role of assisting cyber security researchers to detect botnet C&C servers. However, many of the existing DGA detection models only focus on single scale word embedding method, and very few models are specially designed to extract more effective features for DGA detection from multiple scales word embedding. To alleviate above questions, first we propose a hybrid word embedding method, which combines character level embedding and bigram level embedding to make full use of the domain names information, and then, we design a deep neural network with hybrid embedding method to distinguish DGA domains from known legitimate domains. Finally, we evaluate our hybrid embedding method and the proposed model on ONIST dataset and compare our methods with several state-of-the-art DGA classification methods.
ER  - 

TY  - JOUR
T1  - Automatic code generation based on Abstract Syntax-based encoding. Application on malware detection code generation based on MITRE ATT&CK techniques
AU  - Sîrbu, Alexandru-Gabriel
AU  - Czibula, Gabriela
JO  - Expert Systems with Applications
VL  - 264
SP  - 125821
PY  - 2025
DA  - 2025/03/10/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2024.125821
UR  - https://www.sciencedirect.com/science/article/pii/S0957417424026885
KW  - Deep learning
KW  - Recurrent neural network
KW  - Abstract syntax tree
KW  - Abstract syntax graph
KW  - Malware detection
AB  - In the last decade, the area of code generation based on natural language was one of the most studied machine learning topics. The paper addresses the problem of code generation from natural language, by generating a syntax-error-free generator model, which creates an Syntax-based model, later translated into code, for generating the structure of the code. Two approaches are comparatively investigated for generating the structure of the program. The first approach generates code templates in the form of an Abstract Syntax Tree, while the second generates the code in the form of an Abstract Syntax Graph, a new introduced concept which reduces the initial redundancy of Abstract Syntax Trees and uses it as a new way to generate code. The proposed methodology is tested on two literature data sets and on malware detection code generation based on a real data set containing MITRE ATT&CK techniques. The results outperform the state-of-the-art Abstract Syntax Tree approaches by 2.46% and the plain text-based approaches with more than 12.5%, highlighting that the proposed methodology learns better the structural representation than other literature approaches.
ER  - 

TY  - JOUR
T1  - Deep learning and pre-training technology for encrypted traffic classification: A comprehensive review
AU  - Dong, Wenqi
AU  - Yu, Jing
AU  - Lin, Xinjie
AU  - Gou, Gaopeng
AU  - Xiong, Gang
JO  - Neurocomputing
VL  - 617
SP  - 128444
PY  - 2025
DA  - 2025/02/07/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2024.128444
UR  - https://www.sciencedirect.com/science/article/pii/S0925231224012153
KW  - Encrypted traffic classification
KW  - Deep learning
KW  - Graph representing learning
KW  - Pre-training
KW  - Fine-tuning
KW  - Large language model
AB  - Network traffic classification has long been a pivotal topic in network security. In the past two decades, methods like port-based classification, deep packet inspection, and machine learning approaches have significantly progressed. Still, they are now facing reduced effectiveness due to the evolving complexity of the Internet, new encryption protocols, and advanced defense strategies. Given the problem that traditional models cannot efficiently generalize encrypted traffic, two promising technology paths are currently: deep learning and pre-training. On the one hand, deep learning-based methods effectively dissect complex network structures and unearth pivotal relational patterns. These approaches excel due to the neural networks’ robust generalization capabilities, significantly boosting the accuracy and efficiency of recognition processes. Graph representation learning stands out as the most compelling contemporary model for such intricate analysis, adeptly revealing the critical relationships within network communication structures. We emphatically introduce mainstream deep learning-based methods, and the mechanism and scenarios are also analyzed. On the other hand, recognizing that although the analysis based on large models is the trend of the field, the application is truly limited now, we underscore the importance of pre-training, which aligns with the future trajectory towards the adoption of large-scale models in encrypted traffic analysis. The pre-trained model can overcome various defects of previous models and achieve more remarkable performance through its low labeled data dependency and strong scenario adaptability. We provide a comprehensive overview of existing pre-training-based approaches from the three stages of operation: pre-processing, pre-training, fine-tuning, and comparing representative relevant work. Finally, because of the current needs and the improvement space of the existing pre-training methods in the field, we synthetically analyze the challenges and opportunities for interested researchers to explore.
ER  - 

TY  - JOUR
T1  - Generative AI in Medical Practice: In-Depth Exploration of Privacy and Security Challenges
AU  - Chen, Yan
AU  - Esmaeilzadeh, Pouyan
JO  - Journal of Medical Internet Research
VL  - 26
PY  - 2024
DA  - 2024/01/01/
SN  - 1438-8871
DO  - https://doi.org/10.2196/53008
UR  - https://www.sciencedirect.com/science/article/pii/S1438887124001055
KW  - artificial intelligence
KW  - AI
KW  - generative artificial intelligence
KW  - generative AI
KW  - medical practices
KW  - potential benefits
KW  - security and privacy threats
AB  - As advances in artificial intelligence (AI) continue to transform and revolutionize the field of medicine, understanding the potential uses of generative AI in health care becomes increasingly important. Generative AI, including models such as generative adversarial networks and large language models, shows promise in transforming medical diagnostics, research, treatment planning, and patient care. However, these data-intensive systems pose new threats to protected health information. This Viewpoint paper aims to explore various categories of generative AI in health care, including medical diagnostics, drug discovery, virtual health assistants, medical research, and clinical decision support, while identifying security and privacy threats within each phase of the life cycle of such systems (ie, data collection, model development, and implementation phases). The objectives of this study were to analyze the current state of generative AI in health care, identify opportunities and privacy and security challenges posed by integrating these technologies into existing health care infrastructure, and propose strategies for mitigating security and privacy risks. This study highlights the importance of addressing the security and privacy threats associated with generative AI in health care to ensure the safe and effective use of these systems. The findings of this study can inform the development of future generative AI systems in health care and help health care organizations better understand the potential benefits and risks associated with these systems. By examining the use cases and benefits of generative AI across diverse domains within health care, this paper contributes to theoretical discussions surrounding AI ethics, security vulnerabilities, and data privacy regulations. In addition, this study provides practical insights for stakeholders looking to adopt generative AI solutions within their organizations.
ER  - 

TY  - JOUR
T1  - CADefender: Detection of unknown malicious AutoLISP computer-aided design files using designated feature extraction and machine learning methods
AU  - Yevsikov, Alexander
AU  - Muralidharan, Trivikram
AU  - Panker, Tomer
AU  - Nissim, Nir
JO  - Engineering Applications of Artificial Intelligence
VL  - 138
SP  - 109414
PY  - 2024
DA  - 2024/12/01/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2024.109414
UR  - https://www.sciencedirect.com/science/article/pii/S0952197624015720
KW  - Computer-aided design
KW  - Auto list processing
KW  - Machine learning
KW  - Malware detection
KW  - Feature extraction
AB  - Computer-aided design (CAD) files are used to create digital designs for various structures – from the smallest chips in the high-tech industry to large-scale buildings and bridges in the civil engineering space. We found that most exploits and malicious payloads are deployed through Auto List Processing (AutoLISP) source code (LSP) or Fast Load AutoLISP (FAS) files, which are non-executable files (NEFs) containing scripts in the AutoLISP language that are native to AutoCAD; While antivirus software is capable of detecting many malicious CAD files, the potential to improve protection by using a dedicated machine learning (ML) based detection solution remains, especially against unknown and sophisticated CAD malware. In this study, we are the first to propose designated feature extraction methods and a robust framework aimed at the detection of known and unknown AutoLISP malware using ML algorithms. To accomplish this, we examined the structure, functionality, and ecosystems of AutoLISP files and collected the largest known representative collection of LSP files consisting of 6418 malicious and benign files (labeled and verified). We then explored the use of two novel static-analysis-based feature extraction methods (knowledge-based and structural) designated for LSP files to extract a discriminative set of informative features, which can subsequently be used by ML models to detect malicious LSP files. These two feature extraction methods serve as the basis of the proposed detection framework, whose performance we comprehensively compare to both widely used antiviruses and baseline ML models based on existing feature extraction methods, including MinHash, Bidirectional Encoder Representations from Transformers (BERT), and n-gram. Our results highlight our methods' contributions to the detection of unknown AutoLISP malware and demonstrate their ability to outperform existing methods. The best performance in the task of unknown malicious LSP file detection was obtained by the Artificial Neural Networks (ANN) model trained on 100 knowledge-based features, which obtained a true positive rate (TPR) of 99.49% with a false positive rate (FPR) of 0.57%. Our framework's role in explainability is also highlighted, as we also present the prominent features that contribute most to the model's detection capabilities; this information can be used for explainability purposes. We conclude by evaluating the proposed framework's ability to detect a malicious file from an unknown AutoLISP malware family and by evaluating our framework on an additional independent test set that originated from another source, scenarios that are often faced by malware detection solutions.
ER  - 

TY  - JOUR
T1  - Artificial intelligence and digital Nationalism: A social media discourse analysis
AU  - Li, Yuhang
AU  - Ma, Chunhao
AU  - Yu, Lisai
JO  - Technology in Society
VL  - 85
SP  - 103197
PY  - 2026
DA  - 2026/06/01/
SN  - 0160-791X
DO  - https://doi.org/10.1016/j.techsoc.2025.103197
UR  - https://www.sciencedirect.com/science/article/pii/S0160791X25003872
KW  - Artificial intelligence
KW  - nationalism
KW  - Social media
KW  - ANTMN
KW  - Lexicon
AB  - Amid the rapid advancement of generative artificial intelligence (AI), public perceptions and emotional attitudes toward AI have become increasingly complex. Existing research has predominantly focused on micro-level aspects such as risk perception and technology acceptance, with limited attention to its connections with national identity and cultural sentiment. Adopting a nationalism perspective, this study employs computational social science methods to examine whether and how nationalistic expressions emerge in public discussions on the Chinese large language model DeepSeek on the social media platform Weibo. We developed a lexicon-based methodology for nationalism, structured around five dimensions: national pride, national revival, anti-foreign, techno-nationalism, and cultural nationalism. Leveraging large-scale text mining and the Analysis of Topic Model Networks (ANTMN), we identify two distinct discursive clusters named the Utility cluster and the Sociopolitical cluster, and further conducted a comparative analysis of how nationalism was discursively articulated within each cluster. The results show that discussions of DeepSeek prominently reflect nationalistic sentiment, with techno-nationalism emerging as the most salient dimension. Significant structural differences were observed between clusters in the ways nationalism is articulated. This study expands the theoretical scope of AI public opinion research, proposes a quantifiable framework for analyzing nationalism, and offers new empirical insights into the national symbolism and collective emotions embedded in contemporary AI technologies.
ER  - 

TY  - JOUR
T1  - Can ChatGPT be used to generate scientific hypotheses?
AU  - Park, Yang Jeong
AU  - Kaplan, Daniel
AU  - Ren, Zhichu
AU  - Hsu, Chia-Wei
AU  - Li, Changhao
AU  - Xu, Haowei
AU  - Li, Sipei
AU  - Li, Ju
JO  - Journal of Materiomics
VL  - 10
IS  - 3
SP  - 578
EP  - 584
PY  - 2024
DA  - 2024/05/01/
SN  - 2352-8478
DO  - https://doi.org/10.1016/j.jmat.2023.08.007
UR  - https://www.sciencedirect.com/science/article/pii/S2352847823001557
KW  - large language models
KW  - scientific hypothesis generation
KW  - generative AI
KW  - GPT-4
AB  - We investigate whether large language models can perform the creative hypothesis generation that human researchers regularly do. While the error rate is high, generative AI seems to be able to effectively structure vast amounts of scientific knowledge and provide interesting and testable hypotheses. The future scientific enterprise may include synergistic efforts with a swarm of “hypothesis machines”, challenged by automated experimentation and adversarial peer reviews.
ER  - 

TY  - JOUR
T1  - Semi-supervised traceability analysis of investigative scanners of darknet traffic
AU  - Abduaziz, Kayumov
AU  - Han, Chansu
AU  - Shin, Ji Sun
JO  - Computers & Security
VL  - 159
SP  - 104681
PY  - 2025
DA  - 2025/12/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104681
UR  - https://www.sciencedirect.com/science/article/pii/S0167404825003700
KW  - Darknet
KW  - Semi-supervised learning
KW  - Scanner patterns
KW  - Word embedding
KW  - Threat intelligence
AB  - Darknet, an unused IP address space on the Internet, has led to significant research advances in the analyses of global scanning activities, predictions of incoming cyber threats, and the classification of scanning patterns in unsolicited network traffic. However, most darknet traffic research has focused on classification methods that rely on supervised learning, or on unsupervised methods that require further expert effort. To study the applicability of semi-supervision for darknet traffic analysis, we propose a semi-supervised framework that efficiently clusters and classifies scanner behaviors based on existing knowledge for the traceability analysis of investigative scanners on the darknet. The framework utilizes a word embedding model to represent similarly behaving scanners in close proximity in the vector space, followed by a semi-supervised clustering step that incorporates partial labels of known scanners. We validate the framework by combining two publicly available darknet traffic datasets: CAIDA, providing labeled data for semi-supervision, and NICT, that offers a larger set of unlabeled data for analysis. Experimental results demonstrated that integrating semi-supervised learning into darknet traffic analysis improves the interpretability of diverse scanning behaviors and enhances scalability, offering a three-fold speedup in overall runtime compared to the existing sliding window approach. By reducing reliance on fully labeled datasets, the framework facilitates large-scale threat intelligence while allowing for the smooth integration of ever-growing domain knowledge pertaining to darknet traffic. Future research can further refine the model by incorporating additional classes of darknet scanners and expanding the applicability of the model to real-time darknet traffic analysis.
ER  - 

TY  - JOUR
T1  - Comprehensive benchmarking of knowledge graph embeddings methods for Android malware detection
AU  - Kincl, Jan
AU  - Eftimov, Tome
AU  - Viktorin, Adam
AU  - Šenkeřík, Roman
AU  - Pavleska, Tanja
JO  - Expert Systems with Applications
VL  - 288
SP  - 127888
PY  - 2025
DA  - 2025/09/01/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2025.127888
UR  - https://www.sciencedirect.com/science/article/pii/S0957417425015106
KW  - Mobile android security
KW  - Knowledge graphs embeddings
KW  - Machine learning
KW  - Android malware detection
AB  - The rising popularity and open-source model of the Android operating system has made it a main target for attackers creating malware applications. With the mobile industry being an expanding device ecosystem, there is a critical need for developing effective methods to protect against mobile malware. Recognizing the latest approaches and their limitations, we have conducted a comprehensive empirical analysis on the applicability of knowledge graphs for malware detection in view of the influence of the scoring functions, the vector dimension, the stability of the obtained results, the performance of the individual classifiers, and other important time dependencies. In addition, we propose a knowledge-graph based method aimed at improving the quality of classification input data, while offering greater interfacing capabilities with external knowledge and lower computational complexity. The proposed method offers a new perspective on working with Android malware, demonstrating a unique data processing pipeline for malware sample identification and encouraging further innovation in the field. Our findings demonstrate that knowledge graph representation is not only feasible, but also provides well-performing results, remaining competitive with state-of-the-art approaches.
ER  - 

TY  - JOUR
T1  - Towards sustainable business in the automation era: Exploring its transformative impact from top management and employee perspective
AU  - Gómez Gandía, José Andrés
AU  - Gavrila Gavrila, Sorin
AU  - de Lucas Ancillo, Antonio
AU  - del Val Núñez, María Teresa
JO  - Technological Forecasting and Social Change
VL  - 210
SP  - 123908
PY  - 2025
DA  - 2025/01/01/
SN  - 0040-1625
DO  - https://doi.org/10.1016/j.techfore.2024.123908
UR  - https://www.sciencedirect.com/science/article/pii/S0040162524007066
KW  - Sustainable business automation
KW  - Sustainable business strategies
KW  - Sustainable automation integration
KW  - Workforce sustainability
KW  - Business innovation
AB  - In recent years, organisations are in a continuous race in search of business sustainability, becoming a fundamental pillar of the organisation. The aim is to be more effective and efficient by doing more with less by managing all the organisation's resources. The ways in which organisations face these economic, social, and environmental challenges vary according to their activity. Globalisation has enabled economic growth, allowing the expansion of markets and access to goods and services worldwide. This has led to an increased level of global competition among organisations and the search for markets in which they have no competitors. In most cases they find markets with several players competing for a market with increasingly lower margins and trying to survive by seeking new competitive advantages.
Purpose
The priority objective is to analyse the owner vs employee's perception of artificial intelligence and how it impacts the relationship with the sustainability of the company. For this purpose, a Likert survey has been carried out, which is an effective tool to evaluate this type of perception in a quantitative way. Today it is a strategic area for organisations, and this perception and employee behaviour are key to its proper functioning.
Structure
The introductory section explains where the data comes from, explaining what is known, what is new and the aim of the work. This is followed by the research methodology applied, together with the criteria for selecting the data sets and categories. Finally, the conclusions section highlights the results obtained, their implications along with their limitations and possible future directions of the research.
Findings
Sustainability in organisations is important in the generation and application of ideas and a novel perspective that drives organisational growth and contributes to sustainability, maintaining a balance between the three main dimensions, economic, social, and environmental. Innovation generates the creation of products, services or processes that reduce environmental impact, among others, promoting efficiency and the preservation of resources in the search for economic benefits. These technologies include green technologies, recycling strategies and renewable energies. The use of advanced technologies by organisations in their quest to achieve higher levels of sustainability offers a range of benefits that would otherwise be inaccessible. The integration of tools such as artificial intelligence (AI) and automation into business processes not only optimises operational efficiency, but also contributes significantly to environmental and economic sustainability. These technologies facilitate data-driven decision-making, improve resource management, and reduce waste, which is crucial for sustainable development. In addition, AI and automation can play a vital role in identifying opportunities for sustainable innovation, enabling organisations to proactively adapt to changing market demands and environmental regulations. However, it is essential to consider the ethical and social implications of these technologies, especially in terms of labour impact and data privacy. In this context, the need arises to explore the internal impact of AI and automation in organisations, specifically how these technologies are perceived by different actors within the company, such as owners and workers. To investigate this aspect, the use of Machine Learning Language Models (LLMs) represents a valuable methodological tool. By implementing LLMs, the aim is to compare the perceptions of owners and workers on several issues related to automation in the business environment. This includes aspects such as acceptance of the technology, perceived impact on productivity and well-being at work, and expectations regarding changes in work dynamics. This research could shed light on the discrepancies or overlaps in the perceptions of these groups, offering a deeper understanding of the socio-economic and cultural impact of automation and AI on organisations.
Discussion
Today, it is necessary to manage the acquisition, creation, and application of knowledge differently from the way it was done until the last century. The organisation must be creative as it is essential for subsistence and for the development of sustainable strategies. Today, disruptive changes in technology are happening almost continuously. The research has revealed important results in terms of the perception of automation in the business environment, highlighting differences and alignments in the perspectives of employees and business owners. Artificial intelligence is beginning to have a priority place in the structure of the organisation, where they replace employees or create symbiotic relationships with optimal results. This allows organisations to keep up with such a revolutionary environment, identify opportunities to optimise processes by automating processes, reducing waste, and promoting ethical and socially responsible business practices in a world increasingly concerned with these aspects.
Originality
The research in question, which uses a Machine Learning Language Model (LLM) such as ChatGPT to question perceptions of automation in a business environment, represents an innovative approach in the field of automation research. The use of an LLM to collect and analyse data offers a novel and efficient perspective, allowing for a more dynamic and in-depth analysis of the responses obtained. This methodology is distinguished by its ability to process and interpret a significant volume of qualitative data at a speed and with an accuracy that traditional survey methods cannot match. By using Likert-scale questions and analyzing responses from two different perspectives - that of business leaders and that of employees - the research addresses the complexity of perceptions of automation in a holistic manner. This dual approach allows us to identify not only the differences between these two groups, but also potential areas of alignment, providing a more nuanced view of how automation is perceived and experienced at different levels of the organisation. The advantages of this methodology are multiple. Firstly, using an LLM such as ChatGPT to analyse survey responses allows for a more detailed and nuanced interpretation of the data, especially in terms of capturing and understanding the subtleties of language and emotions implicit in the responses. In addition, the ability to process large datasets quickly and efficiently facilitates broader and more representative analysis, which can lead to more robust and reliable conclusions. In practical terms, this approach can help organisations better understand the attitudes and concerns of their employees and leaders regarding automation, which in turn can inform more effective implementation and change management strategies. It also provides valuable insights for the development of policies and practices that encourage a more harmonious and ethical integration of automation in the workplace, maximising its benefits while minimising potential negative impacts on staff.
Practical implications
Studies on the perception of automation in the business context, both from the point of view of employees and owners, underline the need for adapted and differentiated approaches to integrating automation in the workplace. It highlights the divergent needs and concerns of these groups, suggesting that automation implementation strategies should not only focus on operational efficiency, but also address employee concerns about job security and the relevance of skills. This includes integrating training and professional development as key components of automation programmes, making sure that employees feel equipped and valued in the evolving automated workspace. In addition, the results highlight the importance of effective and transparent communication about the goals and impacts of automation and advocate the joint involvement of employees and managers in the design and implementation of automated solutions. Taken as a whole, the study emphasises the need for holistic and empathetic management of automation in organisations, viewing technology to improve the working environment and support employees' professional growth.
ER  - 

TY  - JOUR
T1  - From scattered sources to comprehensive technology landscape : A recommendation-based retrieval approach
AU  - Duong, Chi Thang
AU  - David, Dimitri Perica
AU  - Dolamic, Ljiljana
AU  - Mermoud, Alain
AU  - Lenders, Vincent
AU  - Aberer, Karl
JO  - World Patent Information
VL  - 73
SP  - 102198
PY  - 2023
DA  - 2023/06/01/
SN  - 0172-2190
DO  - https://doi.org/10.1016/j.wpi.2023.102198
UR  - https://www.sciencedirect.com/science/article/pii/S0172219023000285
KW  - Technology monitoring
KW  - Information retrieval
KW  - Entity-based retrieval
KW  - Technology classifier
KW  - Recommender system
AB  - Mapping the technology landscape is crucial for market actors to take informed investment decisions. However, given the large amount of data on the Web and its subsequent information overload, manually retrieving information is a seemingly ineffective and incomplete approach. In this work, we propose an end-to-end recommendation based retrieval approach to support automatic retrieval of technologies and their associated companies from raw Web data. This is a two-task setup involving (i) technology classification of entities extracted from company corpus, and (ii) technology and company retrieval based on classified technologies. Our proposed framework approaches the first task by leveraging DistilBERT which is a state-of-the-art language model. For the retrieval task, we introduce a recommendation-based retrieval technique to simultaneously support retrieving related companies, technologies related to a specific company and companies relevant to a technology. To evaluate these tasks, we also construct a data set that includes company documents and entities extracted from these documents together with company categories and technology labels. Experiments show that our approach is able to return 4 times more relevant companies while outperforming traditional retrieval baseline in retrieving technologies.
ER  - 

TY  - JOUR
T1  - Industry 4.0 for smart transport systems: Foundations and applications
AU  - Ahmad, Wasim
AU  - Khan, Sunawar
AU  - Mazhar, Tehseen
AU  - Shahzad, Tariq
AU  - Jiang, Weiwei
AU  - Hamam, Habib
JO  - Telematics and Informatics Reports
VL  - 20
SP  - 100255
PY  - 2025
DA  - 2025/12/01/
SN  - 2772-5030
DO  - https://doi.org/10.1016/j.teler.2025.100255
UR  - https://www.sciencedirect.com/science/article/pii/S2772503025000696
KW  - Industry 4.0
KW  - Smart transport systems
KW  - Smart grid integration
KW  - Electric vehicles (EV)
KW  - Vehicle-to-grid (V2G)
AB  - This paper examines how Industry 4.0 technologies enable smart transport systems through energy-aware architectures that integrate vehicles with the smart grid. We provide a concise synthesis of application patterns across cyber-physical systems (CPS), Industrial IoT sensing, edge and cloud analytics, and secure data exchange, and present application-oriented cases spanning EV–grid interaction (V2G), predictive maintenance, and operational optimization. We map enabling components—data ingestion, model inference, decision support, and secure interoperability—to transport tasks and discuss implementation trade-offs observed in practice. While our analysis is grounded in Industry 4.0 foundations, we explain how these foundations support a measured transition toward Industry 5.0—prioritizing human-centric, resilient, and sustainability-aligned operations— with Industry 5.0 features and LLM-based interfaces treated as future work rather than scope-defining elements.
ER  - 

TY  - JOUR
T1  - Online grooming detection: A comprehensive survey of child exploitation in chat logs
AU  - Borj, Parisa Rezaee
AU  - Raja, Kiran
AU  - Bours, Patrick
JO  - Knowledge-Based Systems
VL  - 259
SP  - 110039
PY  - 2023
DA  - 2023/01/10/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2022.110039
UR  - https://www.sciencedirect.com/science/article/pii/S0950705122011327
KW  - Cyber grooming
KW  - Child exploitation
KW  - Online predators
KW  - Chat analysis
KW  - Stylometry
KW  - Text analysis
KW  - Keystroke dynamics
AB  - Social media platforms present significant threats against underage users targeted for predatory intents. Many early research works have applied the footprints left by online predators to investigate online grooming. While digital forensics tools provide security to online users, it also encounters some critical challenges, such as privacy issues and the lack of data for research in this field. Our literature review investigates all research papers on grooming detection in online conversations by looking at the psychological definitions and aspects of grooming. We study the psychological theories behind the grooming characteristics used by machine learning models that have led to predatory stage detection. Our survey broadly considers the authorship profiling research works used for grooming detection in online conversations, along with predatory conversation detection and predatory identification approaches. Various approaches for online grooming detection have been evaluated based on the metrics used in the grooming detection problem. We have also categorized the available datasets and used feature vectors to give readers a deep knowledge of the problem considering their constraints and open research gaps. Finally, this survey details the constraints that challenge grooming detection, unaddressed problems, and possible future solutions to improve the state-of-the-art and make the algorithms more reliable.
ER  - 

TY  - JOUR
T1  - Contextual Embeddings based on Fine-tuned Urdu-BERT for Urdu threatening content and target identification
AU  - Malik, Muhammad Shahid Iqbal
AU  - Cheema, Uswa
AU  - Ignatov, Dmitry I.
JO  - Journal of King Saud University - Computer and Information Sciences
VL  - 35
IS  - 7
SP  - 101606
PY  - 2023
DA  - 2023/07/01/
SN  - 1319-1578
DO  - https://doi.org/10.1016/j.jksuci.2023.101606
UR  - https://www.sciencedirect.com/science/article/pii/S131915782300160X
KW  - Threatening content
KW  - Target identification
KW  - Fine-tuned BERT
KW  - Urdu
KW  - Twitter
KW  - Text representation
AB  - Identification of threatening text on social media platforms is a challenging task. Contrary to the high-resource languages, the Urdu language has very limited such approaches and the benchmark approach has an issue of inappropriate data annotation. Therefore, we present robust threatening content and target identification as a hierarchical classification model for Urdu tweets. This study investigates the potential of the Urdu-BERT (Bidirectional Encoder Representations from Transformer) language model to learn universal contextualized representations aiming to showcase its usefulness for binary classification tasks of threatening content and target identification. We propose to exploit a pre-trained Urdu-BERT as a transfer learning model after fine-tuning its parameters on a newly designed Urdu corpus from the Twitter platform. The proposed dataset contains 2,400 tweets manually annotated as threatening or non-threatening at the first level and threatening tweets are further categorized into individual or group at the second level. The performance of fine-tuned Urdu-BERT is compared with the benchmark study and other feature models. Experimental results show that the fine-tuned Urdu-BERT model achieves state-of-the-art performance by obtaining 87.5% accuracy and 87.8% F1-score for threatening content identification and 82.5% accuracy and 83.2% F1-score for target identification task. Furthermore, the proposed model outperforms the benchmark study.
ER  - 

TY  - JOUR
T1  - A 3D geospatial platform and AI tour application for visualizing archaeological, analytical, and conservation data: the case of the Vryokastro archaeological ensemble, Kythnos Island
AU  - Kyropoulou, Dafni
AU  - Karalis, Petros
AU  - Dotsika, Elissavet
AU  - Rizou, Foteini
AU  - Raptis, Iakovos
AU  - Drosou, Anastasios
AU  - Tzovaras, Dimitrios
AU  - Ainian, Alexandros Mazarakis
AU  - Kolofotia, Evangelia
JO  - Journal of Archaeological Science: Reports
VL  - 68
SP  - 105480
PY  - 2025
DA  - 2025/12/01/
SN  - 2352-409X
DO  - https://doi.org/10.1016/j.jasrep.2025.105480
UR  - https://www.sciencedirect.com/science/article/pii/S2352409X25005139
KW  - Three-dimensional user interfaces
KW  - Geospatial platform
KW  - Virtual reality
KW  - Artificial intelligence
KW  - PostgreSQL, PostGIS
KW  - Kythnos, virtual tour
AB  - This study presents an integrated digital platform developed under the Palimpsisto project to enhance the visualization, interpretation, and conservation of cultural heritage, using the archaeological site of Vryokastro on Kythnos island as a case study. The platform combines a three-dimensional geospatial system with a virtual tour application powered by artificial intelligence (AI) to enable immersive, interactive access to archaeological, analytical, and conservation data. This multidisciplinary approach, which included stable isotope analysis of bone, glass, and mortar samples, aimed to reconstruct past dietary practices, determine the provenance of raw materials, and monitor degradation phenomena. This data was integrated into a PostgreSQL/PostGIS geodatabase and visualized through Unity and Cesium, enabling real-time, georeferenced 3D rendering. The platform features include a “smart conservator” chatbot, a storytelling engine trained on custom T5 language models for dynamic narration and question answering, as well as tools for degradation simulation. By combining archaeometric research with advanced digital technologies, the system promotes heritage education, public engagement, and decision-making in conservation practices. The Palimpsisto platform provides a replicable model for future applications in digital archaeology and heritage informatics.
ER  - 

TY  - JOUR
T1  - A SysML-based language for evaluating the integrity of simulation and physical embodiments of Cyber–Physical systems
AU  - Dudek, Wojciech
AU  - Miguel, Narcis
AU  - Winiarski, Tomasz
JO  - Robotics and Autonomous Systems
VL  - 185
SP  - 104884
PY  - 2025
DA  - 2025/03/01/
SN  - 0921-8890
DO  - https://doi.org/10.1016/j.robot.2024.104884
UR  - https://www.sciencedirect.com/science/article/pii/S0921889024002689
KW  - Design analysis and evaluation
KW  - Digital twins
KW  - System architecture
KW  - Model-based evaluation
KW  - Domain-specification language
KW  - Multi-agent systems
KW  - Robotics
AB  - Evaluating early design concepts is crucial as it impacts quality and cost. This process is often hindered by vague and uncertain design information. This article introduces the SysML-based Simulated–Physical Systems Modelling Language (SPSysML). It is a Domain-Specification Language for evaluating component reusability in Cyber–Physical Systems incorporating Digital Twins and other simulated parts. The proposed factors assess the design quantitatively. SPSysML uses a requirement-based system structuring method to couple simulated and physical parts with requirements. SPSysML-based systems incorporate DTs that perceive exogenous actions in the simulated world. SPSysML validation is survey- and application-based. First, we develop a robotic system for an assisted living project. We propose an SPSysML application procedure called SPSysAP that manages the considered system development by evaluating the system designs with the proposed quantitative factors. As a result of the SPSysML application, we observed an integrity improvement between the simulated and physical parts of the system. Thus, more system components are shared between the simulated and physical setups. The system was deployed on the physical robot and two simulators based on ROS and ROS2. Additionally, we share a questionnaire for SPSysML assessment. The feedback that we already received is published in this article.
ER  - 

TY  - JOUR
T1  - DongTing: A large-scale dataset for anomaly detection of the Linux kernel
AU  - Duan, Guoyun
AU  - Fu, Yuanzhi
AU  - Cai, Minjie
AU  - Chen, Hao
AU  - Sun, Jianhua
JO  - Journal of Systems and Software
VL  - 203
SP  - 111745
PY  - 2023
DA  - 2023/09/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2023.111745
UR  - https://www.sciencedirect.com/science/article/pii/S0164121223001401
KW  - Anomaly detection
KW  - Dataset
KW  - Linux kernel
KW  - System calls
KW  - Kernel BUG
KW  - Deep learning
AB  - Host-based intrusion detection systems (HIDS) can automatically identify adversarial applications by learning models from system events that represent normal system behaviors. The system call is the only way for applications to interact with the operating system (OS). Thus, system call sequences are traditionally used in HIDS to train models to detect novel attacks, and a wide range of datasets has been proposed for this task. However, existing datasets are either built for user-level applications (not for OS kernels), or completely outdated (proposed more than 20 years ago). To address this issue, this paper presents the first large-scale dataset specifically assembled for anomaly detection of the Linux kernel. The task of creating such a dataset is challenging due to the difficulty both in collecting a diversified set of programs that can trigger bugs in the kernel and in tracing events that may crash the kernel at runtime. In this paper, we describe in detail how to collect the data through an automated and efficient framework. The raw dataset is 85 GB in size, and contains 18,966 system call sequences that are labeled with normal and abnormal attributes. Our dataset covers more than 200 kernel versions (including major/minor releases and revisions) and 3,600 bug-triggering programs in the past five years. In addition, we conduct cross-dataset evaluation to demonstrate that training on our dataset enables superior generalization ability than other related datasets, and provide benchmark results for anomaly detection of Linux kernel on our dataset. Our extensive dataset is both useful for machine learning researchers focusing on algorithmic optimizations and practitioners in kernel development who are interested in deploying deep learning models in OS kernels.
ER  - 

TY  - JOUR
T1  - Federated learning for solar energy applications: A case study on real-time fault detection
AU  - Abdelmoula, Ibtihal Ait
AU  - Oufettoul, Hicham
AU  - Lamrini, Nassim
AU  - Motahhir, Saad
AU  - Mehdary, Adil
AU  - Aroussi, Mohamed El
JO  - Solar Energy
VL  - 282
SP  - 112942
PY  - 2024
DA  - 2024/11/01/
SN  - 0038-092X
DO  - https://doi.org/10.1016/j.solener.2024.112942
UR  - https://www.sciencedirect.com/science/article/pii/S0038092X24006376
KW  - Solar PV
KW  - Federated learning
KW  - Anomaly detection
KW  - Machine learning
KW  - Smart grids
AB  - Federated learning (FL) has recently gained popularity as a distributed machine learning approach that protects privacy. However, this concept has not yet been extensively adopted for distributed solar systems. In this context, the current research suggests the use of federated learning as a novel method that complements the principles of smart grids and enables collaborative anomaly detection in distributed photovoltaic (PV) systems. The proposed strategy employs a federated learning framework in several anomaly detection scenarios for PV plants using both balanced and unbalanced datasets. By simulating even extreme situations, the proposed approach achieved similar accuracy to the centralized approach while maintaining privacy. The performance of the centralized approach was notably high, achieving a precision of 98%, a recall of 93%, and an f1-score of 95%. Similarly, the federated approach applied to a balanced dataset yielded comparable results, with a precision of 97%, a recall of 91%, and an f1-score of 93%. Even when applied to extremely unbalanced scenarios, the federated approach maintained good performance resulting in a precision of 95%, a recall of 91%, and an f1-score of 93% after 200 rounds of federation. Therefore, this study presents a new research perspective on incorporating federated learning in distributed and decentralized solar farms.
ER  - 

TY  - JOUR
T1  - Network intrusion datasets: A survey, limitations, and recommendations
AU  - Goldschmidt, Patrik
AU  - Chudá, Daniela
JO  - Computers & Security
VL  - 156
SP  - 104510
PY  - 2025
DA  - 2025/09/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104510
UR  - https://www.sciencedirect.com/science/article/pii/S0167404825001993
KW  - Network intrusion detection
KW  - NIDS
KW  - Machine learning for intrusion detection
KW  - Cybersecurity datasets
KW  - NIDS best practices
KW  - Comparative dataset analysis
AB  - Data-driven cyberthreat detection has become a crucial defense technique in modern cybersecurity. Network defense, supported by Network Intrusion Detection Systems (NIDSs), has also increasingly adopted data-driven approaches, leading to greater reliance on data. Despite the importance of data, its scarcity has long been recognized as a major obstacle in NIDS research. In response, the community has published many new datasets recently. However, many of them remain largely unknown and unanalyzed, leaving researchers uncertain about their suitability for specific use cases. In this paper, we aim to address this knowledge gap by performing a systematic literature review (SLR) of 89 public datasets for NIDS research. Each dataset is comparatively analyzed across 13 key properties, and its potential applications are outlined. Beyond the review, we also discuss domain-specific challenges and common data limitations to facilitate a critical view on data quality. To aid in data selection, we conduct a dataset popularity analysis in contemporary state-of-the-art NIDS research. Furthermore, the paper presents best practices for dataset selection, generation, and usage. By providing a comprehensive overview of the domain and its data, this work aims to guide future research toward improving data quality and the robustness of NIDS solutions.
ER  - 

TY  - JOUR
T1  - Adaptive security framework for multi-environment networks using ensemble data drift detection and incremental deep learning
AU  - Rustam, Furqan
AU  - Jurcut, Anca Delia
JO  - Journal of Information Security and Applications
VL  - 94
SP  - 104219
PY  - 2025
DA  - 2025/11/01/
SN  - 2214-2126
DO  - https://doi.org/10.1016/j.jisa.2025.104219
UR  - https://www.sciencedirect.com/science/article/pii/S221421262500256X
KW  - Network security
KW  - Explainable AI
KW  - Multi-environment network
KW  - Data drift detection
KW  - Incremental learning
AB  - Modern multi-environment (M-En) networks comprise diverse architectures such as IoT and traditional IP-based networks. These networks pose significant challenges for threat mitigation due to heterogeneous protocols and traffic patterns. This study proposes a unified incremental learning framework to efficiently secure M-En networks by reducing management overhead, improving scalability, and lowering costs. We designed this approach for real-time environments, enabling adaptation to new scenarios with high accuracy and efficiency. To develop the framework, we first generate an M-En dataset using partial least squares canonical analysis, synthesizing data from two benchmark datasets: IoT23 and CICDDoS2019, representing IoT and traditional IP-based networks, respectively. Our approach employs an ensemble data drift detection (EDDD) mechanism that combines ADaptive WINdowing and autoencoders, enabling adaptive model updates. A deep neural network is incrementally retrained only when data drift is detected, ensuring adaptability to evolving attacks while conserving computational resources. To avoid catastrophic forgetting, we incorporate replay-based memory, regularization, and an interpolation mechanism governed by a blending parameter α∈[0,1], which balances the integration of new and historical knowledge. Furthermore, the explainable AI technique LIME is integrated to enhance the transparency of the model’s decision-making process. Experimental results indicate that our approach achieves a mean accuracy of 0.999 while maintaining low memory usage, approximately 32.1 MB, and a stable model size of 0.11 MB.
ER  - 

TY  - JOUR
T1  - Intelligent fault detection in battery systems: a machine learning approach with transformer-enhanced multi-modal Sensing
AU  - Antony, A. Santhi Mary
AU  - Sundaram, K. Meenakshi
AU  - Raman, C.J.
AU  - Murthy, G. Ramana
JO  - Electric Power Systems Research
VL  - 251
SP  - 112279
PY  - 2026
DA  - 2026/02/01/
SN  - 0378-7796
DO  - https://doi.org/10.1016/j.epsr.2025.112279
UR  - https://www.sciencedirect.com/science/article/pii/S0378779625008661
KW  - Battery safety
KW  - Machine learning framework
KW  - Transformer-based anomaly detection
KW  - Convolutional Autoencoder, Redundant architecture
KW  - Multi-modal sensing
AB  - This study presents a new intelligent battery safety framework that improves fault detection and risk management from traditional static monitoring systems. The proposed method simultaneously used redundant multi-modal sensing of battery safety data with a Convolutional Autoencoder (CAE), followed by an anomaly classifier based on Transformer networks that captured spatial and temporal dependencies in sensing data for fault prediction. The proposed method introduces the use of Bayesian sensor fusion to correct the redundant measurements and fuzzy logic reasoning to convert anomaly scores into risk-based safety actions that support interpretable decision-making. The estimate of the State of Health (SoH) of the battery is derived from real-time fusion of thermal profiles, routing voltage, and cycle aging data, enabling fidelity in tracing degradation trends during faults. Experimental evidence of validity using MATLAB/Simulink and real-time hardware-in-the-loop fault injection indicates a 15 % reduction in false positives, fault detection accuracy up to 98 %, and reliable actuating capability within 20 ms. These results celebrate notable improvements over traditional single-modality, threshold systems, while providing robust, proactive safety for electric vehicles and grid storage applications. This research provides a definitive proof of concept for the CAE-Transformer-Fuzzy hybrid framework as an effective and implementable approach to adaptive battery management in dynamic and safety-critical situations.
ER  - 

TY  - JOUR
T1  - Image-based intrusion detection system for GPS spoofing cyberattacks in unmanned aerial vehicles
AU  - Korium, Mohamed Selim
AU  - Saber, Mohamed
AU  - Ahmed, Ahmed Mahmoud
AU  - Narayanan, Arun
AU  - Nardelli, Pedro H.J.
JO  - Ad Hoc Networks
VL  - 163
SP  - 103597
PY  - 2024
DA  - 2024/10/01/
SN  - 1570-8705
DO  - https://doi.org/10.1016/j.adhoc.2024.103597
UR  - https://www.sciencedirect.com/science/article/pii/S1570870524002087
KW  - Unmanned aerial vehicles
KW  - CNN architectures
KW  - Transfer learning
KW  - Learning and loss curves
AB  - The operations of unmanned aerial vehicles (UAVs) are susceptible to cybersecurity risks, mainly because of their firm reliance on the Global Positioning System (GPS) and radio frequency (RF) sensors. GPS and RF sensors are vulnerable to potential threats, such as spoofing attacks that can cause the UAVs to behave erratically. Since these threats are widespread and potent, it is imperative to develop effective intrusion detection systems. In this paper, we propose an image-based intrusion detection system for detecting GPS spoofing cyberattacks based on a deep learning methodology. We combine convolutional neural networks with Principal Component Analysis (PCA) to reduce the dimensionality of the dataset features, data augmentation to increase the size and diversity of the training dataset, and transfer learning to improve the proposed model’s performance with limited data to design a fast, accurate, and general method. Extensive numerical experiments demonstrate the effectiveness of the proposed solution carried out using benchmark datasets. We achieved an accuracy of 100% within a running time of 120.64 s at 0.3529 ms latency and a detection time of 2.035 s in the case of the training dataset. Further, using this trained model, we achieved an accuracy of 99.25% within a detection time of 2.721 s on an unseen dataset that was unrelated to the one used for training the model. In contrast, other models, such as Inception-v3, showed lower accuracy on unseen datasets. However, Inception-v3 performance improved significantly after Bayesian optimization, with the Tree-structured Parzen Estimator reaching 99.06% accuracy. Our results demonstrate that the proposed image-based intrusion detection method outperforms the existing solutions while providing a general model for detecting cyberattacks included in unseen datasets.
ER  - 

TY  - JOUR
T1  - Wireless Sensor Network Modeling and Analysis for Attack Detection
AU  - Zhukabayeva, Tamara
AU  - Desnitsky, Vasily
AU  - Abdildayeva, Assel
JO  - CMES - Computer Modeling in Engineering and Sciences
VL  - 144
IS  - 2
SP  - 2591
EP  - 2625
PY  - 2025
DA  - 2025/08/31/
SN  - 1526-1492
DO  - https://doi.org/10.32604/cmes.2025.067142
UR  - https://www.sciencedirect.com/science/article/pii/S1526149225002589
KW  - Wireless sensor network
KW  - modeling
KW  - security
KW  - attack
KW  - detection
KW  - monitoring
AB  - Wireless Sensor Networks (WSN) have gained significant attention over recent years due to their extensive applications in various domains such as environmental monitoring, healthcare systems, industrial automation, and smart cities. However, such networks are inherently vulnerable to different types of attacks because they operate in open environments with limited resources and constrained communication capabilities. The paper addresses challenges related to modeling and analysis of wireless sensor networks and their susceptibility to attacks. Its objective is to create versatile modeling tools capable of detecting attacks against network devices and identifying anomalies caused either by legitimate user errors or malicious activities. A proposed integrated approach for data collection, preprocessing, and analysis in WSN outlines a series of steps applicable throughout both the design phase and operation stage. This ensures effective detection of attacks and anomalies within WSNs. An introduced attack model specifies potential types of unauthorized network layer attacks targeting network nodes, transmitted data, and services offered by the WSN. Furthermore, a graph-based analytical framework was designed to detect attacks by evaluating real-time events from network nodes and determining if an attack is underway. Additionally, a simulation model based on sequences of imperative rules defining behaviors of both regular and compromised nodes is presented. Overall, this technique was experimentally verified using a segment of a WSN embedded in a smart city infrastructure, simulating a wormhole attack. Results demonstrate the viability and practical significance of the technique for enhancing future information security measures. Validation tests confirmed high levels of accuracy and efficiency when applied specifically to detecting wormhole attacks targeting routing protocols in WSNs. Precision and recall rates averaged above the benchmark value of 0.95, thus validating the broad applicability of the proposed models across varied scenarios.
ER  - 

TY  - JOUR
T1  - A Big Data architecture for early identification and categorization of dark web sites
AU  - Pastor-Galindo, Javier
AU  - Sandlin, Hông-Ân
AU  - Mármol, Félix Gómez
AU  - Bovet, Gérôme
AU  - Pérez, Gregorio Martínez
JO  - Future Generation Computer Systems
VL  - 157
SP  - 67
EP  - 81
PY  - 2024
DA  - 2024/08/01/
SN  - 0167-739X
DO  - https://doi.org/10.1016/j.future.2024.03.025
UR  - https://www.sciencedirect.com/science/article/pii/S0167739X24000967
KW  - Dark web
KW  - Big Data
KW  - Web content categorization
KW  - BERT
KW  - Tor network analysis
KW  - Threat intelligence
AB  - The dark web has become notorious for its association with illicit activities and there is a growing need for systems to automate the monitoring of this space. This paper proposes an end-to-end scalable architecture for the continuous early identification of new Tor sites and the daily analysis of their content. The solution is built using an Open Source Big Data stack for data serving with Kubernetes, Kafka, Kubeflow, and MinIO, continuously discovering onion addresses in different sources (threat intelligence, code repositories, web-Tor gateways, and Tor repositories), downloading the HTML from Tor and deduplicating the content using MinHash LSH, and categorizing with the BERTopic modeling (SBERT embedding, UMAP dimensionality reduction, HDBSCAN document clustering and c-TF-IDF topic keywords). In 93 days, the system identified 80,049 onion services and characterized 90% of them, addressing the challenge of Tor volatility. A disproportionate amount of repeated content is found, with only 6.1% unique sites. From the HTML files of the dark sites, 31 different low-topics are extracted, manually labeled, and grouped into 11 high-level topics. The five most popular included sexual and violent content, repositories and search engines, carding, cryptocurrencies, and marketplaces. During the experiments, we identified 14 sites with 13,946 clones that shared a suspiciously similar mirroring rate per day, suggesting an extensive common phishing network. Among the related works, this study is the most representative characterization of onion services based on topics to date.
ER  - 

TY  - JOUR
T1  - Research on SQL Injection Detection Technology Based on Content Matching and Deep Learning
AU  - Chen, Yuqi
AU  - Liang, Guangjun
AU  - Wang, Qun
JO  - Computers, Materials and Continua
VL  - 84
IS  - 1
SP  - 1145
EP  - 1167
PY  - 2025
DA  - 2025/06/09/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2025.063319
UR  - https://www.sciencedirect.com/science/article/pii/S1546221825005314
KW  - SQL injection
KW  - network security
KW  - deep learning
KW  - convolution neural network
AB  - Structured Query Language (SQL) injection attacks have become the most common means of attacking Web applications due to their simple implementation and high degree of harm. Traditional injection attack detection techniques struggle to accurately identify various types of SQL injection attacks. This paper presents an enhanced SQL injection detection method that utilizes content matching technology to improve the accuracy and efficiency of detection. Features are extracted through content matching, effectively avoiding the loss of valid information, and an improved deep learning model is employed to enhance the detection effect of SQL injections. Considering that grammar parsing and word embedding may conceal key features and introduce noise, we propose training the transformed data vectors by preprocessing the data in the dataset and post-processing the word segmentation based on content matching. We optimized and adjusted the traditional Convolutional Neural Network (CNN) model, trained normal data, SQL injection data, and XSS data, and used these three deep learning models for attack detection. The experimental results show that the accuracy rate reaches 98.35%, achieving excellent detection results.
ER  - 

TY  - JOUR
T1  - An analytical approach to named entity recognition for military aerospace intelligence
AU  - Zabala-López, Alexandra
AU  - Linares-Vásquez, Mario
AU  - Haiduc, Sonia
AU  - Donoso, Yezid
JO  - Decision Analytics Journal
VL  - 16
SP  - 100613
PY  - 2025
DA  - 2025/09/01/
SN  - 2772-6622
DO  - https://doi.org/10.1016/j.dajour.2025.100613
UR  - https://www.sciencedirect.com/science/article/pii/S2772662225000694
KW  - Text analytics
KW  - Entity extraction
KW  - Military intelligence
KW  - Aerospace decision-making
KW  - Contextual modeling
KW  - Language processing
AB  - Named Entity Recognition (NER) models have been used in various contexts to automate the analysis of textual data, supporting tasks such as text categorization and relationship extraction across entities. While these models are typically trained on large corpora, their efficacy should be evaluated in specific domains where texts include specialized jargon and terminology. We assess the performance of NER models on Spanish-language documents from the Colombian Aerospace Force, focusing on the analysis of textual reports. Transformer and convolutional architectures were applied to three datasets. Our findings suggest that these models, when used off-the-shelf, face limitations, particularly in recognizing traditional words, military jargon, and compound entities. In Colombia, where names often include two given names and two surnames, and place names span multiple words, the models struggled to accurately parse and identify these linguistic patterns. However, after fine-tuning, their performance improved significantly, enabling effective extraction of valuable information from texts containing aerospace terms and military jargon in Spanish. As part of this study, we release six fine-tuned NER models and two of the datasets used in our experiments. Further research may yield additional optimizations, particularly for aerospace intelligence applications in Latin America.
ER  - 

TY  - JOUR
T1  - A survey on Deep Learning in Edge–Cloud Collaboration: Model partitioning, privacy preservation, and prospects
AU  - Zhang, Xichen
AU  - Razavi-Far, Roozbeh
AU  - Isah, Haruna
AU  - David, Amir
AU  - Higgins, Griffin
AU  - Zhang, Michael
JO  - Knowledge-Based Systems
VL  - 310
SP  - 112965
PY  - 2025
DA  - 2025/02/15/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2025.112965
UR  - https://www.sciencedirect.com/science/article/pii/S0950705125000139
KW  - Deep Learning
KW  - Edge–Cloud Collaboration
KW  - Model partitioning
KW  - Privacy preservation
AB  - Recently, the rapid advancements of AI technologies and mobile computing have led to the growing prevalence of smart devices and rising demands for on-device Deep Learning applications. Given this context, the Edge–Cloud Collaboration System has attracted considerable attention. This survey article focuses on a typical architecture in such a system, called Partitioned Deep Neural Network. Concretely, a complex Deep Learning model is partitioned into two segments. The shallow part, which serves as the feature extractor, is deployed on the edge device, while the remaining layers are processed on the cloud server for result inferences. We provide a comprehensive overview of Partitioning Deep Neural Networks for the Edge–Cloud Collaboration System, including model split, experimental settings, threat models, and assessment metrics. Then, we conduct a systematic summary of state-of-the-art privacy-preserving technologies, providing detailed comparisons of their advantages and limitations in practice. Finally, we highlight the main open challenges and propose intriguing research problems as future directions from various aspects, including attacking settings, novel application scenarios, evaluation measurements, and the applications and potential influences of Large Language Models in related domains.
ER  - 

TY  - JOUR
T1  - Legally-aware AI moderation in Vietnam: A cybersecurity law-compliant framework for platform governance
AU  - Vu Bui, Luong
JO  - Journal of Economic Criminology
VL  - 10
SP  - 100193
PY  - 2025
DA  - 2025/12/01/
SN  - 2949-7914
DO  - https://doi.org/10.1016/j.jeconc.2025.100193
UR  - https://www.sciencedirect.com/science/article/pii/S2949791425000697
KW  - Economic criminology
KW  - Deterrence
KW  - Externalities
KW  - Platform governance
KW  - AI moderation
KW  - Human-in-the-loop
KW  - Vietnam
KW  - Compliance economics
AB  - Digital platforms increasingly mediate fraud, illicit trade, misinformation, and incitement, often under stringent statutory timelines that demand rapid and auditable responses. Conventional moderation pipelines remain tuned to classifier accuracy, leaving them misaligned with legal categories, due-process safeguards, and deterrence goals. This produces costly false positives that chill lawful expression, false negatives that enable social harm, and thin audit trails that weaken accountability. We address this gap by introducing a legally-aware AI moderation framework that integrates law → policy → model label → evidence minima → action tier → appeal path into a single, auditable pipeline with human-in-the-loop review and mandatory rationales. The framework embeds economic criminology by modeling the expected utility of offending and demonstrating how risk thresholds, graduated sanctions, and appeal quality shift incentives while internalizing enforcement externalities. We develop a decision-analytic simulation of 50,000 multi-signal items that calibrates governance choices on a harm–cost frontier. Results show that at matched thresholds, a graduated action menu achieves 2.51 × greater harm reduction per unit enforcement cost compared to binary removal, while sustaining deterrence and lowering appeal overturn rates. This evidence demonstrates that moderation choices function as price signals in a crime market: raising certainty and proportional severity reduces offenders’ expected payoffs while protecting legitimacy through reversibility and transparency. By quantifying deterrence, externality reduction, and enforcement-cost efficiency, the framework reframes moderation as a problem of governance economics, not just technical accuracy. Situated within economic criminology, it operationalizes deterrence (certainty × severity), rational-choice incentives, and capable guardianship via a cost-adjusted harm-reduction frontier. Through open research objects and a jurisdictional portability protocol, it offers a replicable and auditable blueprint for platform governance that is compliant, economically rational, and transferable across sectors and jurisdictions.
ER  - 

TY  - JOUR
T1  - A decentralized defense model for covert zero-dynamic attacks in industrial control systems
AU  - Peng, Xiangzhen
AU  - Zheng, Chengliang
AU  - Shi, Jianyu
AU  - Cui, Xiaohui
JO  - Reliability Engineering & System Safety
VL  - 265
SP  - 111483
PY  - 2026
DA  - 2026/01/01/
SN  - 0951-8320
DO  - https://doi.org/10.1016/j.ress.2025.111483
UR  - https://www.sciencedirect.com/science/article/pii/S0951832025006830
KW  - Industrial control systems
KW  - Blockchain smart contracts
KW  - Zero-dynamic attacks
KW  - Reliability engineering
KW  - Cyber security
AB  - The architecture of Industrial Control Systems (ICS) has evolved into an integrated cyber-physical system, introducing covert, zero-dynamic cyberattack vectors that threaten the reliability of ICS. We address two issues: (1) how to use decentralized solutions to defend resource-constrained ICS against highly covert zero-dynamic attacks; (2) how to improve performance (meeting real-time, high-frequency interaction demands) while enhancing reliability via decentralization. We propose a defense model integrating blockchain, zero-knowledge proofs, and smart contract (SC) obfuscation to bolster ICS resilience. A customized zk-SNARK algorithm enables efficient identity authentication, completed in under 3 ms. The Garble framework obfuscates SCs, concealing ICS device IP addresses and disrupting attack chains. A blockchain acts as a secure intermediary between the engineer workstation (EW) and programmable logic controller (PLC). To reduce blockchain overhead, we refine a proportional–integral–derivative (PID)–based roulette wheel algorithm. Obfuscated SCs resist decompilation by tools such as Objdump, ensuring robust protection. Our node selection mechanism balances security and diversity, mitigating systemic biases like the Matthew effect. By leveraging blockchain to supply computational power for encrypting and protecting ICS data flows, we offer new insights into defending ICS against highly covert cyberattacks. Experimental evaluation validates the model’s effectiveness under real-world ICS scenarios.
ER  - 

TY  - JOUR
T1  - Workplace security and privacy implications in the GenAI age: A survey
AU  - Diro, Abebe
AU  - Kaisar, Shahriar
AU  - Saini, Akanksha
AU  - Fatima, Samar
AU  - Hiep, Pham Cong
AU  - Erba, Fikadu
JO  - Journal of Information Security and Applications
VL  - 89
SP  - 103960
PY  - 2025
DA  - 2025/03/01/
SN  - 2214-2126
DO  - https://doi.org/10.1016/j.jisa.2024.103960
UR  - https://www.sciencedirect.com/science/article/pii/S221421262400262X
KW  - Cybersecurity
KW  - Generative AI
KW  - ChatGPT
KW  - Bard
KW  - Privacy
KW  - Security
KW  - Ethics
AB  - Generative Artificial Intelligence (GenAI) is transforming the workplace, but its adoption introduces significant risks to data security and privacy. Recent incidents underscore the urgency of addressing these issues. This comprehensive survey investigates the implications of GenAI integration in workplaces, focusing on its impact on organizational operations and security. We analyze vulnerabilities within GenAI systems, threats they face, and repercussions of AI-driven workplace monitoring. By examining diverse attack vectors like model attacks and automated cyberattacks, we expose their potential to undermine data integrity and privacy. Unlike previous works, this survey specifically focuses on the security and privacy implications of GenAI within workplace settings, addressing issues like employee monitoring, deepfakes, and regulatory compliance. We delve into emerging threats during model training and usage phases, proposing countermeasures such as differential privacy for training data and robust authentication for access control. Additionally, we provide a comprehensive analysis of evolving regulatory frameworks governing AI tools globally. Based on our comprehensive analysis, we propose targeted recommendations for future research and policy-making to promote responsible and secure adoption of GenAI in the workplace, such as incentivizing the development of explainable AI (XAI) and establishing clear guidelines for ethical data usage. This survey equips stakeholders with a comprehensive understanding of GenAI’s complex workplace landscape, empowering them to harness its benefits responsibly while mitigating risks.
ER  - 

TY  - JOUR
T1  - Toward greener logistics: uncovering key enablers of the physical internet using AI-powered theme analysis
AU  - Hirata, Enna
AU  - Sunio, Varsolo
AU  - Thompson, Russell G.
AU  - Foliente, Greg
JO  - Cleaner Logistics and Supply Chain
VL  - 17
SP  - 100263
PY  - 2025
DA  - 2025/12/01/
SN  - 2772-3909
DO  - https://doi.org/10.1016/j.clscn.2025.100263
UR  - https://www.sciencedirect.com/science/article/pii/S2772390925000629
KW  - Natural language processing
KW  - Topic modeling
KW  - Sustainability
KW  - Industry 4.0
KW  - Physical Internet
AB  - Transitioning to a zero-carbon, sustainable logistics ecosystem requires a fundamental shift in how physical, digital, and organizational systems interact. The Physical Internet (PI) presents a transformative vision for logistics and supply chain management by providing a blueprint for decarbonized, circular, and resilient operations. However, the complex, interdisciplinary nature of its knowledge base presents challenges for coordinated global implementation. This study introduces a dual-model natural language processing (NLP) approach combining transformer-based topic modeling (BERTopic) with maximal marginal relevance (MMR) and generative pretrained transformer (GPT) techniques. This hybrid approach enables the extraction and synthesis of key research themes from over 2600 scientific publications on PI. Thematic analysis revealed eight critical domains, ranging from smart infrastructure and energy systems to cybersecurity and governance that are foundational to PI’s sustainable development and adoption. Furthermore, we evaluated the alignment of these themes with the PI roadmaps and the UN sustainable development goals (SDGs), especially SDG 9 (Industry, Innovation and Infrastructure), SDG 11 (Sustainable Cities and Communities), and SDG 13 (Climate Action). Results highlight the importance of interoperability, digital twin technologies, renewable energy integration, and secure data exchange for achieving greener and more adaptive logistics networks. This work provides a scalable, data-driven methodology for strategic decision-making and knowledge synthesis, thereby supporting the sustainable transformation of logistics and supply chains.
ER  - 

TY  - JOUR
T1  - MalwareNet: an intelligent malware detection and classification using advanced extreme leaning machine in edge computing environment
AU  - Shailaja, P.
AU  - Jahan, Thanveer
AU  - Sharmila, Karramreddy
AU  - Varma, P. Bharath Siva
AU  - Arra, Swetha
AU  - Kumar, Pala Mahesh
JO  - Egyptian Informatics Journal
VL  - 31
SP  - 100714
PY  - 2025
DA  - 2025/09/01/
SN  - 1110-8665
DO  - https://doi.org/10.1016/j.eij.2025.100714
UR  - https://www.sciencedirect.com/science/article/pii/S1110866525001070
KW  - Intelligent malware detection
KW  - Extreme learning machine
KW  - Edge computing environment
KW  - Independent component analysis
KW  - Hybrid wrapper with filter
KW  - Feature selection
KW  - Security threats
AB  - Malware continues to wreak havoc on global digital ecosystems, with companies facing an average financial loss of $4.35 million per data breach in recent years. At the same time, individual users suffer from identity theft, affecting over 1.1 billion personal records annually. Existing malware detection systems often struggle with high latency in centralized cloud environments and fail to generalize across diverse malware variants generated by edge devices. To address these challenges, this work introduces MalwareNet, a novel multiclass malware detection network designed specifically for edge computing environments. MalwareNet innovatively processes data directly on edge devices, enabling real-time detection and classification with minimal latency and enhanced data privacy. The system employs a robust preprocessing pipeline to clean raw data, followed by Independent Component Analysis (ICA) to extract discriminative features while reducing dataset dimensionality. A Hybrid Wrapper-Filter (HWF) feature selection method optimizes feature subsets by integrating wrapper and filter techniques, ensuring compatibility with the chosen machine-learning classifier to maximize classification accuracy. The Extreme Learning Machine (ELM), selected for its rapid training and strong generalization, classifies malware into distinct categories, effectively identifying threats in edge settings. By combining edge-based processing, advanced feature engineering, and efficient classification, MalwareNet offers a scalable and reliable solution, significantly advancing malware detection capabilities for resource-constrained environments and providing a foundation for future adaptive security systems. Experimental evaluations on a large-scale malware dataset demonstrate the effectiveness of the proposed approach with an accuracy of 99.7 %, and F-measure of 99.55 %. The system also achieves high Jaccard index with an increment of 2.63 % in detecting and classifying malware, providing reliable security measures in edge computing environments.
ER  - 

TY  - JOUR
T1  - Linking online activity to offline behavior: A meta-review of three decades of online-to-offline scholarship with future implications for AI
AU  - Renshaw, Scott Leo
AU  - Carley, Kathleen M.
JO  - Emerging Trends in Drugs, Addictions, and Health
VL  - 4
SP  - 100154
PY  - 2024
DA  - 2024/12/01/
SN  - 2667-1182
DO  - https://doi.org/10.1016/j.etdah.2024.100154
UR  - https://www.sciencedirect.com/science/article/pii/S2667118224000138
KW  - Network analysis
KW  - Social reinforcement
KW  - Meta-review
KW  - Online influences
KW  - Offline behavior
AB  - As society grapples with the emerging significance and implications of Large Language Models (LLMs), such as OpenAI’s ChatGPT, or Google’s Gemini, as well as other advancements in modern generative Artificial Intelligence (AI), it is crucial to recognize the existing role that data, algorithms, and online social networks have already played in shaping our contemporary society. This review article provides the first comprehensive examination of the current state of knowledge, across disciplinary divides, on how online influences impact offline behaviors, laying the necessary groundwork for investigating and researching the potential impact that these new technologies will have on our “offline” lives. Through a deep-dive collection of articles (n=149), we review and analyze research with measurable Online-to-Offline impacts (n=88). Within this Online-to-Offline criteria, we identify five emergent cross-cutting themes, namely: Social Diffusion, Social Reinforcement, Social Boundary & Identity Maintenance, Cognitive and Attitudinal Research, and Research on Vulnerable & Marginalized Impacts. Through a second wave snowball collection process, we construct a citation network from the broader Online and Offline research literature, allowing us to locate the Online-to-Offline subset as part of a larger intellectual discussion. Finally, we conduct a Term Frequency-Inverse Document Frequency (TF-IDF) analysis of terms used in the titles of these online/offline research papers, from 1990 to 2023, to identify the evolution of researchers’ conceptualization and framing of Online and Offline research across the past 30 years. The meta-review, presentation of high-level cross-cutting interdisciplinary themes, co-citation network analysis, and TF-IDF analysis collectively provide a cohesive and deeper understanding of the research space of online/offline influences. By taking stock of the ways in which online factors have already shaped individual, group, or organizational behaviors and social dynamics broadly in “offline” contexts, this work aims to provide a cohesive theoretical and empirical foundation for future researchers to better anticipate, address, and frame the future consequences of the rapidly evolving digitally influenced landscape we find ourselves in today.
ER  - 

TY  - JOUR
T1  - Role of digital technologies to enhance the human integration in industrial cyber–physical systems
AU  - Piardi, Luis
AU  - Leitão, Paulo
AU  - Queiroz, Jonas
AU  - Pontes, Joseane
JO  - Annual Reviews in Control
VL  - 57
SP  - 100934
PY  - 2024
DA  - 2024/01/01/
SN  - 1367-5788
DO  - https://doi.org/10.1016/j.arcontrol.2024.100934
UR  - https://www.sciencedirect.com/science/article/pii/S1367578824000038
KW  - Human integration
KW  - Human-in-the-loop
KW  - Cyber–physical systems
KW  - Digital technologies
AB  - In the digital transformation era, and particularly in Industry 5.0, humans play an active role in industrial cyber–physical systems (CPS) since they are the most flexible piece in such automated systems. However, their integration is not easy and constitutes a relevant challenge, presenting different requirements according to the activities they execute and the related integration levels, i.e., Human-in-the-Loop (HitL) and Human-in-the-Mesh (HitM). Besides the use of human-centric design approaches, the use of digital technologies, namely Internet of Things, Artificial Intelligence, virtual and augmented reality and collaborative robotics, can contribute to empower humans to perform their operations in a faster and more efficient manner. This paper discusses how emergent digital technologies can enhance a more symbiotic integration of humans in industrial CPS, contributing with the analysis of different aspects and concerns that must be considered to properly enable the HitL and HitM integration levels in CPS. Four experimental case studies are presented to demonstrate the feasibility of using digital technologies to enhance the human-CPS integration, covering HitL and HitM levels. Furthermore, some challenges related to the human-integration factors affected by the digital technologies in such environments are briefly discussed and pointed out as research directions.
ER  - 

TY  - JOUR
T1  - MFFURL: Multi-modal feature fusion-based approach for malicious URL detection
AU  - Li, Zhengfa
AU  - Huang, Chuanhe
AU  - Jia, Xudong
JO  - Computer Networks
VL  - 275
SP  - 111898
PY  - 2026
DA  - 2026/02/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2025.111898
UR  - https://www.sciencedirect.com/science/article/pii/S1389128625008643
KW  - Malicious URL detection
KW  - URL representation
KW  - Multi-modal feature fusion
KW  - Semantic feature
KW  - Lexical feature
AB  - Detecting malicious Uniform Resource Locators (URL) is crucial for enhancing network security; however, current methods often rely on a single type of feature representation, which limits their robustness and generalization capabilities. Since URLs are essentially character sequences, transforming them into informative numerical representations that fully capture their semantic, lexical, and behavioral characteristics remains a major challenge. To address this limitation, this paper proposes a multi-modal URL anomaly detection framework that integrates deep semantic, lexical, and web-based features in a unified model. Specifically, semantic information is extracted using the pre-trained CharBERT model, while lexical and web features-such as character frequency patterns and position distributions-are obtained through detailed string-level analysis. A hybrid architecture combining a Multi-Scale Convolutional Neural Network (MSCNN) and a Deep Cross Network (DCN) is designed to effectively learn complementary patterns from these heterogeneous modalities. Furthermore, an adaptive feature fusion mechanism is introduced to enhance cross-modal interaction, enabling the model to generate highly discriminative feature representations. Extensive experiments on two benchmark datasets, UD and PSU, validate the effectiveness and impact of our approach. On the UD dataset, the model achieves an accuracy of 99.85 %, precision of 99.83 %, recall of 99.53 %, and an f1-score of 99.68 %. Similarly, on the PSU dataset, it attains an accuracy of 98.98 %, precision of 98.16 %, recall of 97.93 %, and an f1-score of 98.19 %. These results not only validate the effectiveness of multi-modal information fusion methods but also demonstrate the model’s strong generalization capabilities across diverse datasets. The proposed multi-modal fusion framework offers an effective approach for URL security analysis and provides a viable solution to build more comprehensive and scalable malicious URL detection systems.
ER  - 

TY  - JOUR
T1  - Extending limited datasets with GAN-like self-supervision for SMS spam detection
AU  - Anidjar, Or Haim
AU  - Marbel, Revital
AU  - Dubin, Ran
AU  - Dvir, Amit
AU  - Hajaj, Chen
JO  - Computers & Security
VL  - 145
SP  - 103998
PY  - 2024
DA  - 2024/10/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.103998
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824003031
KW  - SMS-spamming
KW  - Fraud detection
KW  - Out of Distribution
KW  - GAN
KW  - Textual anomaly detection
AB  - Short Message Service (SMS) spamming is a harmful phishing attack on mobile phones. That is, fraudsters are trying to misuse personal user information, using tricky text messages, sometimes included with a fake URL that asks for this personal information, such as passwords, usernames, etc. In the world of Machine Learning, several approaches have tried to attitudinize this problem, but the lack of available data resources was commonly the main drawback towards a good enough solution. Therefore, in this paper, we suggest a dataset extension technique for small datasets, based on an Out Of Distribution (OOD) metric. Hence, different approaches such as Generative Adversarial Networks (GANs) were suggested, yet GANs are hard to train whenever datasets are limited in terms of sample size. In this paper, we present a GAN-like method that imitates the generator concept of GANs for the purpose of limited datasets extension, using the OOD concept. By using a sophisticated text generation method, we show how to apply it over datasets from the domain of fraud and spam detection in SMS messages, and achieve over 25% relative improvement, compared to two other solutions. In addition, due to the class imbalance in typical spam datasets, our approach is being examined over another dataset, in order to verify that the false alarm rate is low enough.
ER  - 

TY  - JOUR
T1  - Frequency adaptive enhancement and multi-view feature fusion for image manipulation detection
AU  - Tang, Wenzhong
AU  - Gao, Shijun
AU  - Wang, Shuai
AU  - Lv, Wenrui
AU  - Xu, Xu
JO  - Neurocomputing
VL  - 658
SP  - 131782
PY  - 2025
DA  - 2025/12/28/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2025.131782
UR  - https://www.sciencedirect.com/science/article/pii/S0925231225024543
KW  - Image tampering detection
KW  - Deep learning
KW  - Frequency-domain attention
KW  - Multi-view fusion
AB  - There are more and more manipulated images on the internet, and some of them mislead individuals and the public, which could be a potential threat to social security. The rapidly developing deep-learning method provides an effective solution to detect these manipulated images. It is significant for the manipulation detection task to extract and capture tamper-related features from the input images. To this end, we propose a multi-view features fused network with a frequency domain attention module and convolutional additive self-attention. First, the attention module is designed to adaptively highlight tampering features through frequency conversion and learnable weights based on a prior experience. It is helpful for extracting manipulation features to highlight the high-frequency information while suppressing the low-frequency. Second, a dual-branch network is proposed, which can extract features from the frequency and noise domains and properly combine them to segment manipulation regions. Experimental results on eight typical datasets demonstrate that our network is effective and has surpassed peer algorithms. Our code will be available at https://github.com/XuXu/DNMFNet.
ER  - 

TY  - JOUR
T1  - Coding style matters: Scalable and efficient identification of memory management functions in monolithic firmware
AU  - Cai, Ruijie
AU  - Zhang, Zhaowei
AU  - Zhu, Xiaoya
AU  - Zhang, Yongguang
AU  - Yin, Xiaokang
AU  - Liu, Shengli
JO  - Journal of Systems and Software
VL  - 228
SP  - 112472
PY  - 2025
DA  - 2025/10/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2025.112472
UR  - https://www.sciencedirect.com/science/article/pii/S0164121225001402
KW  - Memory management function identification
KW  - Firmware security
KW  - Memory corruption vulnerabilities
KW  - Vulnerability detection
KW  - Monolithic firmware
KW  - Coding style
AB  - The occurrence of memory corruption vulnerabilities is often closely associated with improper use or implementation of memory management functions. Monolithic firmware typically uses custom memory management functions and lacks information such as function names, which poses significant challenges for vulnerability detection. Therefore, it is crucial for the identification of memory management functions. Existing methods are rendered ineffective due to the absence of metadata, and the diversity in implementation across different firmware images further complicates the identification process. To address the above problem, we introduce MemIdent, a new method leveraging the coding style inherent in identifying memory management functions. MemIdent is engineered to be scalable and efficient, capable of discerning consistent call features across various compiler optimizations and instruction architectures. It leverages three key observations derived from an in-depth analysis of monolithic firmware: the regularity in memory allocation calls, the co-occurrence of allocation and deallocation functions, and the statistical prominence of these features. MemIdent extracts features of call site such as function parameter types and return values using data flow analysis, which are then analyzed through statistical patterns to identify memory allocation and deallocation functions. We evaluate MemIdent’s performance using 44 firmware images covering 6 vendors (i.e., Tenda, Cisco, SonicWall, D-Link, TP-Link, and Comtech) across 3 architectures (MIPS, ARM, and PPC). The experimental results demonstrate that MemIdent has higher accuracy, greater efficiency, and better generality than state-of-the-art (SOTA) approaches, including Heapster, IDA Lumina, and MLM, which offers a significant advancement in memory management function identification methods for monolithic firmware.
ER  - 

TY  - JOUR
T1  - Artificial intelligence and machine learning for distributed energy resource management systems: Applications, frameworks, and future directions
AU  - Satpathy, Priya Ranjan
AU  - Ramachandaramurthy, Vigna Kumaran
JO  - Applied Energy
VL  - 403
SP  - 127109
PY  - 2026
DA  - 2026/01/15/
SN  - 0306-2619
DO  - https://doi.org/10.1016/j.apenergy.2025.127109
UR  - https://www.sciencedirect.com/science/article/pii/S0306261925018392
KW  - Distributed energy resource (DER)
KW  - Artificial intelligence (AI)
KW  - Machine learning (ML)
KW  - Optimization
KW  - Forecasting
KW  - Distributed energy resource management system (DERMS)
AB  - The integration of distributed energy resources (DERs) introduces significant operational challenges to conventional power systems due to their decentralized, variable, and bidirectional nature. This paper presents a comprehensive review of artificial intelligence (AI) and machine learning (ML) techniques applied within distributed energy resource management systems (DERMS). Core applications, such as forecasting, optimization, real-time control, demand-side management, energy trading, and cybersecurity, are systematically analyzed using a structured taxonomy that encompasses deep learning, reinforcement learning, federated learning, and explainable AI. A layered framework is proposed to align the AI/ML lifecycle with DERMS functional layers, bridging the gap between theoretical research and practical deployment. Benchmark datasets are designed to standardize algorithm evaluation, while comparative analyses across forecasting, optimization, and fault detection reveal performance differences among techniques. Economic case studies and cost-benefit assessments further underscore the operational and financial benefits of AI-enabled DERMS. Finally, the paper identifies prevailing limitations across edge AI, hybrid modeling, and privacy-preserving learning, and outlines future directions for intelligent, resilient, and scalable distributed energy systems. Overall, this study serves as a foundational reference for researchers, industry stakeholders, and policymakers seeking to advance smart, resilient, and scalable DERMS for future energy infrastructures.
ER  - 

TY  - JOUR
T1  - Attack Behavior Extraction Based on Heterogeneous Cyberthreat Intelligence and Graph Convolutional Networks
AU  - Tang, Binhui
AU  - Wang, Junfeng
AU  - Qiu, Huanran
AU  - Yu, Jian
AU  - Yu, Zhongkun
AU  - Liu, Shijia
JO  - Computers, Materials and Continua
VL  - 74
IS  - 1
SP  - 235
EP  - 252
PY  - 2022
DA  - 2022/08/16/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2023.029135
UR  - https://www.sciencedirect.com/science/article/pii/S1546221822001564
KW  - Attack behavior extraction
KW  - cyber threat intelligence (CTI)
KW  - graph convolutional network (GCN)
KW  - heterogeneous textual network (HTN)
AB  - The continuous improvement of the cyber threat intelligence sharing mechanism provides new ideas to deal with Advanced Persistent Threats (APT). Extracting attack behaviors, i.e., Tactics, Techniques, Procedures (TTP) from Cyber Threat Intelligence (CTI) can facilitate APT actors’ profiling for an immediate response. However, it is difficult for traditional manual methods to analyze attack behaviors from cyber threat intelligence due to its heterogeneous nature. Based on the Adversarial Tactics, Techniques and Common Knowledge (ATT&CK) of threat behavior description, this paper proposes a threat behavioral knowledge extraction framework that integrates Heterogeneous Text Network (HTN) and Graph Convolutional Network (GCN) to solve this issue. It leverages the hierarchical correlation relationships of attack techniques and tactics in the ATT&CK to construct a text network of heterogeneous cyber threat intelligence. With the help of the Bidirectional Encoder Representation from Transformers (BERT) pretraining model to analyze the contextual semantics of cyber threat intelligence, the task of threat behavior identification is transformed into a text classification task, which automatically extracts attack behavior in CTI, then identifies the malware and advanced threat actors. The experimental results show that F1 achieve 94.86% and 92.15% for the multi-label classification tasks of tactics and techniques. Extend the experiment to verify the method’s effectiveness in identifying the malware and threat actors in APT attacks. The F1 for malware and advanced threat actors identification task reached 98.45% and 99.48%, which are better than the benchmark model in the experiment and achieve state of the art. The model can effectively model threat intelligence text data and acquire knowledge and experience migration by correlating implied features with a priori knowledge to compensate for insufficient sample data and improve the classification performance and recognition ability of threat behavior in text.
ER  - 

TY  - JOUR
T1  - IoT-PRIDS: Leveraging packet representations for intrusion detection in IoT networks
AU  - Zohourian, Alireza
AU  - Dadkhah, Sajjad
AU  - Molyneaux, Heather
AU  - Neto, Euclides Carlos Pinto
AU  - Ghorbani, Ali A.
JO  - Computers & Security
VL  - 146
SP  - 104034
PY  - 2024
DA  - 2024/11/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104034
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824003390
KW  - Internet of Things (IoT)
KW  - IoT security
KW  - IoT profiling
KW  - Intrusion detection
KW  - Intrusion Detection System (IDS)
AB  - The Internet of Things (IoT) devices have been integrated into almost all everyday applications of human life such as healthcare, transportation and agriculture. This widespread adoption of IoT has opened a large threat landscape to computer networks, leaving security gaps in IoT-enabled networks. These resource-constrained devices lack sufficient security mechanisms and become the weakest link in our in computer networks and jeopardize systems and data. To address this issue, Intrusion Detection Systems (IDS) have been proposed as one of many tools to mitigate IoT related intrusions. While IDS have proven to be a crucial tools for threat detection, their dependence on labeled data and their high computational costs have become obstacles to real life adoption. In this work, we present IoT-PRIDS, a new framework equipped with a host-based anomaly-based intrusion detection system that leverages “packet representations” to understand the typical behavior of devices, focusing on their communications, services, and packet header values. It is a lightweight non-ML model that relies solely on benign network traffic for intrusion detection and offers a practical way for securing IoT environments. Our results show that this model can detect the majority of abnormal flows while keeping false alarms at a minimum and is promising to be used in real-world applications.
ER  - 

TY  - JOUR
T1  - Deep neural network for text anomaly detection in SIoT
AU  - Mu, Jie
AU  - Zhang, Xianchao
AU  - Li, Yuangang
AU  - Guo, Jun
JO  - Computer Communications
VL  - 178
SP  - 286
EP  - 296
PY  - 2021
DA  - 2021/10/01/
SN  - 0140-3664
DO  - https://doi.org/10.1016/j.comcom.2021.08.016
UR  - https://www.sciencedirect.com/science/article/pii/S0140366421003108
KW  - Anomaly detection
KW  - Text mining
KW  - Social Internet of Things (SIoT)
AB  - Unsupervised textual anomaly detection, which discovers anomalies from unlabeled texts, is critical to improve the cybersecurity and interaction ability among the objects in the Social Internet of Things (SIoT). Recently, detecting anomalies by deep neural networks has become a popular trend. Specially, context vector data description (CVDD) method shows the promising performance. However, CVDD has two limitations: (1) it uses an one-class classification objective to constrain the sentence embeddings, which leads the learned embeddings to lose content information of text. (2) Scalar-based attention weights, which are used to extract sentence features, fail to focus on dimensional properties in a word. Learning the text contents and the dimensional properties is important for detection task in SIoT, which can help detector capture the difference between normal and anomaly texts. To overcome these limits, this paper proposes a textual anomaly detection network. First, an adversarial training strategy is designed to fight against the problem of missing content information. Second, a textual anomaly detection module with multiple dimensional transformation matrices is constructed to learn dimensional properties of words in diverse semantic subspaces. Experimental results on several textual datasets show that our proposed method outperforms CVDD and other strong baselines.
ER  - 

TY  - JOUR
T1  - From screens to scenes: A survey of embodied AI in healthcare
AU  - Liu, Yihao
AU  - Cao, Xu
AU  - Chen, Tingting
AU  - Jiang, Yankai
AU  - You, Junjie
AU  - Wu, Minghua
AU  - Wang, Xiaosong
AU  - Feng, Mengling
AU  - Jin, Yaochu
AU  - Chen, Jintai
JO  - Information Fusion
VL  - 119
SP  - 103033
PY  - 2025
DA  - 2025/07/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2025.103033
UR  - https://www.sciencedirect.com/science/article/pii/S156625352500106X
KW  - Embodied artificial intelligence
KW  - Multi-modality
KW  - Healthcare
KW  - Surgical robot
KW  - Large language model
KW  - Multimodal large language model
KW  - World model
AB  - Healthcare systems worldwide face persistent challenges in efficiency, accessibility, and personalization. Modern artificial intelligence (AI) has shown promise in addressing these issues through precise predictive modeling; however, its impact remains constrained by limited integration into clinical workflows. Powered by modern AI technologies such as multimodal large language models and world models, Embodied AI (EmAI) represents a transformative frontier, offering enhanced autonomy and the ability to interact with the physical world to address these challenges. As an interdisciplinary and rapidly evolving research domain, “EmAI in healthcare” spans diverse fields such as algorithms, robotics, and biomedicine. This complexity underscores the importance of timely reviews and analyses to track advancements, address challenges, and foster cross-disciplinary collaboration. In this paper, we provide a comprehensive overview of the “brain” of EmAI for healthcare, wherein we introduce foundational AI algorithms for perception, actuation, planning, and memory, and focus on presenting the healthcare applications spanning clinical interventions, daily care & companionship, infrastructure support, and biomedical research, covering 35 specialized tasks. These significant advancements have the potential to enable personalized care, enhance diagnostic accuracy, and optimize treatment outcomes. Despite its promise, the development of EmAI for healthcare is hindered by critical challenges such as safety concerns, gaps between simulation platforms and real-world applications, the absence of standardized benchmarks, and uneven progress across interdisciplinary domains. We discuss the technical barriers and explore ethical considerations, offering a forward-looking perspective on the future of EmAI in healthcare. A hierarchical framework of intelligent levels for EmAI systems is also introduced to guide further development. By providing systematic insights, this work aims to inspire innovation and practical applications, paving the way for a new era of intelligent, patient-centered healthcare.
ER  - 

TY  - JOUR
T1  - Towards prompt tuning-based software vulnerability assessment with continual learning
AU  - Xue, Jiacheng
AU  - Chen, Xiang
AU  - Wang, Jiyu
AU  - Cui, Zhanqi
JO  - Computers & Security
VL  - 150
SP  - 104184
PY  - 2025
DA  - 2025/03/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104184
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824004899
KW  - Software vulnerability assessment
KW  - Large language model
KW  - Prompt tuning
KW  - Continual learning
KW  - Information fusion
AB  - Software vulnerability assessment (SVA) has become increasingly important due to the growing reliance on various software systems and the rising complexity of cyber threats. SVA aims to quickly identify and remediate high-risk vulnerabilities in software systems, which helps protect sensitive information and maintain the integrity of digital infrastructure. In our study, we focus on prompt tuning-based SVA. Prompt tuning reduces computational costs by tuning the input prompts instead of the entire model. We further incorporate the continual learning paradigm to enable the SVA model to adapt to new vulnerabilities as they emerge dynamically. This paradigm ensures the SVA model remains up-to-date, reduces the risk of catastrophic forgetting, and provides resource-efficient updates. To achieve this goal, we propose a novel method SVACL. SVACL combines confidence-based replay and regularization methods for continual learning. Additionally, SVACL uses both source code and vulnerability descriptions to create hybrid prompts for prompt tuning with the pre-trained model CodeT5. Experimental results demonstrate that SVACL outperforms state-of-the-art SVA baselines by 20% to 380% in terms of MCC performance measure. Finally, our ablation study results confirm the effectiveness of the component settings (such as confidence-based replay, regularization method, vulnerability information fusion, CodeT5, and hybrid prompts) for SVACL. Therefore, our study provides the first promising step toward prompt tuning-based SVA with continual learning.
ER  - 

TY  - JOUR
T1  - An ethical assessment framework for AI security and ethics in smart grid
AU  - Zhang, Yiying
AU  - Zhao, Congcong
AU  - Meng, Ziang
AU  - Lai, Chun Sing
AU  - Chen, Xi
JO  - Global Energy Interconnection
PY  - 2025
DA  - 2025/11/21/
SN  - 2096-5117
DO  - https://doi.org/10.1016/j.gloei.2025.10.006
UR  - https://www.sciencedirect.com/science/article/pii/S2096511725001252
KW  - Smart grid
KW  - Artificial intelligence technology
KW  - Ethics of science and technology
KW  - Assessment framework
AB  - The advancement of smart grid, facilitated by the extensive integration of information communication, automated control, and artificial intelligence (AI) technologies, signifies a significant transformation of the power system towards holistic perception, intelligent management, and secure operation. This article focuses on the security and ethical compliance of smart grid, intending to offer guiding insights for this new technological domain. This study initially delineates the potential applications, technical attributes, and design of smart grid, followed by a thorough examination of the security threats and ethical dilemmas arising from technological advancements. This study examines the pivotal role of AI in smart grid and its intricate interplay with security and ethical concerns. It performs a comprehensive analysis of the possible technical deficiencies and ethical challenges of AI systems in smart grid and assesses the extensive repercussions that these difficulties may entail. This study presents a security ethics evaluation methodology for smart grid, which thoroughly examines the ethical implications of AI technology in power grid applications and identifies existing obstacles and threats. This paper conducts a thorough policy analysis to evaluate the present security and ethical conditions of smart grid, with the objective of offering substantive theoretical support to enhance their security and ethical advancement, thereby fostering their healthy and sustainable development.
ER  - 

TY  - JOUR
T1  - Human-understandable explanation for software vulnerability prediction
AU  - Nguyen, Hong Quy
AU  - Hoang, Thong
AU  - Dam, Hoa Khanh
AU  - Su, Guoxin
AU  - Xing, Zhenchang
AU  - Lu, Qinghua
AU  - Sun, Jiamou
JO  - Journal of Systems and Software
VL  - 228
SP  - 112455
PY  - 2025
DA  - 2025/10/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2025.112455
UR  - https://www.sciencedirect.com/science/article/pii/S0164121225001232
KW  - Vulnerability prediction
KW  - Explainable AI
KW  - Text generation
KW  - Key aspects
AB  - Recent advances in deep learning have significantly improved the performance of software vulnerability prediction (SVP). To enhance trustworthiness, the SVP highlights predicted lines of code (LoC) that may be vulnerable. However, providing LoC alone is often insufficient for software practitioners, as it lacks detailed information about the nature of the vulnerability. This paper introduces a novel framework that is built on SVP by offering additional explanatory information based on the suggested LoC. Similar to security reports, our framework comprehensively explains the vulnerability aspects, such as Root Cause, Impact, Attack Vector, and Vulnerability Type. The proposed framework is powered by transformer architectures. Specifically, we leverage pre-trained language models for code to fine-tune on two practical datasets: BigVul and Vulnerability Key Aspect, ensuring our framework’s applicability to real-world scenarios. Experiments using the ROUGE and BLEU scores as evaluation metrics show that our framework achieves better performance with CodeT5+, statistically outperforming a baseline study in generating key vulnerability aspects. Additionally, we conducted a small-scale user study with experienced software practitioners to assess the effectiveness of the framework. The results show that 72% of the participants found our framework helpful in accepting the SVP results, and 68% rated the additional explanations as moderately to extremely useful. Editor’s note: Open Science material was validated by the Journal of Systems and Software Open Science Board.
ER  - 

TY  - JOUR
T1  - Context-aware embeddings for robust multiclass fraudulent URL detection in online social platforms
AU  - Afzal, Sara
AU  - Asim, Muhammad
AU  - Beg, Mirza Omer
AU  - Baker, Thar
AU  - Awad, Ali Ismail
AU  - Shamim, Nouman
JO  - Computers and Electrical Engineering
VL  - 119
SP  - 109494
PY  - 2024
DA  - 2024/10/01/
SN  - 0045-7906
DO  - https://doi.org/10.1016/j.compeleceng.2024.109494
UR  - https://www.sciencedirect.com/science/article/pii/S004579062400421X
KW  - Artificial neural networks
KW  - BERT embeddings
KW  - URL classification
KW  - Securing online social networks
AB  - The current ubiquity of online social networks (OSNs) cannot be overstated, and they have over 4.8 billion users worldwide. These platforms have become integrated into modern life, representing an important means of communication and information sharing. However, this widespread popularity has also drawn the attention of cybercriminals, who seek to exploit OSNs using deceptive Uniform Resource Locators (URLs) as their weapons of choice. Conventional URL-classification methods, which rely on post-access features or static analysis, face significant limitations; they struggle to keep pace with the ever-evolving tactics of cybercriminals, and they often lack the granularity required for precise URL categorization. The methodology proposed herein takes a different path, leveraging the power of an artificial neural network (ANN) in tandem with Bidirectional Encoder Representations from Transformers (BERT) to extract contextual embeddings from URLs. By combining the cutting-edge capabilities of ANNs and BERT, we introduce an efficient approach to safeguarding OSN users from the insidious threats lurking behind deceptive URLs by classifying them into five distinct categories: benign, defacement, phishing, malware, and spam. The proposed approach was found to achieve an impressive accuracy rate of 98.0%, surpassing the previous best of 97.92%. This technique thus has the potential to serve as a crucial defense mechanism for the billions of individuals who rely on OSNs for their social and informational needs.
ER  - 

TY  - JOUR
T1  - Prompting GPT–4 to support automatic safety case generation
AU  - Sivakumar, Mithila
AU  - Belle, Alvine B.
AU  - Shan, Jinjun
AU  - Khakzad Shahandashti, Kimya
JO  - Expert Systems with Applications
VL  - 255
SP  - 124653
PY  - 2024
DA  - 2024/12/01/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2024.124653
UR  - https://www.sciencedirect.com/science/article/pii/S0957417424015203
KW  - Safety cases
KW  - Safety assurance
KW  - Machine learning
KW  - Large language models
KW  - Generative AI
KW  - Requirements engineering
AB  - In the ever-evolving field of software engineering, the advent of large language models and conversational interfaces, exemplified by ChatGPT, represents a significant revolution. While their potential is evident in various domains, this paper expands upon our previous research, where we experimented with GPT–4, on its ability to create safety cases. A safety case is a structured argument supported by a body of evidence to demonstrate that a given system is safe to operate in a given environment. In this paper, we first determine GPT–4’s comprehension of the Goal Structuring Notation (GSN), a well-established notation for visually representing safety cases. Additionally, we conduct four distinct experiments using GPT–4 to evaluate its ability to generate safety cases within a specified system and application domain. To assess GPT–4’s performance in this context, we compare the results it produces with the ground-truth safety cases developed for an X-ray system, a machine learning-enabled component for tire noise recognition in a vehicle, and a lane management system from the automotive domain. This comparison enables us to gain valuable insights into the model’s generative capabilities. Our findings indicate that GPT–4 is able to generate moderately accurate and reasonable safety cases.
ER  - 

TY  - JOUR
T1  - Threat intelligence named entity recognition techniques based on few-shot learning
AU  - Wang, Haiyan
AU  - Yang, Weimin
AU  - Feng, Wenying
AU  - Zeng, Liyi
AU  - Gu, Zhaoquan
JO  - Array
VL  - 23
SP  - 100364
PY  - 2024
DA  - 2024/09/01/
SN  - 2590-0056
DO  - https://doi.org/10.1016/j.array.2024.100364
UR  - https://www.sciencedirect.com/science/article/pii/S2590005624000304
KW  - Named entity recognition
KW  - Few-shot learning
KW  - Threat intelligence
KW  - Multi-view learning
AB  - In today’s digital and internet era, threat intelligence analysis is of paramount importance to ensure network and information security. Named Entity Recognition (NER) is a fundamental task in natural language processing, aimed at identifying and extracting specific types of named entities from text, such as person names, locations, organization names, dates, times, currencies, and more. The quality of entities determines the effectiveness of upper-layer applications such as knowledge graphs. Recently, there has been a scarcity of training data in the threat intelligence field, and single models suffer from poor generalization ability. To address this, we propose a multi-view learning model, named the Few-shot Threat Intelligence Named Entity Recognition Model (FTM). We enhance the fusion method based on FTM, and further propose the FTM-GRU (Gate Recurrent Unit) model. The FTM model is based on the Tri-training algorithm to collaboratively train three few-shot NER models, leveraging the complementary nature of different model views to enable them to capture more threat intelligence domain knowledge at the coding level.FTM-GRU improves the fusion of multiple views. FTM-GRU uses the improved GRU model structure to control the memory and forgetting of view information, and introduces a relevance calculation unit to avoid redundancy of view information while highlighting important semantic features. We label and construct a few-shot Threat Intelligence Dataset (TID), and experiments on TID as well as the publicly available National Vulnerability Database (NVD) validate the effectiveness of our model for NER in the threat intelligence domain. Experimental results demonstrate that our proposed model achieves better recognition results in the task.
ER  - 

TY  - JOUR
T1  - NFIoT-GATE-DTL IDS: Genetic algorithm-tuned ensemble of deep transfer learning for NetFlow-based intrusion detection system for internet of things
AU  - Li, Jing
AU  - Chen, Hewan
AU  - Othman, Mohd Shahizan
AU  - Salim, Naomie
AU  - Yusuf, Lizawati Mi
AU  - Kumaran, Shamini Raja
JO  - Engineering Applications of Artificial Intelligence
VL  - 143
SP  - 110046
PY  - 2025
DA  - 2025/03/01/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2025.110046
UR  - https://www.sciencedirect.com/science/article/pii/S0952197625000466
KW  - Internet of things
KW  - Genetic algorithm
KW  - Deep transfer learning
KW  - Ensemble learning
KW  - Cybersecurity
KW  - NetFlow
KW  - Intrusion detection system
AB  - Industry 5.0 requires robust Internet of Things (IoT) networks, which are constantly vulnerable to cyber threats. Despite contributions in intrusion detection systems (IDS), creating generalized attack classification models remains a challenge. Conventional machine learning or deep learning-driven IDSs struggle to retain learned knowledge and to keep up with rapidly increasing IoT threats, whereas transfer learning-based models may lose the resilience required for model generalization. Thus, this study proposes a Genetic Algorithm-Tuned Ensemble of Deep Transfer Learning for NetFlow-Based Intrusion Detection System for Internet of Things (NFIoT-GATE-DTL IDS) to fill the gap. Two public NetFlow IoT datasets are preprocessed and transformed into three-dimensional images for convolutional neural networks (CNNs). Six pre-trained CNNs, including Xception, Inception, MobileNet, MobileNetV2, DenseNet121, and EfficientNetB0, undergo hyperparameter optimization using a Genetic Algorithm (GA). The top-five models are then combined using a soft voting ensemble to boost detection robustness across diverse attack types. Validation methods are employed, including assessing the impact of GA optimization, comparing it to optimizers like the covariance matrix adaptation evolution strategy and the coyote optimization algorithm, and comparing it to cutting-edge studies. The proposed framework consistently achieves 100% accuracy across 15 attack classes, including three highly minority threats like backdoors, ransomware, and theft in IoT networks. Furthermore, the NFIoT-GATE-DTL IDS outperforms recent methodologies, achieving a 5–7% multi-classification higher accuracy on average. This research significantly contributes to a robust IDS with a high detection rate for NetFlow-based IoT networks.
ER  - 

TY  - JOUR
T1  - ScamGen: Unveiling psychological patterns in tele-scam through advanced template-augmented corpus generation
AU  - Han, Xu
AU  - Li, Qiang
AU  - Qi, Yaling
AU  - Cao, Hongbo
AU  - Pedrycz, Witold
AU  - Wang, Wei
JO  - Computers in Human Behavior
VL  - 162
SP  - 108451
PY  - 2025
DA  - 2025/01/01/
SN  - 0747-5632
DO  - https://doi.org/10.1016/j.chb.2024.108451
UR  - https://www.sciencedirect.com/science/article/pii/S0747563224003194
KW  - Telephone scam
KW  - Psychological impacts
KW  - Data augmentation
KW  - Open dataset
AB  - Telephone scams, with their profound psychological impact, often compel victims to make hasty and severe decisions. Studying these scams is challenging due to the scarcity of comprehensive datasets, a result of the private nature of telephone interactions. In this paper, we introduce ScamGen, a template-based data augmentation technique designed to enhance Chinese telephone scam data. ScamGen leverages psychological insights to generate diverse and realistic scam scenarios, focusing on the psychological dynamics between scammers and victims. This novel approach integrates psychological theory with data augmentation, diverging from traditional methods by emphasizing scammer–victim interactions. Our method begins with a multi-source data collection framework, compiling an initial seed dataset of tele-scam samples. Using sentence- and word-level perturbations, we expand this seed data to create a comprehensive and diverse dataset covering a wide range of scam scenarios. Rigorous evaluations demonstrate that ScamGen outperforms large language models in generating high-quality, varied datasets. Additionally, we develop five deep learning models for intent detection on this dataset, with BERT achieving the highest precision at 86.68%. The dataset, which will be made publicly available, marks a significant step toward understanding scammer tactics and improving tele-scam detection systems.
ER  - 

TY  - JOUR
T1  - Interactive Process Drift Detection (IPDD) for condition-based maintenance using process mining
AU  - Vecino Sato, Denise Maria
AU  - Ruschel, Edson
AU  - Scalabrin, Edson Emilio
AU  - de Freitas Rocha Loures, Eduardo
AU  - Alves Portela Santos, Eduardo
JO  - Advanced Engineering Informatics
VL  - 66
SP  - 103397
PY  - 2025
DA  - 2025/07/01/
SN  - 1474-0346
DO  - https://doi.org/10.1016/j.aei.2025.103397
UR  - https://www.sciencedirect.com/science/article/pii/S1474034625002903
KW  - Condition-based maintenance
KW  - P-F curve
KW  - Process drift
KW  - Industrial maintenance
KW  - Process mining
AB  - This paper presents a framework based on a process drift detection tool called Interactive Process Drift Detection (IPDD). The main idea is to detect potential failures in manufacturing equipment early and apply this information in condition-based maintenance (CBM) policies. IPDD identifies possible anomalies close to the point they started based on some monitored parameters from the production process and the configured sensitivity of the detection (δ parameter). Thus, the manager can analyze the detected anomalies and apply them in the corrective or proactive domains in the maintenance strategies. The IPDD combines features, making it an efficient and versatile alternative to traditional condition-based maintenance techniques, unlike approaches such as time series analysis or machine learning, which often require large volumes of data and high computational complexity. We tested a synthetic dataset of possible manufacturing scenarios to validate the proposed framework and analyze the δ parameter. Then, we conducted a case study with a real-life dataset to validate the method and prove its effectiveness by numerical evaluation. We applied two approaches in the case study, indicating possible proactive and corrective actions. In both scenarios, we estimated a considerable reduction in the production time, 1.64% and 2.06%. The estimated reduction represents the time required to produce approximately 114 and 143 products, which indicates the solution’s potential to optimize manufacturing processes. Finally, the potential of IPDD integration with existing process data and the ease of interpretation of the results make it more practical and straightforward, facilitating adoption in modern industrial environments.
ER  - 

TY  - JOUR
T1  - Detecting technology opportunities appropriate for enterprise R&D: The synthesis analysis of industrial technical windows and enterprise competition relations
AU  - Xiang, Bo
AU  - Pan, Zhuoya
AU  - Yu, Dejian
AU  - Zuo, Wenjin
JO  - Technology in Society
VL  - 82
SP  - 102951
PY  - 2025
DA  - 2025/09/01/
SN  - 0160-791X
DO  - https://doi.org/10.1016/j.techsoc.2025.102951
UR  - https://www.sciencedirect.com/science/article/pii/S0160791X25001411
KW  - Technology opportunity detection
KW  - Industrial technical windows
KW  - Enterprise competition relations
KW  - Technology innovation management
KW  - Text analytics
AB  - Technological opportunities (TOs) are the potential and set of possibilities for technology advances in a given industry. When enterprises are able to catch and adapt to them in a timely manner, they can grab market share from competitors who have failed to adapt to these challenges. However, when there exist large gaps between enterprises and their competitors, it should be carefully evaluated whether enterprise-specific TOs are worth exploring. Moreover, faced with diversified competitive relations, enterprises also need to formulate differentiated research and development (R&D) strategies for different TOs. To address these research gaps, this paper argues for the theoretical concepts of technical windows (TWs), emerging technologies (ETs), and TOs, and proposes a three-stage framework to detect enterprise-specific TOs. This framework is empirically validated in 282,778 patents from the artificial intelligence (AI) industry of China. To begin with, this paper extracts 53 candidate technical knowledge in the AI industry based on topic modeling, which covers various application scenarios such as power, logistics and agriculture. Then, this work identifies 15 industry-specific TWs based on the impact, growth and novelty of technologies, which are calculated with pre-trained language model and aggregated mapping. Moreover, technological competitiveness that combines quality and scale is applied to carve out competitive positions of enterprises across different TWs, which is also utilized to screen out suitable TOs and formulate differentiated R&D strategies. The case of Baidu reveals these results in detail. At last, comparative and extensible fine-grained analyses confirm the robustness and theoretical value of this thesis in the technology innovation management.
ER  - 

TY  - JOUR
T1  - Cracks in the chain: A technical analysis of real-life supply chain security incidents
AU  - Kampourakis, Vyron
AU  - Kavallieratos, Georgios
AU  - Gkioulos, Vasileios
AU  - Katsikas, Sokratis
JO  - Computers & Security
VL  - 159
SP  - 104673
PY  - 2025
DA  - 2025/12/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104673
UR  - https://www.sciencedirect.com/science/article/pii/S0167404825003621
KW  - Supply chain attacks
KW  - ATT&CK MITRE
KW  - Tactics
KW  - Techniques
KW  - Procedures
KW  - Classification
KW  - Security controls
KW  - NIST SP 800-161
AB  - As Industry 5.0 drives greater digitalization and interconnectivity, supply chains have become vital to global commerce, ensuring the seamless flow of goods, services, and data. However, this reliance has also swelled the attack surface, rendering supply chains a prime target for evildoers. Meanwhile, the inherent complexity of supply chain ecosystems prevents defenders from fully applying contemporary security controls promptly and effectively. Clearly, the combination of these hindering factors has led to some of the most severe cybersecurity incidents of the past years. This study is the first to our knowledge that undertakes a comprehensive technical analysis of reported supply chain security incidents. Our analysis is done both from offensive and defensive prisms, leveraging well-established cybersecurity frameworks and guidelines, namely, the ATT&CK MITRE knowledge base matrix and the NIST SP 800-161, respectively. Furthermore, to consolidate our findings and facilitate future research initiatives, we compiled a fundamental dataset that can be used as the basis for automated analysis and potential integration with cybersecurity workflows. The key observations of a 33-incident analysis through the lens of an ATT&CK MITRE- and NIST SP 800-161-based taxonomies we propose can be wrapped up into two key points. First, the attack surface continues to expand, following an upward spiral due to the mushrooming of tactics and techniques that can facilitate the early or late stages of attacks, highlighting their complexity, sophistication, and widespread impact. Second, our findings underscore the necessity of a multifaceted approach to strengthening supply chain resilience. This includes implementing robust cybersecurity controls, comprehensive risk assessment methodologies, and transparent collaboration among suppliers, customers, and vendors to ensure adherence to state-of-the-art cybersecurity best practices.
ER  - 

TY  - JOUR
T1  - Towards safer online communities: Deep learning and explainable AI for hate speech detection and classification
AU  - Kibriya, Hareem
AU  - Siddiqa, Ayesha
AU  - Khan, Wazir Zada
AU  - Khan, Muhammad Khurram
JO  - Computers and Electrical Engineering
VL  - 116
SP  - 109153
PY  - 2024
DA  - 2024/05/01/
SN  - 0045-7906
DO  - https://doi.org/10.1016/j.compeleceng.2024.109153
UR  - https://www.sciencedirect.com/science/article/pii/S0045790624000818
KW  - Hate speech detection
KW  - Social media
KW  - Deep learning
KW  - Explainable Artificial Intelligence
KW  - Machine learning
KW  - Toxic comments
KW  - Hate speech
AB  - The internet and social media facilitate widespread idea sharing but also contribute to cyber-crimes and harmful behaviors, notably the dissemination of abusive and hateful speech, which poses a significant threat to societal cohesion. Hence, prompt and accurate detection of such harmful content is crucial. To address this issue, our study introduces a fully automated end-to-end model for hate speech detection and classification using Natural Language Processing and Deep Learning techniques. The proposed architecture comprising embedding, Convolutional, bidirectional Recurrent Neural Network, and bidirectional Long Short Term Memory layers, achieved the highest accuracy of 98.5%. Additionally, we employ explainable AI techniques, such as SHapley Additive exPlanations (SHAP) and Local Interpretable Model-agnostic Explanations (LIME), to gain insights into the performance of the proposed framework. This comprehensive approach meets the pressing demand for swift and precise detection and categorization of harmful online content.
ER  - 

TY  - JOUR
T1  - Unveiling metaverse sentiments using machine learning approaches
AU  - Natarajan, Thamaraiselvan
AU  - Pragha, P.
AU  - Dhalmahapatra, Krantiraditya
AU  - Veera Raghavan, Deepak Ramanan
JO  - Kybernetes
VL  - 54
IS  - 8
SP  - 4114
EP  - 4137
PY  - 2024
DA  - 2024/04/23/
SN  - 0368-492X
DO  - https://doi.org/10.1108/K-11-2023-2268
UR  - https://www.sciencedirect.com/science/article/pii/S0368492X24000070
KW  - Qualitative research
KW  - Behavior
KW  - Neural nets
KW  - Information technology
AB  - Purpose
The metaverse, which is now revolutionizing how brands strategize their business needs, necessitates understanding individual opinions. Sentiment analysis deciphers emotions and uncovers a deeper understanding of user opinions and trends within this digital realm. Further, sentiments signify the underlying factor that triggers one’s intent to use technology like the metaverse. Positive sentiments often correlate with positive user experiences, while negative sentiments may signify issues or frustrations. Brands may consider these sentiments and implement them on their metaverse platforms for a seamless user experience.
Design/methodology/approach
The current study adopts machine learning sentiment analysis techniques using Support Vector Machine, Doc2Vec, RNN, and CNN to explore the sentiment of individuals toward metaverse in a user-generated context. The topics were discovered using the topic modeling method, and sentiment analysis was performed subsequently.
Findings
The results revealed that the users had a positive notion about the experience and orientation of the metaverse while having a negative attitude towards the economy, data, and cyber security. The accuracy of each model has been analyzed, and it has been concluded that CNN provides better accuracy on an average of 89% compared to the other models.
Research limitations/implications
Analyzing sentiment can reveal how the general public perceives the metaverse. Positive sentiment may suggest enthusiasm and readiness for adoption, while negative sentiment might indicate skepticism or concerns. Given the positive user notions about the metaverse’s experience and orientation, developers should continue to focus on creating innovative and immersive virtual environments. At the same time, users' concerns about data, cybersecurity and the economy are critical. The negative attitude toward the metaverse’s economy suggests a need for innovation in economic models within the metaverse. Also, developers and platform operators should prioritize robust data security measures. Implementing strong encryption and two-factor authentication and educating users about cybersecurity best practices can address these concerns and enhance user trust.
Social implications
In terms of societal dynamics, the metaverse could revolutionize communication and relationships by altering traditional notions of proximity and the presence of its users. Further, virtual economies might emerge, with virtual assets having real-world value, presenting both opportunities and challenges for industries and regulators.
Originality/value
The current study contributes to research as it is the first of its kind to explore the sentiments of individuals toward the metaverse using deep learning techniques and evaluate the accuracy of these models.
ER  - 

TY  - JOUR
T1  - The end of open source? Regulating open source under the cyber resilience act and the new product liability directive
AU  - Colonna, Liane
JO  - Computer Law & Security Review
VL  - 56
SP  - 106105
PY  - 2025
DA  - 2025/04/01/
SN  - 2212-473X
DO  - https://doi.org/10.1016/j.clsr.2024.106105
UR  - https://www.sciencedirect.com/science/article/pii/S0267364924001705
KW  - Open source software
KW  - Information security
KW  - Model card
KW  - SBOM
AB  - Rooted in idealism, the open-source model leverages collaborative intelligence to drive innovation, leading to major benefits for both industry and society. As open-source software (OSS) plays an increasingly central role in driving the digitalization of society, policymakers are examining the interactions between upstream open-source communities and downstream manufacturers. They aim to leverage the benefits of OSS, such as performance enhancements and adaptability across diverse domains, while ensuring software security and accountability. The regulatory landscape is on the brink of a major transformation with the recent adoption of both the Cyber Resilience Act (CRA) as well as the Product Liability Directive (PLD), raising concerns that these laws could threaten the future of OSS. This paper investigates how the CRA and the PDL regulate OSS, specifically exploring the scope of exemptions found in the laws. It further explores how OSS practices might adapt to the evolving regulatory landscape, focusing on the importance of documentation practices to support compliance obligations, thereby ensuring OSS's continued relevance and viability. It concludes that due diligence requirements mandate a thorough assessment of OSS components to ensure their safety for integration into commercial products and services. Documentation practices like security attestations, Software Bill of Materials (SBOMs), data cards and model cards will play an increasingly important role in the software supply chain to ensure that downstream entities can meet their obligations under these new legal frameworks.
ER  - 

TY  - JOUR
T1  - DSGN: Log-based anomaly diagnosis with dynamic semantic gate networks
AU  - Yang, Haitian
AU  - Sun, Degang
AU  - Wang, Yan
AU  - Huang, Weiqing
JO  - Information Sciences
VL  - 680
SP  - 121174
PY  - 2024
DA  - 2024/10/01/
SN  - 0020-0255
DO  - https://doi.org/10.1016/j.ins.2024.121174
UR  - https://www.sciencedirect.com/science/article/pii/S0020025524010880
KW  - Log anomaly diagnosis
KW  - Statistical features
KW  - Semantic features
KW  - System behavior
KW  - Graph convolution networks
KW  - Dynamic semantic gating network
AB  - Existing log anomaly diagnosis methods still face challenges in the lack of statistical features of log messages and insufficient exploitation of textual semantic features. In order to tackle this issue, we propose a novel approach called Dynamic Semantic Gating Network (DSGN). The core idea of DSGN is to enrich the semantic representation of log texts by selectively utilizing statistical information, thus achieving an organic integration of statistical and semantic features. Specifically, DSGN incorporates a variational encoding module to encode statistical features, and a log content-aware graph convolutional network module to capture semantic features from the log context. Furthermore, DSGN introduces a dynamic semantic threshold mechanism that dynamically adjusts the information flow based on the confidence level of semantic features and feeds it into the classifier. This design not only helps train a more robust classifier, but also leverages the advantages of both statistical and semantic features while avoiding overfitting caused by using statistical features. Experimental results show that the DSGN model achieves significant performance improvements on seven public datasets, with a macro-average F1 score exceeding 83% and a micro-average F1 score exceeding 81%, outperforming existing baseline techniques and demonstrating its substantial advantages.
ER  - 

TY  - JOUR
T1  - bjCnet: A contrastive learning-based framework for software defect prediction
AU  - Han, Jiaxuan
AU  - Huang, Cheng
AU  - Liu, Jiayong
JO  - Computers & Security
VL  - 145
SP  - 104024
PY  - 2024
DA  - 2024/10/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104024
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824003298
KW  - Deep learning
KW  - Defect prediction
KW  - Transformer
KW  - Large language model
KW  - Contrastive learning
AB  - Defect prediction based on deep learning is proposed to provide practitioners with reliable and practical tools to determine whether an area of code is defective. Compared with traditional code features, semantic features of source codes automatically extracted by neural networks can better reflect the semantic differences between codes. However, the small difference between some bug codes and clean codes poses a challenge for deep learning models in distinguishing them, leading to a low accuracy in defect prediction. In this paper, we propose bjCnet, a software defect prediction framework based on contrastive learning. It fine-tunes the pre-trained Transformer-based code large language model via a supervised contrastive learning network, achieving accurate defect prediction. We evaluate the prediction effect of bjCnet, the results demonstrate that the highest accuracy and f1-score achieved by bjCnet are both 0.948, surpassing the performance of the state-of-the-art approaches selected for comparison.
ER  - 

TY  - JOUR
T1  - Phishing email detection using vector similarity search leveraging transformer-based word embedding
AU  - Patra, Chanchal
AU  - Giri, Debasis
AU  - Nandi, Sutanu
AU  - Das, Ashok Kumar
AU  - Alenazi, Mohammed J.F.
JO  - Computers and Electrical Engineering
VL  - 124
SP  - 110403
PY  - 2025
DA  - 2025/05/01/
SN  - 0045-7906
DO  - https://doi.org/10.1016/j.compeleceng.2025.110403
UR  - https://www.sciencedirect.com/science/article/pii/S0045790625003465
KW  - Phishing
KW  - Similarity search
KW  - Vector database
KW  - Transformers
KW  - Phishing emails
KW  - Security
AB  - As cybercrime increases, using email cautiously is crucial. Phishing emails are a major threat, often exploited to steal sensitive data and cause financial losses. While anti-phishing techniques exist, evolving phishing tactics make countering them challenging. This study proposes a phishing detection system using transformer-based word embedding and vector similarity search. Pre-trained models like Dense Passage Retrieval (DPR) create high-dimensional vector embeddings from emails, stored in a vector database for real-time similarity searches. The proposed approach outperforms traditional machine learning by automating feature extraction and improving similarity search efficiency, making it more effective in detecting phishing emails. Empirical evaluation has been conducted using three publicly available datasets Enron, Nazario phishing corpora, and the Phishing validation emails dataset. The system demonstrates the superior performance, achieving 98.43% accuracy, 98.44% precision, 98.38% recall, 98.41% F1-score, and an area under the curves (AUC) of 0.984 using cosine similarity.
ER  - 

TY  - JOUR
T1  - Artificial Intelligence as an Innovative Element of Support in Policing
AU  - Dubravova, Hana
AU  - Cap, Jan
AU  - Holubova, Kristyna
AU  - Hribnak, Lukas
JO  - Procedia Computer Science
VL  - 237
SP  - 237
EP  - 244
PY  - 2024
DA  - 2024/01/01/
T2  - International Conference on Industry Sciences and Computer Science Innovation
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.05.101
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924011177
KW  - artificial intelligence
KW  - police
KW  - GPT
KW  - large language model
KW  - administrative burden
KW  - chat
AB  - Currently, the public security sector is faced with an increasing administrative burden that limits the ability of police officers to focus on core security tasks. This paper focuses on the possibility of using large-scale language models (LSMs) as an innovative tool to address this challenge. Based on a careful literature review and analysis of current trends in artificial intelligence, the author team develops a concept for integrating GPTs into police practice, with an emphasis on the potential for reducing administrative burden and supporting efficient processing of relevant information. As part of this research, we have identified key areas of policing where AI could bring significant value, including data analysis and document production assistance. However, it should be emphasized that this technology is still in its early stages of development and its implementation would require a carefully considered approach involving interdisciplinary collaboration and further research to test the theoretical assumptions presented in this study. Thus, this paper contributes to a deeper understanding of the potential benefits and challenges of integrating GPT into policing practice and outlines a path towards future innovative solutions in the field of public safety.
ER  - 

TY  - JOUR
T1  - MTRC: A self-supervised network intrusion detection framework based on multiple Transformers enabled data reconstruction with contrastive learning
AU  - Wang, Yufeng
AU  - Xu, Hao
AU  - Ma, Jianhua
AU  - jin, Qun
JO  - Journal of Network and Computer Applications
VL  - 243
SP  - 104300
PY  - 2025
DA  - 2025/11/01/
SN  - 1084-8045
DO  - https://doi.org/10.1016/j.jnca.2025.104300
UR  - https://www.sciencedirect.com/science/article/pii/S1084804525001973
KW  - Network intrusion detection
KW  - Multiple transformers
KW  - Feature correlation
KW  - Data reconstruction
KW  - Contrastive learning
AB  - Nowadays, Network Intrusion Detection System (NIDS) is essential for identifying and mitigating network threats in increasingly complex and dynamic network environments. Due to the benefits of automatic feature extraction and powerful expressive capability, Deep Neural Networks (DNN) based NIDS has witnessed great deployment. Considering the extremely high annotation cost, i.e., the extreme difficulty of labeling anomalous samples in supervised DNN based NIDS schemes, practically, many NIDS schemes are unsupervised. which either use generative-based approaches, such as encoder-decoder structure to identify deviated samples without the labeled intrusion data, or employ discriminative-based methods by designing pretext tasks to construct additional supervisory signals from the given data. However, the former only generates a single reconstruction version for each input sample, lacking a holistic view of the latent distribution of input sample, while the latter focuses on learning the global perspective of samples, often neglecting internal structures. To address these issues, this paper proposes a novel self-supervised NIDS framework based on multiple Transformers enabled data reconstruction with contrastive learning, MTRC, through combining generative-based and discriminative-based paradigms. In detail, our paper's contributions are threefold. First, a cross-feature correlation module is proposed to convert each tabular network traffic record into an original data view that effectively captures the cross-feature correlations. Second, inspired by the idea of the multiple-view reconstruction and contrastive learning, multiple Encoder-Decoder structured Transformers are used to generate different views for each original data view, which intentionally make each reconstructed view semantically similar to the original data view, and while these reconstructed views diversified between each other, aiming to holistically capture the latent features of normal data samples. Experimental results on multiple real network traffic datasets demonstrate that MTRC outperforms state-of-the-art unsupervised and self-supervised NIDS schemes, achieving superior performance in terms of AUC-ROC, AUC-PR, and F1-score metrics. The MTRC source code is publicly available at: https://github.com/sunyifen/MTRC.
ER  - 

TY  - JOUR
T1  - Using chat GPT to evaluate police threats, risk and harm
AU  - Halford, Eric
AU  - Webster, Andrew
JO  - International Journal of Law, Crime and Justice
VL  - 78
SP  - 100686
PY  - 2024
DA  - 2024/09/01/
SN  - 1756-0616
DO  - https://doi.org/10.1016/j.ijlcj.2024.100686
UR  - https://www.sciencedirect.com/science/article/pii/S1756061624000387
AB  - General purpose artificial intelligence (GPAI) is a form of advanced AI system that includes the recently introduced ChatGPT. GPAI is known for its capacity to understand and emulate human responses, and potentially offers an opportunity to reduce human error when conducting tasks that involve analysis, judgement, and reasoning. To support officers to do this, the police presently use a range of decision-making support tools, one of which is called THRIVE (Threat, Harm, Risk, Investigation, Vulnerability, and Engagement). THRIVE is designed to provide police practitioners with a model to improve their identification and response to vulnerability. Despite the existence of such decision models, a 2020 meta-analysis of police cases resulting in death or serious injury identified contributory failures that included poor risk identification, risk management, failure to adhere to evidentiary processes, poor criminal investigations, and inadequate police engagement with victims, including the level of care and assistance provided (Allnock, et al, 2020). Importantly, this report outlined human error as being a major underpinning factor of the failures. Although GPAI offers an opportunity to improve analysis, judgement, and reasoning, such systems have not yet been tested in policing, a field where any reduction in human error, particularly in the assessment of threat, harm, risk, and vulnerability can potentially save lives. This study is the first attempt to do this by using the chain-of-thought prompt methodology to test the GPAI ChatGPT (3.5 vs 4) in a controlled environment using 30 life-like police scenarios, crafted, and analyzed by expert practitioners. In doing so, we identify that ChatGPT 4 significantly outperforms its 3.5 predecessor, indicating that GPAI presents considerable opportunity in policing. However, systems that use this technology require extensive directional prompting to ensure outputs that can be considered accurate, and therefore, potentially safe to utilize in an operational setting. The article concludes by discussing how practitioners and researchers can further refine police related chain-of-thought prompts or use application programming interfaces (APIs) to improve responses provided by such GPAI.
ER  - 

TY  - JOUR
T1  - Critical meter identification and network embedding based attack detection for power systems against false data injection attacks
AU  - Lian, Xianglong
AU  - Qian, Tong
AU  - Zhang, Yin
AU  - Tang, Wenhu
AU  - Wu, Qinghua
JO  - International Journal of Electrical Power & Energy Systems
VL  - 143
SP  - 108389
PY  - 2022
DA  - 2022/12/01/
SN  - 0142-0615
DO  - https://doi.org/10.1016/j.ijepes.2022.108389
UR  - https://www.sciencedirect.com/science/article/pii/S0142061522004021
KW  - False data injection attacks (FDIAs)
KW  - Network embedding
KW  - State estimation
KW  - Power system
AB  - Modern power systems are becoming vulnerable to false data injection attacks (FDIAs) due to the high penetration of communication devices. To deal with such threats and challenges, this research develops a multi-task framework for power system operations against FDIAs, which aims to: (1) investigate the mechanism for the grid response model to FDIAs; (2) identify and protect critical meter measurements to reduce the loss of grids to such attacks; (3) detect attacks which may lead to severe consequences. To this end, a quantitative critical meter index (CMI) and a severe attack detection method based on network embeddings are proposed. The performance of the proposed method is evaluated by FDIAs simulations in the Institute of Electrical and Electronic Engineers (IEEE) 30- and 118-bus systems. Results show that protecting the identified meters can reduce the load shedding of 118-bus system greatly, and the accuracy rate of the proposed method to detect severe attacks reaches 96.62% and 98.91% for 30- and 118-bus systems against FDIAs, respectively.
ER  - 

TY  - JOUR
T1  - Edge AI for Internet of Energy: Challenges and perspectives
AU  - Himeur, Yassine
AU  - Sayed, Aya Nabil
AU  - Alsalemi, Abdullah
AU  - Bensaali, Faycal
AU  - Amira, Abbes
JO  - Internet of Things
VL  - 25
SP  - 101035
PY  - 2024
DA  - 2024/04/01/
SN  - 2542-6605
DO  - https://doi.org/10.1016/j.iot.2023.101035
UR  - https://www.sciencedirect.com/science/article/pii/S254266052300358X
KW  - Edge AI
KW  - Internet of energy (IoE)
KW  - Energy efficiency in buildings
KW  - Federated learning
KW  - Blockchain
KW  - Large language models (LLMs)
AB  - The digital landscape of the Internet of Energy (IoE) is on the brink of a revolutionary transformation with the integration of edge Artificial Intelligence (AI). This comprehensive review elucidates the promise and potential that edge AI holds for reshaping the IoE ecosystem. Commencing with a meticulously curated research methodology, the article delves into the myriad of edge AI techniques specifically tailored for IoE. The myriad benefits, spanning from reduced latency and real-time analytics to the pivotal aspects of information security, scalability, and cost-efficiency, underscore the indispensability of edge AI in modern IoE frameworks. As the narrative progresses, readers are acquainted with pragmatic applications and techniques, highlighting on-device computation, secure private inference methods, and the avant-garde paradigms of AI training on the edge. A critical analysis follows, offering a deep dive into the present challenges including security concerns, computational hurdles, and standardization issues. However, as the horizon of technology ever expands, the review culminates in a forward-looking perspective, envisaging the future symbiosis of 5G networks, federated edge AI, deep reinforcement learning, and more, painting a vibrant panorama of what the future beholds. For anyone vested in the domains of IoE and AI, this review offers both a foundation and a visionary lens, bridging the present realities with future possibilities.
ER  - 

TY  - JOUR
T1  - Blockchain-based auditing of legal decisions supported by explainable AI and generative AI tools
AU  - Sachan, Swati
AU  - Liu (Lisa), Xi
JO  - Engineering Applications of Artificial Intelligence
VL  - 129
SP  - 107666
PY  - 2024
DA  - 2024/03/01/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2023.107666
UR  - https://www.sciencedirect.com/science/article/pii/S095219762301850X
KW  - Legal
KW  - Law
KW  - Explainable AI
KW  - Blockchain
KW  - Generative AI
KW  - Responsible AI
AB  - Generative AI tools powered by Large Language Models (LLMs) have demonstrated advanced capabilities in understanding and articulating legal facts closer to the level of legal practitioners. However, scholars hold contrasting views on the reliability of the reasoning behind a decision derived from LLMs due to its black-box nature. Law firms are vigilant in recognizing the potential risks of violating confidentiality and inappropriate exposure of sensitive legal data through the prompt sent to Generative AI. This research attempts to find an equilibrium between responsible usage and control of human legal professionals over content produced by Generative AI through regular audits. It investigates the potential of Generative AI in drafting correspondence for pre-litigation decisions derived from an eXplainable AI (XAI) algorithm. This research presents an end-to-end process of designing the architecture and methodology for a blockchain-based auditing system. It detects unauthorized alterations of data repositories containing the decisions by an XAI model and automated textual explanation by Generative AI. The automated auditing by blockchain facilitates responsible usage of AI technologies and reduces discrepancies in tracing the accountability of adversarial decisions. It conceptualizes the two algorithms. First, strategic on-chain (within blockchain) and off-chain (outside blockchain) data storage in compliance with the data protection laws and critical requirements of stakeholders in a legal firm. Second, auditing by comparison of the unique signature as Merkle roots of files stored off-chain with their immutable blockchain counterpart. A case study on liability cases under tort law demonstrates the system implementation results.
ER  - 

TY  - JOUR
T1  - Comparative Analysis of Machine Learning Algorithms for Email Phishing Detection Using TF-IDF, Word2Vec, and BERT
AU  - Tawil, Arar Al
AU  - Almazaydeh, Laiali
AU  - Qawasmeh, Doaa
AU  - Qawasmeh, Baraah
AU  - Alshinwan, Mohammad
AU  - Elleithy, Khaled
JO  - Computers, Materials and Continua
VL  - 81
IS  - 2
SP  - 3395
EP  - 3412
PY  - 2024
DA  - 2024/11/18/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2024.057279
UR  - https://www.sciencedirect.com/science/article/pii/S1546221824008117
KW  - Attacks
KW  - email phishing
KW  - machine learning
KW  - security
KW  - representations from transformers (BERT)
KW  - text classifeir
KW  - natural language processing (NLP)
AB  - Cybercriminals often use fraudulent emails and fictitious email accounts to deceive individuals into disclosing confidential information, a practice known as phishing. This study utilizes three distinct methodologies, Term Frequency-Inverse Document Frequency, Word2Vec, and Bidirectional Encoder Representations from Transformers, to evaluate the effectiveness of various machine learning algorithms in detecting phishing attacks. The study uses feature extraction methods to assess the performance of Logistic Regression, Decision Tree, Random Forest, and Multilayer Perceptron algorithms. The best results for each classifier using Term Frequency-Inverse Document Frequency were Multilayer Perceptron (Precision: 0.98, Recall: 0.98, F1-score: 0.98, Accuracy: 0.98). Word2Vec’s best results were Multilayer Perceptron (Precision: 0.98, Recall: 0.98, F1-score: 0.98, Accuracy: 0.98). The highest performance was achieved using the Bidirectional Encoder Representations from the Transformers model, with Precision, Recall, F1-score, and Accuracy all reaching 0.99. This study highlights how advanced pre-trained models, such as Bidirectional Encoder Representations from Transformers, can significantly enhance the accuracy and reliability of fraud detection systems.
ER  - 

TY  - JOUR
T1  - A novel framework for effective phishing URL detection using an LSTM-based siamese network
AU  - K, Sruthi
AU  - Naik S, Manohar
JO  - Knowledge-Based Systems
VL  - 329
SP  - 114271
PY  - 2025
DA  - 2025/11/04/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2025.114271
UR  - https://www.sciencedirect.com/science/article/pii/S0950705125013127
KW  - Phishing attacks
KW  - Siamese network
KW  - Deep learning
KW  - Cyber attack detection
KW  - Malicious URL
AB  - Detecting phishing attacks in the era of generative AI presents a significant challenge due to the increasing sophistication of AI-generated phishing schemes. Neural network-driven approaches, including deep learning-based detection techniques, face notable limitations such as vulnerability to adversarial perturbations, reliance on large labeled datasets, poor generalization to novel attack patterns, and an over-dependence on shallow lexical features that fail to capture deeper semantic patterns. To address these limitations, we propose a pioneering approach leveraging a Siamese network that integrates twin LSTM subnetworks with shared weights, transforming URL sequences into robust feature representations. The Siamese Network effectively distinguishes between phishing and legitimate URLs by comparing the latent representations of URL pairs. Central to this approach is a specially curated pairwise dataset of phishing and legitimate URLs meticulously designed to facilitate fine-grained similarity analysis. This paired dataset enables the model to capture subtle distinctions between the two URL classes. Rigorous evaluation, including a dedicated test set of traditional and AI-generated URLs, demonstrates the model’s robust generalization capability. This innovative twin LSTM-based framework sets a new benchmark in phishing detection, providing a scalable, adaptive solution to combat increasingly sophisticated attacks.
ER  - 

TY  - JOUR
T1  - Redefining boundaries in innovation and knowledge domains: Investigating the impact of generative artificial intelligence on copyright and intellectual property rights
AU  - Al-Busaidi, Adil S.
AU  - Raman, Raghu
AU  - Hughes, Laurie
AU  - Albashrawi, Mousa Ahmed
AU  - Malik, Tegwen
AU  - Dwivedi, Yogesh K.
AU  - Al- Alawi, Thuraiya
AU  - AlRizeiqi, Mohammed
AU  - Davies, Gareth
AU  - Fenwick, Mark
AU  - Gupta, Parul
AU  - Gurpur, Shashikala
AU  - Hooda, Apeksha
AU  - Jurcys, Paulius
AU  - Lim, Daryl
AU  - Lucchi, Nicola
AU  - Misra, Tanvi
AU  - Raman, Ramakrishnan
AU  - Shirish, Anuragini
AU  - Walton, Paul
JO  - Journal of Innovation & Knowledge
VL  - 9
IS  - 4
SP  - 100630
PY  - 2024
DA  - 2024/10/01/
SN  - 2444-569X
DO  - https://doi.org/10.1016/j.jik.2024.100630
UR  - https://www.sciencedirect.com/science/article/pii/S2444569X24001690
KW  - ChatGPT
KW  - Generative artificial intelligence
KW  - GenAI
KW  - Generative scholar
KW  - Innovation
KW  - Intellectual property (IP) Risks
KW  - Large language models (LLMs)
KW  - Misuse case analysis
KW  - Personality rights
AB  - The rapid integration of generative AI (GenAI) into industries and society has prompted a re-evaluation of copyright and intellectual property rights (IPR) frameworks. GenAI's ability to produce original content using data from human-created sources raises critical ethical and legal concerns. Current copyright and IPR frameworks, designed around human authorship, are insufficient to address these challenges. This study, using a multi-perspective approach, explores GenAI's disruptive potential in replicating or transforming copyrighted materials, challenging established IPR norms. Findings highlight gaps in legislation and the opacity of GenAI platforms. To address these issues, this study presents a Dynamic Ethical Framework linked to a future global fair use policy, aiming to guide responsible GenAI development and use. By incorporating insights from domain experts, this study contextualizes emerging challenges and potential solutions within broader societal and technological trends. That said, this study calls for international collaboration and further research to reform IPR related laws and frameworks, ensuring they remain relevant and equitable in a GenAI-driven era.
ER  - 

TY  - JOUR
T1  - Research status and application of artificial intelligence large models in the oil and gas industry
AU  - LIU, He
AU  - REN, Yili
AU  - LI, Xin
AU  - DENG, Yue
AU  - WANG, Yongtao
AU  - CAO, Qianwen
AU  - DU, Jinyang
AU  - LIN, Zhiwei
AU  - WANG, Wenjie
JO  - Petroleum Exploration and Development
VL  - 51
IS  - 4
SP  - 1049
EP  - 1065
PY  - 2024
DA  - 2024/08/01/
SN  - 1876-3804
DO  - https://doi.org/10.1016/S1876-3804(24)60524-0
UR  - https://www.sciencedirect.com/science/article/pii/S1876380424605240
KW  - foundation model
KW  - large language mode
KW  - visual large model
KW  - multimodal large model
KW  - large model of oil and gas industry
KW  - pre-training
KW  - fine-tuning
AB  - This article elucidates the concept of large model technology, summarizes the research status of large model technology both domestically and internationally, provides an overview of the application status of large models in vertical industries, outlines the challenges and issues confronted in applying large models in the oil and gas sector, and offers prospects for the application of large models in the oil and gas industry. The existing large models can be briefly divided into three categories: large language models, visual large models, and multimodal large models. The application of large models in the oil and gas industry is still in its infancy. Based on open-source large language models, some oil and gas enterprises have released large language model products using methods like fine-tuning and retrieval augmented generation. Scholars have attempted to develop scenario-specific models for oil and gas operations by using visual/multimodal foundation models. A few researchers have constructed pre-trained foundation models for seismic data processing and interpretation, as well as core analysis. The application of large models in the oil and gas industry faces challenges such as current data quantity and quality being difficult to support the training of large models, high research and development costs, and poor algorithm autonomy and control. The application of large models should be guided by the needs of oil and gas business, taking the application of large models as an opportunity to improve data lifecycle management, enhance data governance capabilities, promote the construction of computing power, strengthen the construction of “artificial intelligence + energy” composite teams, and boost the autonomy and control of large model technology.
ER  - 

TY  - JOUR
T1  - Towards unbalanced multiclass intrusion detection with hybrid sampling methods and ensemble classification
AU  - Le, Thi-Thu-Huong
AU  - Shin, Yeongjae
AU  - Kim, Myeongkil
AU  - Kim, Howon
JO  - Applied Soft Computing
VL  - 157
SP  - 111517
PY  - 2024
DA  - 2024/05/01/
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2024.111517
UR  - https://www.sciencedirect.com/science/article/pii/S1568494624002916
KW  - Intrusion detection
KW  - Unbalanced data
KW  - Ensemble classification
KW  - Undersampling
KW  - Oversampling
KW  - Hybrid sampling
AB  - Intrusion Detection Systems (IDS) play a crucial role in securing computer networks against malicious activities. However, their efficacy is consistently hindered by the persistent challenge of class imbalance in real-world datasets. While various methods, such as resampling techniques, ensemble methods, cost-sensitive learning, data augmentation, and so on, have individually addressed imbalance classification issues, there exists a notable gap in the literature for effective hybrid methodologies aimed at enhancing IDS performance. To bridge this gap, our research introduces an innovative methodology that integrates hybrid undersampling and oversampling strategies within an ensemble classification framework. This novel approach is designed to harmonize dataset distributions and optimize IDS performance, particularly in intricate multi-class scenarios. In-depth evaluations were conducted using well-established intrusion detection datasets, including the Car Hacking: Attack and Defense Challenge 2020 (CHADC2020) and IoTID20. Our results showcase the remarkable efficacy of the proposed methodology, revealing significant improvements in precision, recall, and F1-score metrics. Notably, the hybrid-ensemble method demonstrated an exemplary average F1 score exceeding 98% for both datasets, underscoring its exceptional capability to substantially enhance intrusion detection accuracy. In summary, this research represents a significant contribution to the field of IDS, providing a robust solution to the pervasive challenge of class imbalance. The hybrid framework not only strengthens IDS efficacy but also illuminates the seamless integration of undersampling and oversampling within ensemble classifiers, paving the way for fortified network defenses.
ER  - 

TY  - JOUR
T1  - CSGVD: A deep learning approach combining sequence and graph embedding for source code vulnerability detection
AU  - Tang, Wei
AU  - Tang, Mingwei
AU  - Ban, Minchao
AU  - Zhao, Ziguo
AU  - Feng, Mingjun
JO  - Journal of Systems and Software
VL  - 199
SP  - 111623
PY  - 2023
DA  - 2023/05/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2023.111623
UR  - https://www.sciencedirect.com/science/article/pii/S0164121223000183
KW  - Graph neural networks
KW  - Vulnerability detection
KW  - Sequence embedding
KW  - Graph embedding
KW  - Pre-trained language model
KW  - Attention pooling
AB  - In order to secure software, it is critical to detect potential vulnerabilities. The performance of traditional static vulnerability detection methods is limited by predefined rules, which rely heavily on the expertise of developers. Existing deep learning-based vulnerability detection models usually use only a single sequence or graph embedding approach to extract vulnerability features. Sequence embedding-based models ignore the structured information inherent in the code, and graph embedding-based models lack effective node and graph embedding methods. As a result, we propose a novel deep learning-based approach, CSGVD (Combining Sequence and Graph embedding for Vulnerability Detection), which considers function-level vulnerability detection as a graph binary classification task. Firstly, we propose a PE-BL module, which inherits and enhances the knowledge from the pre-trained language model. It extracts the code’s local semantic features as node embedding in the control flow graph by using sequence embedding. Secondly, CSGVD uses graph neural networks to extract the structured information of the graph. Finally, we propose a mean biaffine attention pooling, M-BFA, to better aggregate node information as a graph’s feature representation. The experimental results show that CSGVD outperforms the existing state-of-the-art models and obtains 64.46% accuracy on the real-world benchmark dataset from CodeXGLUE for vulnerability detection.
ER  - 

TY  - JOUR
T1  - G2MBCF: Enhanced Named Entity Recognition for sensitive entities identification
AU  - Tian, Weibin
AU  - Gu, Kaiming
AU  - Xiao, Shihui
AU  - Zhang, Junbo
AU  - Cui, Wei
JO  - Data & Knowledge Engineering
VL  - 159
SP  - 102444
PY  - 2025
DA  - 2025/09/01/
SN  - 0169-023X
DO  - https://doi.org/10.1016/j.datak.2025.102444
UR  - https://www.sciencedirect.com/science/article/pii/S0169023X25000394
KW  - Sensitive entities identification
KW  - Data privacy
KW  - Named Entity Recognition
KW  - Latent factor model
AB  - With the increasing growth of data, work on data security is becoming increasingly important. As the core of important data detection, the sensitive entities identification (SEI) problem has become a hot topic in natural language processing (NLP) science. Named Entity Recognition (NER) is the foundation of SEI, however, current studies treat SEI only as a special case of the NER problem. It lacks more detailed considerations of implicit links between entities and relations. In this paper, we propose a novel enhanced method called G2MBCF based on latent factor model (LFM). We use knowledge graph to represent the NER primary result with semantic structure. Then we use G2MBCF to inscribe entities and relations through a E−R matrix to mine implicit connections. Experiments show that compared to existing NER methods, our method enhances Recall and Precision of SEI. We also studied the influence of parameters in the experiments.
ER  - 

TY  - JOUR
T1  - Application of meta-learning in cyberspace security: a survey
AU  - Yang, Aimin
AU  - Lu, Chaomeng
AU  - Li, Jie
AU  - Huang, Xiangdong
AU  - Ji, Tianhao
AU  - Li, Xichang
AU  - Sheng, Yichao
JO  - Digital Communications and Networks
VL  - 9
IS  - 1
SP  - 67
EP  - 78
PY  - 2023
DA  - 2023/02/01/
SN  - 2352-8648
DO  - https://doi.org/10.1016/j.dcan.2022.03.007
UR  - https://www.sciencedirect.com/science/article/pii/S2352864822000281
KW  - Meta-learning
KW  - Cyberspace security
KW  - Machine learning
KW  - Few-shot learning
AB  - In recent years, machine learning has made great progress in intrusion detection, network protection, anomaly detection, and other issues in cyberspace. However, these traditional machine learning algorithms usually require a lot of data to learn and have a low recognition rate for unknown attacks. Among them, “one-shot learning”, “few-shot learning”, and “zero-shot learning” are challenges that cannot be ignored for traditional machine learning. The more intractable problem in cyberspace security is the changeable attack mode. When a new attack mode appears, there are few or even zero samples that can be learned. Meta-learning comes from imitating human problem-solving methods as humans can quickly learn unknown things based on their existing knowledge when learning. Its purpose is to quickly obtain a model with high accuracy and strong generalization through less data training. This article first divides the meta-learning model into five research directions based on different principles of use. They are model-based, metric-based, optimization-based, online-learning-based, or stacked ensemble-based. Then, the current problems in the field of cyberspace security are categorized into three branches: cyber security, information security, and artificial intelligence security according to different perspectives. Then, the application research results of various meta-learning models on these three branches are reviewed. At the same time, based on the characteristics of strong generalization, evolution, and scalability of meta-learning, we contrast and summarize its advantages in solving problems. Finally, the prospect of future deep application of meta-learning in the field of cyberspace security is summarized.
ER  - 

TY  - JOUR
T1  - Into the next generation of digital protection: AI resiliency as a public responsibility
AU  - Noam, Eli
JO  - Telecommunications Policy
VL  - 49
IS  - 3
SP  - 102907
PY  - 2025
DA  - 2025/04/01/
SN  - 0308-5961
DO  - https://doi.org/10.1016/j.telpol.2025.102907
UR  - https://www.sciencedirect.com/science/article/pii/S0308596125000047
KW  - Artificial intelligence
KW  - AI resilience
KW  - AI regulation
KW  - Network security
KW  - Cybersecurity
KW  - Human-AI collaboration
KW  - Self-regulation
KW  - Transparency
KW  - Interoperability
KW  - Post-human
AB  - Even as the reliability of networks has risen, their control mechanisms up in the hierarchy of digital activities have become more vulnerable. Artificial intelligence algorithms are increasingly embedded in infrastructure and economic systems and their resiliency is essential for social and economic stability. This has led to widespread dystopic fears and defensive regulations, ignoring the considerable positives of AI-enhanced activities and institutions. AI resiliency problems include hardware failures, natural calamities, human error, software defects, and external attacks. AI networks of AI networks have emerged with high interdependence and complexity. Operations are often non-transparent ‘black boxes’ operating at lightning speeds, and hard to oversee or fix by humans. Most likely is a control of AI by other AI. This raises the question of human responsibility. The article examines various responses, including technology tools, managerial actions, self-regulation, and a role for government. The latter include rules evolving with technology and applications in a dynamic common law approach for liability, transparency, performance, market structure, interoperation, and more. Needed are principles for a ‘shared intelligence’ of humans with AI, with clear protocols for human overrides of AI. All this raises a new agenda for policymakers, managers, and researchers.
ER  - 

TY  - JOUR
T1  - DarkMor: A framework for darknet traffic detection that integrates local and spatial features
AU  - Yang, Jin
AU  - Liang, Weiheng
AU  - Wang, Xin
AU  - Li, Siyu
AU  - Jiang, Xinyun
AU  - Mu, Yufei
AU  - Zeng, Shunyang
JO  - Neurocomputing
VL  - 607
SP  - 128377
PY  - 2024
DA  - 2024/11/28/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2024.128377
UR  - https://www.sciencedirect.com/science/article/pii/S0925231224011482
KW  - Darknet traffic
KW  - Deep learning
KW  - Feature tokenizer transformer
KW  - Local features
KW  - Spatial features
AB  - The dark web, as an integral part of the multi-layered structure of the internet, provides anonymity and high levels of concealment absent on the surface web. Users can engage in various online activities without leaving any trace, making the dark web a hub for illicit activities, such as drug and weapon trafficking. Consequently, this poses a significant threat to social order and network security. However, due to the high concealment of the dark web, traditional detection methods suffer with insufficient extraction of characteristic information from darknet traffic and inadequate consideration of feature correlations. As a result, the accuracy of these conventional detection methods in detecting the dark web in real network environments is suboptimal. This paper proposes a darknet traffic detection framework called DarkMor to address these challenges. It integrates local and spatial features, automates feature mining and fusion, and models spatial relationship between features to fully exploit their potential. The core components of DarkMor consist of the feature fusion module and the traffic perception module. Using an improved feature tokenizer transformer architecture, the feature fusion module enhances the extraction of local features within high-dimensional feature clusters, effectively combining local feature information with global context. Additionally, the traffic perception module leverages a temporal model that incorporates self-attention mechanisms to learn the spatiotemporal characteristics of fused features, thereby further enhancing the model’s detection. Experimental results demonstrated that DarkMor achieved an accuracy of 97.78% on real network datasets, surpassing the latest cross-modal darknet traffic detection models. Furthermore, DarkMor maintained an accuracy of 97.57% even in network environments with reduced training samples, confirming the feasibility and robustness of the proposed detection framework.
ER  - 

TY  - JOUR
T1  - Fuzzing JavaScript engines with a syntax-aware neural program model
AU  - Xu, Haoran
AU  - Wang, Yongjun
AU  - Jiang, Zhiyuan
AU  - Fan, Shuhui
AU  - Fu, Shaojing
AU  - Xie, Peidai
JO  - Computers & Security
VL  - 144
SP  - 103947
PY  - 2024
DA  - 2024/09/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.103947
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824002529
KW  - Fuzzing
KW  - JavaScript engines
KW  - Language model
KW  - Neural network
KW  - Grammar
KW  - Vocabulary
AB  - Neural network language modeling has become a remarkable approach in the generation of test cases for fuzzing JavaScript engines. Fuzzers built upon neural language models offer several advantages. They obviate the need for manually developing code generation rules, enable the extraction of patterns from high-quality seed sets, and exhibit commendable portability. Nevertheless, existing works confront challenges in three key aspects: diminished language modeling performance attributable to extensive vocabularies, potential semantic errors within generated test cases, and the limitation of black-box fuzzing, which fails to leverage the internal feedback from the target engine. This paper proposes an innovative neural model-based grey-box fuzzing approach for JavaScript engines. We incorporate the context-free grammar of JavaScript into the neural language model to mitigate the challenges associated with extensive vocabularies, thereby enhancing the model’s performance. Furthermore, to enhance the semantic validity of the generated test cases, we introduce semantic constraints into the mutation process. Notably, this work pioneers the integration of grey-box testing into a fuzzer built upon a neural language model, thereby enhancing the exploration of deep paths. Our prototype, PMFuzz, surpasses NNLM-based counterparts in both language modeling performance and test case generation capabilities. PMFuzz demonstrates a high level of competitiveness in exploring the software state space when compared to traditional coverage-guided grey-box fuzzers. In our evaluation, PMFuzz successfully identified 20 new defects within mainstream JS engines. Eight of them have been confirmed and fixed. Moreover, upon applying our method to C compilers, PMFuzz has revealed 11 new defects.
ER  - 

TY  - JOUR
T1  - Otupy: A flexible, portable, and extensible framework for remote control of security functions
AU  - Repetto, Matteo
JO  - Computers & Security
VL  - 158
SP  - 104597
PY  - 2025
DA  - 2025/11/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104597
UR  - https://www.sciencedirect.com/science/article/pii/S016740482500286X
KW  - Cybersecurity
KW  - Network security
KW  - Command and control
KW  - Openc2
AB  - The growing proliferation of heterogeneous security functions ensures diversity, robustness, and adaptivity in addressing cyber-threats, but also poses management and integration challenges. OpenC2 defines a vendor- and application-agnostic abstract language for remote command and control of cyber-defense technologies. Its architecture supports multiple encoding and transfer options, but this might complicate its implementation and usage. This paper describes Otupy, a flexible and extensible implementation of the OpenC2 language specification. Otupy defines an Application Programming Interface (API) that allows programmers to focus on the control and business logic of security functions, rather than the communication syntax, protocol, and encoding. The design of Otupy leverages an abstract data notation, an inheritance model, and meta-serialization to simplify the development of extensions for specific profiles of security functions, as well as additional encoding and transfer protocols. We evaluate the correctness of our implementation by validating its output against both a syntax schema and external good and bad samples provided by a third party. Our analysis points out unclear and ambiguous aspects of OpenC2 that deserve further attention by its technical committee.
ER  - 
