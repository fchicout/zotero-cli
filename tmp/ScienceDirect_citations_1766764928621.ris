TY  - JOUR
T1  - PatchView: Multi-modality detection of security patches
AU  - Farhi, Nitzan
AU  - Koenigstein, Noam
AU  - Shavitt, Yuval
JO  - Computers & Security
VL  - 151
SP  - 104356
PY  - 2025
DA  - 2025/04/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104356
UR  - https://www.sciencedirect.com/science/article/pii/S0167404825000458
KW  - CVE
KW  - Machine learning
KW  - Git
KW  - GitHub
KW  - Behavioral data
KW  - LSTM
KW  - Conv1D
AB  - Patching software become overwhelming for system administrators due to the large amounts of patch releases. Administrator should prioritize security patches to reduce the exposure to attacks, and can use for this task the Common Vulnerabilities and Exposures (CVE) system, which catalogs known security vulnerabilities in publicly released software or firmware. However, some developers choose to omit CVE publication and merely update their repositories, keeping the vulnerabilities undisclosed. Such actions leave users uninformed and potentially at risk. To this end, we present PatchView, an innovative multi-modal system tailored for the classification of commits as security patches. The system draws upon three unique data modalities associated with a commit: (1) Time-series representation of developer behavioral data within the Git repository, (2) Commit messages, and (3) The code patches. PatchView merges three single-modality sub-models, each adept at interpreting data from its designated source. A distinguishing feature of this solution is its ability to elucidate its predictions by examining the outputs of each sub-model, underscoring its interpretability. Notably, this research pioneers a language-agnostic methodology for security patch classification. Our evaluations indicate that the proposed solution can reveal concealed security patches with an accuracy of 94.52% and F1-scoreof 95.12%. The code for this paper will be made publicly available on GitHub: https://github.com/nitzanfarhi/PatchView.
ER  - 

TY  - JOUR
T1  - Multi-stage self-training social bot detection based on graph neural network
AU  - Wang, Keke
AU  - Wang, Xiujuan
AU  - Chen, Kangmiao
AU  - Wang, Zhengxiang
AU  - Zheng, Kangfeng
JO  - Engineering Applications of Artificial Intelligence
VL  - 152
SP  - 110816
PY  - 2025
DA  - 2025/07/15/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2025.110816
UR  - https://www.sciencedirect.com/science/article/pii/S0952197625008164
KW  - Social bot detection
KW  - Pseudo-label
KW  - Semi-supervised learning
KW  - Graph neural network
AB  - With the popularity of social networks, social bots are increasingly interfering with human social activities, which have negatively impacted social network ecology and user experience. How to detect social bots effectively has become a challenging task. Most of existing social bot detection methods are based on the supervised learning mechanism, but the labelled data collection is resource-intensive. In this paper, a Multi-stage Self-training Social Bot detection method based on a Graph Neural Network (MSSBot) is proposed to improve the performance of social bot detection with a small amount of labelled data. MSSBot exploits pseudo-labels to expand the dataset and trains a Relational Graph Convolutional Network in multiple stages, while uncertainty-aware and deep clustering are used to reduce the noise present in the pseudo-labels acquisition process. The experiments were conducted on a real-world social network dataset Twibot-20, a small high-quality dataset focused on social bot behavior patterns Cresci-2015, and a large-scale graph-based dataset Twibot-22 with high annotation quality. The experimental results show that our method achieves accuracies of 0.9259, 0.9979, and 0.8358 on the Twibot-20, Cresci-2015, and Twibot-22 datasets, respectively, outperforming the state-of-the-art methods, with improvements of 5.68 %, 2.64 %, and 3.92 % over the existing state-of-the-art methods.
ER  - 

TY  - JOUR
T1  - Malicious encrypted traffic detection method based on multi-granularity representation under data imbalance conditions
AU  - Li, Tao
AU  - Yang, Zhiwei
AU  - Li, Wenshan
AU  - Du, Linfeng
AU  - Lan, Xiaolong
AU  - He, Junjiang
JO  - Knowledge-Based Systems
VL  - 316
SP  - 113320
PY  - 2025
DA  - 2025/05/12/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2025.113320
UR  - https://www.sciencedirect.com/science/article/pii/S0950705125003673
KW  - Malicious encrypted traffic detection
KW  - Multi-granularity feature representation
KW  - Prompt learning
KW  - Imbalanced data
AB  - Traffic encryption technology safeguards the secure transmission of user data but also enables attackers to conceal malicious activities. With the widespread adoption of encrypted communication protocols and the growing volume of encrypted traffic, accurately identifying malicious encrypted traffic has become a critical challenge in network security. Traditional methods for encrypted traffic classification rely on manual feature extraction and are hindered by imbalanced data distribution, leading to low classification accuracy. In this paper, we propose a maliciously encrypted traffic detection method based on multi-granularity representation under data imbalance conditions. Firstly, we propose a feature extraction method for encrypted traffic based on multi-granularity representation to fully extract the behavioral and temporal characteristics of the traffic in depth and improve the feature extraction effect. Secondly, to address the problem of imbalanced data distribution in malicious encrypted traffic, we introduce the prompt learning algorithm, which solves the issue of imbalanced malicious encrypted traffic datasets. This method improves detection effectiveness by constructing prompt samples, comprehensively learning the feature space of data samples, and transforming the multi-classification problem into multiple dichotomous classification problems. Lastly, we conduct experiments using real network traffic datasets to validate our proposed method. The results demonstrate that our approach outperforms the MLM model by 30% in both binary and multi-class classification tasks. Furthermore, when compared to other deep learning models, our method improves performance by 20% to 50%. Overall, our proposed method exhibits strong generalization and usability, along with effective capabilities for detecting and classifying malicious encrypted traffic.
ER  - 

TY  - JOUR
T1  - DecomCAM: Advancing beyond saliency maps through decomposition and integration
AU  - Yang, Yuguang
AU  - Guo, Runtang
AU  - Wu, Sheng
AU  - Wang, Yimi
AU  - Yang, Linlin
AU  - Fan, Bo
AU  - Zhong, Jilong
AU  - Zhang, Juan
AU  - Zhang, Baochang
JO  - Neurocomputing
VL  - 610
SP  - 127826
PY  - 2024
DA  - 2024/12/28/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2024.127826
UR  - https://www.sciencedirect.com/science/article/pii/S0925231224005976
KW  - Interpretability
KW  - Saliency maps
KW  - Deep neural networks
KW  - Singular value decomposition
AB  - Interpreting complex deep networks, notably pre-trained vision-language models (VLMs), is a formidable challenge. Current Class Activation Map (CAM) methods highlight regions revealing the model’s decision-making basis but lack clear saliency maps and detailed interpretability. To bridge this gap, we propose DecomCAM, a novel decomposition-and-integration method that distills shared patterns from channel activation maps. Utilizing singular value decomposition, DecomCAM decomposes class-discriminative activation maps into orthogonal sub-saliency maps (OSSMs), which are then integrated together based on their contribution to the target concept. Extensive experiments on six benchmarks reveal that DecomCAM not only excels in locating accuracy but also achieves an optimizing balance between interpretability and computational efficiency. Further analysis unveils that OSSMs correlate with discernible object components, facilitating a granular understanding of the model’s reasoning. This positions DecomCAM as a potential tool for fine-grained interpretation of advanced deep learning models. The code is available at https://github.com/CapricornGuang/DecomCAM.
ER  - 

TY  - JOUR
T1  - E-WebGuard: Enhanced neural architectures for precision web attack detection
AU  - Zhou, Luchen
AU  - Yau, Wei-Chuen
AU  - Gan, Y.S.
AU  - Liong, Sze-Teng
JO  - Computers & Security
VL  - 148
SP  - 104127
PY  - 2025
DA  - 2025/01/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104127
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824004322
KW  - Web applications
KW  - Web attacks detection
KW  - SVM
KW  - LSTM
KW  - CNN
KW  - HTTP
AB  - Web applications have become a favored tool for organizations to disseminate vast amounts of information to the public. With the increasing adoption and inherent openness of these applications, there is an observed surge in web-based attacks exploited by adversaries. However, most of the web attack detection works are based on public datasets that are outdated or do not cover a sufficient quantity of web application attacks. Furthermore, most of them are binary detection (i.e., normal or attack) and there is little work on multi-class web attack detection. This highlights the crucial need for automated web attack detection models to bolster web security. In this study, a suite of integrated machine learning and deep learning models is designed to detect web attacks. Specifically, this study employs the Character-level Support Vector Machine (Char-SVM), Character-level Long Short-Term Memory (Char-LSTM), Convolutional Neural Network - SVM (CNN-SVM), and CNN-Bi-LSTM models to differentiate between standard HTTP requests and HTTP-based attacks in both the CSIC 2010 and SR-BH 2020 datasets. Note that the CSIC 2010 dataset involves binary classification, while the SR-BH 2020 dataset involves multi-class classification, specifically with 13 classes. Notably, the input data is first converted to the character level before being fed into any of the proposed model architectures. In the binary classification task, the Char-SVM model with a linear kernel outperforms other models, achieving an accuracy rate of 99.60%. The CNN-Bi-LSTM model closely follows with a 99.41% accuracy, surpassing the performance of the CNN-LSTM model presented in previous research. In the context of multi-class classification, the CNN-Bi-LSTM model demonstrates outstanding performance with a 99.63% accuracy rate. Furthermore, the multi-class classification models, namely Char-LSTM and CNN-Bi-LSTM, achieve validation accuracies above 98%, outperforming the two machine learning-based methods mentioned in the original research.
ER  - 

TY  - JOUR
T1  - Continual learning for energy management systems: A review of methods and applications, and a case study
AU  - Sayed, Aya Nabil
AU  - Himeur, Yassine
AU  - Varlamis, Iraklis
AU  - Bensaali, Faycal
JO  - Applied Energy
VL  - 384
SP  - 125458
PY  - 2025
DA  - 2025/04/15/
SN  - 0306-2619
DO  - https://doi.org/10.1016/j.apenergy.2025.125458
UR  - https://www.sciencedirect.com/science/article/pii/S0306261925001886
KW  - Continual learning
KW  - Lifelong learning
KW  - Deep learning
KW  - Catastrophic forgetting
KW  - Energy management systems
KW  - Non-intrusive load monitoring
KW  - Demand-side management
KW  - Fault/anomaly detection
KW  - Load forecasting
KW  - Renewable energy integration
AB  - An intelligent system must incrementally acquire, update, accumulate, and exploit knowledge to navigate the real world’s intricacies. This trait is frequently referred to as Continual Learning (CL), and it can be limited by catastrophic forgetting, a phenomenon in which learning a new task acutely reduces the system’s performance on prior tasks. Numerous strategies have been developed to address this issue, as CL is essential for developing Artificial Intelligence (AI) systems that adapt to dynamic environments. This study examines the practical applications of CL, concentrating on energy management systems and their integration with Deep Learning (DL) models. Energy management systems are strategies and methods for monitoring, controlling, and optimizing energy use within a system or organization. The literature is systematically analyzed, highlighting methods such as replay techniques, regularization strategies, and architectural adaptations that address the challenges of catastrophic forgetting. Moreover, the review encompasses various energy-related applications, including non-intrusive load monitoring, demand-side management, fault/anomaly detection, load forecasting/prediction, and renewable energy integration. Additionally, a case study on anomaly detection in energy systems is conducted, comparing different CL approaches. The case study findings aim to bridge the gap between theoretical advancements and real-world applications, providing insights and guidelines for implementing CL in diverse fields. Finally, this survey identifies key challenges that impede the deployment of CL and suggests potential directions to enhance its implementation in the energy management sector.
ER  - 

TY  - JOUR
T1  - DST-IDS: Dynamic spatial-temporal graph-transformer network for in-vehicle network intrusion detection system
AU  - Al-Absi, Gaber A.
AU  - Fang, Yong
AU  - Qaseem, Adnan A.
AU  - Al-Absi, Huda
JO  - Vehicular Communications
VL  - 55
SP  - 100962
PY  - 2025
DA  - 2025/10/01/
SN  - 2214-2096
DO  - https://doi.org/10.1016/j.vehcom.2025.100962
UR  - https://www.sciencedirect.com/science/article/pii/S2214209625000890
KW  - Dynamic spatial-temporal dependencies
KW  - Intrusion detection system
KW  - In-vehicle network
KW  - Controller area network
KW  - Electronic control units
KW  - Graph-transformer network
AB  - The development of the Internet of Vehicles (IoV) has greatly increased connectivity, making the In-Vehicle Network (IVN) more susceptible to intrusions. Furthermore, the utilization of Electronic Control Units (ECUs) in current vehicles has experienced a significant increase, establishing the Controller Area Network (CAN) as the widely used standard in the automotive field. However, it lacks provisions for authentication. The attackers have exploited these weaknesses to launch various attacks on CAN-based IVN. Sequential data approaches such as Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) have emerged as prominent approaches in this domain, contributing significantly to the evolution of the Intrusion Detection System (IDS). However, these methods are limited in feature extraction as they depend solely on previously interacted hidden states, potentially overlooking critical features. Additionally, capturing the complex spatial-temporal dynamics of CAN messages remains a significant challenge. In response to these challenges, we propose the Dynamic Spatial-Temporal Graph-Transformer Network for In-vehicle Network Intrusion Detection System, denoted as the “DST-IDS”. It comprises three modules: a graph spatial-temporal embedding module that converts the row CAN messages correlation into latent graph representations, a spatial-temporal learning module, and a classification module. The second module utilizes a graph-transformer network to capture and learn the dynamic spatial-temporal dependencies between CAN messages. The last module classifies the learnt features into either normal or attack messages. The model was evaluated on two publicly available datasets (CAR-Hacking and IVN-IDS), achieving exceptionally high accuracy scores of 0.999999 and 0.9996, respectively. These results demonstrate that the proposed model significantly outperforms state-of-the-art methods in detection accuracy and false alarm rate for in-vehicle network intrusion detection.
ER  - 

TY  - JOUR
T1  - Reproducibility of machine learning-based fault detection and diagnosis for HVAC systems in buildings: An empirical study
AU  - Mukhtar, Adil
AU  - Hadwiger, Michael
AU  - Wotawa, Franz
AU  - Schweiger, Gerald
JO  - Energy and AI
VL  - 22
SP  - 100658
PY  - 2025
DA  - 2025/12/01/
SN  - 2666-5468
DO  - https://doi.org/10.1016/j.egyai.2025.100658
UR  - https://www.sciencedirect.com/science/article/pii/S2666546825001909
KW  - Fault detection and diagnosis (FDD)
KW  - Energy systems
KW  - Machine learning (ML)
KW  - Reproducibility
KW  - Transparency
KW  - Methodological review
KW  - Open science
AB  - Reproducibility is a cornerstone of credible scientific research. The topic gained prominence in fields such as psychology, medicine and artificial intelligence where concerns about non-replicable results sparked ongoing discussions about research practices. However, its status within machine learning for building systems is underexamined. Therefore, this work contributes to closing this gap by analyzing the reproducibility of machine learning-based fault detection and diagnosis studies published over the past decade. We found that nearly all articles are not reproducible due to insufficient disclosure across key dimensions of reproducibility. Notably, 72% of the articles do not specify whether the dataset used is public, proprietary, or commercially available. Only two papers share a link to their code, one of which was broken. Two-thirds of the publications were authored exclusively by academic researchers, yet no significant differences in reproducibility were observed compared to publications with industry-affiliated authors. These findings highlight the need for targeted interventions, including reproducibility guidelines, training for researchers, and policies by journals and conferences that promote transparency and reproducibility.
ER  - 

TY  - JOUR
T1  - An ensemble of pre-trained transformer models for imbalanced multiclass malware classification
AU  - Demirkıran, Ferhat
AU  - Çayır, Aykut
AU  - Ünal, Uğur
AU  - Dağ, Hasan
JO  - Computers & Security
VL  - 121
SP  - 102846
PY  - 2022
DA  - 2022/10/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2022.102846
UR  - https://www.sciencedirect.com/science/article/pii/S0167404822002401
KW  - Transformer
KW  - Tokenization-free
KW  - API Calls
KW  - Imbalanced
KW  - Multiclass
KW  - BERT
KW  - CANINE
KW  - Ensemble
KW  - Malware classification
AB  - Classification of malware families is crucial for a comprehensive understanding of how they can infect devices, computers, or systems. Hence, malware identification enables security researchers and incident responders to take precautions against malware and accelerate mitigation. API call sequences made by malware are widely utilized features by machine and deep learning models for malware classification as these sequences represent the behavior of malware. However, traditional machine and deep learning models remain incapable of capturing sequence relationships among API calls. Unlike traditional machine and deep learning models, the transformer-based models process the sequences in whole and learn relationships among API calls due to multi-head attention mechanisms and positional embeddings. Our experiments demonstrate that the Transformer model with one transformer block layer surpasses the performance of the widely used base architecture, LSTM. Moreover, BERT or CANINE, the pre-trained transformer models, outperforms in classifying highly imbalanced malware families according to evaluation metrics: F1-score and AUC score. Furthermore, our proposed bagging-based random transformer forest (RTF) model, an ensemble of BERT or CANINE, reaches the state-of-the-art evaluation scores on the three out of four datasets, specifically it captures a state-of-the-art F1-score of 0.6149 on one of the commonly used benchmark dataset.
ER  - 

TY  - JOUR
T1  - PEGNN: Peripheral-Enhanced graph neural network for social bot detection
AU  - Guyan, Qitian
AU  - Liu, Yaowen
AU  - Liu, Jing
AU  - Zhang, Peng
JO  - Expert Systems with Applications
VL  - 278
SP  - 127294
PY  - 2025
DA  - 2025/06/10/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2025.127294
UR  - https://www.sciencedirect.com/science/article/pii/S0957417425009169
KW  - Social Robot Detection
KW  - Graph Neural Networks
KW  - Peripheral Reinforcement
AB  - The development of social networks plays a stronger role in the increased importance of social bot detection. One of the most common existing graph-based detection methods is graph neural networks (GNNs). However, researchers mainly focus on the improvement of GNN architecture while neglecting the in-depth analysis of social network structure. In this paper, after in-depth analysis of the social graph structure, it demonstrate that there exists a graph stratification phenomenon, i.e., the social graph is divided into central and peripheral layers according to its topology. Based on this phenomenon, the idea that the social robot detection task should focus on the central node is proposed, and the existing detection task is adapted to a central node classification task. The task is then further investigated, and the Peripheral-Enhanced Graph Neural Network (PEGNN) framework is proposed to tackle the problem that existing frameworks cannot effectively utilize the information of peripheral networks. PEGNN effectively utilizes the information of peripheral networks via the synergistic effect of three losses. Eventually, the graph stratification phenomenon is verified on two datasets, and the original task is adjusted for central node classification to verify the enhancement effect of PEGNN. The experimental results exhibit that PEGNN obviously improves the model performance. On Twibot-20, the average improvement in accuracy is 1.30%, and the average improvement in F1 score is 1.37%; on Twibot-22, the average improvement in accuracy is 2.46%, the average improvement in F1 score is 5.91%; apparently, other metrics also show obvious improvement.
ER  - 

TY  - JOUR
T1  - Analyzing the market's reaction to AI narratives in corporate filings
AU  - Basnet, Anup
AU  - Elias, Maxim
AU  - Salganik-Shoshan, Galla
AU  - Walker, Thomas
AU  - Zhao, Yunfei
JO  - International Review of Financial Analysis
VL  - 105
SP  - 104378
PY  - 2025
DA  - 2025/09/01/
SN  - 1057-5219
DO  - https://doi.org/10.1016/j.irfa.2025.104378
UR  - https://www.sciencedirect.com/science/article/pii/S105752192500465X
KW  - Narrative
KW  - Artificial intelligence
KW  - Corporate disclosure
KW  - Firm value
KW  - Textual analysis
AB  - The recent surge in artificial intelligence (AI) interest and investment, driven by advances in large language models, has led the market to reward adopters and penalize laggards. Yet, AI integration predates this “AI gold rush,” with earlier adopters reaping significant benefits. Drawing on a 2005–2018 sample, a formative period before AI became mainstream, this paper examines how early AI adoption and its disclosure in corporate filings affect U.S. firms. Analyzing 10-K filings, we categorize AI-related mentions as actionable, speculative, or irrelevant. We establish causal links between these disclosures and firm value, with innovation and productivity as likely channels. Our findings indicate that markets distinguish between substantive AI initiatives and opportunistic signaling, swiftly pricing anticipated future gains. Actionable disclosures outlining clear implementation plans yield significant valuation benefits, particularly upon first introduction, whereas speculative or irrelevant disclosures have no impact. Moreover, firms with substantive AI disclosures subsequently increase innovation activities, evidenced by higher R&D spending and patent filings, which are a key step in a pathway to modest, lagged productivity gains and ultimately improved valuation. We further find that these innovation activities act as concurrent signals of strategic reorientation towards AI, reinforcing the market's swift positive valuation. We show that early adopters of actionable disclosures gain competitive advantages, while peers that either remain silent or offer only vague AI disclosures face market penalties. These findings highlight that the strategic communication of genuine technological initiatives can significantly impact a company's perceived value and competitive positioning in the market.
ER  - 

TY  - JOUR
T1  - Ethio-Fake: Cutting-Edge Approaches to Combat Fake News in Under-Resourced Languages Using Explainable AI
AU  - Gemeda yigezu, Mesay
AU  - Mersha, Melkamu Abay
AU  - Bade, Girma Yohannis
AU  - Kalita, Jugal
AU  - Kolesnikova, Olga
AU  - Gelbukh, Alexander
JO  - Procedia Computer Science
VL  - 244
SP  - 133
EP  - 142
PY  - 2024
DA  - 2024/01/01/
T2  - 6th International Conference on AI in Computational Linguistics
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.10.186
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924029879
KW  - Fake News
KW  - Misinformation
KW  - Amharic
KW  - Under-resourced Languages
KW  - Low-resourced Languages
KW  - Ethiopian Languages
KW  - Basic Neural Network
KW  - Traditional Machine Learning
KW  - Ensemble
KW  - Transfer Learning
KW  - LIME
KW  - Explainable AI
AB  - The proliferation of fake news has emerged as a significant threat to the integrity of information dissemination, particularly on social media platforms. Misinformation can spread quickly due to the ease of creating and disseminating content, affecting public opinion and sociopolitical events. Identifying false information is therefore essential to reducing its negative consequences and maintaining the reliability of online news sources. Traditional approaches to fake news detection often rely solely on content-based features, overlooking the crucial role of social context in shaping the perception and propagation of news articles. In this paper, we propose a comprehensive approach that integrates social context-based features with news content features to enhance the accuracy of fake news detection in under-resourced languages. We perform several experiments utilizing a variety of methodologies, including traditional machine learning, neural networks, ensemble learning, and transfer learning. Assessment of the outcomes of the experiments shows that the ensemble learning approach has the highest accuracy, achieving a 0.99 F1 score. Additionally, when compared with monolingual models, the fine-tuned model with the target language outperformed others, achieving a 0.94 F1 score. We analyze the functioning of the models, considering the important features that contribute to model performance, using explainable AI techniques.
ER  - 

TY  - JOUR
T1  - A Novel Approach for Android Malware Detection Based on Intelligent Computing
AU  - Minh, Manh Vu
AU  - Xuan, Cho Do
JO  - Computers, Materials and Continua
VL  - 81
IS  - 3
SP  - 4371
EP  - 4396
PY  - 2024
DA  - 2024/12/19/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2024.058168
UR  - https://www.sciencedirect.com/science/article/pii/S1546221824008592
KW  - Android malware detection
KW  - malware behavior profile
KW  - function call graph
KW  - graph neural network
KW  - graph-structured features
KW  - semantic features
AB  - Detecting malware on mobile devices using the Android operating system has become a critical challenge in the field of cybersecurity, in the context of the rapid increase in the number of malware variants and the frequency of attacks targeting Android devices. In this paper, we propose a novel intelligent computational method to enhance the effectiveness of Android malware detection models. The proposed method combines two main techniques: (1) constructing a malware behavior profile and (2) extracting features from the malware behavior profile using graph neural networks. Specifically, to effectively construct an Android malware behavior profile, this paper proposes an information enrichment technique for the function call graph of malware files, based on new graph-structured features and semantic features of the malware’s source code. Additionally, to extract significant features from the constructed behavior profile, the study proposes using the GraphSAGE graph neural network. With this novel intelligent computational method, a variety of significant features of the malware have been effectively represented, synthesized, and extracted. The approach to detecting Android malware proposed in this paper is a new study and has not been explored in previous research. The experimental results on a dataset of 40,819 Android software indicate that the proposed method performs well across all metrics, with particularly impressive accuracy and recall scores of 99.03% and 99.19%, respectively, which outperforms existing state-of-the-art methods.
ER  - 

TY  - JOUR
T1  - Blockchain-enabled dynamic honeypot conversion for resource-efficient IoT security
AU  - Commey, Daniel
AU  - Nkoom, Matilda
AU  - Hounsinou, Sena G.
AU  - Crosby, Garth V.
JO  - Journal of Information Security and Applications
VL  - 93
SP  - 104109
PY  - 2025
DA  - 2025/09/01/
SN  - 2214-2126
DO  - https://doi.org/10.1016/j.jisa.2025.104109
UR  - https://www.sciencedirect.com/science/article/pii/S2214212625001462
KW  - Internet of Things
KW  - IoT security
KW  - Dynamic honeypots
KW  - Adaptive IDS
KW  - Cybersecurity
KW  - Artificial intelligence
KW  - Network security
AB  - The rapid growth of Internet of Things (IoT) devices presents significant security challenges, particularly in managing large-scale, resource-constrained deployments. While honeypots are effective security tools, traditional static deployments lack the adaptability and resource efficiency needed for dynamic IoT environments, and ensuring verifiable event logging is challenging. This paper introduces BHICS (Blockchain-enabled Honeypot IoT Conversion System), a novel approach that dynamically converts regular IoT nodes into honeypots based on detected threat levels using a lightweight machine learning (ML) model. BHICS employs a state-driven conversion mechanism with blockchain-based logging for verifiable security event recording. Experimental evaluations demonstrate that BHICS achieves an attack prevention rate of 76.5% (±0.9%), comparable to dedicated honeypot deployments (79.6% ±1.0%), while significantly reducing node compromise rates from 49.8% to 22.3%. The system exhibits strong scalability, maintaining consistent performance in networks ranging from 100 to 1,000 nodes, with blockchain transaction times remaining stable around 15.17 ms (±0.03 ms), ensuring minimal overhead. Our approach provides an efficient, scalable solution for IoT network security that balances protection capabilities with resource utilization and ensures reliable security event logging.
ER  - 

TY  - JOUR
T1  - A novel ensemble method for enhancing Internet of Things device security against botnet attacks
AU  - Arshad, Amina
AU  - Jabeen, Maira
AU  - Ubaid, Saqib
AU  - Raza, Ali
AU  - Abualigah, Laith
AU  - Aldiabat, Khaled
AU  - Jia, Heming
JO  - Decision Analytics Journal
VL  - 8
SP  - 100307
PY  - 2023
DA  - 2023/09/01/
SN  - 2772-6622
DO  - https://doi.org/10.1016/j.dajour.2023.100307
UR  - https://www.sciencedirect.com/science/article/pii/S2772662223001479
KW  - Botnet attacks
KW  - Deep learning
KW  - Ensemble learning
KW  - IoT devices
KW  - Network security
KW  - Cyber security
AB  - The growing number of connected Internet of Things (IoT) devices has led to the daily growth of network botnet attacks. The networks of compromised devices controlled by a single entity can be used for malicious purposes such as denial of service distributed IoT botnet attacks and theft of personal information. The weak security measures of many IoT devices make them easy targets for compromise and inclusion in botnets. In this research, we propose a system for detecting botnet attacks. We develop an ensemble learning system to detect botnets in network traffic with high-performance scores. The system will analyze the traffic and identify any suspicious behavior that may indicate the presence of a botnet. For this purpose, we use the benchmark CTU-13 dataset to build the applied machine learning and deep learning techniques for comparison. We propose a novel ensemble technique, K-neighbors, Decision tree, and Random forest (KDR), to achieve high performance for botnet attack detection. Study results show that the proposed KDR gives 99.7% accuracy in 12.99 s. Hyperparameter optimization and k-fold cross-validation are employed to substantiate the performance. Our research study contributes to the body of knowledge on the detection of botnet attacks and provides a practical solution for securing IoT devices against botnet attacks.
ER  - 

TY  - JOUR
T1  - SLIFER: Investigating performance and robustness of malware detection pipelines
AU  - Ponte, Andrea
AU  - Trizna, Dmitrijs
AU  - Demetrio, Luca
AU  - Biggio, Battista
AU  - Ogbu, Ivan Tesfai
AU  - Roli, Fabio
JO  - Computers & Security
VL  - 150
SP  - 104264
PY  - 2025
DA  - 2025/03/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104264
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824005704
KW  - Malware detection
KW  - Machine learning
KW  - Pipeline
KW  - Robustness
KW  - Adversarial EXEmples
AB  - As a result of decades of research, Windows malware detection is approached through a plethora of techniques. However, there is an ongoing mismatch between academia – which pursues an optimal performances in terms of detection rate and low false alarms – and the requirements of real-world scenarios. In particular, academia focuses on combining static and dynamic analysis within a single or ensemble of models, falling into several pitfalls like (i) firing dynamic analysis without considering the computational burden it requires; (ii) discarding impossible-to-analyze samples; and (iii) analyzing robustness against adversarial attacks without considering that malware detectors are complemented with more non-machine-learning components. Thus, in this paper we bridge these gaps, by investigating the properties of malware detectors built with multiple and different types of analysis. To do so, we develop SLIFER, a Windows malware detection pipeline sequentially leveraging both static and dynamic analysis, interrupting computations as soon as one module triggers an alarm, requiring dynamic analysis only when needed. Contrary to the state of the art, we investigate how to deal with samples that impede analyzes, showing how much they impact performances, concluding that it is better to flag them as legitimate to not drastically increase false alarms. Lastly, we perform a robustness evaluation of SLIFER. Counter-intuitively, the injection of new content is either blocked more by signatures than dynamic analysis, due to byte artifacts created by the attack, or it is able to avoid detection from signatures, as they rely on constraints on file size disrupted by attacks. As far as we know, we are the first to investigate the properties of sequential malware detectors, shedding light on their behavior in real production environment.
ER  - 

TY  - JOUR
T1  - A semantic element representation model for malicious domain name detection
AU  - Yang, Luhui
AU  - Liu, Guangjie
AU  - Wang, Jinwei
AU  - Zhai, Jiangtao
AU  - Dai, Yuewei
JO  - Journal of Information Security and Applications
VL  - 66
SP  - 103148
PY  - 2022
DA  - 2022/05/01/
SN  - 2214-2126
DO  - https://doi.org/10.1016/j.jisa.2022.103148
UR  - https://www.sciencedirect.com/science/article/pii/S2214212622000382
KW  - Domain generation algorithms
KW  - Representation model
KW  - Malicious domain name
KW  - Information security
AB  - The existing detection methods of algorithmically generated malicious domain names lack theoretical modelling methods for domain name element composition. To address this problem, a semantic element representation model for domain names is constructed based on the set of semantic elements of domain names and the probabilistic context free grammar model. The model first analyses and categorises the constituent elements of the domain name, and then proposes a syntax tree analysis method for the semantical relationships between the elements, which enables efficient representation of multiple elements in domain names. Based on the proposed model, the malicious domain names are categorised into four categories: random character-based, word-based, predicted character-based, and multi-element hybrid. Experiments are conducted to analyse the anomalies and concealment of domain names, the results denote that there are significant differences between malicious and legitimate domain names, as well as between malicious domain names, and the comparative experimental results denote the proposed model can effectively improve the detection accuracy of malicious domain names.
ER  - 

TY  - JOUR
T1  - SCsVulSegLytix: Detecting and extracting vulnerable segments from smart contracts using weakly-supervised learning
AU  - Ahmadzadeh, Borna
AU  - Haghighian Roudsari, Arousha
AU  - HajiHosseinKhani, Sepideh
AU  - Habibi Lashkari, Arash
JO  - Journal of Systems and Software
VL  - 230
SP  - 112532
PY  - 2025
DA  - 2025/12/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2025.112532
UR  - https://www.sciencedirect.com/science/article/pii/S0164121225002006
KW  - SCs
KW  - Vulnerability
KW  - Analyzers
KW  - Tools
KW  - Vulnerability detection
KW  - Vulnerabilities’ causes
KW  - Security attacks
AB  - Smart contracts (SCs), self-executing digital contracts deployed on blockchain networks, are becoming increasingly more prevalent in various sectors, such as finance, thanks to their automation, transparency, and cost efficiency. Given the substantial size of assets managed by them, SCs have become attractive targets for hackers, who exploit vulnerabilities in them to steal funds. Blockchain’s inherent immutability means vulnerabilities cannot be fixed quickly, and the immaturity of the Solidity programming language, which introduces potential security threats to SCs, exacerbates this problem. As such, there is a pressing need to develop security measures to identify vulnerabilities in SCs. Non-learning-based detection methods utilizing heuristics designed by experts often cannot handle the evolving complexity of SC vulnerabilities. In contrast, though typically outperforming non-learning-based solutions, learning-based solutions generally do not pinpoint the locations of vulnerabilities in SCs. Learning-based approaches that identify the locations of vulnerabilities come with several challenges: First, they convert SCs into graphs, incurring computational overhead and making the learning system more complex. Second, most require line- or function-level labels to be trained, which are difficult to gather. Lastly, their coverage of vulnerability types is not extensive, exposing the user to vulnerabilities not covered by them. This work presents SCsVulSegLytix, a learning-based approach for detecting and extracting vulnerable segments in SCs. SCsVulSegLytix uses a source code-based Transformer model trained with contract-level labels to classify entire contracts as vulnerable, followed by a post-hoc interpretability method to extract vulnerable segments in SCs according to relevance scores. Unlike previous extraction models, SCsVulSegLytix requires no line-level annotations and can be trained using contract-wide labels only, which are much easier to collect. Moreover, it operates directly on Solidity source code, substantially improving efficiency compared to expensive graph-based models. Finally, it extends support to several important classes of SC vulnerabilities, meaning developers are protected against various potential attacks. Experiments show that our model outperforms existing models concerning both contract- and line-level vulnerability identification while achieving greater computation efficiency.
ER  - 

TY  - JOUR
T1  - Building robust traffic classifier under low quality data: A federated contrastive learning approach
AU  - Qin, Tian
AU  - Cheng, Guang
AU  - Yin, Zhichao
AU  - Wei, Yichen
AU  - Yao, Zifan
AU  - Chen, Zihan
JO  - Digital Communications and Networks
VL  - 11
IS  - 5
SP  - 1479
EP  - 1492
PY  - 2025
DA  - 2025/10/01/
SN  - 2352-8648
DO  - https://doi.org/10.1016/j.dcan.2025.06.001
UR  - https://www.sciencedirect.com/science/article/pii/S235286482500080X
KW  - Federated learning
KW  - Network traffic classification
KW  - Contrastive learning
KW  - Robust machine learning
KW  - Packet loss
AB  - In the big data era, the surge in network traffic volume poses challenges for network management and cybersecurity. Network Traffic Classification (NTC) employs deep learning to categorize traffic data, aiding security and analysis systems as Intrusion Detection Systems (IDS) and Intrusion Prevention Systems (IPS). However, current NTC methods, based on isolated network simulations, usually fail to adapt to new protocols and applications and ignore the effects of network conditions and user behavior on traffic patterns. To improve network traffic management insights, federated learning frameworks have been proposed to aggregate diverse traffic data for collaborative model training. This approach faces challenges like data integrity, label noise, packet loss, and skewed data distributions. While label noise can be mitigated through the use of sophisticated traffic labeling tools, other issues such as packet loss and skewed data distributions encountered in Network Packet Brokers (NPB) can severely impede the efficacy of federated learning algorithms. In this paper, we introduced the Robust Traffic Classifier with Federated Contrastive Learning (FC-RTC), combining federated and contrastive learning methods. Using the Supcon-Loss function from contrastive learning, FC-RTC distinguishes between similar and dissimilar samples. Training by sample pairs, FC-RTC effectively updates when receiving corrupted traffic data with packet loss or disorder. In cases of sample imbalance, contrastive loss functions for similar samples reduce model bias towards higher proportion data. By addressing uneven data distribution and packet loss, our system enhances its capability to adapt and perform accurately in real-world network traffic analysis, meeting the specific demands of this complex field.
ER  - 

TY  - JOUR
T1  - Log2Evt: Constructing high-level events for IoT Systems through log-code execution path correlation
AU  - Li, Teng
AU  - Zheng, Baichuan
AU  - Feng, Yebo
AU  - Quan, Xiaowen
AU  - Xu, Jiahua
AU  - Liu, Yang
AU  - Ma, Jianfeng
JO  - Journal of Systems Architecture
VL  - 168
SP  - 103578
PY  - 2025
DA  - 2025/11/01/
SN  - 1383-7621
DO  - https://doi.org/10.1016/j.sysarc.2025.103578
UR  - https://www.sciencedirect.com/science/article/pii/S1383762125002504
KW  - Internet of things
KW  - Smart society
KW  - Log analysis
KW  - Event converting
KW  - Graph theory
AB  - The detection of cyberattacks in IoT ecosystems requires comprehensive log auditing across distributed devices, yet the volume and heterogeneity of IoT logs exceed traditional analysis capabilities. Therefore, it is essential to narrow down the scope of forensics precisely and efficiently to target attack-related events. Existing schemes have the disadvantage of low accuracy and flexibility. We propose a novel approach that synthesizes high-level security events from low-level IoT logs by correlating firmware execution traces with runtime call stack contexts. Our approach implements lightweight monitoring probes at critical IoT workflow points and employs an IoT-optimized Common Ancestor algorithm for log sequence analysis. The experiments demonstrate a 15% improvement in accuracy compared to the rule-based matching scheme. Additionally, the results highlight the influence of the threshold parameter and show that the approach has minimal impact on program operation. The approach effectively addresses the challenges of protocol fragmentation and resource constraints in IoT environments, providing a foundation for robust security monitoring in smart city deployments.
ER  - 

TY  - JOUR
T1  - Semi-meta-supervised hate speech detection
AU  - Putra, Cendra Devayana
AU  - Wang, Hei-Chia
JO  - Knowledge-Based Systems
VL  - 287
SP  - 111386
PY  - 2024
DA  - 2024/03/05/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2024.111386
UR  - https://www.sciencedirect.com/science/article/pii/S0950705124000212
KW  - Semisupervised learning
KW  - Single-task learning
KW  - Hate speech
KW  - Shared knowledge
AB  - On social media, hate speech is a daily occurrence but has physical and psychological implications. Utilizing a deep learning strategy to combat hate speech is one method for preventing it. Deep learning techniques may require massive datasets to generate accurate models, but hate speech samples (such as misogyny and cyber samples) are frequently insufficient and diverse. We offer methods for leveraging these diverse datasets and enhancing deep learning models through knowledge sharing. We analyzed the existing Bidirectional Encoder Representations from Transformers (BERT) technique and built a BERT-3CNN method to generate a single-task classifier that optimally absorbs the target dataset's features. Second, we proposed a shared BERT layer to gain a general understanding of hate speech. Third, we proposed a method for adapting another dataset to the desired dataset. We conducted several quantitative experimental investigations on five datasets, including Hatebase, Supremacist, Cybertroll, TRAC, and TRAC 2020, and assessed the achieved performance using the accuracy and F1 metrics. The first experiment demonstrated that our BERT-3CNN model improved the average accuracy by 5% and the F1 score by 18%. The second experiment demonstrated that BERT-SP improved the average accuracy by 0.2% and the F1 score by 2%. TRAC, Supremacist, Hatebase, and Cybertroll all showed improvements in accuracy, with Semi BERT-SP enhancing accuracy by 6% and F1 score by 5%, while TRAC2020 showed 10% and 9% improvements.
ER  - 

TY  - JOUR
T1  - Detection of malicious javascript on an imbalanced dataset
AU  - Phung, Ngoc Minh
AU  - Mimura, Mamoru
JO  - Internet of Things
VL  - 13
SP  - 100357
PY  - 2021
DA  - 2021/03/01/
SN  - 2542-6605
DO  - https://doi.org/10.1016/j.iot.2021.100357
UR  - https://www.sciencedirect.com/science/article/pii/S2542660521000019
KW  - Malicious JavaScript
KW  - Attention mechanism
KW  - Natural language processing
KW  - Oversampling
KW  - Machine learning
AB  - In order to be able to detect new malicious JavaScript with low cost, methods with machine learning techniques have been proposed and gave positive results. These methods focus on achieving a light-weight filtering model that can quickly and precisely filter out malicious data for dynamic analysis. A method constructs a language model using Natural Language Processing techniques to represent the data in vector form from the source code for machine learning. This method has high score with the balanced dataset, however the experiment with an imbalanced dataset has not been done. Previous studies mainly focus on a balanced dataset, however the dataset is not representative of real-world data, and it rises questions in practical uses of the model. A good model that can have a high recall score with imbalanced dataset is needed for a good filter. To construct an efficient language model, and to deal with the data imbalance problem, we focus on oversampling techniques. In our research, our method is the first to use oversampling and machine learning to detect malicious JavaScript. The experimental result shows that our method can detect new malicious JavaScript more accurately and efficiently. Our model can quickly filter out malicious data for dynamic analysis. The best recall score achieves 0.72 with the Doc2Vec model. Our proposed method is shown to outperform the baseline method by 210% in terms of recal score with the same training time and test time per sample.
ER  - 

TY  - JOUR
T1  - Design of countermeasure to packet falsification in vehicle platooning by explainable artificial intelligence
AU  - Mongelli, M.
JO  - Computer Communications
VL  - 179
SP  - 166
EP  - 174
PY  - 2021
DA  - 2021/11/01/
SN  - 0140-3664
DO  - https://doi.org/10.1016/j.comcom.2021.06.026
UR  - https://www.sciencedirect.com/science/article/pii/S0140366421002504
KW  - Vehicle platooning
KW  - Cyber attacks
KW  - eXplainable AI
KW  - Collision avoidance
AB  - In view of system reliability, extraction of knowledge from models of artificial intelligence may be more important than their forecasting ability. The elaboration of rules found by explainable artificial intelligence gives here insight into the problem of packet falsification in vehicle platooning. Detection and countermeasure are designed on the basis of feature and value ranking as well as rule confidence and they are validated under a large range of working conditions. The certification of safe operating conditions is found by achieving (statistically) zero false negatives, namely, the operating conditions predicted as ‘safe’ never lead to collision despite the cyber attack.
ER  - 

TY  - JOUR
T1  - “Language is the dress of thought”: A new method for automatic detection of AI-generated text
AU  - Wang, Zhenhua
AU  - Xu, Guang
AU  - Ren, Ming
JO  - Decision Support Systems
VL  - 201
SP  - 114578
PY  - 2026
DA  - 2026/02/01/
SN  - 0167-9236
DO  - https://doi.org/10.1016/j.dss.2025.114578
UR  - https://www.sciencedirect.com/science/article/pii/S0167923625001794
KW  - AI-generated text
KW  - Language latent level
KW  - Human-written text
KW  - Deep learning
AB  - While AI technologies have garnered widespread attention for their revolutionary text generation capabilities, concerns have arisen regarding the risks associated with AI-generated text (AIGT), especially when used maliciously. Motivated by the recognition that AIGT is generated based on high-probability tokens, a process that inherently differs from the biological-based thought processes underlying human-written text (HWT), we trace and build upon theories of the language latent level to explore the fundamental differences between AIGT and HWT, particularly in terms of potentiality, logicality, and complexity. A novel method named LA2HDetect is proposed for automatic AIGT detection. Specifically, we discover that HWT exhibits higher potentiality than AIGT; AIGT and HWT each possesses unique characteristics in terms of logicality and complexity. These human-AI differences collectively form the decision-making mechanism of LA2HDetect. Extensive experiments on general domain datasets confirm the competitiveness and robustness of LA2HDetect, which outperforms existing methods. In addition, we evaluate the extensibility of LA2HDetect in multiple vertical domains, and explore the insights across progressively advanced AI models.
ER  - 

TY  - JOUR
T1  - CASI: Context-aware Automatic Semantic Inference by fusing video and network traffic information in industrial control systems
AU  - Hetu, Zheqiu
AU  - Zhang, Zhenyong
AU  - Wang, Mufeng
AU  - Xv, Zidong
AU  - Meng, Jie
JO  - Information Fusion
VL  - 122
SP  - 103174
PY  - 2025
DA  - 2025/10/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2025.103174
UR  - https://www.sciencedirect.com/science/article/pii/S1566253525002477
KW  - Industrial control system
KW  - Semantic inference
KW  - Information fusion
KW  - Reverse engineering
KW  - Network security
AB  - The increasing adoption of Internet of Things devices in Industrial Control Systems (ICS) has provided both attackers and security professionals with new perspectives on these traditionally safety-critical systems. Our observations reveal that video captured by field-deployed cameras contains process variables (PVs) essential for both ICS attack and defense. Based on this insight, we propose a Context-Aware Semantic Inference (CASI) method. CASI integrates video information from cameras with network traffic to infer the physical semantics of PVs in network packets, serving as a tactical tool for attackers or security professionals. A key advantage of CASI is its non-intrusive nature, deriving PVs location in the packets and semantics solely from video and network traffic without interacting with the runtime ICS, which is both covert and ensures the uninterrupted operation of the system. We constructed an ICS testbed using real devices to replicate a simplified industrial process, collecting traffic from 2 industrial protocols and creating 4 datasets. We evaluated CASI’s precision and recall in detecting PVs within this context, comparing it with similar tools. Experimental results demonstrate that CASI achieves a recall rate of 1.00 in PV semantic extraction, significantly outperforming other tools. Furthermore, leveraging CASI-derived semantic information for data tampering attacks successfully disrupted monitoring and data acquisition programs, posing a severe security threat to the ICS.
ER  - 

TY  - JOUR
T1  - AI and Blockchain-based source code vulnerability detection and prevention system for multiparty software development
AU  - Nath, Panchanan
AU  - Mushahary, Jaya Rani
AU  - Roy, Ujjal
AU  - Brahma, Maharaj
AU  - Singh, Pranav Kumar
JO  - Computers and Electrical Engineering
VL  - 106
SP  - 108607
PY  - 2023
DA  - 2023/03/01/
SN  - 0045-7906
DO  - https://doi.org/10.1016/j.compeleceng.2023.108607
UR  - https://www.sciencedirect.com/science/article/pii/S0045790623000320
KW  - Deep learning
KW  - Blockchain
KW  - Smart contract
KW  - IPFS
KW  - Software testing
KW  - Software development
AB  - With the growing demand for application software, there is a race among industries to develop software as quickly as possible. However, maintaining pace and ensuring bug-free software has become increasingly challenging in a work-from-home arrangement as software developers are not under constant supervision. It increases the possibility of buggy products, and traditional testing techniques fail to provide optimal performance. We propose an Artificial Intelligence (AI) and blockchain-based novel decentralized software testing system. The proposed system aims to detect and prevent vulnerable code by synergizing deep learning capabilities and smart-contract-powered blockchain. The vulnerability detection is performed automatically without relying on manually written rules. We propose a non-vulnerability score range map to classify the source code. Furthermore, we integrate an InterPlanetary File System (IPFS) to ensure efficient storage over the blockchain. We conduct a testbed-based experiment to demonstrate the effectiveness of AI and blockchain integration for secure code development and testing.
ER  - 

TY  - JOUR
T1  - AI Agents vs. Agentic AI: A Conceptual taxonomy, applications and challenges
AU  - Sapkota, Ranjan
AU  - Roumeliotis, Konstantinos I.
AU  - Karkee, Manoj
JO  - Information Fusion
VL  - 126
SP  - 103599
PY  - 2026
DA  - 2026/02/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2025.103599
UR  - https://www.sciencedirect.com/science/article/pii/S1566253525006712
KW  - AI agents
KW  - Agentic AI
KW  - Context awareness
KW  - Multi-agent systems
KW  - Conceptual taxonomy
AB  - Information fusion, in the context of the Generative AI era, must distinguish AI Agents from Agentic AI. This review critically distinguishes between AI Agents and Agentic AI, offering a structured, conceptual taxonomy, application mapping, and analysis of opportunities and challenges to clarify their divergent design philosophies and capabilities. We begin by outlining the search strategy and foundational definitions, characterizing AI Agents as modular systems driven and enabled by LLMs and LIMs for task-specific automation. Generative AI is positioned as a precursor providing the foundation, with AI agents advancing through tool integration, prompt engineering, and reasoning enhancements. We then characterize Agentic AI systems, which, in contrast to AI Agents, represent a paradigm shift marked by multi-agent collaboration, dynamic task decomposition, persistent memory, and coordinated autonomy. Through a chronological evaluation of architectural evolution, operational mechanisms, interaction styles, and autonomy levels, we present a comparative analysis across both AI agents and agentic AI paradigms. Application domains enabled by AI Agents such as customer support, scheduling, and data summarization are then contrasted with Agentic AI deployments in research automation, robotic coordination, and medical decision support. We further examine unique challenges in each paradigm including hallucination, brittleness, emergent behavior, and coordination failure, and propose targeted solutions such as ReAct loops, retrieval-augmented generation (RAG), automation coordination layers, and causal modeling. This work aims to provide a roadmap for developing robust, scalable, and explainable AI-driven systems.
ER  - 

TY  - JOUR
T1  - A model-driven approach to streamline the development of prescriptive services for digital twins
AU  - Barriga, Arturo
AU  - Barriga, José A.
AU  - Portillo, Pablo A.
AU  - Lozano-Tello, Adolfo
AU  - Clemente, Pedro J.
JO  - Information and Software Technology
VL  - 191
SP  - 108001
PY  - 2026
DA  - 2026/03/01/
SN  - 0950-5849
DO  - https://doi.org/10.1016/j.infsof.2025.108001
UR  - https://www.sciencedirect.com/science/article/pii/S0950584925003404
KW  - Prescriptive digital twins
KW  - Model-driven development
KW  - Domain-specific language
KW  - Model-to-text transformations
KW  - Software engineering
AB  - Context:
Digital twins are dynamic virtual replicas of physical systems that offer significant benefits in terms of efficiency and productivity. In particular, prescriptive digital twins are able to provide specific recommendations to help stakeholders optimize physical system performance, reduce risks, and proactively solve problems. However, despite the high value of prescriptive services, most current digital twin implementations remain focused on monitoring and descriptive analytics, lacking the advanced capabilities required to provide actionable, prescriptive insights.
Objective:
This paper aims to streamline the development of prescriptive services for digital twin systems, thus fostering their adoption and unlocking their full potential.
Methods:
To this end, a Model-Driven Development (MDD) approach specifically designed for prescriptive digital twin services is proposed.
Results:
With the proposed Domain-Specific Language (DSL), developers can focus on designing their prescriptive services from a high-level perspective. Then, Model-to-Text (M2T) transformations generate the required code, configuration files, and deployment artifacts.
Conclusion:
Thus, this approach not only reduces the development time and cost of these services, but also reduces the need for technical expertise. In addition, the applicability of the proposal is validated through two digital twin use cases in the agriculture and manufacturing domains.
ER  - 

TY  - JOUR
T1  - Beyond domain dependency in security requirements identification
AU  - Casillo, Francesco
AU  - Deufemia, Vincenzo
AU  - Gravino, Carmine
JO  - Information and Software Technology
VL  - 182
SP  - 107702
PY  - 2025
DA  - 2025/06/01/
SN  - 0950-5849
DO  - https://doi.org/10.1016/j.infsof.2025.107702
UR  - https://www.sciencedirect.com/science/article/pii/S0950584925000412
KW  - Security Requirements Classification
KW  - Natural Language Processing
KW  - Machine Learning
KW  - Transformers
AB  - Context:
Early security requirements identification is crucial in software development, facilitating the integration of security measures into IT networks and reducing time and costs throughout software life-cycle.
Objectives:
This paper addresses the limitations of existing methods that leverage Natural Language Processing (NLP) and machine learning techniques for detecting security requirements. These methods often fall short in capturing syntactic and semantic relationships, face challenges in adapting across domains, and rely heavily on extensive domain-specific data. In this paper we focus on identifying the most effective approaches for this task, highlighting both domain-specific and domain-independent strategies.
Method:
Our methodology encompasses two primary streams of investigation. First, we explore shallow machine learning techniques, leveraging word embeddings. We test ensemble methods and grid search within and across domains, evaluating on three industrial datasets. Next, we develop several domain-independent models based on BERT, tailored to better detect security requirements by incorporating data on software weaknesses and vulnerabilities.
Results:
Our findings reveal that ensemble and grid search methods prove effective in domain-specific and domain-independent experiments, respectively. However, our custom BERT models showcase domain independence and adaptability. Notably, the CweCveCodeBERT model excels in Precision and F1-score, outperforming existing approaches significantly. It improves F1-score by ∼3% and Precision by ∼14% over the best approach currently in the literature.
Conclusion:
BERT-based models, especially with specialized pre-training, show promise for automating security requirement detection. This establishes a foundation for software engineering researchers and practitioners to utilize advanced NLP to improve security in early development phases, fostering the adoption of these state-of-the-art methods in real-world scenarios.
ER  - 

TY  - JOUR
T1  - Future themes in regulating artificial intelligence in investment management
AU  - Buczynski, Wojtek
AU  - Steffek, Felix
AU  - Jamnik, Mateja
AU  - Cuzzolin, Fabio
AU  - Sahakian, Barbara
JO  - Computer Law & Security Review
VL  - 56
SP  - 106111
PY  - 2025
DA  - 2025/04/01/
SN  - 2212-473X
DO  - https://doi.org/10.1016/j.clsr.2025.106111
UR  - https://www.sciencedirect.com/science/article/pii/S0267364925000068
KW  - AI
KW  - Artificial intellogence
KW  - Investments
KW  - investment management
KW  - Finance
KW  - Financial services
KW  - Regulations
KW  - law
KW  - Laws
KW  - Regulation
AB  - We are witnessing the emergence of the “first generation” of AI and AI-adjacent soft and hard laws such as the EU AI Act or South Korea's Basic Act on AI. In parallel, existing industry regulations, such as GDPR, MIFID II or SM&CR, are being “retrofitted” and reinterpreted from the perspective of AI. In this paper we identify and analyze ten novel, “second generation” themes which are likely to become regulatory considerations in the near future: non-personal data, managerial accountability, robo-advisory, generative AI, privacy enhancing techniques (PETs), profiling, emergent behaviours, smart contracts, ESG and algorithm management. The themes have been identified on the basis of ongoing developments in AI, existing regulations and industry discussions. Prior to making any new regulatory recommendations we explore whether novel issues can be solved by existing regulations. The contribution of this paper is a comprehensive picture of emerging regulatory considerations for AI in investment management, as well as broader financial services, and the ways they might be addressed by regulations – future or existing ones.
ER  - 

TY  - JOUR
T1  - PypiGuard: A novel meta-learning approach for enhanced malicious package detection in PyPI through static-dynamic feature fusion
AU  - Iqbal, Tahir
AU  - Wu, Guowei
AU  - Iqbal, Zahid
AU  - Mahmood, Muhammad Bilal
AU  - Shafique, Amreen
AU  - Guo, Wenbo
JO  - Journal of Information Security and Applications
VL  - 90
SP  - 104032
PY  - 2025
DA  - 2025/05/01/
SN  - 2214-2126
DO  - https://doi.org/10.1016/j.jisa.2025.104032
UR  - https://www.sciencedirect.com/science/article/pii/S2214212625000705
KW  - Malicious package detection
KW  - Hybrid ensemble meta-model
KW  - Static and dynamic feature fusion
KW  - Python package security (PyPI)
KW  - Software supply chain security
AB  - The increasing reliance on open-source software repositories, especially the Python Package Index (PyPi), has introduced serious security vulnerabilities as malicious actors embed malware into widely adopted packages, threatening the integrity of the software supply chain. Traditional detection methods, often based on static analysis, struggle to capture the complex and obfuscated behaviors characteristic of modern malware. Addressing these limitations, we present PypiGuard, an advanced hybrid ensemble meta-model for malicious package detection that integrates both static metadata and dynamic Application Programming Interface (API) call behaviors, enhancing detection accuracy and reducing error rates. Leveraging the MalwareBench dataset, our approach utilizes an innovative preprocessing pipeline that fuses metadata features with categorized API behaviors. The PypiGuard model employs a hybrid ensemble structure composed of Random Forest (RF), Gradient Boosting (GB), Decision Tree (DT), K-Nearest Neighbors (KNN), LightGBM, and an Artificial Neural Network (ANN), assembled through dynamically optimized stacking-based meta-learning framework that adapts to model-specific prediction strengths. Compared to Deep Learning (DL) baselines like Long-Short Term Memory (LSTM) and Convolutional Neural Network (CNN), PypiGuard achieves significant improvements in accuracy and False Positive Rate (FPR), with a detection accuracy of 98.43% and a markedly low FPR, confirming its enhanced effectiveness in accurately identifying malicious packages.
ER  - 

TY  - JOUR
T1  - ALBERT-BiLSTM cross-attention network with progressive knowledge distillation for multi-domain SMS spam classification
AU  - Aparna, B.S.
AU  - S, Remya
AU  - Pillai, Manu J.
AU  - Subbareddy, Somula Rama
AU  - Cho, Yong Yun
JO  - Results in Engineering
VL  - 27
SP  - 106727
PY  - 2025
DA  - 2025/09/01/
SN  - 2590-1230
DO  - https://doi.org/10.1016/j.rineng.2025.106727
UR  - https://www.sciencedirect.com/science/article/pii/S259012302502794X
KW  - Spam detection
KW  - BiLSTM
KW  - ALBERT
KW  - Knowledge distillation
KW  - Deep learning
KW  - Text classification
KW  - Transformer-based embeddings
KW  - Cybersecurity
AB  - SMS spam detection remains a critical challenge in digital communication systems, particularly in agriculture where farmers depend on SMS services for weather updates, crop prices, and government notifications. Traditional spam detection methods fail to handle evolving spam tactics and class imbalance effectively. This paper proposes a hybrid ensemble model that combines ALBERT transformer embeddings with BiLSTM networks enhanced by attention mechanisms and knowledge distillation. Experimental evaluation on the SMS Spam Collection dataset demonstrates superior performance with 98% accuracy, 0.98 precision, 0.97 recall, and 0.98 F1-score. The ensemble model significantly outperforms individual ALBERT (88% accuracy) and BiLSTM (54% accuracy) models. Knowledge distillation reduces model size from 425 MB to 67 MB, enabling real-time deployment with 0.045-second processing time per message. The system achieves 22.2 messages per second throughput, making it suitable for practical applications. Real-world testing in agricultural communication networks demonstrates significant improvements in spam filtering compared to traditional keyword-based filters. The hybrid approach provides an effective solution for SMS spam detection with demonstrated real-time performance and practical applicability in resource-constrained environments.
ER  - 

TY  - JOUR
T1  - Understanding privacy concerns in ChatGPT: A data-driven approach with LDA topic modeling
AU  - Alkamli, Shahad
AU  - Alabduljabbar, Reham
JO  - Heliyon
VL  - 10
IS  - 20
SP  - e39087
PY  - 2024
DA  - 2024/10/30/
SN  - 2405-8440
DO  - https://doi.org/10.1016/j.heliyon.2024.e39087
UR  - https://www.sciencedirect.com/science/article/pii/S2405844024151183
KW  - ChatGPT
KW  - Privacy concerns
KW  - Generative AI
KW  - Twitter
KW  - Survey
KW  - Latent dirichlet allocation (LDA)
KW  - Data categorization
KW  - Unauthorized access
KW  - Data exploitation
KW  - Personal input
AB  - This study investigates privacy concerns associated with ChatGPT, a prominent generative AI model, through a data-driven approach combining Twitter data analysis and a user survey. Leveraging Latent Dirichlet Allocation (LDA) topic modeling and data categorization techniques, the research identifies key areas of concern: 1) Privacy Leakage Due to Public Data Exploitation, 2) Privacy Leakage Due to Personal Input Exploitation, and 3) Privacy Leakage Due to Unauthorized Access. Twitter data analysis of over 500k tweets, supplemented by a survey of 67 ChatGPT users, reveals nuanced user perceptions and experiences regarding privacy risks. A Python program was used to improve a dataset of 500k tweets referencing “ChatGPT” during the data preparation stage. To get a refined collection of terms, steps included converting text to lowercase, eliminating mentions and hyperlinks, tokenizing, eliminating stopwords, and keyword matching to extract tweets about ChatGPT's privacy features. Once preprocessing was completed, there were 11k refined tweets. Results highlight significant apprehensions, particularly regarding unauthorized access, underscoring the importance of robust privacy measures in AI systems. The study contributes to understanding user concerns, informing policy decisions, and guiding future research on privacy in generative AI. These studies might improve ChatGPT and other AI systems' security and privacy. The public, corporations, researchers, lawmakers, and AI developers may all benefit from the useful information it provides in better understanding and managing privacy threats.
ER  - 

TY  - JOUR
T1  - A uniform assessment of host-based intrusion detection data sets
AU  - Bergner, Kevin
AU  - Landes, Dieter
JO  - Computers & Security
VL  - 157
SP  - 104503
PY  - 2025
DA  - 2025/10/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104503
UR  - https://www.sciencedirect.com/science/article/pii/S0167404825001919
KW  - Intrusion detection
KW  - Ids
KW  - Host intrusion detection
KW  - Hids
KW  - Data sets
AB  - A crucial element for the evaluation of host-based intrusion detection systems is the selection of appropriate host data sets. Due to the variations in the characteristics used to describe the individual data sets, it can be challenging to compare and select suitable host data for this purpose. To assist researchers with this endeavor, we compiled 23 properties that can be used to uniformly assess data sets regarding their usefulness in evaluating HIDS. To emphasize the applicability of the properties, we applied them to 15 public host data sets, which were identified based on a systematic literature review. This work offers a baseline for the comparability of multiple host data sets used to evaluate host-based intrusion detection systems. Finally, we also provide recommendations to researchers for generating more comparable HIDS evaluation data in the future.
ER  - 

TY  - JOUR
T1  - Real-Time Identity Authentication Scheme Based on Dynamic Credentials for Power AIGC System
AU  - Wei, Feng
AU  - Chen, Zhao
AU  - Wang, Yin
AU  - Liu, Dongqing
AU  - Zhang, Xun
AU  - Zhou, Zhao
JO  - Computers, Materials and Continua
VL  - 82
IS  - 3
SP  - 5325
EP  - 5341
PY  - 2025
DA  - 2025/03/06/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2025.058802
UR  - https://www.sciencedirect.com/science/article/pii/S1546221825001754
KW  - Cyber security
KW  - identity authentication
KW  - dynamic credential update
KW  - AIGC
AB  - The integration of artificial intelligence (AI) with advanced power technologies is transforming energy system management, particularly through real-time data monitoring and intelligent decision-making driven by Artificial Intelligence Generated Content (AIGC). However, the openness of power system channels and the resource-constrained nature of power sensors have led to new challenges for the secure transmission of power data and decision instructions. Although traditional public key cryptographic primitives can offer high security, the substantial key management and computational overhead associated with these primitives make them unsuitable for power systems. To ensure the real-time and security of power data and command transmission, we propose a lightweight identity authentication scheme tailored for power AIGC systems. The scheme utilizes lightweight symmetric encryption algorithms, minimizing the resource overhead on power sensors. Additionally, it incorporates a dynamic credential update mechanism, which can realize the rotation and update of temporary credentials to ensure anonymity and security. We rigorously validate the security of the scheme using the Real-or-Random (ROR) model and AVISPA simulation, and the results show that our scheme can resist various active and passive attacks. Finally, performance comparisons and NS3 simulation results demonstrate that our proposed scheme offers enhanced security features with lower overhead, making it more suitable for power AIGC systems compared to existing solutions.
ER  - 

TY  - JOUR
T1  - Wordcloud: Detecting mobile malware with deep learning and word of cloud
AU  - Che Yahaya, Che Akmal
AU  - Firdaus, Ahmad
AU  - Zabidi, Azlee
AU  - Ab Razak, Mohd Faizal
AU  - Narudin, Fairuz Amalina
JO  - Egyptian Informatics Journal
VL  - 32
SP  - 100834
PY  - 2025
DA  - 2025/12/01/
SN  - 1110-8665
DO  - https://doi.org/10.1016/j.eij.2025.100834
UR  - https://www.sciencedirect.com/science/article/pii/S1110866525002270
KW  - Root exploit
KW  - Android
KW  - Static analysis
KW  - Convolutional neural network
KW  - Deep learning
AB  - Mobile malware poses an increasing threat as it operates covertly and jeopardises user data and device functionality. Security professionals adopt two forms of analysis (static and dynamic) to detect malware. Dynamic analysis requires a significant amount of computational power and time to monitor, whereas static analysis uses fewer resources and processes more efficiently. However, finding the relevant features in static analysis is challenging, as the categories of features (permission, system calls, and intent) are constantly evolving, with too many options to choose from, and obfuscation presents additional challenges. In this paper, we present Wordcloud, a framework that uses static analysis, deep learning, and visual semantic representation to overcome these challenges. Our approach reverse-engineers Android APK files to smali code, then converts it into visual Wordcloud patterns that encode token frequency and structural patterns of the malware. These images are then classified using a convolutional neural network (CNN) to determine whether a sample is benign or malicious. Wordcloud survives obfuscation as it transforms the smali code into a visual “signature” that reflects statistical and structural traits of malware. We evaluated a real-world dataset of 50,000 Android samples from AMD and Androzoo, achieving 99.48% accuracy with high precision, recall, specificity, and F1 score metrics. Statistical tests were also performed to validate the performance improvement from our filtering process. This work contributes to a scalable, efficient malware prediction and detection solution for early threat identification in mobile security systems.
ER  - 

TY  - JOUR
T1  - Cyberbullying Sexism Harassment Identification by Metaheurustics-Tuned eXtreme Gradient Boosting
AU  - Dobrojevic, Milos
AU  - Jovanovic, Luka
AU  - Babic, Lepa
AU  - Cajic, Miroslav
AU  - Zivkovic, Tamara
AU  - Zivkovic, Miodrag
AU  - Muthusamy, Suresh
AU  - Antonijevic, Milos
AU  - Bacanin, Nebojsa
JO  - Computers, Materials and Continua
VL  - 80
IS  - 3
SP  - 4997
EP  - 5027
PY  - 2024
DA  - 2024/09/12/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2024.054459
UR  - https://www.sciencedirect.com/science/article/pii/S1546221824006532
KW  - Coyote optimization algorithm
KW  - NLP
KW  - TF-IDF
KW  - BERT
KW  - XGBoost
KW  - online harassment and cyberbullying
KW  - metaheuristics
AB  - Cyberbullying is a form of harassment or bullying that takes place online or through digital devices like smartphones, computers, or tablets. It can occur through various channels, such as social media, text messages, online forums, or gaming platforms. Cyberbullying involves using technology to intentionally harm, harass, or intimidate others and may take different forms, including exclusion, doxing, impersonation, harassment, and cyberstalking. Unfortunately, due to the rapid growth of malicious internet users, this social phenomenon is becoming more frequent, and there is a huge need to address this issue. Therefore, the main goal of the research proposed in this manuscript is to tackle this emerging challenge. A dataset of sexist harassment on Twitter, containing tweets about the harassment of people on a sexual basis, for natural language processing (NLP), is used for this purpose. Two algorithms are used to transform the text into a meaningful representation of numbers for machine learning (ML) input: Term frequency inverse document frequency (TF-IDF) and Bidirectional encoder representations from transformers (BERT). The well-known eXtreme gradient boosting (XGBoost) ML model is employed to classify whether certain tweets fall into the category of sexual-based harassment or not. Additionally, with the goal of reaching better performance, several XGBoost models were devised conducting hyperparameter tuning by metaheuristics. For this purpose, the recently emerging Coyote optimization algorithm (COA) was modified and adjusted to optimize the XGBoost model. Additionally, other cutting-edge metaheuristics approach for this challenge were also implemented, and rigid comparative analysis of the captured classification metrics (accuracy, Cohen kappa score, precision, recall, and F1-score) was performed. Finally, the best-generated model was interpreted by Shapley additive explanations (SHAP), and useful insights were gained about the behavioral patterns of people who perform social harassment.
ER  - 

TY  - JOUR
T1  - Building Society 5.0: a foundation for decision-making based on open models and digital twins
AU  - Fonseca i Casas, Pau
AU  - Pi i Palomes, Xavier
JO  - Advanced Engineering Informatics
VL  - 69
SP  - 103970
PY  - 2026
DA  - 2026/01/01/
SN  - 1474-0346
DO  - https://doi.org/10.1016/j.aei.2025.103970
UR  - https://www.sciencedirect.com/science/article/pii/S1474034625008638
KW  - Society 5.0, Digital Twins
KW  - LLM, AI
KW  - Governance
KW  - AI Agents
AB  - Human societies have undergone significant transformations throughout history, driven by technological advancements and societal needs. The emergence of Industry 4.0 marked a pivotal moment, with the digitalization, integrating automation, data exchange, artificial intelligence, and generating Digital Twins into manufacturing processes. However, as we move forward, the concept of Society 5.0 presents an even more profound shift. Society 5.0 is not an industrial revolution but an application of the industry 4.0 revolution for the decision making at all levels. It emphasizes holistic well-being, sustainability, and inclusivity. It aims to address social, economic, environmental, and technological challenges while fostering economic growth. Therefore, Society 5.0 envisions a harmonious coexistence between humans and technology, leveraging innovations such as artificial intelligence, the Internet of Things (IoT), through data-driven decision-making. At the heart of Society 5.0 lies the concept of Open Models and Digital Twins. These models must be transparent, accessible, and collaborative, allowing citizens to engage directly with assumptions, predictions, and validation processes. Digital Twins with Open Models provide visibility into their inner workings, enabling citizens to understand how decisions are made. Assumptions, data sources, and algorithms become accessible to all. Citizens can actively participate in discussions about model assumptions. By democratizing access to information, we empower individuals to make informed choices that impact their lives, therefore, validation and accountability of these models are key aspects. Digital Twins must undergo rigorous validation processes. Citizens can scrutinize these processes, ensuring accountability and trustworthiness. Society 5.0 represents a radical shift of our society organization founded in the existing Industry 4.0. revolution.
ER  - 

TY  - JOUR
T1  - Vishing: Detecting social engineering in spoken communication — A first survey & urgent roadmap to address an emerging societal challenge
AU  - Triantafyllopoulos, Andreas
AU  - Spiesberger, Anika A.
AU  - Tsangko, Iosif
AU  - Jing, Xin
AU  - Distler, Verena
AU  - Dietz, Felix
AU  - Alt, Florian
AU  - Schuller, Björn W.
JO  - Computer Speech & Language
VL  - 94
SP  - 101802
PY  - 2025
DA  - 2025/11/01/
SN  - 0885-2308
DO  - https://doi.org/10.1016/j.csl.2025.101802
UR  - https://www.sciencedirect.com/science/article/pii/S0885230825000270
KW  - Vishing
KW  - Social engineering
KW  - Human–computer interaction
KW  - Computational paralinguistics
AB  - Vishing – the use of voice calls for phishing – is a form of Social Engineering (SE) attacks. The latter have become a pervasive challenge in modern societies, with over 300,000 yearly victims in the US alone. An increasing number of those attacks is conducted via voice communication, be it through machine-generated ‘robocalls’ or human actors. The goals of ‘social engineers’ can be manifold, from outright fraud to more subtle forms of persuasion. Accordingly, social engineers adopt multi-faceted strategies for voice-based attacks, utilising a variety of ‘tricks’ to exert influence and achieve their goals. Importantly, while organisations have set in place a series of guardrails against other types of SE attacks, voice calls still remain ‘open ground’ for potential bad actors. In the present contribution, we provide an overview of the existing speech technology subfields that need to coalesce into a protective net against one of the major challenges to societies worldwide. Given the dearth of speech science and technology works targeting this issue, we have opted for a narrative review that bridges the gap between the existing psychological literature on the topic and research that has been pursued in parallel by the speech community on some of the constituent constructs. Our review reveals that very little literature exists on addressing this very important topic from a speech technology perspective, an omission further exacerbated by the lack of available data. Thus, our main goal is to highlight this gap and sketch out a roadmap to mitigate it, beginning with the psychological underpinnings of vishing, which primarily include deception and persuasion strategies, continuing with the speech-based approaches that can be used to detect those, as well as the generation and detection of AI-based vishing attempts, and close with a discussion of ethical and legal considerations.
ER  - 

TY  - JOUR
T1  - Resilient cognitive twin: A generative approach
AU  - Ge, Chenyu
AU  - Qin, Shengfeng
JO  - Advanced Engineering Informatics
VL  - 68
SP  - 103768
PY  - 2025
DA  - 2025/11/01/
SN  - 1474-0346
DO  - https://doi.org/10.1016/j.aei.2025.103768
UR  - https://www.sciencedirect.com/science/article/pii/S1474034625006615
KW  - Human-Cyber-Physical System
KW  - Digital twin
KW  - Cognitive twin
KW  - Engineered system
KW  - Resilience
KW  - Decision assistance
KW  - Smart city
AB  - Improving the resilience of an engineering system can be addressed from both a physical engineered system (PES) and its virtual replica--digital twin (DT) system. On the one hand, a DT can enhance the resilience of its PES by enabling real-time monitoring/proactive intervention and predictive maintenance. On the other hand, its deep integration with PES also increases the complexity of the overall system--both virtual and physical. This interdependence can transform single-sided risks into overall system-wide vulnerabilities, potentially undermining--even compromising--the resilience of the PES itself. To address this challenge, this paper proposes a new concept and framework of the Resilient Cognitive Twin (RCT), that supports generative reconfiguration and bidirectional feedback across the human–cyber–physical continuum. The framework is supported by a generative approach with three new enabling mechanisms: (1) a requirement decomposition and recompositing mechanism with edge-cloud-centre collaboration for forming a unified yet loosely coupled and low-level foundation of RCT; (2) a dynamic evolution mechanism enabling right-time co-evolution of data-model-service relationships for a changing environment and stakeholder needs; and (3) a generative cognitive mechanism for situational awareness and decision-making, responding to changing situations with proper and resilient services and their coordination/scheduling. The proposed framework and enabling approach are validated through an urban flood resilient DT system, demonstrating its capability to enhance resilience in complex, distributed environments, paving the way for Human-Cyber-Physical Systems and future industrial and societal applications.
ER  - 

TY  - JOUR
T1  - Generating customized low-code development platforms for digital twins
AU  - Dalibor, Manuela
AU  - Heithoff, Malte
AU  - Michael, Judith
AU  - Netz, Lukas
AU  - Pfeiffer, Jérôme
AU  - Rumpe, Bernhard
AU  - Varga, Simon
AU  - Wortmann, Andreas
JO  - Journal of Computer Languages
VL  - 70
SP  - 101117
PY  - 2022
DA  - 2022/06/01/
SN  - 2590-1184
DO  - https://doi.org/10.1016/j.cola.2022.101117
UR  - https://www.sciencedirect.com/science/article/pii/S2590118422000235
KW  - Digital twin
KW  - Low-code development platform
KW  - Domain-specific languages
KW  - Model-driven engineering
KW  - Code generation
AB  - A digital twin improves our use of a cyber–physical system and understanding of its emerging behavior. To this effect, a digital twin is to be developed and configured and potentially also operated by domain experts, who rarely have a professional software engineering background and for whom easy access and support, e.g., in form of low-code platforms are missing. In this paper, we report on an integrated method for the model-driven engineering of low-code development platforms for digital twins that enables domain experts to create and operate digital twins for cyber–physical systems using the most appropriate modeling languages. The foundation of this method is (1) a code generation infrastructure for information systems combined with (2) an extensible base architecture for self-adaptive digital twins and (3) reusable language components for their configuration. Using this method, software engineers first configure the information system with the required modeling languages to generate the low-code development platform for digital twins before domain experts leverage the generated platform to create digital twins. This two-step method facilitates creating tailored low-code development platforms as well as creating and operating customized digital twins for a variety of applications.
ER  - 

TY  - JOUR
T1  - Semantic Malware Classification Using Artificial Intelligence Techniques
AU  - Martins, Eliel
AU  - Higuera, Javier Bermejo
AU  - Sant’Ana, Ricardo
AU  - Higuera, Juan Ramón Bermejo
AU  - Montalvo, Juan Antonio Sicilia
AU  - Castillo, Diego Piedrahita
JO  - CMES - Computer Modeling in Engineering and Sciences
VL  - 142
IS  - 3
SP  - 3031
EP  - 3067
PY  - 2025
DA  - 2025/03/03/
SN  - 1526-1492
DO  - https://doi.org/10.32604/cmes.2025.061080
UR  - https://www.sciencedirect.com/science/article/pii/S1526149225000566
KW  - Malware
KW  - portable executable
KW  - semantic
KW  - convolutional neural networks
AB  - The growing threat of malware, particularly in the Portable Executable (PE) format, demands more effective methods for detection and classification. Machine learning-based approaches exhibit their potential but often neglect semantic segmentation of malware files that can improve classification performance. This research applies deep learning to malware detection, using Convolutional Neural Network (CNN) architectures adapted to work with semantically extracted data to classify malware into malware families. Starting from the Malconv model, this study introduces modifications to adapt it to multi-classification tasks and improve its performance. It proposes a new innovative method that focuses on byte extraction from Portable Executable (PE) malware files based on their semantic location, resulting in higher accuracy in malware classification than traditional methods using full-byte sequences. This novel approach evaluates the importance of each semantic segment to improve classification accuracy. The results revealed that the header segment of PE files provides the most valuable information for malware identification, outperforming the other sections, and achieving an average classification accuracy of 99.54%. The above reaffirms the effectiveness of the semantic segmentation approach and highlights the critical role header data plays in improving malware detection and classification accuracy.
ER  - 

TY  - JOUR
T1  - SIDiLDNG: A similarity-based intrusion detection system using improved Levenshtein Distance and N-gram for CAN
AU  - Song, Jiaru
AU  - Qin, Guihe
AU  - Liang, Yanhua
AU  - Yan, Jie
AU  - Sun, Minghui
JO  - Computers & Security
VL  - 142
SP  - 103847
PY  - 2024
DA  - 2024/07/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.103847
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824001482
KW  - Controller area network
KW  - Intrusion detection
KW  - N-gram
KW  - Levenshtein distance
KW  - Vehicle security
AB  - Due to the absence of encryption and authentication mechanisms in the Controller Area Network (CAN), it is highly susceptible to attacks, especially with the increasing connectivity of cars to networks. Existing statistical-based intrusion detection systems for CAN often focus solely on individual message transition relationships or consider only the overall message properties within a given time window, thereby failing to capture some essential features in CAN communication. To address the limitations of existing methods, we propose a novel Similarity-based Intrusion Detection System using improved Levenshtein Distance and N-gram algorithms (SIDiLDNG) to effectively capture both the overall characteristics and individual attributes of message sequences. Moreover, to enhance the detection time and response time for anomalous messages, we propose a combined block- and stream-based detection method. Evaluation on two publicly available datasets and a self-developed CAN prototype demonstrates that our method exhibits superior detection performance, faster detection times, and reduced response messages.
ER  - 

TY  - JOUR
T1  - Multi-paradigm modeling for cyber–physical systems: A systematic mapping review
AU  - Barišić, Ankica
AU  - Ruchkin, Ivan
AU  - Savić, Dušan
AU  - Mohamed, Mustafa Abshir
AU  - Al-Ali, Rima
AU  - Li, Letitia W.
AU  - Mkaouar, Hana
AU  - Eslampanah, Raheleh
AU  - Challenger, Moharram
AU  - Blouin, Dominique
AU  - Nikiforova, Oksana
AU  - Cicchetti, Antonio
JO  - Journal of Systems and Software
VL  - 183
SP  - 111081
PY  - 2022
DA  - 2022/01/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2021.111081
UR  - https://www.sciencedirect.com/science/article/pii/S0164121221001783
KW  - Cyber–Physical System
KW  - Model
KW  - Formalism
KW  - Development process
KW  - Modeling paradigm
KW  - Systematic review
AB  - Cyber–Physical Systems (CPS) are heterogeneous and require cross-domain expertise to model. The complexity of these systems leads to questions about prevalent modeling approaches, their ability to integrate heterogeneous models, and their relevance to the application domains and stakeholders. The methodology for Multi-Paradigm Modeling (MPM) of CPS is not yet fully established and standardized, and researchers apply existing methods for modeling of complex systems and introducing their own. No systematic review has been previously performed to create an overview of the field on the methods used for MPM of CPS. In this paper, we present a systematic mapping study that determines the models, formalisms, and development processes used over the last decade. Additionally, to determine the knowledge necessary for developing CPS, our review studied the background of actors involved in modeling and authors of surveyed studies. The results of the survey show a tendency to reuse multiple existing formalisms and their associated paradigms, in addition to a tendency towards applying transformations between models. These findings suggest that MPM is becoming a essential approach to model CPS, and highlight the importance of future integration of models, standardization of development process and education.
ER  - 

TY  - JOUR
T1  - A Comparison and Critical Reflection of Information Disorder Detection Techniques: Performing a Cross-Data and Cross-Model Evaluation
AU  - Gruensteidl, Mark Nicolas
AU  - Kirrane, Sabrina
JO  - Information Fusion
VL  - 127
SP  - 103806
PY  - 2026
DA  - 2026/03/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2025.103806
UR  - https://www.sciencedirect.com/science/article/pii/S1566253525008681
KW  - Information disorder
KW  - Detection
KW  - Data-centric AI
KW  - Natural language processing
KW  - Data quality
KW  - Data complexity
AB  - Information disorders, such as dis-, mis-, and malinformation, can lead to societal and/or economic harm. They are rapidly spread, extensively consumed on the web, and represent a threat to democracy. AI-based detection models can identify information disorders to some extent. However, major issues are the dynamics of news characteristics and concept drift. The generalization ability of a model is an important requirement and refers to its robustness when applied on unseen data. The aim of this work is to better understand the state of the art regarding information disorder detection approaches by conducting a reproducibility study and a cross-data and cross-model comparative analysis that leads to: (i) insights with respect to the effectiveness of binary information disorder classification; (ii) performance results on seen and unseen data; and (iii) new mixed European datasets named MENA. We conduct an evaluation of a fine-tuned BERT-based model applied on European data, which has received limited attention to date. The best performing models in our experiments are the RoBERTa and the Longformer models. The evaluation gives insights about potential biases of datasets that can be used to improve a model’s generalization ability. We also show that using domain-specific datasets for fine-tuning contributes to the robustness of models. Finally, we provide takeaways concerning reproducibility and stress the need for more transparent AI-based detection techniques.
ER  - 

TY  - JOUR
T1  - Generative modeling in smart manufacturing: Applications, challenges, and future directions
AU  - Ahsan, M. Nafis
AU  - Islam, M.D. Shafikul
AU  - Bappy, Mahathir Mohammad
JO  - Manufacturing Letters
VL  - 44
SP  - 1285
EP  - 1295
PY  - 2025
DA  - 2025/08/01/
T2  - 53rd SME North American Manufacturing Research Conference (NAMRC 53)
SN  - 2213-8463
DO  - https://doi.org/10.1016/j.mfglet.2025.06.148
UR  - https://www.sciencedirect.com/science/article/pii/S2213846325001804
KW  - Smart manufacturing
KW  - Generative models
KW  - Artificial intelligence
KW  - Machine learning
KW  - Industry 4.0
AB  - Generative modeling has emerged as a transformative tool in smart manufacturing, leveraging advanced machine learning architectures to optimize various manufacturing processes. In the data-rich environment of smart manufacturing, generative models enable the generation and synthesis of diverse process data that drive applications in design automation, quality control, and predictive maintenance. While the potential benefits are substantial, adopting generative models presents several challenges, including model interpretability issues, data privacy concerns, and integration difficulties with existing industrial systems. Addressing these obstacles is essential for the broader implementation of generative modeling across industrial settings. This review systematically explores the applications of generative modeling in smart manufacturing, focusing on its impact in areas such as additive manufacturing, defect prediction, and adaptive supply chain management. Furthermore, by exploring core components of smart manufacturing, this study situates generative modeling within Industry 4.0 contexts, providing a structured overview of recent advancements and technological foundations. This paper highlights future research directions, proposing integrations with digital twins, cyber-physical systems, collaborative robotics, and circular economy to strengthen adaptability, resilience, and real-time decision-making capabilities. By analyzing current applications, challenges, and future pathways, this review aims to equip researchers and practitioners with critical insights, guiding the effective deployment of generative modeling to drive a resilient, data-driven future in smart manufacturing.
ER  - 

TY  - JOUR
T1  - A systematic review of metaheuristics-based and machine learning-driven intrusion detection systems in IoT
AU  - Ahsan, Mohammad Shamim
AU  - Islam, Salekul
AU  - Shatabda, Swakkhar
JO  - Swarm and Evolutionary Computation
VL  - 96
SP  - 101984
PY  - 2025
DA  - 2025/07/01/
SN  - 2210-6502
DO  - https://doi.org/10.1016/j.swevo.2025.101984
UR  - https://www.sciencedirect.com/science/article/pii/S2210650225001427
KW  - Internet of Things (IoT)
KW  - Intrusion Detection Systems (IDS)
KW  - Machine Learning (ML)
KW  - Deep Learning (DL)
KW  - Metaheuristic algorithms
KW  - Cybersecurity
KW  - Optimization techniques
AB  - The widespread adoption of the Internet of Things (IoT) has raised a new challenge for developers since it is prone to known and unknown cyberattacks due to its heterogeneity, flexibility, and close connectivity. To defend against such security breaches, researchers have focused on building sophisticated intrusion detection systems (IDSs) using machine learning (ML) techniques. Although these algorithms notably improve detection performance, they require excessive computing power and resources, which are crucial issues in IoT networks considering the recent trends of decentralized data processing and computing systems. Consequently, many optimization techniques have been incorporated with these ML models. Specifically, a special category of optimizer adopted from the behavior of living creatures and different aspects of natural phenomena, known as metaheuristic algorithms, has been a central focus in recent years and brought about remarkable results. Considering this vital significance, we present a comprehensive and systematic review of various applications of metaheuristics algorithms in developing a machine learning-based IDS, especially for IoT. A significant contribution of this study is the discovery of hidden correlations between these optimization techniques and machine learning models integrated with state-of-the-art IoT-IDSs. In addition, the effectiveness of these metaheuristic algorithms in different applications, such as feature selection, parameter or hyperparameter tuning, and hybrid usages are separately analyzed. Moreover, a taxonomy of existing IoT-IDSs is proposed. Furthermore, we investigate several critical issues related to such integration. Our extensive exploration ends with a discussion of promising optimization algorithms and technologies that can enhance the efficiency of IoT-IDSs.
ER  - 

TY  - JOUR
T1  - Semantic-based defense mechanism for ai model networks using rich semantic identifier mapping
AU  - Ba, Linjiang
AU  - Guan, Jianfeng
AU  - Jiang, Jiapeng
JO  - Computers and Electrical Engineering
VL  - 122
SP  - 109977
PY  - 2025
DA  - 2025/03/01/
SN  - 0045-7906
DO  - https://doi.org/10.1016/j.compeleceng.2024.109977
UR  - https://www.sciencedirect.com/science/article/pii/S0045790624009029
KW  - Semantic-rich
KW  - Identifier mapping
KW  - Distributed AI training
KW  - AI threats
KW  - DDoS
KW  - Access control
AB  - As AI models rapidly advance, they face increasing network threats. Distributed AI training lacks effective security mechanisms; current centralized networking schemes focus on transmission speed but fail to ensure communication security for distributed servers. When AI models provide online services, servers can suffer from DDoS and man-in-the-middle attacks, leading to service outages or privacy breaches due to reliance on the traditional TCP/IP system. These security issues can be mitigated by designing a more robust identifier network system. Mainstream solutions like RoCE and Infiniband lack identifier-related message security, and the TCP/IP protocol stack has weak identification mechanisms. Therefore, research on AI networking and traditional network identification management is crucial. This paper introduces a semantic-rich identifier mapping (SRIM) management mechanism, which uses multi-dimensional identifiers to enhance network communication security. We designed a network layer packet addressing process based on semantic-rich identifiers to improve message transmission security in AI networks. This mechanism also supports AI service providers’ access control strategies, enabling rapid identification and interception of common network attacks through identifier features. The SRIM mechanism’s communication interface with control entities allows them to block malicious users’ data flows at the network layer by issuing correlation verification policies. Finally, simulations and analyses demonstrate SRIM’s security advantages.
ER  - 

TY  - JOUR
T1  - Impact of Portable Executable Header Features on Malware Detection Accuracy
AU  - Al-Khshali, Hasan H.
AU  - Ilyas, Muhammad
JO  - Computers, Materials and Continua
VL  - 74
IS  - 1
SP  - 153
EP  - 178
PY  - 2022
DA  - 2022/08/16/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2023.032182
UR  - https://www.sciencedirect.com/science/article/pii/S1546221822001795
KW  - AI driven cybersecurity
KW  - artificial intelligence
KW  - cybersecurity
KW  - Decision Tree
KW  - Neural Network Multi-Layer Perceptron Classifier
KW  - portable executable (PE) file header features
AB  - One aspect of cybersecurity, incorporates the study of Portable Executables (PE) files maleficence. Artificial Intelligence (AI) can be employed in such studies, since AI has the ability to discriminate benign from malicious files. In this study, an exclusive set of 29 features was collected from trusted implementations, this set was used as a baseline to analyze the presented work in this research. A Decision Tree (DT) and Neural Network Multi-Layer Perceptron (NN-MLPC) algorithms were utilized during this work. Both algorithms were chosen after testing a few diverse procedures. This work implements a method of subgrouping features to answer questions such as, which feature has a positive impact on accuracy when added? Is it possible to determine a reliable feature set to distinguish a malicious PE file from a benign one? when combining features, would it have any effect on malware detection accuracy in a PE file? Results obtained using the proposed method were improved and carried few observations. Generally, the obtained results had practical and numerical parts, for the practical part, the number of features and which features included are the main factors impacting the calculated accuracy, also, the combination of features is as crucial in these calculations. Numerical results included, finding accuracies with enhanced values, for example, NN_MLPC attained 0.979 and 0.98; for DT an accuracy of 0.9825 and 0.986 was attained.
ER  - 

TY  - JOUR
T1  - Syscall-BSEM: Behavioral semantics enhancement method of system call sequence for high accurate and robust host intrusion detection
AU  - Zhang, Yifei
AU  - Luo, Senlin
AU  - Pan, Limin
AU  - Zhang, Hanqing
JO  - Future Generation Computer Systems
VL  - 125
SP  - 112
EP  - 126
PY  - 2021
DA  - 2021/12/01/
SN  - 0167-739X
DO  - https://doi.org/10.1016/j.future.2021.06.030
UR  - https://www.sciencedirect.com/science/article/pii/S0167739X21002259
KW  - Host intrusion detection
KW  - System call
KW  - Obfuscation attack
KW  - Behavioral semantics
KW  - Deep learning
AB  - The system call sequence is widely used as raw data due to its prospective performance in host-based intrusion detection methods using machine learning. However, evolutionary intrusion attacks such as the obfuscation technique can achieve the same invasion purpose and effect while changing the malicious system call combination to bypass the abnormal identification, which makes the detection results not robust and even invalid. In this paper, we present a behavioral semantics enhancement method of system call sequence to overcome the problem. This method combines sequence completion to extend behavior information capacity with system calls abstraction and invocation switching differential encoding to improve abstractive representation ability. To complete behavioral semantics features extraction and data classification, the enhanced sequences are transformed to vector matrices and input into the multi-channel Text-CNN. Evaluation experiments show that the proposed method outperforms all of the compared works significantly, which suggests it has a more accurate and robust performance in detecting obfuscation attacks.
ER  - 

TY  - JOUR
T1  - Classifying spam emails using agglomerative hierarchical clustering and a topic-based approach
AU  - Jáñez-Martino, Francisco
AU  - Alaiz-Rodríguez, Rocío
AU  - González-Castro, Víctor
AU  - Fidalgo, Eduardo
AU  - Alegre, Enrique
JO  - Applied Soft Computing
VL  - 139
SP  - 110226
PY  - 2023
DA  - 2023/05/01/
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2023.110226
UR  - https://www.sciencedirect.com/science/article/pii/S1568494623002442
KW  - Spam detection
KW  - Multi-classification
KW  - Image-based spam
KW  - Hidden text
KW  - Text classification
KW  - Word embedding
KW  - Term frequency
AB  - Spam emails are unsolicited, annoying and sometimes harmful messages which may contain malware, phishing or hoaxes. Unlike most studies that address the design of efficient anti-spam filters, we approach the spam email problem from a different and novel perspective. Focusing on the needs of cybersecurity units, we follow a topic-based approach for addressing the classification of spam email into multiple categories. We propose SPEMC-15K-E and SPEMC-15K-S, two novel datasets with approximately 15K emails each in English and Spanish, respectively, and we label them using agglomerative hierarchical clustering into 11 classes. We evaluate 16 pipelines, combining four text representation techniques -Term Frequency-Inverse Document Frequency (TF-IDF), Bag of Words, Word2Vec and BERT- and four classifiers: Support Vector Machine, Näive Bayes, Random Forest and Logistic Regression. Experimental results show that the highest performance is achieved with TF-IDF and LR for the English dataset, with a F1 score of 0.953 and an accuracy of 94.6%, and while for the Spanish dataset, TF-IDF with NB yields a F1 score of 0.945 and 98.5% accuracy. Regarding the processing time, TF-IDF with LR leads to the fastest classification, processing an English and Spanish spam email in 2ms and 2.2ms on average, respectively.
ER  - 

TY  - JOUR
T1  - Hybrid Distributed Deep-GAN Intrusion Detection System in IoT with Autoencoder
AU  - S., Balaji
AU  - S., Sankaranarayanan
JO  - International Journal of Fuzzy System Applications
VL  - 11
IS  - 4
PY  - 2022
DA  - 2022/01/01/
SN  - 2156-177X
DO  - https://doi.org/10.4018/IJFSA.312238
UR  - https://www.sciencedirect.com/science/article/pii/S2156177X22000125
KW  - Auto Encoders
KW  - Deep Learning
KW  - Improved Flower Pollination
KW  - Internet of Things
KW  - Intrusion Detection
AB  - ABSTRACT
Internet of things integrates intelligent and smart devices in the surrounding environment to form dynamic heterogeneous networks. Hence, it is a time-consuming process for the IDS model to detect the anomaly behavior and a challenging task to provide security to the IoT networks. In this paper, the authors develop a hybrid distributed deep learning algorithm integrated with GAN (HDDGAN-IDS) and data mining techniques to detect intrusion attacks. In these proposed DDGAN-IDS, they deploy wrapper and filter-based flower pollination method in feature selection to reduce training time and avoids the overfitting of data and an auto encoder for feature extraction and dimensionality reduction which expedite the processing speed and finally the GAN network model performs classification. The experimental results prove that the HDDGAN-IDS algorithm provides better intrusion detection performance with respect to higher accuracy, precision, recall, f-measure, and lower false positive rate (FPR) compared to the existing deep learning algorithms.
ER  - 

TY  - JOUR
T1  - I-MAD: Interpretable malware detector using Galaxy Transformer
AU  - Li, Miles Q.
AU  - Fung, Benjamin C.M.
AU  - Charland, Philippe
AU  - Ding, Steven H.H.
JO  - Computers & Security
VL  - 108
SP  - 102371
PY  - 2021
DA  - 2021/09/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2021.102371
UR  - https://www.sciencedirect.com/science/article/pii/S0167404821001954
KW  - Cybersecurity
KW  - Malware detection
KW  - Deep learning
KW  - Transformers
KW  - Interpretability
AB  - Malware currently presents a number of serious threats to computer users. Signature-based malware detection methods are limited in detecting new malware samples that are significantly different from known ones. Therefore, machine learning-based methods have been proposed, but there are two challenges these methods face. The first is to model the full semantics behind the assembly code of malware. The second challenge is to provide interpretable results while keeping excellent detection performance. In this paper, we propose an Interpretable MAlware Detector (I-MAD) that outperforms state-of-the-art static malware detection models regarding accuracy with excellent interpretability. To improve the detection performance, I-MAD incorporates a novel network component called the Galaxy Transformer network that can understand assembly code at the basic block, function, and executable levels. It also incorporates our proposed interpretable feed-forward neural network to provide interpretations for its detection results by quantifying the impact of each feature with respect to the prediction. Experiment results show that our model significantly outperforms existing state-of-the-art static malware detection models and presents meaningful interpretations.
ER  - 

TY  - JOUR
T1  - MalGEA: A malware analysis framework via matrix factorization based node embedding and graph external attention
AU  - Li, Ruisheng
AU  - Zhang, Qilong
AU  - Shen, Huimin
JO  - Array
VL  - 27
SP  - 100493
PY  - 2025
DA  - 2025/09/01/
SN  - 2590-0056
DO  - https://doi.org/10.1016/j.array.2025.100493
UR  - https://www.sciencedirect.com/science/article/pii/S2590005625001201
KW  - Malware detection
KW  - Malware classification
KW  - Function Call Graph
KW  - Graph node embedding
KW  - Graph neural network
AB  - As one of the major threats in cybersecurity, malware has been growing continuously and steadily. In recent years, researchers have proposed a number of graph representation learning based malware detection methods by leveraging the intrinsic topological features of malware, which has led to considerable development in this area. However, these existing malware studies still have two major limitations. (1) The complex topological structures of malware graphs often result in high computational overhead during feature extraction and processing. (2) Most existing approaches rely on conventional graph neural networks that are not specifically designed for malware classification tasks, leading to suboptimal performance, especially when dealing with minority class samples. To address these problems, we propose MalGEA, a novel malware detection and classification framework based on matrix factorization and graph external attention mechanisms. First, MalGEA extracts function call information from malware and constructs corresponding function call graphs. These graphs are then processed using sparse matrix factorization and spectral propagation to efficiently generate node embeddings. Finally, we employ an graph external attention network to model inter-graph relationships and perform malware detection and classification. To evaluate our approach, we utilized a benchmark malware dataset which contains 6 categories and 35 families, including 50k benign and 50k malicious samples. Experimental results demonstrate that our method significantly outperforms existing node embedding approaches in terms of computational efficiency, while also achieving high accuracy in malware detection and family classification tasks.
ER  - 

TY  - JOUR
T1  - OptAML: Optimized adversarial machine learning on water treatment and distribution systems
AU  - Ayas, Mustafa Sinasi
AU  - Kara, Enis
AU  - Ayas, Selen
AU  - Sahin, Ali Kivanc
JO  - International Journal of Critical Infrastructure Protection
VL  - 48
SP  - 100740
PY  - 2025
DA  - 2025/03/01/
SN  - 1874-5482
DO  - https://doi.org/10.1016/j.ijcip.2025.100740
UR  - https://www.sciencedirect.com/science/article/pii/S1874548225000022
KW  - Adversarial machine learning
KW  - Adversarial training
KW  - Optimized adversarial sample
KW  - Water Distribution System (WADI)
KW  - Water Treatment System (SWaT)
AB  - This research presents the optimized adversarial machine learning framework, OptAML, which is developed for use in water distribution and treatment systems. In consideration of the physical invariants of these systems, the OptAML generates adversarial samples capable of deceiving a hybrid convolutional neural network-long short-term memory network model. The efficacy of the framework is assessed using the Secure Water Treatment (SWaT) and Water Distribution (WADI) datasets. The findings demonstrate that OptAML is capable of effectively evading rule checkers and significantly reducing the accuracy of anomaly detection frameworks in both systems. Additionally, the study investigates a defense mechanism that demonstrates enhanced robustness against these adversarial attacks and is based on adversarial training. Our results underscore the necessity for robust and flexible protection tactics and highlight the shortcomings of the machine learning-based anomaly detection systems for critical infrastructure that are currently in place.
ER  - 

TY  - JOUR
T1  - The Psychological Manipulation of Phishing Emails: A Cognitive Bias Approach
AU  - Yao, Yulin
AU  - Zheng, Kangfeng
AU  - Wu, Bin
AU  - Wu, Chunhua
AU  - Gao, Jiaqi
AU  - Wang, Jvjie
AU  - Yang, Minjiao
JO  - Computers, Materials and Continua
VL  - 85
IS  - 3
SP  - 4753
EP  - 4776
PY  - 2025
DA  - 2025/10/23/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2025.065059
UR  - https://www.sciencedirect.com/science/article/pii/S1546221825009968
KW  - Phishing emails
KW  - cognitive bias
KW  - cognitive processing model
KW  - machine learning
KW  - cybersecurity
AB  - Cognitive biases are commonly used by attackers to manipulate users’ psychology in phishing emails. This study systematically analyzes the exploitation of cognitive biases in phishing emails and addresses the following questions: (1) Which cognitive biases are frequently exploited in phishing emails? (2) How are cognitive biases exploited in phishing emails? (3) How effective are cognitive bias features in detecting phishing emails? (4) How can the exploitation of cognitive biases in phishing emails be modelled? To address these questions, this study constructed a cognitive processing model that explains how attackers manipulate users by leveraging cognitive biases at different cognitive stages. By annotating 482 phishing emails, this study identified 10 common types of cognitive biases and developed corresponding detection models to evaluate the effectiveness of these bias features in phishing email detection. The results show that models incorporating cognitive bias features significantly outperform baseline models in terms of accuracy, recall, and F1 score. This study provides crucial theoretical support for future anti-phishing methods, as a deeper understanding of cognitive biases offers key insights for designing more effective detection and prevention strategies.
ER  - 

TY  - JOUR
T1  - A mathematical model of a novel proportional control scheme for mitigating DDoS attacks in TCP/AQM-NPC networks
AU  - Huang, Kaijiao
AU  - Peng, Gang
AU  - Mehmood, Faisal
JO  - Computer Networks
VL  - 275
SP  - 111893
PY  - 2026
DA  - 2026/02/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2025.111893
UR  - https://www.sciencedirect.com/science/article/pii/S138912862500859X
KW  - Novel proportional controller(NPC) scheme
KW  - TCP/AQM-NPC networks
KW  - Distributed Denial of service (DDoS) attacks
KW  - Mathematical model
KW  - Stability
AB  - Distributed Denial of Service (DDoS) attacks continue to threaten Internet stability by overwhelming network resources and degrading service quality. In this paper, we propose a novel proportional controller (NPC) scheme and develop a corresponding executable mathematical model to characterize the behavior of a transmission control protocol/active queue management (TCP/AQM) network integrated with NPC–referred to as the TCP/AQM-NPC network–under DDoS attack conditions. We rigorously demonstrate that, under reasonable and realistic assumptions, the system remains dynamically stable, and the queue length converges asymptotically to its desired operating point, ensuring reliable queue regulation even during attack scenarios. To substantiate the proposed framework, we perform a comparative analysis against traditional AQM schemes (such as RED and PI) and state-of-the-art DDoS-aware approaches (e.g., DESiRED and AQM-LLM). The results show that NPC is better at keeping queues stable, maintaining TCP throughput, being fair between TCP and UDP flows, and adjusting to changing attack intensities. The simulations show that the suggested controller not only maintains queue stability but also significantly improves throughput during DDoS attacks. The results show that we can use our theoretical model to change the way AQM works over time. This makes the Internet’s infrastructure stronger against modern DDoS attacks.
ER  - 

TY  - JOUR
T1  - Context2Vector: Accelerating security event triage via context representation learning
AU  - Liu, Jia
AU  - Zhang, Runzi
AU  - Liu, Wenmao
AU  - Zhang, Yinghua
AU  - Gu, Dujuan
AU  - Tong, Mingkai
AU  - Wang, Xingkai
AU  - Xue, Jianxin
AU  - Wang, Huanran
JO  - Information and Software Technology
VL  - 146
SP  - 106856
PY  - 2022
DA  - 2022/06/01/
SN  - 0950-5849
DO  - https://doi.org/10.1016/j.infsof.2022.106856
UR  - https://www.sciencedirect.com/science/article/pii/S095058492200026X
KW  - Context modeling
KW  - Event triage
KW  - Topic model
KW  - Representation learning
AB  - Context:
Security teams are overwhelmed by thousands of alerts and events everyday, which are comprehensively collected for threat analysis in security operations center. Although methods based on rules, intelligence and data mining are utilized, the alert fatigue situation is still a challenging problem, slowing down the overall threat investigation process.
Objective:
‘Event polysemy’ phenomenon broadly exists in large-scale event dataset, which means that events of the same category can reveal different purposes in different contexts. This paper aims at exploring, revealing and evaluating the latent patterns embedding in the event contexts, to gain insight on context semantics and reduce manual intervention in event triage tasks.
Method:
A context representation learning based method, named Context2Vector, is proposed. Contexts are extracted from multiple behavioral views. Then, both dense event representations and sparse topic representations are learnt at the same time and in the same space. A human-in-the-loop topic annotation process is involved and finally, a context deviation detection based method is integrated to generate explainable and informative labels for automated context semantic decoding.
Results:
Various experiments are conducted on a enterprise-scale event dataset. The topic annotation, context related feature importance and top-N event ranking evaluation results show that Context2Vector outperforms traditional methods on the high-risk event identification problems, improving the attacker recall rate by up to 2.25 times within limited events to be investigated.
Conclusion:
It is concluded that event contexts imply practicable and abundant information in regard to behaviors and intents of real threat actors. More precise profiling of network entities can be extracted from contexts, compared to rules, intelligence, and anomaly detectors used in practice.
ER  - 

TY  - JOUR
T1  - Evolving malware detection through instant dynamic graph inverse reinforcement learning
AU  - Liu, Chen
AU  - Li, Bo
AU  - Liu, Xudong
AU  - Li, Chunpei
AU  - Bao, Jingru
JO  - Knowledge-Based Systems
VL  - 299
SP  - 111991
PY  - 2024
DA  - 2024/09/05/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2024.111991
UR  - https://www.sciencedirect.com/science/article/pii/S0950705124006257
KW  - Malware detection
KW  - Inverse reinforcement learning
KW  - Dynamic graph representation learning
KW  - Markov decision process
AB  - The rapid development and increasing evolution of malware necessitate novel defensive techniques with high accuracy and minimal false positives to safeguard information systems against potential threats. Unfortunately, current malware detection methods, primarily relying on deep learning to identify malicious fingerprints from extensive training sets, prove ineffective against few-shot and evolving malware variants. To address these challenges, this paper introduces MalIRL, which designs a model-free inverse reinforcement learning (IRL) mechanism to automatically capture the evolving attack intent of malware. Specifically, MalIRL explores six representative categories of malware actions and employs sliding windows to organically divide the massive malware execution event stream into multiple attack stages, achieving a reduced action space and state space. To model dynamic malicious environments, MalIRL proposes an instant dynamic heterogeneous graph representation learning technique. This technique learns state representations of different malware attack stages, enhancing detection accuracy and efficiency by incrementally capturing the newly added contextual semantics of diverse malware entities and relations. In experiments with three real-world malware datasets, MalIRL surpasses existing state-of-the-art methods, particularly in few-shot malware detection scenarios, MalIRL exhibits performance benefits of up to 18.9%.
ER  - 

TY  - JOUR
T1  - FIN: Boosting binary code embedding by normalizing function inlinings
AU  - Amouei, Mohammadhossein
AU  - Fung, Benjamin C.M.
AU  - Charland, Philippe
JO  - Journal of Systems and Software
VL  - 231
SP  - 112603
PY  - 2026
DA  - 2026/01/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2025.112603
UR  - https://www.sciencedirect.com/science/article/pii/S0164121225002729
KW  - Binary code
KW  - Similarity detection
KW  - Function inlining
KW  - Control flow graph
KW  - Random forest
AB  - Binary code similarity detection (BCSD) is essential for identifying similar code sections across different programs, regardless of their source languages, compilation options, or underlying architectures. It plays a crucial role in areas such as code plagiarism detection, malware analysis, and vulnerability discovery. However, BCSD faces significant challenges due to compiler optimizations, such as function inlining, which alter the binary structure. Existing rule-based function control flow graph (CFG) expansion strategies have limited success, due to low precision and recall in identifying inlined call sites. In this study, we present a detailed investigation of function inlining and propose an AI-driven solution to expand CFGs, offering improvements for BCSD approaches. We designed a set of features for a machine learning algorithm to identify functions at O0 and O1 optimizations that may be inlined at the higher optimizations O2 and O3, without prior knowledge of the optimization level. By utilizing this information to expand function CFGs, we observed significant enhancements in the performance of state-of-the-art binary code representation learning techniques. Experimental results show that our proposed method increases the effectiveness of representation learning approaches by up to 21.54%. Additionally, our experiments show that our proposed method can improve true positive rate in identifying known vulnerabilities.
ER  - 

TY  - JOUR
T1  - Stacking ensemble-based HIDS framework for detecting anomalous system processes in Windows based operating systems using multiple word embedding
AU  - Kumar, Yogendra
AU  - Subba, Basant
JO  - Computers & Security
VL  - 125
SP  - 102961
PY  - 2023
DA  - 2023/02/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2022.102961
UR  - https://www.sciencedirect.com/science/article/pii/S0167404822003534
KW  - Host based Intrusion Detection System(HIDS)
KW  - Ensemble-based classifier
KW  - Word Embedding
KW  - Word2Vec & GloVe
KW  - ADFA-WD dataset
AB  - Globally, more than 80% of end-user devices run on Microsoft’s Windows-based operating systems. Therefore, majority of the cyber-attack payloads are crafted explicitly for exploiting various vulnerabilities that exist across different software modules of Windows-based operating systems. To address this security issue, a stacking ensemble-based HIDS framework for detecting anomalous system processes is proposed in this paper. The proposed HIDS framework analyzes the process files comprising sequence of dll instruction calls made by various application and system processes to the Windows operating system’s kernel for detecting anomalous processes. The framework initially transforms the system process files comprising sequence of dll invocations into their corresponding n-gram feature vectors. It then uses two different state-of-the-art word embedding techniques namely, Word2Vec and GloVe to learn the contextual inter-dependencies between n-gram terms of the feature vectors, and generate fixed length word embedding vectors for each n-gram terms. These learned numeric word embedding vectors along with the n-gram feature vectors corresponding to the system process files are then provided as input to train an ensemble-based classifier model comprising LSTM, Bi-LSTM, GRU and Bi-GRU based base-level classifiers, and a fully connected neural network based meta-level classifier for classification of system process files as either normal or anomalous. The proposed HIDS framework is capable of detecting wide range of Windows-based attacks with high accuracy and precision. Experimental results show that the proposed HIDS framework achieves high accuracy and precision of 91.00% and 93.30%, respectively on the benchmark binary class Australian Defense Force Academy Windows Dataset (ADFA-WD) dataset. It also achieves an accuracy and precision of 68.70% and 67.80%, respectively on the multi-class ADFA-WD dataset, which are significantly higher than other similar HIDS frameworks proposed in the literature.
ER  - 

TY  - JOUR
T1  - A novel end-to-end ensemble framework for enhanced android malware detection accuracy
AU  - Suhaila, S. Syed
AU  - Krishnan, K. Sundara
JO  - Egyptian Informatics Journal
VL  - 32
SP  - 100827
PY  - 2025
DA  - 2025/12/01/
SN  - 1110-8665
DO  - https://doi.org/10.1016/j.eij.2025.100827
UR  - https://www.sciencedirect.com/science/article/pii/S1110866525002208
KW  - Malware detection
KW  - Ensemble learning
KW  - Static analysis
KW  - Visual analysis
KW  - Dynamic analysis
AB  - The accelerated growth in the use of the Android platform globally has positioned it as a prime target for cybercriminals. The malware creators meticulously and prudently craft fraudulent code with a range of capabilities, including spying, stealing credentials, and unauthorised system access. As a result, detecting harmful behaviour is highly challenging, stressing the importance of studying malware detection. Several proposals have recently surfaced for malware detection through the use of machine learning algorithms. However, many ideas lack the extraction of representative features, resulting in intrinsic flaws such as inaccuracy, low efficiency, and insufficient robustness to detect current malware. In this article, we propose E3Droid, an end-to-end ensemble framework to detect Android malware. The study involves extracting features from ensemble analysis, including static, visual, and dynamic analysis. An ensemble feature selection method is applied to choose the optimal features, combining Relief, Chi-square, and MRMR algorithms. In addition, an ensemble classifier consisting of basic learners SVM, KNN, and NB algorithms, is employed. The proposed E3Droid framework is thoroughly evaluated and compared with state-of-the-art techniques through extensive experimentation. It showcases outstanding results in all assessment criteria, attaining an accuracy level of 99.80% and a false positive rate of 00.24%.
ER  - 

TY  - JOUR
T1  - Lightweight and robust multi-source domain generalization for classifying internet of things malware
AU  - Wang, Fangwei
AU  - Li, Yanyan
AU  - Ma, Haibin
AU  - Li, Qingru
AU  - Wang, Changguang
AU  - Liu, Yan
JO  - Applied Soft Computing
VL  - 188
SP  - 114421
PY  - 2026
DA  - 2026/02/01/
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2025.114421
UR  - https://www.sciencedirect.com/science/article/pii/S156849462501734X
KW  - Internet of things malware
KW  - Malware classification
KW  - Multi-source domain generalization
KW  - Evolving malware
KW  - Tag-aware selector
AB  - Malware detection and classification in the Internet of Things (IoT) face significant challenges, including high memory and computational demands, uneven sample distributions, and limited model generalization. To address these problems, we propose a lightweight IoT malware classification model that combines multi-source domain generalization (DG) with Mamba, termed MSDGM. MSDGM employs a multi-source DG strategy to improve adaptability to domain shifts and enhance generalization in IoT malware detection. To further increase efficiency, an optimized MobileNet is utilized for software feature extraction, which reduces computational overhead and maintains faster performance. Moreover, the model integrates a Mamba-based Tag Aware Selector (MTAS) that identifies and mitigates adverse factors, thus improving classification accuracy and robustness. Building upon the above results, MSDGM dynamically adjusts parameters according to sample variations without manual intervention. Experimental results indicate that MSDGM achieves accuracies of 97.05 %, 99.46 %, and 89.13 % on the BIG2015, Malimg, and BenchMFC datasets, respectively, outperforming existing methods and showing superior generalization for evolving malware. We anticipate that MSDGM will serve as an effective countermeasure for detecting and classifying IoT malware, thereby safeguarding critical IoT applications.
ER  - 

TY  - JOUR
T1  - An enhanced mechanism for detection of spam emails by deep learning technique with bio-inspired algorithm
AU  - Nicholas, Neomi Nelin
AU  - Nirmalrani, V.
JO  - e-Prime - Advances in Electrical Engineering, Electronics and Energy
VL  - 8
SP  - 100504
PY  - 2024
DA  - 2024/06/01/
SN  - 2772-6711
DO  - https://doi.org/10.1016/j.prime.2024.100504
UR  - https://www.sciencedirect.com/science/article/pii/S277267112400086X
KW  - Tokenization
KW  - Bag of words
KW  - Curse of dimensionality
KW  - Sand Cat Swarm
KW  - Optimization algorithm
KW  - Email spam classification
AB  - This study aims to create a highly effective system for classifying email spam, with the key objective of improving performance and accuracy in classification. Rigorous pre-processing techniques, including lemmatization and tokenization, are applied to refine the dataset. The impact of optimal feature selection on deep learning algorithm stability with varying training datasets is investigated and to improve classifier performance, pre-stages such as feature extraction and selection using bag of words are utilized. The hybrid model is further enhanced by combining feature extraction and classification algorithms with optimization. The inclusion of multiple features, such as n-gram features, addresses the 'Curse of Dimensionality,' and optimal feature selection is employed to improve the spam detection process. The proposed system undergoes three main modifications: multiple feature extraction, feature selection, and an enhanced hybrid model, all aimed at improving spam detection accuracy. The e-mail classification phase involves mapping between training and testing sets, with deep learning algorithms utilized for feature extraction and classification. The recently introduced Sand Cat Swarm Optimization algorithm is employed to refine weights during each epoch, enhancing accuracy and minimizing loss. The proposed system extends its capabilities to identify phishing attacks within the network, offering a comprehensive approach to email security.
ER  - 

TY  - JOUR
T1  - Collision course detection for personal watercrafts using models based on recurrent neural networks
AU  - Žužić, Lucija
AU  - Hržić, Franko
AU  - Lerga, Jonatan
JO  - Knowledge-Based Systems
VL  - 333
SP  - 114974
PY  - 2026
DA  - 2026/01/30/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2025.114974
UR  - https://www.sciencedirect.com/science/article/pii/S095070512502012X
KW  - Personal watercraft
KW  - Trajectory forecasting
KW  - Recurrent neural network
KW  - Attention mechanism
KW  - Foundation model
AB  - Collision course detection plays a vital role in enhancing safety in personal watercraft rental services, particularly in tourist regions where inexperienced operators frequently navigate busy waterways. Collision course detection is defined here as forecasting personal watercraft trajectories up to 30 seconds ahead and identifying potential intersections that may result in collisions. This work builds on previous research by the authors, introducing deep learning approaches for personal watercraft trajectory forecasting on real-world data with RNN (Recurrent Neural Network), LSTM (Long Short-Term Memory), and GRU (Gated Recurrent Unit) architectures, an attention-based model, and the foundation model Unified Time Series (UniTS) for time-series data. Trajectory forecasting is integrated into collision detection, replacing the previous Intelligent Distance Control (IDC) system by analyzing data from 527 locations across continents collected over several years, and analyzing key variables such as longitude, latitude, speed, and heading. The attention model using longitude and latitude offsets, with the longest forecasting horizon of thirty seconds, increased the true negative rate to 95.45 %, which is a significant improvement compared to the non-machine learning approach. This study applies forecasting in real-time safety systems, replacing static proximity-based rules with advanced learning for adaptive and accurate collision prevention. The GRU attention model achieves inference under 12 milliseconds per sequence, enabling real-time deployment.
ER  - 

TY  - JOUR
T1  - Automatic detection of cyberbullying behaviour on social media using Stacked Bi-Gru attention with BERT model
AU  - Mali, Mohan K.
AU  - Pawar, Ranjeet R.
AU  - Shinde, Sandeep A.
AU  - Kale, Satish D.
AU  - Mulik, Sameer V.
AU  - Jagtap, Asmita A.
AU  - Tambewagh, Pratibha A.
AU  - Rajput, Punam U.
JO  - Expert Systems with Applications
VL  - 262
SP  - 125641
PY  - 2025
DA  - 2025/03/01/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2024.125641
UR  - https://www.sciencedirect.com/science/article/pii/S0957417424025089
KW  - Cyberbullying
KW  - Automatic Detection
KW  - Social Networks
KW  - Feature Selection
KW  - Binary Chimp Optimization
KW  - Stacked Bidirectional Gated Recurrent Unit
KW  - Aggressive Behaviour
AB  - Cyberbullying behaviour has drawn more attention as social media usage has grown. Teen suicide has been related to cyberbullying, among other serious and harmful effects on a person’s life. Using the appropriate natural language processing and machine learning techniques, it is possible to proactively identify bullying content to reduce and eventually eradicate cyberbullying. Accordingly, the article proposed an automated deep-learning model for detecting aggressive activity in cyberbullying. Initially, the data was extracted from the social media platform using Formspring, Instagram and MySpace datasets for perceiving cyberbullying behaviour, then the collected data are input for preprocessing. To remove the raw data, several preprocessing processes have been introduced. They consist of removing stop words, white spaces for punctuation, and changing the comments to lowercase. Lexical Density (LD) has been one of the metrics used to gauge language complexity generally. As a result, the study made use of the Feature Density (FD) to calculate how complicated certain natural language datasets are using the linguistically backed preprocessing model. After preprocessing, the data are input to the feature selection process which selects the pertinent features or attributes to include in predictive modelling and which to leave out. Since, the article proposed a Binary Chimp Optimization (BCO)-based Feature Selection (BCO-FSS) technique, which selects the subset of features for classification performance improvement. The selected features are exploited for cyberbullying behaviour detection. To identify the exploit of social media for cyberbullying text content, the article suggested Stacked Bidirectional Gated Recurrent Unit (SBiGRU) Attention for learning spatial location information and sequential semantic representations using a Bi-GRU. Additionally, the BERT model is employed as a base classifier to recognize and categorise aggressive behaviour in the textual content. The Matlab software is employed for simulation. For accuracy, precision, recall, and F1-Score, this experiment yielded a practically perfect outcome with values of 99.12%, 94.73%, 97.45%, and 93.91% respectively.
ER  - 

TY  - JOUR
T1  - Evaluating the substitutability of generative AI-generated faces in biometric applications: From a lens of age, gender, ethnicity detection
AU  - Ghosh, Tanusree
AU  - Seth, Baisnabi
AU  - Kar, Subhashis
AU  - Naskar, Ruchira
JO  - Pattern Recognition Letters
VL  - 197
SP  - 257
EP  - 266
PY  - 2025
DA  - 2025/11/01/
SN  - 0167-8655
DO  - https://doi.org/10.1016/j.patrec.2025.08.013
UR  - https://www.sciencedirect.com/science/article/pii/S0167865525002909
AB  - Despite widespread use in sensitive applications, biometric technologies often underperform for underrepresented population groups. Although creating balanced datasets to train biometric models can help, relying on real face images raises ethical, legal, and logistical concerns. To address these challenges, we utilize LLM-based image generation to produce a hyper-realistic synthetic face dataset that covers diverse ages, genders, and ethnicities, created using seven state-of-the-art (SOTA) diffusion-based models. We evaluate twelve SOTA biometric attribute classifiers on both conventional real-face datasets and our synthetic dataset. Our results reveal that SOTA biometric models trained on synthetic faces, perform impressively close and many times better compared to when trained with real images. These findings indicate that synthetic datasets hold promise as viable substitutes for real data. Our findings simultaneously open up an equally important need for improving the cross-(real)-dataset generalization capabilities of current biometric detectors. We conclude by proposing directions for improved ‘substitutability’, including enhanced model architectures and refined synthetic image generation to boost overall generalization.
ER  - 

TY  - JOUR
T1  - Using data analytics to distinguish legitimate and illegitimate shell companies
AU  - Tiwari, Milind
AU  - Gepp, Adrian
AU  - Kumar, Kuldeep
JO  - Journal of Economic Criminology
VL  - 7
SP  - 100123
PY  - 2025
DA  - 2025/03/01/
SN  - 2949-7914
DO  - https://doi.org/10.1016/j.jeconc.2024.100123
UR  - https://www.sciencedirect.com/science/article/pii/S2949791424000757
KW  - Money laundering
KW  - graph analytics
KW  - shell company
KW  - financial crime
KW  - data analytics
AB  - Shell companies can be a legitimate entity but can also been used for illicit activities such as money laundering. Users of shell companies have included illegal arms dealers, drug cartels, terrorists and cyber-criminals, as well as legitimate businesses. To assist in distinguishing between legitimate and illegitimate uses of shell companies, we develop a data-driven model to detect shell companies that are being used for money laundering. We use a hybrid approach combining graph analytics and supervised machine learning. The resulting detection models have an impressive classification accuracy ranging between 88.17 % and 97.85 %. We found no prior study that developed such models to detect illicit shell companies using publicly available information as done with our models. Beneficiaries of this work include government officials and compliance professionals, particularly accountants, tax officials and anti-corruption agencies.
ER  - 

TY  - JOUR
T1  - Adversarial measurements for convolutional neural network-based energy theft detection model in smart grid
AU  - Nirmal, Santosh
AU  - Patil, Pramod
AU  - Shinde, Sagar
JO  - e-Prime - Advances in Electrical Engineering, Electronics and Energy
VL  - 11
SP  - 100909
PY  - 2025
DA  - 2025/03/01/
SN  - 2772-6711
DO  - https://doi.org/10.1016/j.prime.2025.100909
UR  - https://www.sciencedirect.com/science/article/pii/S2772671125000166
KW  - Adversarial examples
KW  - Energy theft detection system
KW  - Evasion attack
KW  - Smart grid
AB  - Electricity theft has become a major problem worldwide and is a significant headache for utility companies. It not only results in revenue loss but also disrupts the quality of electricity, increases generation costs, and raises overall electricity prices. Electricity or Energy theft detection (ETD) systems utilizing machine learning, particularly those employing neural networks, have high accuracy and have become popular in literature, achieving higher detection performance. Recent studies reveal that machine learning and deep learning models are vulnerable. Day by day, different attack techniques are coming up in different fields, including energy, financial, etc. As the use of machine learning for energy theft detection has grown, it has become important to explore its weaknesses. Research has shown that most of the ETD models are vulnerable to evasion attacks (EA). Its goal is to reduce electricity costs by deceiving the model into recognizing a fraudulent customer as legitimate. In this paper, four different experiments are conducted in which we check the performance of Convolutional Neural Network and adaboost (CNN-Adaboost) ETD system. Then, we design an evasion attack to assess the model's performance under attack. The attack comprises two methods: the first is we originally propose a novel Adversarial Data Generation Method (ADGM), which is an algorithm designed to generate adversarial data, and the other is Fast Gradient Sign Method (FGSM). In the third scenario, test the attack success rate on different percentages of malicious consumers. Finally, the performance of CNN-Adaboost and other state-of-the-art methods is tested and compared using 10 % and 20 % adversarial data. Our proposed attack is validated with State Grid Corporation of China (SGCC) dataset. ADGM and FGSM attack models generate adversarial evasion attack samples by modifying the benign sample along with already available malicious data. These samples are transferred to the surrogate model in order to test how efficiently it works on malicious data, and we forward only those data that successfully deceive the surrogate model. The CNN_Adaboost ETD model's overall performance significantly decreased for both methods. The accuracy reduced up to 53.61 % from 96.3 % for ADGM and 63.42 % for FGSM and the transferability rates are 95.82 % and 90.68 % for ADGM and FGSM, respectively. Our findings reveal that the attack success rate (ASR) of ADGM is 94.11 % which is better than FGSM. It is also observed that as the percentage of adversarial data increased, the accuracy of the models decreased. The accuracy of CNN-Adaboost, initially 96.3 %, decreased to 85.45 % and 79.43 % for 10 % and 20 % adversarial data, respectively. These adversaries are transferable and are useful for designing robust and secure machine learning (ML) models.
ER  - 

TY  - JOUR
T1  - Generative AI: Opportunities, challenges, and research directions for supply chain resilience
AU  - Boone, Tonya
AU  - Fahimnia, Behnam
AU  - Ganeshan, Ram
AU  - Herold, David M.
AU  - Sanders, Nada R.
JO  - Transportation Research Part E: Logistics and Transportation Review
VL  - 199
SP  - 104135
PY  - 2025
DA  - 2025/07/01/
SN  - 1366-5545
DO  - https://doi.org/10.1016/j.tre.2025.104135
UR  - https://www.sciencedirect.com/science/article/pii/S1366554525001760
AB  - Generative Artificial Intelligence (GenAI) is emerging as a transformative force in supply chain resilience, offering new ways to enhance decision-making, automate operations, and improve adaptability to disruptions. Unlike traditional AI, which relies on historical data for prediction and optimization, GenAI can generate novel solutions and simulate alternative scenarios in real time. Despite its potential, research on GenAI’s role in supply chain resilience remains limited. This paper explores GenAI applications and possible research questions across key supply chain areas while also addressing challenges such as misinformation, security risks, and governance. As GenAI integrates with existing technologies, its adoption raises critical questions about accountability and systemic dependencies. To ensure responsible implementation, further research is needed to refine oversight mechanisms, establish benchmarks, and develop hybrid decision-making models where AI enhances, rather than replaces, human expertise. These insights provide guidance to managers and policymakers to help make informed decisions about the strategic deployment of GenAI in resilience-oriented supply chains.
ER  - 

TY  - JOUR
T1  - Towards the future of bot detection: A comprehensive taxonomical review and challenges on Twitter/X
AU  - Javed, Danish
AU  - Jhanjhi, NZ
AU  - Khan, Navid Ali
AU  - Ray, Sayan Kumar
AU  - Mazroa, Alanoud Al
AU  - Ashfaq, Farzeen
AU  - Das, Shampa Rani
JO  - Computer Networks
VL  - 254
SP  - 110808
PY  - 2024
DA  - 2024/12/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2024.110808
UR  - https://www.sciencedirect.com/science/article/pii/S1389128624006406
KW  - Harmful Twitter Bots (HTB)
KW  - Twitter
KW  - X
KW  - Bot detection
AB  - Harmful Twitter Bots (HTBs) are widespread and adaptable to a wide range of social network platforms. The use of social network bots on numerous social network platforms is increasing. As the popularity and utility of social networking bots grow, the attacks using social network-based automated accounts are getting more coordinated, resulting in crimes that might endanger democracy, the financial market, and public health. HTB designers develop their bots to elude detection while academics create several algorithms to identify social media bot accounts. This field is active and necessitates ongoing improvement due to the never-ending cat-and-mouse game. X, previously known as Twitter, is among the biggest social network platforms that has been plagued by automated accounts. Even though new research is being conducted to tackle this issue, the number of bots on Twitter keeps on increasing. In this research, we establish a robust theoretical foundation in the continuously evolving domain of Harmful Twitter Bot (HTB) detection by analyzing the existing HTB detection techniques. Our research provides an extensive literature review and introduces an enhanced taxonomy that has the potential to help the scientific community form better generalizations for HTB detection. Furthermore, we discuss this domain's obstacles and open challenges to direct and improve future research. As far as we are aware, this study marks the first comprehensive examination of HTB detection that includes articles published between June 2013 and August 2023. The review's findings include a more thorough classification of detection approaches, a spotlight on ways to spot Twitter bots, and a comparison of recent HTB detection methods. Moreover, we provide a comprehensive list of publicly available datasets for HTB detection. As bots evolve, efforts must be made to raise awareness, equip legitimate users with information, and help future researchers in the field of social network bot detection.
ER  - 

TY  - JOUR
T1  - Pheromone-based graph embedding algorithm for Ethereum phishing detection
AU  - Xiao, Siyi
AU  - Zhang, Lejun
AU  - Tian, Zhihong
AU  - Su, Shen
AU  - Qiu, Jing
AU  - Guo, Ran
JO  - Computer Networks
VL  - 260
SP  - 111123
PY  - 2025
DA  - 2025/04/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2025.111123
UR  - https://www.sciencedirect.com/science/article/pii/S138912862500091X
KW  - Phishing scams
KW  - Representation learning
KW  - Transaction network
KW  - Ant colony algorithm
KW  - Graph embedding
AB  - Phishing scams pose significant risks to Ethereum, the second-largest blockchain-based cryptocurrency platform. Traditional methods for identifying phishing activities, such as machine learning and network representation learning, struggle to capture the temporal and repetitive transaction patterns inherent in Ethereum’s transaction network. To address these limitations, we propose a Pheromone-based Graph Embedding Algorithm (PGEA), which leverages pheromone mechanisms and a taboo list inspired by ant colony behavior to enhance subgraph sampling. This approach improves the identification of phishing activities by ensuring subgraph homogeneity and isomorphism during the sampling process. In our methodology, Ethereum transaction data is collected from known phishing addresses to construct a transaction network graph. The PGEA guides subgraph sampling, producing sequences that are transformed into node embeddings using word2vec. These embeddings are then classified using a Support Vector Machine (SVM) to distinguish between legitimate and malicious nodes. Experimental results demonstrate the superiority of our model over existing methods. PGEA achieves an accuracy of 87.18%, precision of 91.01%, recall of 84.82%, and F1 score of 86.91%, outperforming baseline approaches such as Deepwalk, Node2vec, and Graph2vec. These results highlight the efficacy of PGEA in detecting phishing addresses, contributing to a more secure Ethereum ecosystem.
ER  - 

TY  - JOUR
T1  - A novel AI-driven framework of collaborative intelligent operation and maintenance in cloud-edge computing power networks
AU  - Dui, Hongyan
AU  - Wang, Jiafeng
AU  - Wang, Shuying
AU  - Xia, Wanyun
JO  - Reliability Engineering & System Safety
VL  - 268
SP  - 111963
PY  - 2026
DA  - 2026/04/01/
SN  - 0951-8320
DO  - https://doi.org/10.1016/j.ress.2025.111963
UR  - https://www.sciencedirect.com/science/article/pii/S0951832025011639
KW  - Computing power networks
KW  - Operation and maintenance
KW  - Reliability
KW  - AI
AB  - With the global proliferation of computing power networks driven by rapid IoT and artificial intelligence advancement, cloud-edge computing power networks (CECPN) have become critical foundations for modern digital infrastructure. However, their distributed and heterogeneous nature introduces significant cybersecurity vulnerabilities threatening data transmission reliability, thereby posing substantial challenges to operation and maintenance (O&M) management. Current research lacks comprehensive modeling across CECPN's entire data transmission lifecycle and rarely addresses heterogeneous resource allocation strategies under cyberattack scenarios. This paper proposes an AI-driven collaborative O&M framework for CECPN that optimizes multi-phase data transmission reliability recovery and costs through heterogeneous allocation of communication, computing, and operational resources under cyberattack. A case study is conducted on a 20-unit CECPN simulated environment. This study demonstrates three distinct O&M approaches: cost-oriented, reliability-oriented, and balanced strategies. The results validate the framework's capability to generate diverse solutions across various attack scenarios and recovery time windows.
ER  - 

TY  - JOUR
T1  - Privacy and security vulnerabilities in edge intelligence: An analysis and countermeasures
AU  - Shafee, Ahmed
AU  - Hasan, S.R.
AU  - Awaad, Tasneem A.
JO  - Computers and Electrical Engineering
VL  - 123
SP  - 110146
PY  - 2025
DA  - 2025/04/01/
SN  - 0045-7906
DO  - https://doi.org/10.1016/j.compeleceng.2025.110146
UR  - https://www.sciencedirect.com/science/article/pii/S0045790625000898
KW  - Artificial intelligence
KW  - Cloud computing
KW  - Deep learning
KW  - Edge computing
KW  - Edge intelligence
KW  - Machine learning
KW  - Privacy-preserving
KW  - Security
AB  - Recent advancements in deep learning have significantly accelerated the growth of artificial intelligence (AI) technologies, powering applications like the Metaverse, augmented reality (AR), virtual reality (VR), and tactile communications on emerging 6G networks. The proliferation of Internet of Things (IoT) devices and mobile computing has connected vast numbers of devices to the internet, generating enormous amounts of data at the network edge. To harness the potential of this big data, extending AI capabilities to the network edge has become increasingly vital. Edge AI, or edge intelligence (EI), enables computing tasks to be performed closer to data sources, reducing latency and enhancing efficiency. However, this shift has amplified privacy concerns due to increased data sharing, compounded by the growing prevalence of data breaches. Research also reveals that sharing AI models instead of raw data does not fully safeguard privacy, as certain attacks can still compromise sensitive training information. This paper reviews Edge Intelligence with a focus on privacy and security issues, identifying critical challenges and vulnerabilities in edge and cloud computing environments. It provides a comprehensive analysis of state-of-the-art solutions to address these concerns, offering valuable insights into enhancing privacy and security in distributed computing systems.
ER  - 

TY  - JOUR
T1  - A Hybrid CNN-Brown-Bear Optimization Framework for Enhanced Detection of URL Phishing Attacks
AU  - Gupta, Brij B.
AU  - Gaurav, Akshat
AU  - Attar, Razaz Waheeb
AU  - Arya, Varsha
AU  - Bansal, Shavi
AU  - Alhomoud, Ahmed
AU  - Chui, Kwok Tai
JO  - Computers, Materials and Continua
VL  - 81
IS  - 3
SP  - 4853
EP  - 4874
PY  - 2024
DA  - 2024/12/19/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2024.057138
UR  - https://www.sciencedirect.com/science/article/pii/S1546221824008385
KW  - Phishing attack
KW  - CNN
KW  - brown-bear optimization
AB  - Phishing attacks are more than two-decade-old attacks that attackers use to steal passwords related to financial services. After the first reported incident in 1995, its impact keeps on increasing. Also, during COVID-19, due to the increase in digitization, there is an exponential increase in the number of victims of phishing attacks. Many deep learning and machine learning techniques are available to detect phishing attacks. However, most of the techniques did not use efficient optimization techniques. In this context, our proposed model used random forest-based techniques to select the best features, and then the Brown-Bear optimization algorithm (BBOA) was used to fine-tune the hyper-parameters of the convolutional neural network (CNN) model. To test our model, we used a dataset from Kaggle comprising 11,000+ websites. In addition to that, the dataset also consists of the 30 features that are extracted from the website uniform resource locator (URL). The target variable has two classes: “Safe” and “Phishing.” Due to the use of BBOA, our proposed model detects malicious URLs with an accuracy of 93% and a precision of 92%. In addition, comparing our model with standard techniques, such as GRU (Gated Recurrent Unit), LSTM (Long Short-Term Memory), RNN (Recurrent Neural Network), ANN (Artificial Neural Network), SVM (Support Vector Machine), and LR (Logistic Regression), presents the effectiveness of our proposed model. Also, the comparison with past literature showcases the contribution and novelty of our proposed model.
ER  - 

TY  - JOUR
T1  - Learning from Usage Analysis of Mobile Devices
AU  - Mishra, Subhankar
JO  - Procedia Computer Science
VL  - 167
SP  - 1648
EP  - 1655
PY  - 2020
DA  - 2020/01/01/
T2  - International Conference on Computational Intelligence and Data Science
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2020.03.375
UR  - https://www.sciencedirect.com/science/article/pii/S1877050920308413
KW  - Mobile
KW  - Devices
KW  - Deep learning
KW  - User behaviour
KW  - Usage Analysis
AB  - Mobile devices have evolved from just communication devices into an indispensable part of people’s lives in form of smartphones, tablets and smart watches. Devices are now more personal than ever and carry more information about a person than any other. Extracting user behaviour is rather difficult and time-consuming as most of the work previously has been manual or requires feature extraction. In this paper, a novel approach of user behavior detection is proposed with Deep Learning Network (DNN). Initial approach was to use recurrent neural network (RNN) along with LSTM for completely unsupervised analysis of mobile devices. Next approach is to extract features by using Long Short Term Memory (LSTM) to understand the user behaviour, which are then fed into the Convolution Neural Network (CNN). This work mainly concentrates on detection of user behaviour and anomaly detection for usage analysis of mobile devices. Both the approaches are compared against some baseline methods. Experiments are conducted on the publicly available dataset to show that these methods can successfully capture the user behaviors.
ER  - 

TY  - JOUR
T1  - Meta-knowledge triple driven multi-modal knowledge graph construction method and application in production line control with Gantt charts
AU  - Li, Laiyi
AU  - Yang, Maolin
AU  - Makanda, Inno Lorren Désir
AU  - Jiang, Pingyu
JO  - Journal of Manufacturing Systems
VL  - 80
SP  - 224
EP  - 242
PY  - 2025
DA  - 2025/06/01/
SN  - 0278-6125
DO  - https://doi.org/10.1016/j.jmsy.2025.03.002
UR  - https://www.sciencedirect.com/science/article/pii/S0278612525000639
KW  - Manufacturing knowledge graph
KW  - Entity-relationships model
KW  - The meta-knowledge triples
KW  - Gantt chart
KW  - 3D printing
KW  - Anomaly detection
AB  - Digital manufacturing involves complex and multidimensional interactions among production line resources, resulting in massive multi-modal knowledge. The knowledge often lacks correlation and contextual readability, leading to data silos. The rapid development of knowledge graphs (KGs) has rekindled interest in manufacturing knowledge engineering. Investigating the framework of multi-modal manufacturing data assets in enterprises and transforming them into a general-purpose KG database to support manufacturing processes is of significant importance. Guided by the principle of using KG as a manufacturing database, this study developed a multi-modal production line manufacturing knowledge graph (PLMKG) to support dynamic manufacturing on production lines. Firstly, the schema layer of the PLMKG is constructed using the Entity-Relationship model and a manufacturing knowledge pattern framework, with meta-knowledge triples proposed for schema data expression. Secondly, an event-state trigger dynamic instantiation method based on triples binding is proposed to enable self-growth. Third, a method integrating dynamic Gantt charts is introduced to synchronize the control of PLMKG and the manufacturing process. The anomaly detection model is employed to detect production, with the results stored in the PLMKG and Gantt charts for process control. Finally, a PLMKG prototype system for data management and process visualization is developed, with a 3D printing production line case study validating the construction and application of PLMKG. The results indicate that the proposed PLMKG integrates multi-modal manufacturing knowledge structurally and provides AI readiness for manufacturing, finally supporting the production line operation as a database.
ER  - 

TY  - JOUR
T1  - mURLi: A Tool for Detection of Malicious URLs and Injection Attacks
AU  - Devalla, Vihar
AU  - Srinivasa Raghavan, S
AU  - Maste, Swati
AU  - Kotian, Jaaswin D
AU  - Annapurna, Dr. D
JO  - Procedia Computer Science
VL  - 215
SP  - 662
EP  - 676
PY  - 2022
DA  - 2022/01/01/
T2  - 4th International Conference on Innovative Data Communication Technology and Application
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2022.12.068
UR  - https://www.sciencedirect.com/science/article/pii/S1877050922021391
KW  - mURLi (Malicious URL and Injection Attacks Detection)
KW  - SQL Injection (SQLi)
KW  - NoSQL Injection(NoSQLi)
KW  - Phishing
KW  - Spam
KW  - Malware
KW  - Machine Learning(ML)
KW  - Deep Learning(DL)
KW  - Random Forest(RF)
KW  - XGBoost
KW  - Adaboost
KW  - KNN(K-Nearest Neighbour)
KW  - Artificial Neural Network(ANN)
KW  - Bidirectional Long Short Term Memory (BiLSTM)
KW  - Bidirectional Encoder Representations from Transformers (BERT)
AB  - SQL databases have been a staple for storing data in enterprises to meet their database requirements. SQL injection has also become a major security threat due to the growth of SQL. Injection attacks occur when the query in the database is modified by malicious data from an unsecure user. The use of NoSQL databases has been growing steadily due to advancements in Big Data and similar domains, and as an alternative to SQL databases. But recent studies have proved that even NoSQL is susceptible to injection attacks. Malicious websites can harm a person using the internet in various ways. Phishing attacks, Spam attacks, Defacement Attacks can occur once a user clicks on a URL. In this research, we propose the tool mURLi, for early detection of Malicious URLs, SQLi and NoSQLi, which pose a large threat to the end-users. To build mURLi, we have used various deep learning models (ANN, BiLSTM, BERT) and machine learning models (Random Forest, XGBoost, Adaboost, KNN) in an attempt to detect these attacks (SQLi, NoSQLi and Malicious URLs) more accurately than traditional methods and have presented a comparative study of the same. The results show that BERT model outperforms the existing tools for SQL and NoSQL attacks with an accuracy of 99.6% and 99.01% respectively, which was achievable due to its pre-training and deep language knowledge. BiLSTM proves to be the best tool for detection of Malicious URL attacks, with the results being 95.2% accurate.
ER  - 

TY  - JOUR
T1  - A Systematic Review on Ethereum Phishing Scam Detection: Challenges, Empirical Insights, and Future Directions
AU  - Ghosh, Medhasree
AU  - Halder, Raju
AU  - Chandra, Joydeep
JO  - Blockchain: Research and Applications
SP  - 100424
PY  - 2025
DA  - 2025/12/08/
SN  - 2096-7209
DO  - https://doi.org/10.1016/j.bcra.2025.100424
UR  - https://www.sciencedirect.com/science/article/pii/S2096720925001514
KW  - Ethereum
KW  - Phishing Attacks
KW  - Security and Privacy
KW  - Empirical Evaluation
AB  - The decentralized and anonymous nature of Ethereum makes it a prime target for phishing scams. These scams account for nearly 50% of all blockchain-related fraud, thereby causing a substantial financial loss and eroding user trust. Unlike conventional phishing, Ethereum phishing users exploit user anonymity, lack of awareness, and market-driven dynamics to deceive normal users. Despite of a plethora of research in this direction, there is a lack of a rigorous and comprehensive survey which can fortify an insightful comparison of the existing works and provide a concrete future research guidance. To this end, this paper presents a systematic review of 90 studies published between 2020 and 2024, offering the following novel contributions, (1) Structured Taxonomy: We introduce a structured three-fold taxonomy that classifies existing methods into feature engineering-based, representation learning-based, and fusion-based frameworks. (2) Theoretical Analysis: Through theoretical analysis, we evaluate these approaches against the critical research challenges, such as rapid network dynamism, data leakage, and network sparsity and provide a comparative mapping of novel techniques adopted across the studies. (3) Empirical Evaluation: We conduct an extensive empirical evaluation of 14 representative models over multiple public datasets to assess their robustness under varying data conditions. The findings indicate that while feature-based models are more interpretable, they struggle with temporal adaptability; representation learning approaches, particularly GNN-based models, capture complex behavioral patterns but are computationally demanding and less explainable. Fusion methods demonstrate the most balanced trade-off between accuracy, scalability, and interpretability. (4) Future Research Guidance: Finally, we identify still persisting issues such as network sparsity, behavioral volatility, and scalability, and outline future research directions emphasizing temporal graph reasoning, self-supervised fusion, and explainable AI for developing transparent and deployable phishing detection frameworks on Ethereum.
ER  - 

TY  - JOUR
T1  - Implementation path and reference model for Multilateral Data Circulation System (MDCS) in Datacentric Product-Service System (DPSS): from an industrial practice survey
AU  - Wang, Chengjun
AU  - Ming, Xinguo
AU  - Gao, Xinming
AU  - Zhang, Xianyu
JO  - Advanced Engineering Informatics
VL  - 64
SP  - 103085
PY  - 2025
DA  - 2025/03/01/
SN  - 1474-0346
DO  - https://doi.org/10.1016/j.aei.2024.103085
UR  - https://www.sciencedirect.com/science/article/pii/S1474034624007365
KW  - Datacentric product-service systems
KW  - Data circulation
KW  - Data sovereignty
KW  - Data privacy
AB  - With the digital transformation of enterprises and the development of digital infrastructure (smart sensors, 5G/6G, IoT, Industrial Internet, etc.), large amounts of data are generated in various stages of the product life cycle. The value of data in the Product-Service System is becoming prominent. However, through literature review and industrial practice survey, it has been observed that there is a lack of systematic investigation into the processes of data circulation and utilization within PSS. Additionally, within the existing research on data circulation, scholars focus on partial points such as data privacy computing, data sharing and data transaction, lacking an overall reference model for the data circulation in the Product-Service System and the path of implementing a multilateral data circulation platform in the industry. This paper aims to use the industrial practice survey method, based on the literature review, to propose the Datacentric Product-Service System (DPSS) for the first time, and study the main processes of data circulation in the DPSS. The study of the reference model and industrial implementation path of the multilateral data circulation system that meets the industry’s needs in the Datacentric Product-Service System. It provides a reference for the government and industry to design, implement and regulate the domain data circulation platform. In addition, the proposed data circulation system reference model and implementation path can enhance the value symbiosis among enterprises and increase industry benefits.
ER  - 

TY  - JOUR
T1  - Python source code vulnerability detection with named entity recognition
AU  - Ehrenberg, Melanie
AU  - Sarkani, Shahram
AU  - Mazzuchi, Thomas A.
JO  - Computers & Security
VL  - 140
SP  - 103802
PY  - 2024
DA  - 2024/05/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.103802
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824001032
KW  - Vulnerability detection
KW  - Natural language processing
KW  - Machine learning
KW  - Named entity recognition
KW  - Transformer
KW  - Python
KW  - BERT
KW  - Programming language
KW  - Common weakness enumeration
KW  - CWE
AB  - Vulnerabilities within source code have grown over the last 20 years to become a common threat to systems and networks. As the implementation of open-source software continues to develop, more unknown vulnerabilities will exist throughout system networks. This research proposes an enhanced vulnerability detection method specific to Python source code that utilizes pre-trained, BERT-based transformer models to apply tokenization, embedding, and named entity recognition (a natural language processing technique). The use of named entity recognition not only allows for the detection of potential vulnerabilities, but also for the classification of different vulnerability types. This research uses the publicly available CodeBERT, RoBERTa, and DistilBERT models to fine-tune for the downstream task of token classification for six different common weakness enumeration specifications. The results achieved in this research outperform previous Python-based vulnerability detection methods and demonstrate the effectiveness of applying named entity recognition to enhance the overall research into Python source code vulnerabilities.
ER  - 

TY  - JOUR
T1  - Future of humanity in an artificial intelligence centric world
AU  - Baloda, Sunil
AU  - Sharma, Monika
AU  - Kumar, Mukesh
JO  - Engineering Applications of Artificial Intelligence
VL  - 162
SP  - 112405
PY  - 2025
DA  - 2025/12/15/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2025.112405
UR  - https://www.sciencedirect.com/science/article/pii/S0952197625024303
KW  - Trustworthy artificial intelligence
KW  - Machine learning
KW  - Healthcare
KW  - Anomaly detection
KW  - Societal impact
AB  - This scholarly article rigorously investigates the transformative and disruptive roles of artificial intelligence (AI) in influencing the trajectory of human society. By concentrating on three fundamental sectors—healthcare, finance, and education—it evaluates the ways in which AI augments operational efficiency, facilitates intricate decision-making processes, and introduces innovative capabilities such as personalized medicine and automated financial systems. Concurrently, the analysis underscores urgent ethical dilemmas, encompassing algorithmic bias, accountability deficiencies, data privacy vulnerabilities, and workforce displacement. Employing real-world examples such as Deepfakes, and Neuralink, the article contextualizes emerging challenges within a dynamic socio-technical framework. The research offers a cohesive conceptual model that amalgamates technical, ethical, and governance aspects of AI, while presenting policy recommendations designed to promote transparency, equity, and human-centered AI development. The study emphasizes the necessity for reliable AI systems that humans can trust. The conclusions accentuate the immediate necessity for robust regulatory frameworks and sector-specific ethical supervision to ensure that advancements in AI are harmonized with the well-being of society.
ER  - 

TY  - JOUR
T1  - Unmasking Social Robots’ Camouflage: A GNN-Random Forest Framework for Enhanced Detection
AU  - Fan, Weijian
AU  - Wang, Chunhua
AU  - Han, Xiao
AU  - Lin, Chichen
JO  - Computers, Materials and Continua
VL  - 82
IS  - 1
SP  - 467
EP  - 483
PY  - 2025
DA  - 2025/01/03/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2024.056930
UR  - https://www.sciencedirect.com/science/article/pii/S1546221825000062
KW  - Social robot detection
KW  - graph neural networks
KW  - random forest
KW  - homophily
KW  - heterophily
AB  - The proliferation of robot accounts on social media platforms has posed a significant negative impact, necessitating robust measures to counter network anomalies and safeguard content integrity. Social robot detection has emerged as a pivotal yet intricate task, aimed at mitigating the dissemination of misleading information. While graph-based approaches have attained remarkable performance in this realm, they grapple with a fundamental limitation: the homogeneity assumption in graph convolution allows social robots to stealthily evade detection by mingling with genuine human profiles. To unravel this challenge and thwart the camouflage tactics, this work proposed an innovative social robot detection framework based on enhanced HOmogeneity and Random Forest (HORFBot). At the core of HORFBot lies a homogeneous graph enhancement strategy, intricately woven with edge-removal techniques, to meticulously dissect the graph into multiple revealing subgraphs. Subsequently, leveraging the power of contrastive learning, the proposed methodology meticulously trains multiple graph convolutional networks, each honed to discern nuances within these tailored subgraphs. The culminating stage involves the fusion of these feature-rich base classifiers, harmoniously aggregating their insights to produce a comprehensive detection outcome. Extensive experiments on three social robot detection datasets have shown that this method effectively improves the accuracy of social robot detection and outperforms comparative methods.
ER  - 

TY  - JOUR
T1  - BotSSCL: Social Bot Detection with Self-Supervised Contrastive Learning
AU  - Akhtar, Mohammad Majid
AU  - Bhuiyan, Navid Shadman
AU  - Masood, Rahat
AU  - Ikram, Muhammad
AU  - Kanhere, Salil S.
JO  - Online Social Networks and Media
VL  - 48
SP  - 100318
PY  - 2025
DA  - 2025/09/01/
SN  - 2468-6964
DO  - https://doi.org/10.1016/j.osnem.2025.100318
UR  - https://www.sciencedirect.com/science/article/pii/S2468696425000199
KW  - Social bot detection
KW  - Contrastive learning
KW  - Online social networks
KW  - Self-supervised
KW  - Adversarial robustness
AB  - The detection of automated accounts, also known as “social bots”, has been an important concern for online social networks (OSNs). While several methods have been proposed for detecting social bots, significant research gaps remain. First, current models exhibit limitations in detecting sophisticated bots that aim to mimic genuine OSN users. Second, these methods often rely on simplistic profile features, which are susceptible to adversarial manipulation. In addition, these models lack generalizability, resulting in subpar performance when trained on one dataset and tested on another. To address these challenges, we propose a framework for social Bot detection with Self-Supervised Contrastive Learning (BotSSCL). Our framework leverages contrastive learning to distinguish between social bots and humans in the embedding space to improve linear separability. The high-level representations derived by BotSSCL enhance its resilience to variations in data distribution and ensure generalizability. We evaluate BotSSCL’s robustness against adversarial attempts to manipulate bot accounts to evade detection. Experiments on two datasets featuring sophisticated bots demonstrate that BotSSCL outperforms other supervised, unsupervised, and self-supervised baseline methods. We achieve ≈6% and ≈8% higher (F1) performance than SOTA on both datasets. In addition, BotSSCL also achieves 67% F1 when trained on one dataset and tested with another, demonstrating its generalizability under cross-botnet evaluation. Lastly, under adversarial evasion attack, BotSSCL shows increased complexity for the adversary and only allows 4% success to the adversary in evading detection. The code is available at https://github.com/code4thispaper/BotSSCL.
ER  - 

TY  - JOUR
T1  - Assessing Health Students' Attitudes and Usage of ChatGPT in Jordan: Validation Study
AU  - Sallam, Malik
AU  - Salim, Nesreen A
AU  - Barakat, Muna
AU  - Al-Mahzoum, Kholoud
AU  - Al-Tammemi, Ala'a B
AU  - Malaeb, Diana
AU  - Hallit, Rabih
AU  - Hallit, Souheil
JO  - JMIR Medical Education
VL  - 9
PY  - 2023
DA  - 2023/01/01/
SN  - 2369-3762
DO  - https://doi.org/10.2196/48254
UR  - https://www.sciencedirect.com/science/article/pii/S2369376223000648
KW  - artificial intelligence
KW  - machine learning
KW  - education
KW  - technology
KW  - healthcare
KW  - survey
KW  - opinion
KW  - knowledge
KW  - practices
KW  - KAP
AB  - Background
ChatGPT is a conversational large language model that has the potential to revolutionize knowledge acquisition. However, the impact of this technology on the quality of education is still unknown considering the risks and concerns surrounding ChatGPT use. Therefore, it is necessary to assess the usability and acceptability of this promising tool. As an innovative technology, the intention to use ChatGPT can be studied in the context of the technology acceptance model (TAM).
Objective
This study aimed to develop and validate a TAM-based survey instrument called TAME-ChatGPT (Technology Acceptance Model Edited to Assess ChatGPT Adoption) that could be employed to examine the successful integration and use of ChatGPT in health care education.
Methods
The survey tool was created based on the TAM framework. It comprised 13 items for participants who heard of ChatGPT but did not use it and 23 items for participants who used ChatGPT. Using a convenient sampling approach, the survey link was circulated electronically among university students between February and March 2023. Exploratory factor analysis (EFA) was used to assess the construct validity of the survey instrument.
Results
The final sample comprised 458 respondents, the majority among them undergraduate students (n=442, 96.5%). Only 109 (23.8%) respondents had heard of ChatGPT prior to participation and only 55 (11.3%) self-reported ChatGPT use before the study. EFA analysis on the attitude and usage scales showed significant Bartlett tests of sphericity scores (P<.001) and adequate Kaiser-Meyer-Olkin measures (0.823 for the attitude scale and 0.702 for the usage scale), confirming the factorability of the correlation matrices. The EFA showed that 3 constructs explained a cumulative total of 69.3% variance in the attitude scale, and these subscales represented perceived risks, attitude to technology/social influence, and anxiety. For the ChatGPT usage scale, EFA showed that 4 constructs explained a cumulative total of 72% variance in the data and comprised the perceived usefulness, perceived risks, perceived ease of use, and behavior/cognitive factors. All the ChatGPT attitude and usage subscales showed good reliability with Cronbach α values >.78 for all the deduced subscales.
Conclusions
The TAME-ChatGPT demonstrated good reliability, validity, and usefulness in assessing health care students’ attitudes toward ChatGPT. The findings highlighted the importance of considering risk perceptions, usefulness, ease of use, attitudes toward technology, and behavioral factors when adopting ChatGPT as a tool in health care education. This information can aid the stakeholders in creating strategies to support the optimal and ethical use of ChatGPT and to identify the potential challenges hindering its successful implementation. Future research is recommended to guide the effective adoption of ChatGPT in health care education.
ER  - 

TY  - JOUR
T1  - High interest but low adoption: Navigating organizations’ journey towards generative artificial intelligence implementation
AU  - Wang, Xiaoqing
AU  - Zhong, Wanle
AU  - Huang, Keman
AU  - Liang, Bin
JO  - International Journal of Information Management
VL  - 87
SP  - 103009
PY  - 2026
DA  - 2026/04/01/
SN  - 0268-4012
DO  - https://doi.org/10.1016/j.ijinfomgt.2025.103009
UR  - https://www.sciencedirect.com/science/article/pii/S0268401225001410
KW  - Implementing LLM in organization
KW  - Innovation decision process theory
KW  - Activity theory
KW  - Multi-stage, socio-technical complexity
KW  - Contradictions and solutions
KW  - Priority shifting
KW  - Collaborative mechanism
KW  - Tiered rollout strategy
KW  - Technology capability building
KW  - Accountable governance
AB  - The rapid development of generative artificial intelligence (aka, LLMs) provides high potential to transform organizational operations, yet a pronounced high interest but low adoption gap persists. Hence, moving beyond individual-level studies to examine organization-wide implementation, we draw on Rogers’ innovation decision process and Engeström’s activity theory, and conduct in-depth interviews with 27 front-line experts, including LLM providers, adopters, and advisors. Our analysis uncovers ten key contradictions and corresponding practice-driven solutions that emerge across five implementation stages (agenda-setting, matching, redefining and restructuring, clarifying, and routinizing). These insights illuminate not only the multi-stage, socio-technical complexity of LLM deployment but also shifting priorities among activity subsystems and the collaborative mechanisms essential for success. Building on these findings, we offer actionable recommendations for practitioners: a tiered rollout strategy; the technical capability building including decision-support and trial platforms, agile modular architectures and multi-layer update pipelines; as well as an accountable governance framework that integrates internal controls with external accountability. By synthesizing theoretical and practical perspectives, our study intends to guide researchers and business leaders navigate the challenges of organizational LLM implementation and realize their transformative potential at scale.
ER  - 

TY  - JOUR
T1  - Abusive Content Detection in Online User-Generated Data: A survey
AU  - Kaur, Simrat
AU  - Singh, Sarbjeet
AU  - Kaushal, Sakshi
JO  - Procedia Computer Science
VL  - 189
SP  - 274
EP  - 281
PY  - 2021
DA  - 2021/01/01/
T2  - AI in Computational Linguistics
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2021.05.098
UR  - https://www.sciencedirect.com/science/article/pii/S1877050921012229
KW  - Social Media
KW  - Abusive Content
KW  - Cyberbullying
KW  - Natural Language Processing
KW  - Machine Learning
KW  - Deep Learning
AB  - The proliferation of social media platforms resulted in a remarkable increase in user-generated content. These platforms have empowered users to create, share and exchange content for interacting and communicating with each other. However, these have also opened new avenues to cyber-bullies and haters who can spread their negativity to a larger audience, often anonymously. Due to the pervasiveness and severity of this behavior, many automated approaches that employ natural language processing (NLP), machine learning and deep learning techniques have been proposed in the past. This survey offers an extensive overview of the state-of-the-art approaches proposed by research community to identify offensive content. Based on our comprehensive literature survey, a categorization of different approaches and features employed by the researchers in the detection process are presented. This survey also incorporates the major challenges that require considerable research efforts in this domain. Finally, future research directions with an aim of developing robust abusive content detection system for social media are also discussed.
ER  - 

TY  - JOUR
T1  - Anti-traceable backdoor: Blaming malicious poisoning on innocents in non-IID federated learning
AU  - Chen, Bei
AU  - Li, Gaolei
AU  - Mei, Haochen
AU  - Li, Jianhua
AU  - Chen, Mingzhe
AU  - Debbah, Mérouane
JO  - Journal of Information Security and Applications
VL  - 94
SP  - 104240
PY  - 2025
DA  - 2025/11/01/
SN  - 2214-2126
DO  - https://doi.org/10.1016/j.jisa.2025.104240
UR  - https://www.sciencedirect.com/science/article/pii/S2214212625002777
KW  - Federated learning
KW  - Label distribution skew
KW  - Anti-traceable backdoor attack
KW  - Meta-detection-and-filtering
AB  - Backdoor attacks pose an extremely serious threat to federated learning (FL), where victim models are susceptible to specific triggers. To counter the defense, a smart attacker will forcefully and actively camouflage its behavior profiles (i.e., trigger invisibility and malicious collusion). However, in a more practical scenario where the label distribution on each client is heterogeneous, such camouflage is not highly deceptive and durable, and also malicious clients can be precisely identified by a blanket benchmark comparison. In this paper, we introduce an attack vector that blames innocent clients for malicious poisoning in backdoor tracing and motivates a novel Anti-Traceable Backdoor Attack (ATBA) framework. First, we devise a progressive generative adversarial data inference scheme to compensate missing classes for malicious clients, progressively improving the quality of inferred data through fictitious poisoning. Subsequently, we present a trigger-enhanced specific backdoor learning mechanism, selectively specifying vulnerable classes from benign clients to resist backdoor tracing and adaptively optimizing triggers to adjust specific backdoor behaviors. Additionally, we also design a meta-detection-and-filtering defense strategy, which aims to distinguish fictitiously-poisoned updates. Extensive experiments over three benchmark datasets validate the proposed ATBA’s attack effectiveness, anti-traceability, robustness, and the feasibility of the corresponding defense method.
ER  - 

TY  - JOUR
T1  - Human factors in phishing: Understanding susceptibility and resilience
AU  - Oner, Ufuk
AU  - Cetin, Orcun
AU  - Savas, Erkay
JO  - Computer Standards & Interfaces
VL  - 94
SP  - 104014
PY  - 2025
DA  - 2025/08/01/
SN  - 0920-5489
DO  - https://doi.org/10.1016/j.csi.2025.104014
UR  - https://www.sciencedirect.com/science/article/pii/S0920548925000431
KW  - Phishing
KW  - Phishing susceptibility
KW  - Phishing resilience
KW  - Incident reporting
KW  - Phishing awareness
AB  - This study examines the demographic and organizational factors influencing phishing susceptibility and incident reporting behaviors among employees in a large European financial organization following realistic phishing simulations and how these factors correlate with susceptibility to phishing attacks. In the phishing simulations campaign with 8,102 participants, unannounced, monthly phishing emails with different templates are sent during regular work hours over a duration of 2 years, and the reactions (clicking the link and reporting the phishing email) are collected. The results are combined with demographic and relevant organizational data such as age, gender, level of education, department type, tenure, and job level. Multivariate logistic regression models are developed to analyze the relationship between these variables and phishing behaviors. The analysis reveals significant differences in susceptibility to and resilience against phishing attacks across various demographic and organizational groups. Older employees are more susceptible to phishing, while males show lower vulnerability to phishing attacks. Additionally, our results revealed that higher-level employees often under report phishing emails. These findings highlight the necessity for targeted anti-phishing training tailored to different demographics and departments within the organization and the importance of fostering a culture of incident reporting. Recommendations include customized cyber awareness training programs, regular awareness sessions, and incentivizing reporting. Future research is encouraged to prioritize investigating the root causes of phishing behaviors and evaluating the effectiveness of training programs.
ER  - 

TY  - JOUR
T1  - Explaining vulnerabilities of biased news classifiers through rough sets and granular computing
AU  - Fenza, Giuseppe
AU  - Gaeta, Angelo
AU  - Loia, Vincenzo
AU  - Orciuoli, Francesco
AU  - Stanzione, Claudio
JO  - Information Sciences
VL  - 719
SP  - 122439
PY  - 2025
DA  - 2025/11/01/
SN  - 0020-0255
DO  - https://doi.org/10.1016/j.ins.2025.122439
UR  - https://www.sciencedirect.com/science/article/pii/S0020025525005717
KW  - Information disorder
KW  - Rough set
KW  - Explainability
AB  - In the evolving landscape of artificial intelligence, ensuring the robustness and explainability of machine learning models is valuable. This study presents an innovative method based on the Rough Set Theory and Principles of Justified Granularity to enhance the explainability of text-based classifiers, specifically in style-based news bias classification. The method helps understand why a classifier can be deceived with an Adversarial Attack. It leverages two levels of insight. The first level is independent of the specific classifier and consists of generating rules from a boundary region built with Rough Sets Theory starting from train data. The second level considers the behavior of a specific machine learning model in classifying manipulated observations and, starting from the classification results, constructs information granules of true positives and false negatives. These granules are representative of observations that deceived a classifier. By comparing boundary rules with information granules, it is possible to acquire actionable knowledge that is useful for making decisions on making a machine learning model more resilient. Results are evaluated with real data containing biased news. The success rate of adversarial examples generated using LLM to test classifiers on borderline cases, where minor textual changes cause false negatives, ranges from 45% to 68%.
ER  - 

TY  - JOUR
T1  - A lightweight IoT intrusion detection model based on improved BERT-of-Theseus
AU  - Wang, Zhendong
AU  - Li, Jingfei
AU  - Yang, Shuxin
AU  - Luo, Xiao
AU  - Li, Dahai
AU  - Mahmoodi, Soroosh
JO  - Expert Systems with Applications
VL  - 238
SP  - 122045
PY  - 2024
DA  - 2024/03/15/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2023.122045
UR  - https://www.sciencedirect.com/science/article/pii/S0957417423025472
KW  - Intrusion detection
KW  - Internet of Things system
KW  - Knowledge distillation
KW  - Transformer
AB  - The proliferation of Internet of Things (IoT) technology has resulted in an increase in security vulnerabilities associated with the interconnectivity of IoT devices. As a result, there is a need for intrusion detection mechanisms that can effectively detect attacks on IoT security vulnerabilities. However, due to the resource constraints of IoT deployment devices, intrusion detection schemes must be customized to meet the specific demands of the IoT environment. In this study, we propose a knowledge-distillation-based IoT intrusion detection model named BT-TPF, which is capable of detecting network attacks encountered by IoT devices in an IoT environment with limited computing resources. The proposed BT-TPF model leverages a Siamese network for feature dimensionality reduction of complex high-dimensional network traffic data. Additionally, it employs a large-scale Vision Transformer as a teacher model to guide a small-scale Poolformer model during training, before deploying the trained Poolformer model as a classifier to detect network intrusion traffic. Through knowledge distillation, the final small model obtained in this paper only requires a minimum of 788 parameters, reducing the number of parameters by approximately 90% compared to the large model before knowledge distillation, while maintaining high detection accuracy. Experimental results show that the BT-TPF model achieves over 99% accuracy on both the CIC-IDS2017 and TON_IoT datasets. Furthermore, it exhibits significant advantages compared to traditional Deep Learning methods and recent state-of-the-art models, as evidenced by various evaluation metrics.
ER  - 

TY  - JOUR
T1  - CleanSheet: Advancing backdoor attack techniques for deep neural networks with stealthy trigger embedding
AU  - Bensaoud, Ahmed
AU  - Kalita, Jugal
JO  - Systems and Soft Computing
VL  - 7
SP  - 200335
PY  - 2025
DA  - 2025/12/01/
SN  - 2772-9419
DO  - https://doi.org/10.1016/j.sasc.2025.200335
UR  - https://www.sciencedirect.com/science/article/pii/S277294192500153X
KW  - Backdoor attacks
KW  - Deep neural networks (DNNs)
KW  - CleanSheet attack
KW  - Adversarial machine learning
KW  - Stealth attacks
AB  - Backdoor attacks pose a significant threat to the security of deep neural networks by enabling hidden manipulations that alter model predictions when specific triggers are present. Many existing attacks struggle with limited transferability across architectures, reduced stealth, or vulnerability to detection by current defense methods. This work introduces CleanSheet, a novel backdoor attack framework that addresses these challenges through compact, adaptive trigger designs. CleanSheet is evaluated across a wide range of datasets CIFAR-10, AG News, SVHN, TinyImageNet, IMDB and MalNet-Tiny and models including ResNet-18, VGG-16, DenseNet-121, BERT, and GPT-3. It achieves an attack success rate of up to 96.2% on GPT-3 with the IMDB dataset while maintaining high accuracy on clean inputs. CleanSheet also bypasses advanced defenses such as ONION, input sanitization, and anomaly detection, consistently achieving over 89% attack success even under defense. We further analyze how factors like trigger size and type, dataset scale, training duration, and model complexity affect the attack’s performance. Compared to baseline methods, CleanSheet improves attack success rate by an average of 12.4%. These results highlight the effectiveness and stealth of CleanSheet, calling attention to the need for improved defense mechanisms in machine learning systems.
ER  - 

TY  - JOUR
T1  - Survey on Explainable AI: Techniques, challenges and open issues
AU  - Abusitta, Adel
AU  - Li, Miles Q.
AU  - Fung, Benjamin C.M.
JO  - Expert Systems with Applications
VL  - 255
SP  - 124710
PY  - 2024
DA  - 2024/12/01/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2024.124710
UR  - https://www.sciencedirect.com/science/article/pii/S095741742401577X
KW  - Explainable artificial intelligence
KW  - Machine Learning
KW  - Interpretability
KW  - Trusted artificial intelligence
AB  - Artificial Intelligence (AI) has become an important component of many software applications. It has reached a point where it can provide complex and critical decisions in our life. However, the success of most AI-powered applications is based on black-box approaches (e.g., deep neural networks), which can create learned models that are able to predict and make decisions. While these advanced models could achieve high accuracy, they are generally unable to explain their decisions (e.g., predictions) to users. As a result, there is a pressing need for explainable machine learning systems in order to be trustworthy by governments, organizations, industries, and users. This paper classifies and compares the main findings in the domain of explainable machine learning and deep learning. We also discuss the application of Explainable AI (XAI) in sensitive domains such as cybersecurity. In addition, we characterize each reviewed article on the basis of the methods and techniques used to achieve XAI. This, in turn, allows us to discern the strengths and limitations of the existing XAI techniques. We finally discuss some substantial challenges and future research directions related to XAI.
ER  - 

TY  - JOUR
T1  - Just a little human intelligence feedback! Unsupervised learning assisted supervised learning data poisoning based backdoor removal
AU  - Luo, Ting
AU  - Peng, Huaibing
AU  - Fu, Anmin
AU  - Yang, Wei
AU  - Pang, Lihui
AU  - Al-Sarawi, Said F.
AU  - Abbott, Derek
AU  - Gao, Yansong
JO  - Computer Communications
VL  - 233
SP  - 108052
PY  - 2025
DA  - 2025/03/01/
SN  - 0140-3664
DO  - https://doi.org/10.1016/j.comcom.2025.108052
UR  - https://www.sciencedirect.com/science/article/pii/S014036642500009X
KW  - Backdoor attack
KW  - Human intelligence
KW  - Unsupervised clustering
AB  - Backdoor attacks on deep learning (DL) models are recognized as one of the most alarming security threats, particularly in security-critical applications. A primary source of backdoor introduction is data outsourcing such as when data is aggregated from third parties or end Internet of Things (IoT) devices, which are susceptible to various attacks. Significant efforts have been made to counteract backdoor attacks through defensive measures. However, the majority of them are ineffective to either evolving trigger types or backdoor types. This study proposes a poisoned data detection method, termed as LABOR (unsupervised Learning Assisted supervised learning data poisoning based Backd Or Removal), by incorporating a little human intelligence feedback. LABOR is specifically devised to counter backdoor induced by dirty-label data poisoning on the most common classification tasks. The key insight is that regardless of the underlying trigger types (e.g., patch or imperceptible triggers) and intended backdoor types (e.g., universal or partial backdoor), the poisoned samples still preserve the semantic features of their original classes. By clustering these poisoned samples based on their original categories through unsupervised learning, with category identification assisted by human intelligence, LABOR can detect and remove poisoned samples by identifying discrepancies between cluster categories and classification model predictions. Extensive experiments on eight benchmark datasets, including an intrusion detection dataset relevant to IoT device protection, validate LABOR’s effectiveness in combating dirty-label poisoning-based backdoor attacks. LABOR’s robustness is further demonstrated across various trigger and backdoor types, as well as diverse data modalities, including image, audio and text.
ER  - 

TY  - JOUR
T1  - Detecting DDoS based on attention mechanism for Software-Defined Networks
AU  - Yoon, Namkyung
AU  - Kim, Hwangnam
JO  - Journal of Network and Computer Applications
VL  - 230
SP  - 103928
PY  - 2024
DA  - 2024/10/01/
SN  - 1084-8045
DO  - https://doi.org/10.1016/j.jnca.2024.103928
UR  - https://www.sciencedirect.com/science/article/pii/S108480452400105X
KW  - SDN
KW  - DDoS
KW  - Deep learning
KW  - Attention mechanism
AB  - In this paper, we propose a deep learning model based on a novel Divide and Conquer Attention (DCA) mechanism, for efficient detection of Distributed Denial of Service (DDoS) attacks in a virtual Software Defined Networking(SDN) environment. DDoS is a cyber-attack that depletes the resources of the target victim through excessive traffic attacks, preventing users from using the server normally. As network infrastructure evolves, the threat of cyber-attacks such as DDoS is increasing, and DDoS attack methods are also becoming very diverse. DDoS attacks are more dangerous in SDN because a failure occurring in the SDN controller paralyzes the entire network managed by the controller and has recently received a lot of attention. Therefore, our proposed DCA based detection model learns complex attack patterns and network traffic, providing enhanced detection. The DCA based detection model that focuses on various functions of network traffic based on importance provides a better understanding of abnormal behavior patterns. Our results obtained from virtual network attack scenario experiments with Open Network Operating System (ONOS) SDN controller and Mininet network simulator show that DCA based model outperforms traditional machine learning methods and other deep learning models. Then, we conduct performance evaluations against various recent deep learning-based network analysis studies to provide various advantages for the utilization of DCA based detection model.
ER  - 

TY  - JOUR
T1  - MLAF-VD: A vulnerability detection model based on multi-level abstract features
AU  - Li, Qinghao
AU  - Liu, Wei
AU  - Wang, Yisen
AU  - Dong, Weiyu
JO  - Journal of Information Security and Applications
VL  - 93
SP  - 104189
PY  - 2025
DA  - 2025/09/01/
SN  - 2214-2126
DO  - https://doi.org/10.1016/j.jisa.2025.104189
UR  - https://www.sciencedirect.com/science/article/pii/S2214212625002261
KW  - Vulnerability detection
KW  - Abstract feature
KW  - Deep learning
KW  - Graph neural network
AB  - As key factors that threaten software security, software vulnerabilities need to be effectively detected. In recent years, with the prosperity of deep learning technology, the academic community has witnessed the emergence of numerous software vulnerability detection methods based on deep learning. These methods usually use different-level abstract features such as code snippets, AST, or CFG as feature representations of vulnerability samples, and then feed them into neural networks to learn patterns of the vulnerabilities. However, these abstract features lack direct relevance to vulnerability detection (i.e., they are not specifically designed for vulnerability detection), which makes it difficult for these abstract features to represent the vulnerability semantics accurately. In addition, single-level abstract features face challenges in comprehensively reflecting code information. In this paper, we propose a semantic-level danger structure graph (DSG), which aims to represent the semantic part of the code that is related to the vulnerability. A graph neural network with global attention, Global-GAT, is also proposed to capture the global dependencies of the graph representation. Based on DSG and Global-GAT, we propose a vulnerability detection model based on multi-level abstract features, named MLAF-VD. MLAF-VD learns the sequence-level, structure-level, and semantic-level abstract features of the code with multiple attention mechanisms, and alleviates the influence of noise information through a denoising module. We evaluate MLAF-VD on 3 representative public datasets, and the results show that MLAF-VD outperforms the best baseline methods by 4.88%, 7.40%, and 12.60% in terms of F1-Score, respectively. In practical applications, MLAF-VD detects 20 N-Day vulnerabilities from 6 open-source projects, demonstrating its effectiveness in detecting software vulnerabilities.
ER  - 

TY  - JOUR
T1  - Cyberbullying detection of resource constrained language from social media using transformer-based approach
AU  - Sihab-Us-Sakib, Syed
AU  - Rahman, Md. Rashadur
AU  - Forhad, Md. Shafiul Alam
AU  - Aziz, Md. Atiq
JO  - Natural Language Processing Journal
VL  - 9
SP  - 100104
PY  - 2024
DA  - 2024/12/01/
SN  - 2949-7191
DO  - https://doi.org/10.1016/j.nlp.2024.100104
UR  - https://www.sciencedirect.com/science/article/pii/S2949719124000529
KW  - Cyberbullying classification
KW  - Social media
KW  - Transformers
KW  - Machine Learning
KW  - Low resource language
KW  - Natural Language Processing
AB  - The rise of the internet and social media has facilitated diverse interactions among individuals, but it has also led to an increase in cyberbullying—a phenomenon with detrimental effects on mental health, including the potential to induce suicidal thoughts. To combat this issue, we have developed the Cyberbullying Bengali Dataset (CBD), a novel resource containing 2751 manually labeled texts categorized into five classes, including various forms of cyberbullying and non-bullying instances. In our study on cyberbullying detection, we conducted an extensive evaluation of various machine learning and deep learning models. Specifically, we examined Support Vector Machine (SVM), Multinomial Naive Bayes (MNB), and Random Forest (RF) among the traditional machine learning models. For deep learning models, we explored Gated Recurrent Unit (GRU), Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), and Bidirectional LSTM (BiLSTM). We have also experimented with state-of-the-art transformer architectures, including m-BERT, BanglaBERT, and XLM-RoBERTa. After rigorous experimentation, XLM-RoBERTa emerged as the most effective model, achieving a significant F1-score of 0.83 and an accuracy of 82.61%, outperforming all other models. Our work provides insights into effective cyberbullying detection on platforms like Facebook, YouTube, and Instagram.
ER  - 

TY  - JOUR
T1  - A multi-level and iterative feature engineering framework for deepfake audio detection
AU  - Celik, Burak
AU  - Akbal, Ayhan
JO  - Expert Systems with Applications
VL  - 303
SP  - 130722
PY  - 2026
DA  - 2026/03/25/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2025.130722
UR  - https://www.sciencedirect.com/science/article/pii/S0957417425043374
KW  - FakeSleuthNeXt
KW  - Deepfake speech detection
KW  - Feature engineering
KW  - Machine learning
AB  - This study introduces FakeSleuthNeXt, a lightweight, fully interpretable, handcrafted feature engineering framework for deepfake audio detection. The method relies exclusively on manually designed features without any neural network training. It combines a histogram-driven binary pattern extractor applied to 7-level discrete wavelet transform sub-bands with 15 statistical descriptors per level. An iterative ensemble feature selection strategy fusing INCA, IChi2, and IReliefF algorithms produces compact and highly discriminative representations. Evaluated on six challenging and diverse deepfake audio datasets (over 72,000 segments) using only kNN and Cubic SVM classifiers, the framework achieves accuracies ranging from 89.20% to 99.21%, EER values from 0.97% to 10.85%, and min-tDCF of 0.124 (ASVspoof 2019 LA) and 0.298 (ASVspoof 2021). These results match or surpass many recent deep learning systems while offering significantly lower computational cost, full transparency, and straightforward deployment on resource-constrained devices, making FakeSleuthNeXt particularly suitable for forensic applications. FakeSleuthNeXt provides a fast, transparent, and highly resource-efficient solution, making it particularly well-suited for forensic applications and deployment on resource-constrained devices.
ER  - 

TY  - JOUR
T1  - Brace yourself! Why managers should adopt a synthetic media incident response playbook in an age of falsity and synthetic media
AU  - Whittaker, Lucas
AU  - Kietzmann, Jan
AU  - Letheren, Kate
AU  - Mulcahy, Rory
AU  - Russell-Bennett, Rebekah
JO  - Business Horizons
VL  - 66
IS  - 2
SP  - 277
EP  - 290
PY  - 2023
DA  - 2023/03/01/
SN  - 0007-6813
DO  - https://doi.org/10.1016/j.bushor.2022.07.004
UR  - https://www.sciencedirect.com/science/article/pii/S0007681322000957
KW  - Deepfakes
KW  - Machine learning
KW  - Business artificial intelligence
KW  - Fake news
KW  - Cybersecurity
AB  - Synthetic media presents looming threats to managers in a business setting. To address this issue, we first offer a short overview of the evolution of media manipulation to contextualize the new era of synthetic media. Then, we present the problems associated with synthetic media via veridicality and heuristics to illustrate how consumers have little choice but to believe what they see, read, and hear online. We outline the most likely and impactful types of synthetic media threats and attacks and present a synthetic media incident response playbook. Our aim is to inform managers about six specific phases so they can prepare, assess, detect, analyze, and recover from synthetic media incidents and coordinate their lessons learned.
ER  - 

TY  - JOUR
T1  - Intelligent financial system: How AI is transforming finance
AU  - Aldasoro, I.
AU  - Gambacorta, L.
AU  - Korinek, A.
AU  - Shreeti, V.
AU  - Stein, M.
JO  - Journal of Financial Stability
VL  - 81
SP  - 101472
PY  - 2025
DA  - 2025/12/01/
SN  - 1572-3089
DO  - https://doi.org/10.1016/j.jfs.2025.101472
UR  - https://www.sciencedirect.com/science/article/pii/S1572308925001019
KW  - Artificial intelligence
KW  - Generative AI
KW  - Financial system
KW  - Financial institutions
AB  - At the core of the financial system is the processing and aggregation of vast amounts of information into price signals that coordinate participants in the economy. Throughout history, advances in information processing, from simple book-keeping to artificial intelligence (AI), have transformed the financial sector. We use this framing to analyze how generative AI (GenAI), emerging AI agents and, more speculatively, artificial general intelligence will impact finance. We focus on four functions of the financial system: financial intermediation, insurance, asset management, and payments. We also assess the implications of advances in AI for financial stability and prudential policy. Moreover, we investigate potential spillover effects of AI on the real economy, examining both an optimistic and a disruptive AI scenario. To address the transformative impact of advances in AI on the financial system, we propose a framework for upgrading financial regulation based on well-established general principles for AI governance.
ER  - 
