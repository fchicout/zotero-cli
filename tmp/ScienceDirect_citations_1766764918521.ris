TY  - JOUR
T1  - Q-FlexiViT: A quantum-flexible vision transformer optimized by Octopus-inspired algorithm for intrusion detection
AU  - Santhanam, Prem Kumar
AU  - Vellanki, Himaja Chowdary
AU  - Reddy Bellapu, Sai Rohith
AU  - Mithra, K
JO  - Computers and Electrical Engineering
VL  - 129
SP  - 110793
PY  - 2026
DA  - 2026/01/01/
SN  - 0045-7906
DO  - https://doi.org/10.1016/j.compeleceng.2025.110793
UR  - https://www.sciencedirect.com/science/article/pii/S0045790625007360
KW  - Intrusion detection
KW  - Network security
KW  - Q-FlexiViT
KW  - OIO algorithm
KW  - Data preprocessing
KW  - Attention mechanisms
KW  - Quantum computing principles
AB  - Network Intrusion Detection system (IDs) plays a vital role in safeguarding industrial networks against increasingly sophisticated cyberattack. This research presents Quantum Flexi-Attention Vision Transformer (Q-FlexiViT), optimized using the Octopus Inspired Optimization (OIO) algorithm. The framework addresses common data challenges by applying preprocessing steps such as handling missing values, label encoding, dimensionality reduction and feature scaling, followed by partitioning into training and testing values. Q-FlexiViT combines quantum inspired feature encoding with attention based vision transformer to capture complex spatial temporal patterns in network traffic. The OIO algorithm is employed to tune hyperparameters efficiently, enhancing both detection accuracy and adaptability. The entire framework is implemented and validated using the Python programming environment, demonstrating its efficiency in accurately detecting network intrusions by comparative analysis, Q-FlexiViT model accomplishes higher accuracy of (99.12 %) in fold 1 using CICIoT2023 dataset and minimal computational time compared to the other conventional IDS approaches used recently.
ER  - 

TY  - JOUR
T1  - Blind protocol identification using synthetic dataset: A case study on geographic protocols
AU  - Abbasi-Azar, Mohammad
AU  - Teimouri, Mehdi
AU  - Nikray, Mohsen
JO  - Forensic Science International: Digital Investigation
VL  - 53
SP  - 301911
PY  - 2025
DA  - 2025/06/01/
SN  - 2666-2817
DO  - https://doi.org/10.1016/j.fsidi.2025.301911
UR  - https://www.sciencedirect.com/science/article/pii/S2666281725000502
KW  - Blind protocol identification
KW  - Machine learning
KW  - Synthetic datasets
KW  - Network forensics
KW  - Classification
KW  - Geographic encoding standards
AB  - Network forensics faces major challenges, including increasingly sophisticated cyberattacks and the difficulty of obtaining labeled datasets for training AI-driven security tools. Blind Protocol Identification (BPI), essential for detecting covert data transfers, is particularly impacted by these data limitations. This paper introduces a novel and inherently scalable method for generating synthetic datasets tailored for BPI in network forensics. Our approach emphasizes feature engineering and a statistical-analytical model of feature distributions to address the scarcity and imbalance of labeled data. We demonstrate the effectiveness of this method through a case study on geographic protocols, where we train Random Forest models using only synthetic datasets and evaluate their performance on real-world traffic. This work presents a promising solution to the data challenges in BPI, enabling reliable protocol identification while maintaining data privacy and overcoming traditional data collection limitations.
ER  - 

TY  - JOUR
T1  - Learning never stops: Improving software vulnerability type identification via incremental learning
AU  - Xue, Jiacheng
AU  - Chen, Xiang
AU  - Cui, Zhanqi
AU  - Liu, Yong
JO  - Journal of Systems and Software
VL  - 230
SP  - 112544
PY  - 2025
DA  - 2025/12/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2025.112544
UR  - https://www.sciencedirect.com/science/article/pii/S0164121225002134
KW  - Software vulnerability type identification
KW  - Incremental learning
KW  - Prompt tuning
KW  - Vulnerability description
KW  - Vulnerability code
AB  - As new vulnerabilities are continuously discovered, software vulnerability type identification (SVTI) data is dynamic. Moreover, SVTI data often exhibits a long-tailed distribution, where some vulnerability types (i.e., head classes) have numerous samples, while rare ones (i.e., tail classes) have very few. These issues present challenges for SVTI, such as catastrophic forgetting when learning new data and poor performance for rare vulnerability types. To address these challenges, we propose an approach VulTypeIL. Specifically, for incremental learning, we employ a hybrid replay strategy and a regularization strategy with EWC to alleviate the catastrophic forgetting issue. We also integrate focal loss and label smooth cross-entropy loss to tackle the long-tailed distribution issue. For model construction, we customize the verbalizer and hybrid prompt by fusing the Vulnerability code and description. Then, we perform prompt tuning on the pre-trained model CodeT5. To evaluate the effectiveness of VulTypeIL, we construct a large-scale SVTI dataset containing 6,269 vulnerabilities from 992 real-world projects. Our experimental results demonstrate that VulTypeIL outperforms state-of-the-art baselines (such as VulExplainer and LIVABLE) with a significant improvement. The ablation studies further confirm the effectiveness of key component settings (such as the incremental learning setting and long-tailed learning setting) in our approach.
ER  - 

TY  - JOUR
T1  - MGGPT: A Multi-Graph GPT-enhanced framework for dynamic fraud detection in cryptocurrency networks
AU  - Badjie, Ansu
AU  - Ntuala, Grace Mupoyi
AU  - Xia, Qi
AU  - Gao, Jianbin
AU  - Xia, Hu
JO  - Computer Networks
VL  - 270
SP  - 111508
PY  - 2025
DA  - 2025/10/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2025.111508
UR  - https://www.sciencedirect.com/science/article/pii/S138912862500475X
KW  - Graph neural networks
KW  - Cryptocurrency fraud detection
KW  - Temporal graph analysis
KW  - GPT-2 transformers
KW  - Missing information prediction
AB  - The rapid increase in cryptocurrency transactions has increased demand for advanced fraud detection systems. Conventional methods are often rigid and do not effectively capture cryptocurrency networks’ intricate temporal and structural patterns, while existing dynamic approaches struggle with incomplete or missing information. To tackle this issue, we present MGGPT, a new hybrid framework that integrates Graph Attention Neural Networks (GAT) with GPT-based transformers to improve fraud detection within cryptocurrency transaction networks. Our approach utilizes temporal graph structures through reachability networks (reach-nets) to derive essential node features, while also directly integrating edge labels into the embedding vectors, and introduces an innovative mechanism for predicting missing information to address the challenges posed by incomplete data in blockchain networks. The model features a dual-perspective learning strategy, employing local graph structures via GAT Networks and global contextual patterns through GPT-based sequence modeling to capture both structural and temporal dynamics in transaction networks. Our MGGPT framework implements a sophisticated edge classification mechanism using Support Vector Machines (SVM) for the final prediction. Experimental findings on actual cryptocurrency transaction datasets indicate superior efficacy in identifying fraudulent patterns, achieving notable improvements of 8.5% AUC, a 10.2% increase in Precision, 29.5% increment in recall, and 20.5% improvement in F1-score. Compared to baseline models such as STA-GT and CTGN, the proposed MGGPT improves the representation of dynamic relationships and faster convergence. Overall, the analysis reveals that our framework is not only more accurate but also more robust and scalable for real-world temporal graph applications. Ultimately, we assessed the robustness of our framework against adversarial attacks to show its practical applications in blockchains.
ER  - 

TY  - JOUR
T1  - Deep learning for optimizing urban governance by "sensing-processing-responding" cycle: Recent advances, future prospects and challenges
AU  - Cheng, Mingjun
AU  - Jin, Hong
AU  - Zhao, Qinfeng
AU  - Wang, Yurun
AU  - Wu, Yanxi
AU  - Huang, Shan
AU  - Yue, Wenze
JO  - Sustainable Cities and Society
VL  - 135
SP  - 106994
PY  - 2025
DA  - 2025/12/15/
SN  - 2210-6707
DO  - https://doi.org/10.1016/j.scs.2025.106994
UR  - https://www.sciencedirect.com/science/article/pii/S2210670725008650
KW  - Deep learning
KW  - Urban governance
KW  - Large models
KW  - Sensing-Processing-Responding framework
KW  - Sustainable development
KW  - Literature review
AB  - With accelerating urbanization, traditional governance models are increasingly strained. Deep learning (DL) offers powerful solutions, but its application in urban governance lacks a systematic framework and faces significant hurdles. This paper addresses these gaps through a systematic review of 329 articles published from 2016 to 2025. We introduce a novel Sensing-Processing-Responding framework to classify the technological pathways of DL in urban governance. This framework organizes applications into three core stages: (1) Sensing technologies (e.g., CNNs) for dynamic data acquisition; (2) Processing technologies (e.g., RNNs, Transformers) for predictive modeling and analysis; and (3) Responding technologies (e.g., LLMs) for automated decision support. Our analysis reveals that while DL is widely applied in traffic forecasting, environmental monitoring, and disaster response, its deployment is constrained by key challenges. We found a significant gap between research and practice, with only 7.6% of studies demonstrating real-world application. Furthermore, it concerns data privacy and model interpretability limit public acceptance, although our review indicates that fewer than 10% of studies involve high-risk personal data. Future progress depends on integrating emerging technologies like multimodal large models and multi-agent systems. We conclude by advocating for a paradigm shift from focusing purely on accuracy to prioritizing public value, fairness, and transparency. This study provides a comprehensive roadmap for developing more intelligent, resilient, and sustainable urban governance systems.
ER  - 

TY  - JOUR
T1  - Content Disarm and Reconstruction of Microsoft Office OLE files
AU  - Dubin, Ran
JO  - Computers & Security
VL  - 137
SP  - 103647
PY  - 2024
DA  - 2024/02/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2023.103647
UR  - https://www.sciencedirect.com/science/article/pii/S0167404823005564
KW  - Microsoft OLE
KW  - Attack prevention
KW  - CDR
KW  - Malware
KW  - Sensitization
KW  - Threat disarm
KW  - Zero-trust
AB  - Content Disarm and Reconstruction (CDR) is an advanced, zero-trust strategy for neutralizing potential threats in documents and media files. This paper introduces OLECDR, the first Microsoft Object Linking and Embedding (OLE) file format CDR system. This work measures OLECDR prevention rates and verifies that they are similar to the original file. Furthermore, we introduce a novel method for dealing with emerging threats by automatically converting detection rules into disarm and reconstruction rules. Those detection rules are needed in cases where the vulnerability is found in the file reader rather than in the file itself. Microsoft OLE file format is a highly popular format structure of Word, PowerPoint, and Excel file types. In our study, OLECDR successfully disarmed and reconstructed most of the threats while leaving the benign and malicious dataset fully functional and similar to the original source files.
ER  - 

TY  - JOUR
T1  - AI-driven assistants for education and research? A case study on ChatGPT for air transport management
AU  - Wandelt, Sebastian
AU  - Sun, Xiaoqian
AU  - Zhang, Anming
JO  - Journal of Air Transport Management
VL  - 113
SP  - 102483
PY  - 2023
DA  - 2023/10/01/
SN  - 0969-6997
DO  - https://doi.org/10.1016/j.jairtraman.2023.102483
UR  - https://www.sciencedirect.com/science/article/pii/S0969699723001266
KW  - Chatbots
KW  - Artificial Intelligence
KW  - Education
KW  - Research
AB  - Artificial Intelligence is in the process to transform various parts of the aviation industry, from the reduction of delays and increasing fuel efficiency to better demand prediction models. The latest kid on the block is ChatGPT, a large language model developed by OpenAI, which has made into the news for its mind-blowing ability to create textual content in any structured language. Doing so, ChatGPT has the potential to revolutionize the way we communicate with computers, and it could have a lasting impact on aviation education and research. In this study, we investigate the potential of this impact and, the extent to which it has already materialized, based on a set of graduate student surveys and experiments with ChatGPT. The results of our surveys indicate the interest of students in efficient learning, time saving, and improvement in programming/writing skills. Our experiments on terminology explanation, state-of-the-art identification of selected research tasks as well as programming design, highlight the tradeoffs between benefits and potential risks inherent to the usage of ChatGPT and AI-driven assistants in general. Overall, we believe that our study makes a first contribution to evaluating an exciting new technology which has the potential to revolutionize our aviation system.
ER  - 

TY  - JOUR
T1  - Multimodal privacy-leaking image detection method based on multi-image correlation
AU  - Ding, Changhao
AU  - Huang, Jie
AU  - Hao, Qi
AU  - Zhang, Zeping
AU  - Zhang, Yizhun
JO  - Neurocomputing
VL  - 666
SP  - 132222
PY  - 2026
DA  - 2026/02/14/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2025.132222
UR  - https://www.sciencedirect.com/science/article/pii/S0925231225028942
KW  - Privacy-leaking image detection
KW  - Multimodality
KW  - Text summarization
KW  - Multi-image correlation
KW  - Deep learning
AB  - The purpose of privacy-leaking image detection in deep learning is to automatically determine whether an image poses a privacy leakage risk and provide corresponding identification results. However, some of the images with privacy leakage can only be detected by analyzing the overall semantics of multiple content-related images, and are hardly detected in a single-image scenario. To address this issue, a privacy-leaking image detection method combining multi-image correlation and multimodal features is proposed in this paper. This method leverages semantically related image groups along with their corresponding text summaries to establish contextual correlation, and employs both additive and dot-product attention mechanisms to achieve effective multimodal fusion between the two modalities. Furthermore, saliency features from both modalities are incorporated to strengthen the correlation between contents and privacy leakage from different perspectives. The experimental results show that the proposed method can effectively capture inter-image semantic correlation through multi-image text summarization, leading to significant improvements in privacy-leaking image detection performance.
ER  - 

TY  - JOUR
T1  - DNS user profiling and risk assessment: A learning approach
AU  - Baseri, Yaser
AU  - Firoozjaei, Mahdi Daghmehchi
AU  - Sadeghi, Somayeh
AU  - Ghorbani, Ali
AU  - Belanger, William
AU  - Razavi-Far, Roozbeh
JO  - Future Generation Computer Systems
VL  - 176
SP  - 108180
PY  - 2026
DA  - 2026/03/01/
SN  - 0167-739X
DO  - https://doi.org/10.1016/j.future.2025.108180
UR  - https://www.sciencedirect.com/science/article/pii/S0167739X25004741
KW  - User profiling
KW  - DNS security
KW  - Risk assessment
KW  - Graph-based learning
KW  - Threat intelligence
AB  - In the dynamic digital landscape, user profiling plays a crucial role in gathering and utilizing personal information, enabling tailored recommendations across various online platforms. Social media giants like Twitter, Facebook, Instagram, and LinkedIn regularly collect data on users’ browsing habits, interests, preferences, and intent. This profiling serves as a rich data source for analyzing user behaviors, detecting anomalous users, and assessing potential risks. This paper introduces a DNS user profiling approach to evaluate the risk associated with users’ domain-browsing activities, offering a proactive method to minimize risks across different domains. The risk profiling approach extracts information related to the domains accessed by users from DNS servers, employs a new graph-based learning mechanism, presented here, and assigns the risk associated with users and domains. Real data from DNS queries made by Canadian internet users forms the basis of this research. The approach generates a domain similarity graph illustrating threat relationships among domains accessed by users. Through graph-based risk assessment, individual user profiles are crafted based on online activities. This approach facilitates the analysis of users’ malicious behaviors, evaluates associated risks, and detects security threats. The evaluation methodology uses the paired T-test, which is well-suited for consistently comparing different methods across the same set of folds during cross-validation. This method validates the results and confirms high confidence levels of 98.3 % for domains and 96.7 % for users in their respective risk scores. This research introduces an innovative DNS user profiling approach and demonstrates its effectiveness in robustly evaluating and mitigating security risks associated with user-domain interactions.
ER  - 

TY  - JOUR
T1  - VulDIAC: Vulnerability detection and interpretation based on augmented CFG and causal attention learning
AU  - Yang, Shuailin
AU  - Ren, Jiadong
AU  - Li, Jiazheng
AU  - Zhang, Dekai
JO  - Journal of Systems and Software
VL  - 231
SP  - 112595
PY  - 2026
DA  - 2026/01/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2025.112595
UR  - https://www.sciencedirect.com/science/article/pii/S016412122500264X
KW  - Vulnerability detection
KW  - Control flow graph
KW  - Relation graph neural network
KW  - Causal attention learning
KW  - Interpretability
AB  - Vulnerability detection in software source code is essential for ensuring system security. Recently, deep learning methods have gained significant attention in this domain, leveraging structured information extracted from source code, and employing Graph Neural Networks (GNNs) to enhance detection performance through graph representation learning. However, conventional code graph structures exhibit limitations in capturing the comprehensive semantics of source code, and the presence of spurious features may result in incorrect correlations, which undermines the robustness and explainability of vulnerability detection models. In this paper, we propose VulDIAC, a novel framework for Vulnerability Detection and Interpretation that integrates an Augmented Control Flow Graph (ACFG) and a multi-task Causal attention learning module based on Relational Graph Convolutional Networks, referred to as RGCN-CAL. The ACFG incorporates additional relational edges, such as reaching-define and dominator relationships, to better capture the control flow logic and data flow information within the code. The RGCN-CAL module emphasizes causal features while learning multi-relational graph representations. This approach enhances detection accuracy and provides fine-grained, line-level explanations. Experimental evaluations on two public datasets demonstrate that VulDIAC significantly outperforms baseline methods, achieving F1-Score improvements of 27.16% and 53.59%, respectively. Additionally, VulDIAC achieves better Top-k accuracy compared to LineVul on line-level vulnerability detection, which suggests its competitive performance and potential interpretability benefits.
ER  - 

TY  - JOUR
T1  - Opinion Paper: “So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy
AU  - Dwivedi, Yogesh K.
AU  - Kshetri, Nir
AU  - Hughes, Laurie
AU  - Slade, Emma Louise
AU  - Jeyaraj, Anand
AU  - Kar, Arpan Kumar
AU  - Baabdullah, Abdullah M.
AU  - Koohang, Alex
AU  - Raghavan, Vishnupriya
AU  - Ahuja, Manju
AU  - Albanna, Hanaa
AU  - Albashrawi, Mousa Ahmad
AU  - Al-Busaidi, Adil S.
AU  - Balakrishnan, Janarthanan
AU  - Barlette, Yves
AU  - Basu, Sriparna
AU  - Bose, Indranil
AU  - Brooks, Laurence
AU  - Buhalis, Dimitrios
AU  - Carter, Lemuria
AU  - Chowdhury, Soumyadeb
AU  - Crick, Tom
AU  - Cunningham, Scott W.
AU  - Davies, Gareth H.
AU  - Davison, Robert M.
AU  - Dé, Rahul
AU  - Dennehy, Denis
AU  - Duan, Yanqing
AU  - Dubey, Rameshwar
AU  - Dwivedi, Rohita
AU  - Edwards, John S.
AU  - Flavián, Carlos
AU  - Gauld, Robin
AU  - Grover, Varun
AU  - Hu, Mei-Chih
AU  - Janssen, Marijn
AU  - Jones, Paul
AU  - Junglas, Iris
AU  - Khorana, Sangeeta
AU  - Kraus, Sascha
AU  - Larsen, Kai R.
AU  - Latreille, Paul
AU  - Laumer, Sven
AU  - Malik, F. Tegwen
AU  - Mardani, Abbas
AU  - Mariani, Marcello
AU  - Mithas, Sunil
AU  - Mogaji, Emmanuel
AU  - Nord, Jeretta Horn
AU  - O’Connor, Siobhan
AU  - Okumus, Fevzi
AU  - Pagani, Margherita
AU  - Pandey, Neeraj
AU  - Papagiannidis, Savvas
AU  - Pappas, Ilias O.
AU  - Pathak, Nishith
AU  - Pries-Heje, Jan
AU  - Raman, Ramakrishnan
AU  - Rana, Nripendra P.
AU  - Rehm, Sven-Volker
AU  - Ribeiro-Navarrete, Samuel
AU  - Richter, Alexander
AU  - Rowe, Frantz
AU  - Sarker, Suprateek
AU  - Stahl, Bernd Carsten
AU  - Tiwari, Manoj Kumar
AU  - van der Aalst, Wil
AU  - Venkatesh, Viswanath
AU  - Viglia, Giampaolo
AU  - Wade, Michael
AU  - Walton, Paul
AU  - Wirtz, Jochen
AU  - Wright, Ryan
JO  - International Journal of Information Management
VL  - 71
SP  - 102642
PY  - 2023
DA  - 2023/08/01/
SN  - 0268-4012
DO  - https://doi.org/10.1016/j.ijinfomgt.2023.102642
UR  - https://www.sciencedirect.com/science/article/pii/S0268401223000233
KW  - Conversational agent
KW  - Generative artificial intelligence
KW  - Generative AI
KW  - ChatGPT
KW  - Large language models
AB  - Transformative artificially intelligent tools, such as ChatGPT, designed to generate sophisticated text indistinguishable from that produced by a human, are applicable across a wide range of contexts. The technology presents opportunities as well as, often ethical and legal, challenges, and has the potential for both positive and negative impacts for organisations, society, and individuals. Offering multi-disciplinary insight into some of these, this article brings together 43 contributions from experts in fields such as computer science, marketing, information systems, education, policy, hospitality and tourism, management, publishing, and nursing. The contributors acknowledge ChatGPT’s capabilities to enhance productivity and suggest that it is likely to offer significant gains in the banking, hospitality and tourism, and information technology industries, and enhance business activities, such as management and marketing. Nevertheless, they also consider its limitations, disruptions to practices, threats to privacy and security, and consequences of biases, misuse, and misinformation. However, opinion is split on whether ChatGPT’s use should be restricted or legislated. Drawing on these contributions, the article identifies questions requiring further research across three thematic areas: knowledge, transparency, and ethics; digital transformation of organisations and societies; and teaching, learning, and scholarly research. The avenues for further research include: identifying skills, resources, and capabilities needed to handle generative AI; examining biases of generative AI attributable to training datasets and processes; exploring business and societal contexts best suited for generative AI implementation; determining optimal combinations of human and generative AI for various tasks; identifying ways to assess accuracy of text produced by generative AI; and uncovering the ethical and legal issues in using generative AI across different contexts.
ER  - 

TY  - JOUR
T1  - M2VMapper: Malware-to-Vulnerability mapping for Android using text processing
AU  - Garg, Shivi
AU  - Baliyan, Niyati
JO  - Expert Systems with Applications
VL  - 191
SP  - 116360
PY  - 2022
DA  - 2022/04/01/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2021.116360
UR  - https://www.sciencedirect.com/science/article/pii/S0957417421016572
KW  - Android
KW  - Deep Learning
KW  - Malware
KW  - Mapping
KW  - Language model
KW  - Vulnerability
AB  - Over 90% of the mobile malware target Android mobile platform. Many Machine Learning (ML) and Deep Learning (DL) techniques have been used to detect and analyze Android malware, however, there is a many-to-many mapping between malware and vulnerability. This means a single malware can exploit multiple security vulnerabilities (known or unknown) and a single vulnerability can be exploited by multiple malware. Therefore, it is important to analyze the behaviour of malware to identify and reduce the vulnerabilities. Till date, no ML/DL or other technique has been deployed to analyze the malware behaviour to identify and reduce the vulnerabilities. The paper proposes a DL framework ‘M2VMapper’ that combines transfer learning and pretrained language models, which aims to map malware and potential vulnerabilities using a 2D matrix. The many-to-many mapping matrix is obtained by using transformer models such as BERT and XLNET; in addition to DL models such as Multi-layer Perceptron (MLP), Recurrent Neural Network (RNN) and Textual Convolutional Neural Network (TextCNN). This malware-to-vulnerability mapping can be leveraged to measure the severity of unknown vulnerabilities and malware during the initial phase of application development. The study is a first of its kind and considers 150 malware families from different datasets, such as AMD, CICInvesAndMal2019, and Androzoo with a total of 48 907 malware samples and 9 vulnerability types affecting Android. M2VMapper has delivered highly promising results with an accuracy of 99.81%, when XLNET is used with TextCNN, and precision and F1-scores above 95% using DL models.
ER  - 

TY  - JOUR
T1  - Suspicious minds: Psychological techniques correlated with online phishing attacks
AU  - Stylianou, Ioannis
AU  - Bountakas, Panagiotis
AU  - Zarras, Apostolis
AU  - Xenakis, Christos
JO  - Computers in Human Behavior Reports
VL  - 19
SP  - 100694
PY  - 2025
DA  - 2025/08/01/
SN  - 2451-9588
DO  - https://doi.org/10.1016/j.chbr.2025.100694
UR  - https://www.sciencedirect.com/science/article/pii/S2451958825001095
KW  - Cybersecurity
KW  - Social engineering
KW  - Psychological techniques
KW  - Behavioral psychology
KW  - Persuasion
KW  - Compliance
AB  - Phishing remains a pervasive threat to information security, leveraging human psychology to manipulate individuals into disclosing sensitive information or performing actions against their best interests. This study presents a comprehensive taxonomy and analysis of psychological techniques utilized in social engineering, introducing novel metrics such as Absolute Compliance Increase Rate (ACR), Relative Compliance Increase Rate (RCR), and Comprehensive Compliance Increase Rate (CCR) to quantify their effectiveness. Our methodology involved a systematic review of existing literature and empirical data from psychological experiments to evaluate and compare the effectiveness of various techniques, including Authority, Commitment & Consistency, Reciprocity, and Group Pressure. The findings indicate that the Majority Size technique, measured by CCR, is particularly potent in scenarios with low initial compliance rates, while Authority, Commitment & Consistency, and Reciprocity also demonstrate high effectiveness. These insights enhance the understanding of the mechanics of social engineering techniques, enabling the development of more effective countermeasures against social engineering attacks.
ER  - 

TY  - JOUR
T1  - A fine-grained framework for online IoT device firmware identification via version evolution analysis
AU  - Lei, Zhen
AU  - Li, Yijia
AU  - Li, Zhen
AU  - Huang, Xin
AU  - Yu, Dan
AU  - Xue, Nian
AU  - Chen, Yongle
JO  - Internet of Things
VL  - 34
SP  - 101767
PY  - 2025
DA  - 2025/11/01/
SN  - 2542-6605
DO  - https://doi.org/10.1016/j.iot.2025.101767
UR  - https://www.sciencedirect.com/science/article/pii/S2542660525002811
KW  - Firmware identification
KW  - Machine learning
KW  - Transformer
KW  - IoT devices
AB  - The rapid expansion of IoT networks has outpaced the capabilities of firmware management protocols, leaving numerous Internet-connected devices operating on outdated firmware that contains exploitable vulnerabilities. As vulnerabilities are closely tied to specific firmware versions, fine-grained version identification is critical for effective device management and security risk assessment. However, high firmware heterogeneity and subjective biases in feature selection pose significant challenges to online firmware version identification (OFVI) of IoT devices. To address these challenges, we first construct a dataset comprising 444,195 embedded web pages extracted from 1,000 successfully simulated firmware images. Through analyzing update patterns of embedded web interfaces during firmware version evolution, we propose FirmID, a novel OFVI framework for IoT devices that utilizes directory and content changes in embedded web interfaces. To handle the heterogeneity of firmware across different vendors, we introduce the Hierarchical Multimodal Attention Network (HMANet), a machine learning model specifically designed to capture differences across structural, textual, and functional modalities. To overcome the challenge of distinguishing hard samples caused by the frequent reuse of web pages in firmware iteration versions, we design a Hard Negative Mining Contrastive Loss that enhances intra-class compactness and inter-class separability. Moreover, to improve identification efficiency under uncertain network conditions, FirmID incorporates a complementary heuristic search algorithm, Firmware Identification with Monte Carlo Tree Search (FIMCTS). Experimental results demonstrate that FirmID surpasses state-of-the-art methods by 30.2% in accuracy and reduces file requests by 23.3% in recognition efficiency.
ER  - 

TY  - JOUR
T1  - Securing Inclusive Digital Environments: An Adaptive Approach to ISO 27001 for Assistive Technologies in SMEs
AU  - Innomesanghan, Damilola
AU  - Kiwamu, Emmanuel
AU  - Butakov, Sergey
AU  - AbdAllah, Eslam G.
JO  - Procedia Computer Science
VL  - 272
SP  - 343
EP  - 350
PY  - 2025
DA  - 2025/01/01/
T2  - 16th International Conference on Emerging Ubiquitous Systems and Pervasive Networks / 15th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2025.10.214
UR  - https://www.sciencedirect.com/science/article/pii/S1877050925035616
KW  - Assistive Technology
KW  - ISO 27001
KW  - Compliance
KW  - Security Controls
AB  - The integration of Assistive Technologies (AT) within Small and Medium-sized Enterprises (SMEs) is pivotal for fostering inclusive digital environments, particularly for neurodiverse workforces. While AT empowers individuals with disabilities to overcome systemic barriers to employment, it concurrently introduces unique cybersecurity and privacy risks due to the sensitive nature of the user data it handles. This report underscores the critical need for robust information security in such contexts. This report demonstrates how ISO 27001 serves as a foundational framework for achieving a balance between stringent security requirements and essential accessibility needs. Drawing from a detailed case study of a Canadian SME, the report highlights key adaptive strategies, including customized security training, collaborative risk management, and the crucial role of co-creating security policies with neurodiverse employees. These practices illustrate that security and accessibility are not mutually exclusive objectives but rather complementary goals that, when aligned, significantly enhance both compliance and operational efficiency. The analysis reinforces that a proactive, user-centric approach to information security is vital for protecting sensitive AT data, strengthening organizational resilience, and ultimately paving the way for a more equitable and inclusive digital future.
ER  - 

TY  - JOUR
T1  - The cyber-industrialization of catfishing and romance fraud
AU  - Wang, Fangzhou
AU  - Topalli, Volkan
JO  - Computers in Human Behavior
VL  - 154
SP  - 108133
PY  - 2024
DA  - 2024/05/01/
SN  - 0747-5632
DO  - https://doi.org/10.1016/j.chb.2023.108133
UR  - https://www.sciencedirect.com/science/article/pii/S0747563223004843
KW  - Online romance fraud
KW  - Catfishing
KW  - Chat moderators
KW  - Online fraud industrialization
AB  - We examine a new form of online fraud, which we refer to as Intimacy Manipulated Fraud Industrialization (IMFI). This type of fraud bears a strong resemblance to traditional online romance fraud and catfishing, but is “industrialized” through enterprise business practices, software platforms, and customer service processes. To gain a better understanding of this operation, we conducted an inductive analysis of publicly available testimonial and review data provided by current and prior employees of a specific company in the online customer service contract space. Companies hire individuals online to work as “chat moderators” or “customer service providers” who are told that their task is to advance engagement on social media platforms. In fact, they are being recruited as “sexting” workers, paid on a per-text basis to engage in intimate chatting with clients who believe they're interacting with individuals of the opposite gender on a dating site. The process is mediated via client management processes that monitor employee productivity and monetize all interactions between “clients” and “workers.” The company executes these processes with great efficiency by algorithmically assigning multiple workers to individual clients and assembling background files on clients in real time. We find that workers serve as both exploiters of their clients as well as victims of the company they work for. The implications of our study could significantly impact how we address AI-generated online fraud in the future, shedding light on the complex dynamics at play within these fraudulent enterprises.
ER  - 

TY  - JOUR
T1  - Automated Threat Attack Categorisation into Cloud Service Models
AU  - Sharma, Bhubharv Mohan
AU  - Malik, Aruna
JO  - Procedia Computer Science
VL  - 259
SP  - 1883
EP  - 1892
PY  - 2025
DA  - 2025/01/01/
T2  - Sixth International Conference on Futuristic Trends in Networks and Computing Technologies (FTNCT06), held in Uttarakhand, India
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2025.04.144
UR  - https://www.sciencedirect.com/science/article/pii/S1877050925012463
KW  - LSTM - Long-Short Term Memory
KW  - CSP - Cloud Service Provider
KW  - NLP - Natural Language Processing
KW  - IaaS - Infrastructure as a Service
KW  - DDoS - Distributed Denial of Service
KW  - SaaS - Software as a Service
AB  - In today’s interconnected world, our heavy reliance on cloud- based services for daily tasks raises concerns about the security and privacy of our personal information. Cloud services have become an integral part of our lives, offering convenience and accessibility. However, the shared responsibility model and diverse service architectures of cloud computing necessitate different approaches to security assessment and penetration testing. This paper presents a comprehensive model-based approach that focuses on all three service models of the cloud. by adopting a system and model-based perspective, the study emphasizes on a shared approach to security. The methodology incorporates both white hat and grey hat techniques, which thoroughly test the security of cloud systems, ensuring a robust defense against various potential attacks. In addition to this, we are also present a novel approach for categorization using a combination of Long Short-Term Memory (LSTM) and Word2Vec, with a focus on Named Entity Recognition (NER). This approach achieves an impressive accuracy of 85 percent, which indicates its effectiveness in accurately identifying and categorizing named entities within the text data. The findings contribute in improving the overall security posture of cloud services, providing users with the confidence that their data is well protected.
ER  - 

TY  - JOUR
T1  - Chemical, biological, radiological and nuclear event detection and classification using ontology interrogation and social media data
AU  - Alrefaie, Mohamed Taher
AU  - Jackson, Tom W.
AU  - Onojeharho, Ejovwoke
AU  - Elayan, Suzanne
JO  - Engineering Applications of Artificial Intelligence
VL  - 135
SP  - 108654
PY  - 2024
DA  - 2024/09/01/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2024.108654
UR  - https://www.sciencedirect.com/science/article/pii/S0952197624008121
KW  - Ontology
KW  - Disaster management
KW  - Information retrieval
KW  - Social media analysis
KW  - Machine learning
KW  - Natural language processing
AB  - In an era where chemical, biological, radiological, and nuclear (CBRN) incidents present a grave threat to public safety, timely and accurate information is paramount. The complexity of the CBRN concept encompasses a range of incidents, each with unique and overlapping symptoms, related substances, and event descriptions. This study introduces an innovative approach to the development of a CBRN-specific ontology, uniting diverse data sources and domain expertise to construct a comprehensive repository of CBRN events, sub-events, their causes, symptoms, and toxic substances. Unlike prior methodologies reliant on keyword searches and predefined categories, our approach enables a holistic analysis of textual data by capturing intricate relationships between symptoms and toxic substances. We leverage this ontology in conjunction with a tailored interrogation algorithm to detect potential CBRN incidents through social media data. The algorithm was then tested on datasets of three actual CBRN incidents, one fictional incident (TV show) that simulated a nuclear incident and one non-CBRN. The interrogation algorithm was able to detect the five CBRN incidents accurately. However, the study showcased the need to extend the algorithm to distinguish between real and fictional CBRN incidents. These findings underscore the potential of this approach to deliver timely information on potential CBRN incidents. Nevertheless, the study acknowledged the inherent challenges and limitations in utilizing social media data, including the risk of misinformation, fictional events, fake news, and interference from malicious actors, all of which can affect the accuracy and reliability of the information collected.
ER  - 

TY  - JOUR
T1  - General Purpose Artificial Intelligence Systems (GPAIS): Properties, definition, taxonomy, societal implications and responsible governance
AU  - Triguero, Isaac
AU  - Molina, Daniel
AU  - Poyatos, Javier
AU  - Del Ser, Javier
AU  - Herrera, Francisco
JO  - Information Fusion
VL  - 103
SP  - 102135
PY  - 2024
DA  - 2024/03/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2023.102135
UR  - https://www.sciencedirect.com/science/article/pii/S1566253523004517
KW  - General-purpose AI
KW  - Meta-learning
KW  - Reinforcement learning
KW  - Neuroevolution
KW  - Few-shot learning
KW  - AutoML
KW  - Transfer learning
KW  - Generative AI
KW  - Large language models
AB  - Most applications of Artificial Intelligence (AI) are designed for a confined and specific task. However, there are many scenarios that call for a more general AI, capable of solving a wide array of tasks without being specifically designed for them. The term General Purpose Artificial Intelligence Systems (GPAIS) has been defined to refer to these AI systems. To date, the possibility of an Artificial General Intelligence, powerful enough to perform any intellectual task as if it were human, or even improve it, has remained an aspiration, fiction, and considered a risk for our society. Whilst we might still be far from achieving that, GPAIS is a reality and sitting at the forefront of AI research. This work discusses existing definitions for GPAIS and proposes a new definition that allows for a gradual differentiation among types of GPAIS according to their properties and limitations. We distinguish between closed-world and open-world GPAIS, characterising their degree of autonomy and ability based on several factors such as adaptation to new tasks, competence in domains not intentionally trained for, ability to learn from few data, or proactive acknowledgement of their own limitations. We then propose a taxonomy of approaches to realise GPAIS, describing research trends such as the use of AI techniques to improve another AI (commonly referred to as AI-powered AI) or (single) foundation models. As a prime example, we delve into generative AI (GenAI), aligning them with the terms and concepts presented in the taxonomy. Similarly, we explore the challenges and prospects of multi-modality, which involves fusing various types of data sources to expand the capabilities of GPAIS. Through the proposed definition and taxonomy, our aim is to facilitate research collaboration across different areas that are tackling general purpose tasks, as they share many common aspects. Finally, with the goal of providing a holistic view of GPAIS, we discuss the current state of GPAIS, its prospects, implications for our society, and the need for regulation and governance of GPAIS to ensure their responsible and trustworthy development.
ER  - 

TY  - JOUR
T1  - From the past to the present: A social bot detection method based on spatio-temporal interactive perception
AU  - Liu, Feng
AU  - Ma, Rui
JO  - Knowledge-Based Systems
VL  - 322
SP  - 113712
PY  - 2025
DA  - 2025/07/08/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2025.113712
UR  - https://www.sciencedirect.com/science/article/pii/S0950705125007580
KW  - Social bot detection
KW  - Hypergraph neural network
KW  - Spatio-temporal hypergraph
KW  - Cybersecurity
KW  - Social network analysis and mining
AB  - Detecting social bots is crucial in curbing the widespread dissemination of low-quality information. Previous detection methods have primarily modeled interactions between pairs of accounts, overlooking the influence of group interactions. Moreover, traditional methods have often neglected the temporal dimension in social bot detection. This paper proposes BotSTIP, a social bot detection method from the perspective of spatio-temporal interactions within groups of social accounts. Specifically, BotSTIP begins by capturing each account’s earliest and latest activity time, i.e., the account creation and the data acquisition time, on social media and dividing these into fixed time intervals. Within each interval, it constructs a regular graph based on the follower and following relationships among accounts. Then, a community detection algorithm is applied to each time interval to divide the accounts into communities, forming a hypergraph. A hypergraph neural network (HyperGNN) is subsequently used to extract spatial interaction features for each node, while a Transformer is employed to encode the node sequence based on these spatial interaction features, extracting temporal features. These spatio-temporal interaction feature vectors are then used to detect social bots. Extensive experiments on public datasets validate BotSTIP’s performance. The code is available at https://github.com/FengLiuii/BotSTIP.
ER  - 

TY  - JOUR
T1  - HHBT: DNS tunneling detection via hybrid hierarchical bidirectional transformer
AU  - Kuang, Shilei
AU  - Wang, Weiping
AU  - Ye, Yongfei
AU  - Peng, Lingzhi
JO  - Computer Networks
VL  - 275
SP  - 111919
PY  - 2026
DA  - 2026/02/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2025.111919
UR  - https://www.sciencedirect.com/science/article/pii/S1389128625008850
KW  - DNS tunneling detection
KW  - Bidirectional transformer
KW  - Word tokenizer
KW  - Mixture-of-experts
AB  - Domain Name System (DNS) tunneling has emerged as a covert technique frequently exploited by attackers to bypass security systems and exfiltrate data. Traditional detection approaches often rely on manual feature engineering and statistical heuristics, which struggle to capture the complex and hierarchical patterns inherent in DNS query names. To address these limitations, we propose a Hybrid Hierarchical Bidirectional Transformer (HHBT) model for DNS tunneling detection, which incorporates tokenized word-level representations and statistical features to fully capture the semantic and structural characteristics of domain names. The HHBT model leverages a two-stage transformer architecture to sequentially extract features from second-level and top-level domains (2LD.TLD) and their associated subdomains. To further enhance detection accuracy, the Statistical Feature Gated Mixture-of-Experts (SFG-MoE) is proposed to enable adaptive expert activation based on entropy, length, and other statistical properties. In addition, an Adaptive Feature Fusion Module (AFFM) is proposed to perform feature interaction along both channel-wise and feature-wise dimensions with learned attention weights. Extensive experiments are conducted on a large-scale DNS tunneling dataset. The results demonstrate that HHBT significantly outperforms existing models. Moreover, we analyze the impact of different tokenizers, such as Bidirectional Encoder Representations from Transformers (BERT), GPT-2, and T5, on detection performance. The proposed framework of this paper provides a robust and scalable solution for DNS tunneling detection.
ER  - 

TY  - JOUR
T1  - The DevSafeOps dilemma: A systematic literature review on rapidity in safe autonomous driving development and operation
AU  - Nouri, Ali
AU  - Cabrero-Daniel, Beatriz
AU  - Törner, Fredrik
AU  - Berger, Christian
JO  - Journal of Systems and Software
VL  - 230
SP  - 112555
PY  - 2025
DA  - 2025/12/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2025.112555
UR  - https://www.sciencedirect.com/science/article/pii/S0164121225002249
KW  - Continuous development
KW  - Safety-related function
KW  - Autonomous driving
KW  - Safety of the intended function (SOTIF)
KW  - DevOps
KW  - DevSafeOps
AB  - Developing autonomous driving (AD) systems is challenging due to the complexity of the systems and the need to assure their safe and reliable operation. The widely adopted approach of DevOps seems promising to support the continuous technological progress in AI and the demand for fast reaction to incidents, which necessitate continuous development, deployment, and monitoring. We present a systematic literature review meant to identify, analyse, and synthesise a broad range of existing literature related to usage of DevOps in autonomous driving development. Our results provide a structured overview of challenges and solutions, arising from applying DevOps to safety-related AI-enabled functions. Our results indicate that there are still several open topics to be addressed to enable safe DevOps for the development of safe AD.
ER  - 

TY  - JOUR
T1  - CoST: Comprehensive structural and temporal learning of social propagation for fake news detection
AU  - Guo, Zechen
AU  - Wu, Peng
AU  - Liu, Xiaoliang
AU  - Pan, Li
JO  - Neurocomputing
VL  - 648
SP  - 130618
PY  - 2025
DA  - 2025/10/01/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2025.130618
UR  - https://www.sciencedirect.com/science/article/pii/S0925231225012901
KW  - Fake news detection
KW  - Social propagation
KW  - Temporal learning
AB  - The widespread dissemination of fake news on social media platforms presents significant threats to individual privacy and societal stability. Traditional content-based fake news detection methods are vulnerable to sophisticated adversarial manipulations, while existing propagation-based approaches often fail to fully capture the complex structural and temporal dynamics of news diffusion. To address these limitations, this paper proposes CoST, a Comprehensive Structural and Temporal learning of social propagation for fake news detection that jointly models propagation structural patterns and multi-grained temporal dynamics. Specifically, for structural patterns, as the existing Graph Convolution Networks (GCN) based methods are inadequate to embed news’ propagation graphs that typically have hub structures and deep propagation paths, we propose a bi-directional Graph Attention LSTM module to capture the social hub and deep propagation patterns of news’ propagation graphs. Besides structural patterns, news propagation may also have complicated and diverse temporal patterns. To model the multi-grained temporal dynamics of propagation, we adopt a temporal-aware attention mechanism and a Transformer encoder-based self-attention mechanism to learn the local temporal interval and global propagation sequence features, respectively. Experimental results on several real-world datasets demonstrate the superiority of CoST over various state-of-the-arts, especially in the early detection of fake news.
ER  - 

TY  - JOUR
T1  - Explainable malware detection through integrated graph reduction and learning techniques
AU  - Mohammadian, Hesamodin
AU  - Higgins, Griffin
AU  - Ansong, Samuel
AU  - Razavi-Far, Roozbeh
AU  - Ghorbani, Ali A.
JO  - Big Data Research
VL  - 41
SP  - 100555
PY  - 2025
DA  - 2025/08/28/
SN  - 2214-5796
DO  - https://doi.org/10.1016/j.bdr.2025.100555
UR  - https://www.sciencedirect.com/science/article/pii/S2214579625000504
KW  - Malware detection
KW  - Control flow graph
KW  - Graph embedding
KW  - Graph reduction
KW  - Graph neural network
KW  - Explainability
AB  - Recently, Control Flow Graphs and Function Call Graphs have gain attention in malware detection task due to their ability in representation the complex structural and functional behavior of programs. To better utilize these representations in malware detection and improve the detection performance, they have been paired with Graph Neural Networks (GNNs). However, the sheer size and complexity of these graph representation poses a significant challenge for researchers. At the same time, a simple binary classification provided by the GNN models is insufficient for malware analysts. To address these challenges, this paper integrates novel graph reduction techniques and GNN explainability in to a malware detection framework to enhance both efficiency and interpretability. Through our extensive evolution, we demonstrate that the proposed graph reduction technique significantly reduces the size and complexity of the input graphs, while maintaining the detection performance. Furthermore, the extracted important subgraphs using the GNNExplainer, provide better insights about the model's decision and help security experts with their further analysis.
ER  - 

TY  - JOUR
T1  - Detection of malicious URLs using Temporal Convolutional Network and Multi-Head Self-Attention mechanism
AU  - Do, Nguyet Quang
AU  - Selamat, Ali
AU  - Krejcar, Ondrej
AU  - Fujita, Hamido
JO  - Applied Soft Computing
VL  - 169
SP  - 112540
PY  - 2025
DA  - 2025/01/01/
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2024.112540
UR  - https://www.sciencedirect.com/science/article/pii/S1568494624013140
KW  - Phishing detection
KW  - Malicious URL
KW  - Natural language processing
KW  - Deep learning
KW  - Temporal convolutional network
KW  - Attention mechanism
AB  - Natural Language Processing (NLP) and Deep Learning (DL) have achieved remarkable results in various fields and have also been proven to be effective in detecting phishing webpages. Inspired by the great success of NLP and DL models in phishing detection-related tasks, we examined the application of these techniques in classifying malicious and benign URLs (Uniform Resource Locator). We found that the existing NLP-based solutions mainly used Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) for phishing URL detection. However, CNN performs poorly when handling non-spatial data, while RNN cannot capture the long-distance dependency and has higher computational complexity. To overcome these issues, this paper proposes a phishing detection model based on Temporal Convolutional Network (TCN) to address the limitations of the conventional CNN and/or RNN algorithms. The proposed model used character-level and word-level embedding methods to obtain the feature representations of the input URLs. Then, TCN was employed for feature extraction and further enhanced with Multi-Head Self-Attention (MHSA) mechanism to classify legitimate and phishing websites. We conducted several experiments to validate the performance of the proposed model and measured various evaluation metrics. The obtained results showed that our solution performed better than other baseline models in classifying malicious URLs, achieving an accuracy of 98.78%. This implied the proposed approach provided an effective and efficient solution for detecting phishing URLs.
ER  - 

TY  - JOUR
T1  - Advancements on IoT and AI applied to Pneumology
AU  - Cambiaso, Enrico
AU  - Narteni, Sara
AU  - Baiardini, Ilaria
AU  - Braido, Fulvio
AU  - Paglialonga, Alessia
AU  - Mongelli, Maurizio
JO  - Microprocessors and Microsystems
VL  - 108
SP  - 105062
PY  - 2024
DA  - 2024/07/01/
SN  - 0141-9331
DO  - https://doi.org/10.1016/j.micpro.2024.105062
UR  - https://www.sciencedirect.com/science/article/pii/S0141933124000577
KW  - Internet of Things
KW  - Healthcare
KW  - Machine learning
KW  - Intelligible analytics
KW  - Statistical validation
KW  - Cyber-security
AB  - The objective of this work is the design of a technological platform for remote monitoring of patients with Chronic Obstructive Pulmonary Disease (COPD). The concept of the framework is a breakthrough in the state of medical, scientific and technological art, aimed at engaging patients in the treatment plan and supporting interaction with healthcare professionals. The proposed platform is able to support a new paradigm for the management of patients with COPD, by integrating clinical data and parameters monitored in daily life using Artificial Intelligence algorithms. Therefore, the doctor is provided with a dynamic picture of the disease and its impact on lifestyle and vice versa, and can thus plan more personalized diagnostics, therapeutics, and social interventions. This strategy allows for a more effective organization of access to outpatient care and therefore a reduction of emergencies and hospitalizations because exacerbations of the disease can be better prevented and monitored. Hence, it can result in improvements in patients’ quality of life and lower costs for the healthcare system.
ER  - 

TY  - JOUR
T1  - How could Generative AI support and add value to non-technology companies – A qualitative study
AU  - Modgil, Sachin
AU  - Gupta, Shivam
AU  - Kar, Arpan Kumar
AU  - Tuunanen, Tuure
JO  - Technovation
VL  - 139
SP  - 103124
PY  - 2025
DA  - 2025/01/01/
SN  - 0166-4972
DO  - https://doi.org/10.1016/j.technovation.2024.103124
UR  - https://www.sciencedirect.com/science/article/pii/S0166497224001743
KW  - Qualitative study
KW  - Generative artificial intelligence
KW  - Business value
KW  - Business model
KW  - Technology appropriation
AB  - With the spread of generative AI, non-technology companies are also adopting it at a faster rate. Therefore, this study aims to study the appropriation of Generative AI to create value to non-technology businesses through a knowledge based view of the firm. To achieve this objective, we followed a semi-structured interview schedule, where 98 qualitative data points were collected and analysed. We follow open, axial and selective coding along with Gioia methodology for analysis. Findings indicate that companies employ Generative AI for risk management, where potential threats, impact of possible hazards and degree of uncertainty in the business environment are considered in decision-making. Generative AI also helps in knowledge integration, where assimilation, adaptation, application and implementation are achieved. Findings also suggest that an improved business outlook can be achieved regarding accurate demand forecasting, real-time insights, contextual understanding and alignment to the vision through Generative AI. It is also observed that companies are investing in Generative AI to achieve competitive advantage and greater significance. The contribution of this study lies in the development of four propositions and a framework for generative AI-driven value for non-technology companies. The framework also uncovers the internal flow among key elements from risk identification to integration to developing the outlook and driving utility.
ER  - 

TY  - JOUR
T1  - Syntax-Aware Hierarchical Attention Networks for Code Vulnerability Detection
AU  - Jiang, Yongbo
AU  - Huang, Shengnan
AU  - Feng, Tao
AU  - Duan, Baofeng
JO  - Computers, Materials and Continua
VL  - 86
IS  - 1
SP  - 1
EP  - 22
PY  - 2025
DA  - 2025/11/10/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2025.069423
UR  - https://www.sciencedirect.com/science/article/pii/S1546221825010884
KW  - Vulnerability detection
KW  - abstract syntax tree
KW  - syntax rule slicing
KW  - hierarchical attention mechanism
KW  - deep learning
AB  - In the context of modern software development characterized by increasing complexity and compressed development cycles, traditional static vulnerability detection methods face prominent challenges including high false positive rates and missed detections of complex logic due to their over-reliance on rule templates. This paper proposes a Syntax-Aware Hierarchical Attention Network (SAHAN) model, which achieves high-precision vulnerability detection through grammar-rule-driven multi-granularity code slicing and hierarchical semantic fusion mechanisms. The SAHAN model first generates Syntax Independent Units (SIUs), which slices the code based on Abstract Syntax Tree (AST) and predefined grammar rules, retaining vulnerability-sensitive contexts. Following this, through a hierarchical attention mechanism, the local syntax-aware layer encodes fine-grained patterns within SIUs, while the global semantic correlation layer captures vulnerability chains across SIUs, achieving synergistic modeling of syntax and semantics. Experiments show that on benchmark datasets like QEMU, SAHAN significantly improves detection performance by 4.8% to 13.1% on average compared to baseline models such as Devign and VulDeePecker.
ER  - 

TY  - JOUR
T1  - Federated learning: A cutting-edge survey of the latest advancements and applications
AU  - Akhtarshenas, Azim
AU  - Vahedifar, Mohammad Ali
AU  - Ayoobi, Navid
AU  - Maham, Behrouz
AU  - Alizadeh, Tohid
AU  - Ebrahimi, Sina
AU  - López-Pérez, David
JO  - Computer Communications
VL  - 228
SP  - 107964
PY  - 2024
DA  - 2024/12/01/
SN  - 0140-3664
DO  - https://doi.org/10.1016/j.comcom.2024.107964
UR  - https://www.sciencedirect.com/science/article/pii/S0140366424003116
KW  - Artificial intelligence
KW  - 6G
KW  - Machine learning
KW  - Federated learning
KW  - Deep reinforcement learning
KW  - Neural network
KW  - Internet of things
KW  - Edge computing
KW  - Block-chain
KW  - Privacy preserving
KW  - Resource allocation
AB  - Robust machine learning (ML) models can be developed by leveraging large volumes of data and distributing the computational tasks across numerous devices or servers. Federated learning (FL) is a technique in the realm of ML that facilitates this goal by utilizing cloud infrastructure to enable collaborative model training among a network of decentralized devices. Beyond distributing the computational load, FL targets the resolution of privacy issues and the reduction of communication costs simultaneously. To protect user privacy, FL requires users to send model updates rather than transmitting large quantities of raw and potentially confidential data. Specifically, individuals train ML models locally using their own data and then upload the results in the form of weights and gradients to the cloud for aggregation into the global model. This strategy is also advantageous in environments with limited bandwidth or high communication costs, as it prevents the transmission of large data volumes. With the increasing volume of data and rising privacy concerns, alongside the emergence of large-scale ML models like Large Language Models (LLMs), FL presents itself as a timely and relevant solution. It is therefore essential to review current FL algorithms to guide future research that meets the rapidly evolving ML demands. This survey provides a comprehensive analysis and comparison of the most recent FL algorithms, evaluating them on various fronts including mathematical frameworks, privacy protection, resource allocation, and applications. Beyond summarizing existing FL methods, this survey identifies potential gaps, open areas, and future challenges based on the performance reports and algorithms used in recent studies. This survey enables researchers to readily identify existing limitations in the FL field for further exploration.
ER  - 

TY  - JOUR
T1  - Analysis and Experimental Comparison of State-Of-The-Art Deep-Learning Classification Techniques for Cyberbullying Detection
AU  - Cuzzocrea, Alfredo
AU  - Gallo, Carmine
AU  - Akter, Mst. Shapna
AU  - Shahriar, Hossain
JO  - Procedia Computer Science
VL  - 246
SP  - 3800
EP  - 3809
PY  - 2024
DA  - 2024/01/01/
T2  - 28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.09.153
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924021616
KW  - Cyberbullying Detection
KW  - Intelligent Techniques
KW  - Langauge Transformers
KW  - Neural Networks
KW  - Experimental Analysis
AB  - Cyberbullying is becoming a relevant challenge in next-generation online connected systems, especially in the case of social networks, a relevant innovation of our times. This phenomenon is largely recognized as inducting relevant problems in modern societies, due to the pervasiveness of modern personal devices that originated larger and larger networks. Information and Communication Technologies (ICT) can really help to this end, thanks to the application of well-known models and methods mainly falling in the context of language transformers and neural networks, which both represent state-of-the-art solutions for supporting cyberbullying detection in text (e.g., posts). Inspired by this main research area, in this paper we provide an overview of state-of-the-art approaches for cyberbullying detection along with their experimental comparison against the reference TRAC-2 dataset.
ER  - 

TY  - JOUR
T1  - GraphFVD: Property graph-based fine-grained vulnerability detection
AU  - Shao, Miaomiao
AU  - Ding, Yuxin
AU  - Cao, Jing
AU  - Li, Yilin
JO  - Computers & Security
VL  - 151
SP  - 104350
PY  - 2025
DA  - 2025/04/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104350
UR  - https://www.sciencedirect.com/science/article/pii/S0167404825000392
KW  - Vulnerability detection
KW  - Program slicing
KW  - Deep learning
KW  - Hierarchical attention
KW  - Relational Graph Convolutional Network
AB  - Deep learning technology can automatically extract features from software source code, making it widely used for detecting software vulnerabilities. Most existing deep learning-based approaches rely on whole functions or sequence-level program slices to identify vulnerabilities. However, these approaches often struggle to capture comprehensive vulnerability semantics, leading to high false positive rates and false negative rates. In this paper, we propose GraphFVD, a novel property graph-based fine-grained vulnerability detection approach. Our approach extracts property graph-based slices from the Code Property Graph and introduces a Hierarchical Attention Graph Convolutional Network to learn graph embeddings. GraphFVD provides a fine-grained code representation that captures syntax, control flow, data flow, and the natural sequential order of source code relevant to vulnerabilities. We evaluate the effectiveness of our approach on two real-world vulnerability datasets. Experimental results demonstrate that our approach outperforms existing state-of-the-art vulnerability detection methods on both datasets.
ER  - 

TY  - JOUR
T1  - Digital evolution and twin miracle of sugarcane breeding
AU  - Wang, Xiaoding
AU  - Wu, Qibin
AU  - Zeng, Haitao
AU  - Yang, Xu
AU  - Yang, Xuechao
AU  - Yi, Xun
AU  - Khalil, Ibrahim
AU  - Que, Youxiong
JO  - Field Crops Research
VL  - 318
SP  - 109588
PY  - 2024
DA  - 2024/11/01/
SN  - 0378-4290
DO  - https://doi.org/10.1016/j.fcr.2024.109588
UR  - https://www.sciencedirect.com/science/article/pii/S0378429024003411
KW  - Sugarcane breeding
KW  - Smart breeding
KW  - Artificial intelligence
KW  - Blockchain
KW  - Human-Cyber-Physical System
KW  - Digital twin
AB  - Context
Sugarcane, as an important economic crop, faces challenges such as long breeding cycles, low genetic improvement efficiency, and complex breeding operations.
Method
In order to address these challenges and improve the economic benefits of sugarcane breeding, this paper proposes an innovative smart sugarcane breeding system driven by artificial intelligence (AI), blockchain and digital twin technologies.
Results
The system integrates these technologies within a Human-Cyber-Physical System framework to offer a more efficient, secure, and smart strategy for sugarcane breeding. Firstly, AI processes extensive genetic and phenotypic data to enable precise prediction and optimization of sugarcane traits, resulting in shortened breeding cycles and enhanced efficiency and accuracy in selecting elite sugarcane varieties. Secondly, blockchain technology ensures the security and traceability of breeding data, enhancing the reliability and integrity of the breeding process. Thirdly, digital twin technology enables the real-time circulation of lifelike representations of real-world data among breeding-related workers. The system architecture consists of three layers: a physical layer for data collection, a cyber layer responsible for data analysis, storage and circulation managed by AI, blockchain and digital twin, and a human layer comprised of breeders and stakeholders. This multi-layered approach allows for sophisticated interaction and collaboration between the physical and digital realms, enhancing decision-making and breeding outcomes.
Conclusion
Taken together, the system utilizes AI, blockchain, and digital twin technologies to support sugarcane breeding, offering a promising solution to overcome the limitations of traditional methods and establish a more sustainable and profitable sugarcane breeding system.
ER  - 

TY  - JOUR
T1  - Advanced Genetic Algorithm and Penalty Fitness Function for Enhancing DeFi Security and Detecting Ethereum Fraud Transactions
AU  - Lashkari, Arash Habibi
AU  - Hajihosseinkhani, Sepideh
AU  - Duarte, Joshua
AU  - Lopez, Isabella
AU  - Lashkari, Ziba Habibi
AU  - Rios-Aguilar, Sergio
JO  - Blockchain: Research and Applications
SP  - 100376
PY  - 2025
DA  - 2025/09/03/
SN  - 2096-7209
DO  - https://doi.org/10.1016/j.bcra.2025.100376
UR  - https://www.sciencedirect.com/science/article/pii/S2096720925001034
KW  - Centralized Finance (CeFi)
KW  - Decentralized Finance (DeFi)
KW  - Financial Transactions Security
KW  - DeFi Security
KW  - Blockchain Security
KW  - Genetic Algorithm
KW  - Fraud Transactions
AB  - With the shift from Centralized Finance (CeFi) to Decentralized Finance (DeFi), financial transactions have become trustless and self-executing through blockchain platforms, creating new opportunities while exposing the ecosystem to significant fraud risks. However, due to the lack of centralized oversight and the vulnerabilities in the blockchain platforms, DeFi transactions still face several security challenges, including fraud, identity theft, insider threats, and data breaches. Various methods, including regulatory frameworks, machine learning (ML), and deep learning (DL) techniques, are employed to detect these threats, particularly fraud, in DeFi transactions. Although these approaches help identify fraudulent activities, they face challenges related to accuracy and zero-day attacks due to insufficient data and the complexity of emerging fraud patterns. This study presents a novel approach for detecting and profiling fraud attacks, including zero-day ones in DeFi transactions, thereby eliminating the reliance on wallet transaction history, a limitation that previous research has heavily depended on. The proposed approach leverages two key components: a novel analyzer named DeFiTransLyzer (V1.0) and an Advanced Genetic Algorithm (AGA) for fraud transaction profiling. DeFiTransLyzer extracts 79 features from transaction and wallet data. At the same time, the AGA incorporates advanced techniques, including Penalized Fitness Evaluation, Elite Retention Strategy, Dynamic Mutation Rate, and dynamic generation, to create precise fraud profiles. By focusing solely on transaction features, the model ensures that all fraudulent activities, including zero-day ones, initiated within the first transaction of a new account can be effectively detected, without relying on prior wallet activity. To address the scarcity of comprehensive validation datasets, we introduce BCCC-DeFiFraudTrans-2025, which comprises 1,026,867 annotated Ethereum transaction samples from the DeFi ecosystem. Additionally, the study establishes two taxonomies for systematic classification, covering the literature on fraud detection and profiling methods. Experimental results demonstrate that the proposed method achieves superior accuracy, precision, and efficiency while offering interpretability through its profiling mechanism. These promising outcomes highlight the potential of AGA profiling to enhance the detection and identification of fraudulent activities, including zero-day ones within DeFi transactions, contributing to the security and resilience of blockchain-based financial systems.
ER  - 

TY  - JOUR
T1  - On resource consumption of machine learning in communications network security
AU  - Hoque, Md Muzammal
AU  - Ahmad, Ijaz
AU  - Suomalainen, Jani
AU  - Dini, Paolo
AU  - Tahir, Mohammad
JO  - Computer Networks
VL  - 271
SP  - 111600
PY  - 2025
DA  - 2025/10/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2025.111600
UR  - https://www.sciencedirect.com/science/article/pii/S1389128625005675
KW  - Security
KW  - 6G
KW  - Distributed security
KW  - Network security
KW  - Resource consumption
KW  - Resource efficiency
KW  - Machine learning
KW  - ML
KW  - 6G security
KW  - Sustainability
KW  - DNN
AB  - As the complexity of communication networks continues to increase, driven by a diverse array of devices, services and applications, the adoption of Machine Learning (ML) has seen a significant rise to address various challenges ranging from management to security. Regarding network security, the application of ML ranges from preventive measures to detection and remediation due to its ability to dynamically learn and adapt to evolving threat landscapes. However, ML requires a significant amount of resources, mainly due to the fact that ML operates on data, and the volumes of data are consistently rising. This review article explores the resource consumption aspect of ML techniques used for network security and provides a comprehensive review of the current state of research. Moreover, we propose a taxonomy that can be used to classify the methods through which the resource consumption can be reduced for different ML-based network security implementations. The focus of the study encompasses several key aspects related to resource consumption, including energy, computing, memory, latency, bandwidth, and human resources. These resources are critical in improving the efficiency and optimizing the reliability and sustainability of network security solutions. Furthermore, based on an extensive literature review, we summarize key points regarding optimizing resource consumption in ML-based network security solutions. Finally, the challenges and future research directions for resource-efficient, ML-based network security solutions are outlined to aid in the advancement of research in this area.
ER  - 

TY  - JOUR
T1  - Clean up the mess: Addressing data pollution in cryptocurrency abuse reporting services
AU  - Gomez, Gibran
AU  - van Liebergen, Kevin
AU  - Sanvito, Davide
AU  - Siracusano, Giuseppe
AU  - Gonzalez, Roberto
AU  - Caballero, Juan
JO  - Future Generation Computer Systems
VL  - 179
SP  - 108313
PY  - 2026
DA  - 2026/06/01/
SN  - 0167-739X
DO  - https://doi.org/10.1016/j.future.2025.108313
UR  - https://www.sciencedirect.com/science/article/pii/S0167739X25006077
KW  - Cryptocurrency abuse reporting services
KW  - Bitcoin
KW  - Cryptocurrencies
KW  - LLM-based classification
AB  - Cryptocurrency abuse reporting services are a valuable data source about abusive blockchain addresses, prevalent types of cryptocurrency abuse, and their financial impact on victims. However, they may suffer data pollution due to their crowd-sourced nature. This work analyzes the extent and impact of data pollution in cryptocurrency abuse reporting services and proposes a novel LLM-based defense to address the pollution. We collect 289K abuse reports submitted over 6 years to two popular services and use them to answer three research questions. RQ1 analyzes the extent and impact of pollution. We show that spam reports will eventually flood unchecked abuse reporting services, with BitcoinAbuse receiving 75 % of spam before stopping operations. We build a public dataset of 19,443 abuse reports labeled with 19 popular abuse types and use it to reveal the inaccuracy of user-reported abuse types. We identified 91 (0.1 %) benign addresses reported, responsible for 60 % of all the received funds. RQ2 examines whether we can automate identifying valid reports and their classification into abuse types. We propose an unsupervised LLM-based classifier that achieves an F1 score of 0.95 when classifying reports, an F1 of 0.89 when classifying out-of-distribution data, and an F1 of 0.99 when identifying spam reports. Our unsupervised LLM-based classifier clearly outperforms two baselines: a supervised classifier and a naive usage of the LLM. Finally, RQ3 demonstrates the usefulness of our LLM-based classifier for quantifying the financial impact of different cryptocurrency abuse types. We show that victim-reported losses heavily underestimate cybercriminal revenue by estimating a 29 times higher revenue from deposit transactions. We identified that investment scams have the highest financial impact and that extortions have lower conversion rates but compensate for them with massive email campaigns.
ER  - 

TY  - JOUR
T1  - Understanding practitioners’ challenges and requirements in the design, implementation, and evaluation of anti-phishing interventions
AU  - Sarker, Orvila
AU  - Jayatilaka, Asangi
AU  - Haggag, Sherif
AU  - Liu, Chelsea
AU  - Babar, M. Ali
JO  - Journal of Systems and Software
VL  - 225
SP  - 112356
PY  - 2025
DA  - 2025/07/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2025.112356
UR  - https://www.sciencedirect.com/science/article/pii/S016412122500024X
KW  - Phishing education
KW  - Phishing training
KW  - Phishing awareness
KW  - Guidelines
KW  - Human-centric security
KW  - Usable security
AB  - Background:
Research shows that the ineffectiveness of anti-phishing interventions can result from practitioners’ failure to consider end-users’ requirements in the intervention design, implementation, and evaluation. To assist practitioners in addressing usability issues, we reported 41 guidelines through a systematic Multi-vocal Literature Review (MLR). The usefulness of these guidelines in real-world scenarios remains uncertain until the involved challenges and requirements to implement them are investigated.
Objective:
(1) To investigate practitioners’ challenges in the design, implementation, and evaluation of phishing interventions in real-world settings; (2) to understand practitioners’ perspectives on our guidelines and how they can be made easily accessible to the practitioners.
Method:
We interviewed 18 practitioners (intervention designers, security practitioners, and C-suite employees) from 18 organizations in 6 countries.
Results:
(1) We identify 8 challenges in training content design, anti-phishing datasets, post-training knowledge assessment, and so on. We compare these challenges with the challenges identified from our MLR to demonstrate the ecological validity of the challenges found in MLR and derive a set of insights to overcome them; (2) we report practitioners’ feedback on our guidelines; (3) we gather actionable features on an envisioned tool to make these guidelines easily accessible. Conclusion: We provide 15 recommendations to improve the anti-phishing defense in the organisations.
ER  - 

TY  - JOUR
T1  - Armed boundary sabotage: A case study of human malicious behaviors identification with computer vision and explainable reasoning methods
AU  - Li, Zhan
AU  - Song, Xingyu
AU  - Chen, Shi
AU  - Demachi, Kazuyuki
JO  - Computers and Electrical Engineering
VL  - 121
SP  - 109924
PY  - 2025
DA  - 2025/01/01/
SN  - 0045-7906
DO  - https://doi.org/10.1016/j.compeleceng.2024.109924
UR  - https://www.sciencedirect.com/science/article/pii/S0045790624008504
KW  - Human malicious behaviors identification
KW  - Armed boundary sabotage
KW  - Computer vision
KW  - Human-object interaction analysis
KW  - Data-based reasoning method
KW  - Language-based reasoning method
AB  - Nowadays, the technologies in computer vision (CV) are labor-saving and convenient to identify human malicious behaviors. However, they usually fail to consider the robustness, generalization and interpretability of calculation frameworks. In this paper, a very common but sometimes difficult-to-detect case research called armed boundary sabotage is conducted, which is achieved by computer vision module (CVM) and reasoning module (RM). Among them, CVM is used for extracting the key information from raw videos, while RM is applied to obtain the final reasoning results. Considering the transient and confusing properties in such scenarios, a specific human-object interaction analysis process with soft constraint is proposed in CVM. In addition, two reasoning methods which are data-based reasoning method and language-based reasoning methods are implemented in RM. The results show that the human-object interaction analysis process with soft constraint prove to be effective and practical, while the optimal testing accuracy achieves 0.7871. Furthermore, the two proposed reasoning methods are promising for identification of human malicious behaviors. Among them, the advanced language-based reasoning method outperforms others, with highest precision value of 0.8750 and perfect recall value of 1.0000. Besides, these proposals are also verified to be high-performance in other external intrusion scenarios of our previous work. Finally, our research also obtain state-of-the-art results by comparing with other related works.
ER  - 

TY  - JOUR
T1  - The Use of Artificial Intelligence (AI) in the Flight Deck: Enhancing Human-AI Teamwork in Aviation
AU  - Korentsides, Jenna
AU  - Merwin, Elizabeth R.
AU  - Berger, Lila
AU  - Laskey, Lana
AU  - Winter, Scott R.
AU  - Sobel, Briana
AU  - Keebler, Joseph R.
JO  - Journal of the Air Transport Research Society
SP  - 100099
PY  - 2025
DA  - 2025/12/22/
SN  - 2941-198X
DO  - https://doi.org/10.1016/j.jatrs.2025.100099
UR  - https://www.sciencedirect.com/science/article/pii/S2941198X25000430
KW  - Artificial Intelligence
KW  - Teamwork
KW  - Flight Deck
KW  - Human-AI collaboration
KW  - Human-AI interaction
KW  - Decision Support Systems
AB  - Artificial intelligence (AI) is becoming increasingly integrated into aviation, transforming numerous operations, including those performed at the flight deck. This paper explores theoretical approaches to optimizing human-AI teamwork in the context of aviation, such as trust and role clarity, to enhance safety and efficiency. It also outlines strategies for effective task allocation in human-AI teams using a previously developed conceptual model. By applying teamwork and cognitive principles, such as situation awareness, it examines the complementary strengths of humans and AI, and addresses how AI can serve both as a tool and as a collaborative teammate in aviation contexts. This paper evaluates human strengths, such as adaptive decision-making and AI capabilities, including real-time data processing, alongside shared limitations like fatigue and inflexibility. It discusses the risks of over-reliance on AI, reduced situational awareness, and cybersecurity threats. Best practices for fostering trust, clear roles, and interdependence are presented, drawing from Crew Resource Management (CRM) principles. This work extends human factors research by applying a novel theoretical framework to human-AI collaboration in aviation. Unlike prior studies focused solely on technological advances, it provides actionable insights for task allocation, risk mitigation, and training, supporting balanced and effective human-AI teams in the flight deck.
ER  - 

TY  - JOUR
T1  - Territorialising the cloud or clouding the territory? Volumetric vulnerabilities and the militarised conjunctures of Singapore’s smart city-state
AU  - Woods, Orlando
AU  - Bunnell, Tim
AU  - Kong, Lily
JO  - Political Geography
VL  - 115
SP  - 103211
PY  - 2024
DA  - 2024/11/01/
SN  - 0962-6298
DO  - https://doi.org/10.1016/j.polgeo.2024.103211
UR  - https://www.sciencedirect.com/science/article/pii/S0962629824001604
KW  - Cloud computing
KW  - Territory
KW  - Data volumes
KW  - Attack surfaces
KW  - Datastructures
KW  - Military
KW  - Singapore
AB  - This article explores how the volumetric characteristics of cloud computing can create new expressions of territoriality, which in turn can reveal new axes of vulnerability and threat. Whilst recent work in political geography has sought to “locate” the cloud through analyses of data centre geographies and data-driven processes of smart urbanism, we look beyond the material plane and consider the amorphous territorialities of voluminous data instead. As much as these data are acted on by the legal-regulatory mechanics of the state in a bid to territorialise them, so too do these data volumes serve to cloud, and thus obscure, territory. Processes of territorialising and clouding exist in a state of dialectical tension with each other, and reveal the volumetric vulnerabilities of cloud computing. We validate these theoretical claims through an analysis of in-depth interviews with senior stakeholders in Singapore's Smart Nation initiative. In Singapore, defending the city is equivalent to defending the nation, which causes the military to play an outsized role in securing the city-state. We consider how the attack surface of the city becomes a more voluminous construct with cloud computing, how strategies of geofencing attempt to secure the cloud, and how these processes reveal the increasingly militarised conjunctures of everyday life. Overall, these insights reveal a need for political geography to continually evolve its theoretical premises in line with the rapid digitalisation of the world.
ER  - 

TY  - JOUR
T1  - VWA-6G AI assisted continuous security monitoring over open RAN service management orchestration
AU  - Tung, Yi-Chih
AU  - Liou, En-Cheng
AU  - Hu, Pen-Chih
AU  - Yu, Cheng-Han
JO  - Computers & Security
VL  - 157
SP  - 104566
PY  - 2025
DA  - 2025/10/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104566
UR  - https://www.sciencedirect.com/science/article/pii/S016740482500255X
KW  - 6G
KW  - O-RAN
KW  - AI
KW  - Continuous security monitoring
KW  - CVE
KW  - CWE
KW  - CAPEC
AB  - The evolution towards sixth generation (6G) mobile networks and Open Radio Access Network (O-RAN) architectures introduces enhanced flexibility and scalability but also significantly broadens the cybersecurity threat landscape. Integration of open-source software components and third-party applications (xApps) exacerbates security vulnerabilities, challenging conventional protection mechanisms. To address these issues, this study proposes the Vulnerability Weakness Attack for 6G (VWA-6G) system, an artificial intelligence (AI) assisted framework for continuous security monitoring. This framework utilizes a contextually fine-tuned BERT-based model. The VWA-6G AI model automates semantic mapping from Common Vulnerabilities and Exposures (CVEs) to Common Weakness Enumerations (CWEs) and Common Attack Pattern Enumerations and Classifications (CAPECs), leveraging specialized datasets derived from forward-looking 6G technical materials. Empirical results demonstrate that the proposed model achieves superior performance metrics compared to baseline methods, notably an accuracy of 98.62 % and an F1-Score of 99.44 %, representing significant improvements over standard BERT and V2W-BERT approaches. This AI driven semantic approach substantially enhances vulnerability identification and mapping accuracy, thereby providing robust, automated, and proactive security management aligned with Zero Trust principles in 6G O-RAN environments.
ER  - 

TY  - JOUR
T1  - An efficient framework for semantically-correlated term detection and sanitization in clinical documents
AU  - Moqurrab, Syed Atif
AU  - Anjum, Adeel
AU  - Tariq, Noshina
AU  - Srivastava, Gautam
JO  - Computers and Electrical Engineering
VL  - 100
SP  - 107985
PY  - 2022
DA  - 2022/05/01/
SN  - 0045-7906
DO  - https://doi.org/10.1016/j.compeleceng.2022.107985
UR  - https://www.sciencedirect.com/science/article/pii/S0045790622002543
KW  - Machine learning
KW  - Data privacy
KW  - Unsupervised learning
KW  - Semantically-correlated terms
KW  - Detection
KW  - Sanitization
KW  - Utility-preservation
KW  - Clinical documents
KW  - Clinical data privacy
KW  - Word embedding
AB  - In clinical documents, privacy and confidentiality protection are the two main challenges before sharing or publishing data. According to the Health Insurance Portability and Accountability Act (HIPAA) and the General Data Protection Regulation (GDPR), even a few terms can cause privacy threats. In retrospect, confidentiality threats are not fully explored due to the complex nature as well as massive number of clinical terms and phrases. Current approaches use information theoretic-based techniques to detect and sanitize risky semantically-correlated terms. However, they have language ambiguity and non-monotonic behavior, coupled with the fact that pre-trained classifiers and human-tagging are required to construct classifiers. This paper offers a generic and adaptable method for protecting risky terms in clinical data using word embedding (Word2Vec and BERT) for risky term detection and comparative analysis. Our methodology uses WordNet taxonomy to minimize a document’s semantic and utility loss by substituting privacy-preserving generalization for disclosive words and by eliminating manual data tagging. The results show significant protection and utility-preservation, compared to information-theoretic approaches.
ER  - 

TY  - JOUR
T1  - VulTriNet: A software vulnerability detection method based on tri-channel network
AU  - Yang, Yiyao
AU  - Yao, Youjian
AU  - Lv, Xiao
AU  - Chen, Wen
JO  - Information and Software Technology
VL  - 188
SP  - 107893
PY  - 2025
DA  - 2025/12/01/
SN  - 0950-5849
DO  - https://doi.org/10.1016/j.infsof.2025.107893
UR  - https://www.sciencedirect.com/science/article/pii/S0950584925002320
KW  - Vulnerability detection
KW  - Software security
KW  - Code representation
KW  - Deep learning
KW  - RGB image
AB  - Context:
Software vulnerabilities represent a critical concern in cybersecurity. As vulnerability patterns become increasingly complex, advanced detection methods are needed to fully analyze them. Recent studies have treated source codes as text using natural language processing (NLP) techniques. Subsequent advancements transformed programs into intermediate representations, utilizing graph neural network (GNN) for vulnerability learning. However, these approaches exhibit limitations in software vulnerability detection, as they fail to comprehensively analyze the features of source code.
Objective:
To solve this problem, we proposed a novel vulnerability detection method based on a tri-channel network (VulTriNet), which enables comprehensive analysis of source code and effective vulnerability detection.
Methods:
The Method integrates two graph-based and one textual code representation using three distinct methods to transform functions into multiple forms. Then, inspired by the RGB three-channel concept in the image domain, VulTriNet generates corresponding embedding vectors for these transformed representations, which are subsequently merged into a unified three-channel feature matrix. Finally, there is a CNN model integrated with attention mechanisms to improve the capability of detecting vulnerabilities.
Results:
Experimental results demonstrated that, compared to five state-of-the-art approaches, VulTriNet achieves, on average across different datasets: a 4.89% improvement in accuracy, a 3.41% increase in TNR, a 4.09% gain in TPR, and a 4.18% boost in F1-score.
Conclusion:
These results indicate that VulTriNet is more accurate and effective than previous studies. This hybrid analysis model strengthens vulnerability detection capabilities by simultaneously preserving contextual understanding of code and awareness of its structural relationships.
ER  - 

TY  - JOUR
T1  - Spam detection for Youtube video comments using machine learning approaches
AU  - Xiao, Andrew S.
AU  - Liang, Qilian
JO  - Machine Learning with Applications
VL  - 16
SP  - 100550
PY  - 2024
DA  - 2024/06/01/
SN  - 2666-8270
DO  - https://doi.org/10.1016/j.mlwa.2024.100550
UR  - https://www.sciencedirect.com/science/article/pii/S2666827024000264
KW  - Machine learning
KW  - Spam detection
KW  - Random forest
KW  - Naive Bayes
KW  - Logistic regression
KW  - Multi-layer perceptron
KW  - Voting classifier
AB  - Machine Learning models have the ability to streamline the process by which Youtube video comments are filtered between legitimate comments (ham) and spam. In order to integrate machine learning models into regular usage on media-sharing platforms, recent approaches have aimed to develop models trained on Youtube comments, which have emerged as valuable tools for the classification and have enabled the identification of spam content and enhancing user experience. In this paper, eight machine learning approaches are applied to spam detection for YouTube comments. The eight machine learning models include Gaussian Naive Bayes, logistic regression, K-nearest neighbors (KNN) classifier, multi-layer perceptron (MLP), support vector machine (SVM) classifier, random forest classifier, decision tree classifier, and voting classifier. All eight models perform very well, specifically random forest approach can achieve almost perfect performance with average precision of 100% and AUC-ROC of 0.9841. The computational complexity of the eight machine learning approaches are compared.
ER  - 

TY  - JOUR
T1  - A software vulnerability detection method based on multi-modality with unified processing
AU  - Cai, Wenjing
AU  - Chen, Junlin
AU  - Yu, Jiaping
AU  - Hu, Wei
AU  - Gao, Lipeng
JO  - Information and Software Technology
VL  - 182
SP  - 107703
PY  - 2025
DA  - 2025/06/01/
SN  - 0950-5849
DO  - https://doi.org/10.1016/j.infsof.2025.107703
UR  - https://www.sciencedirect.com/science/article/pii/S0950584925000424
KW  - Vulnerability detection
KW  - Code representation
KW  - Multimodality
KW  - Transformer
AB  - With the development of the Internet and the Internet of Things, software has become an indispensable part, making software vulnerabilities one of the main threats to computer security. In recent years, a multitude of deep learning-based software vulnerability detection methods have been proposed, especially those based on multimodal approaches. Although these multimodal methods have proven to be effective, they often treat each modality separately. We propose a novel multimodal deep learning method for software vulnerability detection that achieves unified processing of various modalities. This method uses complex network analysis to convert the Code Property Graph into an image-like matrix, obtains key fragments from the source code using code slicing, and then uses a Transformer for function-level vulnerability detection. This enables deeper integration of information from multiple modalities, enhancing detection accuracy. Additionally, it significantly simplifies the model architecture. The result shows that compared to the state-of-the-art methods, our method has improved accuracy by 3%. Furthermore, our approach is capable of detecting some of the vulnerabilities recently released by CVE.
ER  - 

TY  - JOUR
T1  - MPDroid: A multimodal pre-training Android malware detection method with static and dynamic features
AU  - Zhang, Sanfeng
AU  - Su, Heng
AU  - Liu, Hongxian
AU  - Yang, Wang
JO  - Computers & Security
VL  - 150
SP  - 104262
PY  - 2025
DA  - 2025/03/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104262
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824005686
KW  - Android malware
KW  - Hybrid detection
KW  - Multimodal
KW  - Pre-training
KW  - Unimodal bias
AB  - The widespread deployment and open nature of the Android system have led to a rapid increase in Android malware, presenting significant challenges to mobile device security. Both static and dynamic analysis methods exhibit inherent limitations while hybrid detection approaches that combine static and dynamic features struggle with efficiency. To address these issues, this paper proposes MPDroid, a multimodal pre-training enabled detection approach. MPDroid effectively learns the critical characteristics of malicious behavior during the pre-training phase and achieves efficient single-modality detection in the downstream tasks. MPDroid utilizes an API call graph to represent dynamic features and a function call graph for static features. During pre-training, MPDroid employs graph convolutional networks and multimodal fusion techniques to capture the relationships between static and dynamic features. We also address the unimodal bias problem in multimodal tasks through modality alignment and model-level fusion. Furthermore, MPDroid significantly reduces the training and inferencing time for downstream tasks by implementing a multimodal pre-training framework with static features-based downstream tasks, thereby enhancing detection efficiency. Experimental results demonstrate that MPDroid achieves an average accuracy of 98.3% and an F1-score of 97.6%, with less than 7.39 s of detection duration, indicating superior overall performance compared to existing detection methods.
ER  - 

TY  - JOUR
T1  - Exploring transferable adversarial attacks for Deep Learning-based Network Intrusion Detection
AU  - Mao, Zhongshu
AU  - Lu, Yiqin
AU  - Cheng, Zhe
AU  - Chen, Kaiqiong
JO  - Journal of Network and Computer Applications
VL  - 242
SP  - 104255
PY  - 2025
DA  - 2025/10/01/
SN  - 1084-8045
DO  - https://doi.org/10.1016/j.jnca.2025.104255
UR  - https://www.sciencedirect.com/science/article/pii/S1084804525001523
KW  - NIDS
KW  - Deep learning
KW  - Adversarial attack
KW  - Transferability
AB  - Network Intrusion Detection Systems (NIDSs) increasingly use Deep Learning (DL) techniques due to their superior performance. However, some studies have shown that attackers can bypass DL-based NIDSs by generating Adversarial Attack Traffic (AAT). To better understand the vulnerabilities of DL-based NIDS, more and more adversarial attacks have been proposed. We observed three problems while studying these attacks: (1) Some attacks need to query the target model to construct AAT or surrogate models, which is not stealthy enough; (2) The generated AAT is impractical due to the lack of constraints when modifying features; and (3) The attack methods are limited in their extensibility. We propose a framework called SPTS to address these problems. SPTS runs in the black-box scenario without access to the target model. To generate the practical AAT, SPTS incorporates feature hierarchization and rectification. The correlations and constraints between features are established by mathematics. In addition, we implement a variety of adversarial attack algorithms within the SPTS framework, illustrating its excellent scalability. The AAT is mapped to practical packets to evaluate its transferability. Furthermore, we discover that enhancing the diversity of gradients can further improve the transferability of AAT. We propose a DGM algorithm based on SPTS, which randomly transforms the inputs to produce more robust gradients. Empirical evaluations on the standard dataset demonstrate the effectiveness and superiority of our SPTS and DGM. Defense methods to mitigate SPTS and DGM are also provided, and their advantages and disadvantages are described based on experimental results. Code is available at https://github.com/maozhongshu1995/TransAdvAttForNIDS.
ER  - 

TY  - JOUR
T1  - Defining and generating operation and maintenance management requirements in digital twin applications using the DT-GPT framework
AU  - Bao, Sheng
AU  - Bu, Hangdong
JO  - Journal of Building Engineering
VL  - 104
SP  - 112356
PY  - 2025
DA  - 2025/06/15/
SN  - 2352-7102
DO  - https://doi.org/10.1016/j.jobe.2025.112356
UR  - https://www.sciencedirect.com/science/article/pii/S2352710225005935
KW  - Digital twin
KW  - Operation and maintenance
KW  - Generative pre-trained transformer
KW  - Virtual assistant
KW  - Large language model
AB  - Implementing Digital Twin (DT) technology in Operation and Maintenance (O&M) heavily relies on the continuous availability of information regarding asset conditions and performances. Therefore, this study aims to establish comprehensive guidelines for defining information requirements for various O&M tasks during the design phase. To achieve this objective, data collection, interviews, and investigations were conducted to develop an O&M requirements system, including model requirements, function requirements, and nongeometric data requirements. The importance and attributes of requirement factors were analyzed through the Kano-QFD model. Based on the O&M requirements system, a virtual assistant framework named “DT-GPT” that utilizes the Generative Pre-trained Transformer (GPT) was developed to assist owners in creating guidelines according to their requirements. Evaluations and a case study were introduced to validate the potential of DT-GPT. Results illustrated that DT-GPT had a mean semantic similarity of 87.28 % in generating function lists, a mean accuracy of 92.76 % in extracting components from design drawings, and a mean semantic similarity of 96.34 % in generating nongeometric data lists. The case study further demonstrated the effectiveness of the proposed framework in assisting owners with the creation of O&M guidelines. This study provides valuable insights for identifying O&M management requirements and advancing the practical application of DT in O&M processes.
ER  - 

TY  - JOUR
T1  - Harnessing attention for cropping and fusion in CLIP-based AIGC detection
AU  - Xu, Jiaqi
AU  - Du, Yanhui
AU  - Lyu, Liangwei
AU  - Yang, Chenrui
JO  - Neurocomputing
VL  - 669
SP  - 132482
PY  - 2026
DA  - 2026/03/07/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2025.132482
UR  - https://www.sciencedirect.com/science/article/pii/S0925231225031546
KW  - Generated image detection
KW  - Attention-guided cropping
KW  - Vision transformer
KW  - CLIP model
AB  - CLIP has been used for AI-generated image detection recently, particularly as it often guides mainstream Text-to-Image (T2I) generators. However, a fundamental mismatch exists in migrating CLIP to the detection task: CLIP is optimized for high-level semantics, while detection requires sensitivity to low-level artifacts. This gap is exacerbated by two practical problems: information loss from conventional preprocessing and suboptimal fine-tuning approaches. We propose a framework that bridges this gap with two key innovations. First, Attention-Guided Saliency Cropping (AGSC) leverages the ViT’s own attention to preserve semantically coherent and artifact-rich image regions. Second, we fine-tune only the FFN layers, a strategy proven to capture universal, high-frequency artifacts while avoiding the overfitting common in attention-tuning. Experiments show our method’s superior generalization, successfully repurposing CLIP into a powerful AIGC detector.
ER  - 

TY  - JOUR
T1  - Automating the correctness assessment of AI-generated code for security contexts
AU  - Cotroneo, Domenico
AU  - Foggia, Alessio
AU  - Improta, Cristina
AU  - Liguori, Pietro
AU  - Natella, Roberto
JO  - Journal of Systems and Software
VL  - 216
SP  - 112113
PY  - 2024
DA  - 2024/10/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2024.112113
UR  - https://www.sciencedirect.com/science/article/pii/S0164121224001584
KW  - Code correctness
KW  - AI code generators
KW  - Assembly
KW  - Offensive security
KW  - Symbolic execution
AB  - Evaluating the correctness of code generated by AI is a challenging open problem. In this paper, we propose a fully automated method, named ACCA, to evaluate the correctness of AI-generated code for security purposes. The method uses symbolic execution to assess whether the AI-generated code behaves as a reference implementation. We use ACCA to assess four state-of-the-art models trained to generate security-oriented assembly code and compare the results of the evaluation with different baseline solutions, including output similarity metrics, widely used in the field, and the well-known ChatGPT, the AI-powered language model developed by OpenAI. Our experiments show that our method outperforms the baseline solutions and assesses the correctness of the AI-generated code similar to the human-based evaluation, which is considered the ground truth for the assessment in the field. Moreover, ACCA has a very strong correlation with the human evaluation (Pearson’s correlation coefficient r=0.84 on average). Finally, since it is a full y automated solution that does not require any human intervention, the proposed method performs the assessment of every code snippet in ∼0.17 s on average, which is definitely lower than the average time required by human analysts to manually inspect the code, based on our experience.
ER  - 

TY  - JOUR
T1  - Deepfake detection in generative AI: A legal framework proposal to protect human rights
AU  - Romero-Moreno, Felipe
JO  - Computer Law & Security Review
VL  - 58
SP  - 106162
PY  - 2025
DA  - 2025/09/01/
SN  - 2212-473X
DO  - https://doi.org/10.1016/j.clsr.2025.106162
UR  - https://www.sciencedirect.com/science/article/pii/S2212473X25000355
KW  - Deepfake detection
KW  - Generative AI
KW  - XAI
KW  - C2PA
KW  - Human rights
AB  - Deepfakes, exploited for financial fraud, political misinformation, non-consensual imagery, and targeted harassment, represent a rapidly evolving threat to global information integrity, demanding immediate and coordinated intervention. This research undertakes technical and comparative legal analyses of deepfake detection methods. It examines key mitigation strategies—including AI-powered detection, provenance tracking, and watermarking—highlighting the pivotal role of the Coalition for Content Provenance and Authenticity (C2PA) in establishing media authentication standards. The study investigates deepfakes' complex intersections with the admissibility of legal evidence, non-discrimination, data protection, freedom of expression, and copyright, questioning whether existing legal frameworks adequately balance advances in detection technologies with the protection of individual rights. As national strategies become increasingly vital amid geopolitical realities and fragmented global governance, the research advocates for a unified international approach grounded in UN Resolution 78/265 on safe, secure, and trustworthy AI. It calls for a collaborative framework that prioritizes interoperable technical standards and harmonized regulations. The paper critiques legal frameworks in the EU, US, UK, and China—jurisdictions selected for their global digital influence and divergent regulatory philosophies—and recommends developing robust, accessible, adaptable, and internationally interoperable tools to address evidentiary reliability, privacy, freedom of expression, copyright, and algorithmic bias. Specifically, it proposes enhanced technical standards; regulatory frameworks that support the adoption of explainable AI (XAI) and C2PA; and strengthened cross-sector collaboration to foster a trustworthy deepfake ecosystem.
ER  - 

TY  - JOUR
T1  - Building a multi-class Short Message Service dataset for smishing detection using agglomerative clustering and dataset fusion
AU  - Martínez-Mendoza, Alicia
AU  - Fidalgo, Eduardo
AU  - Alegre, Enrique
AU  - Fernández-Robles, Laura
JO  - Engineering Applications of Artificial Intelligence
VL  - 163
SP  - 112864
PY  - 2026
DA  - 2026/01/01/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2025.112864
UR  - https://www.sciencedirect.com/science/article/pii/S0952197625028957
KW  - Short text classification
KW  - Smishing
KW  - Agglomerative clustering
KW  - Cybersecurity
KW  - Multiclass smishing
KW  - Phishing short message service
AB  - Smishing is a phishing technique in which a cybercriminal sends an SMS (Short Message Service) to a user impersonating a legitimate organization, aiming to steal personal or financial information. Although binary classification of smishing helps protect the user, a multi-class approach provides additional information, allowing to analyze the type of fraud, detect smishing campaigns or develop specific solutions targeting the riskiest types of smishing. In this paper, we introduce a sMishIng MultIClasS dataset: MIMICS-3500. The dataset was created in four phases: data selection, automatic clustering, inter-annotator agreement, and manual labeling. Firstly, we gathered smishing messages from five sources: Kaggle, Mendeley, SmishTank, SpamHunter, and data provided by the Spanish National Cybersecurity Institute (INCIBE). Secondly, we applied agglomerative clustering to analyze how samples are grouped. This led to the identification of seven classes for a general categorization and thirteen classes for a fine-grained categorization. Then, we performed an inter-annotator agreement assessment of the manual labeling on a subset of the dataset to evaluate the definition of the classes. Finally, we manually labeled the entire dataset for seven and thirteen classes of smishing. We evaluated eleven state-of-the-art classification models on MIMICS-3500, achieving 86.94% and 82.43% F1-score with Robustly Optimized Bidirectional Encoder Representations from Transformers (RoBERTa) for the seven-class and thirteen-class proposals, respectively. This result validates the consistency of the labeling and sets a benchmark for future research on multi-class smishing.
ER  - 

TY  - JOUR
T1  - A meta-survey of adversarial attacks against artificial intelligence algorithms, including diffusion models
AU  - Pawlicki, Marek
AU  - Pawlicka, Aleksandra
AU  - Kozik, Rafał
AU  - Choraś, Michał
JO  - Neurocomputing
VL  - 653
SP  - 131231
PY  - 2025
DA  - 2025/11/07/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2025.131231
UR  - https://www.sciencedirect.com/science/article/pii/S0925231225019034
KW  - Adversarial attacks
KW  - Artificial intelligence
KW  - Deep learning
AB  - Deep neural networks have revolutionized artificial intelligence, solving complex issues in areas like healthcare or law enforcement and security. However, they are susceptible to adversarial attacks where small data manipulations can compromise system reliability and security. This paper conducts an umbrella review of the literature on these attacks, synthesizing results from various systematic reviews to assess attack strategies, defense effectiveness, and research gaps. Guided by the PICO framework, this review categorizes and examines adversarial attacks, identifying key challenges in the field. The review finds that even though adversarial vulnerabilities were first explored in computer vision, analogous threats have expanded to domains like graph neural networks, natural language processing, federated learning, and text-to-image models. Despite varied attack surfaces, commonalities can be found.
ER  - 

TY  - JOUR
T1  - DeVAIC: A tool for security assessment of AI-generated code
AU  - Cotroneo, Domenico
AU  - De Luca, Roberta
AU  - Liguori, Pietro
JO  - Information and Software Technology
VL  - 177
SP  - 107572
PY  - 2025
DA  - 2025/01/01/
SN  - 0950-5849
DO  - https://doi.org/10.1016/j.infsof.2024.107572
UR  - https://www.sciencedirect.com/science/article/pii/S0950584924001770
KW  - Static code analysis
KW  - Vulnerability detection
KW  - AI-code generators
KW  - Python
AB  - Context:
AI code generators are revolutionizing code writing and software development, but their training on large datasets, including potentially untrusted source code, raises security concerns. Furthermore, these generators can produce incomplete code snippets that are challenging to evaluate using current solutions.
Objective:
This research work introduces DeVAIC (Detection of Vulnerabilities in AI-generated Code), a tool to evaluate the security of AI-generated Python code, which overcomes the challenge of examining incomplete code.
Methods:
We followed a methodological approach that involved gathering vulnerable samples, extracting implementation patterns, and creating regular expressions to develop the proposed tool. The implementation of DeVAIC includes a set of detection rules based on regular expressions that cover 35 Common Weakness Enumerations (CWEs) falling under the OWASP Top 10 vulnerability categories.
Results:
We utilized four popular AI models to generate Python code, which we then used as a foundation to evaluate the effectiveness of our tool. DeVAIC demonstrated a statistically significant difference in its ability to detect security vulnerabilities compared to the state-of-the-art solutions, showing an F1 Score and Accuracy of 94% while maintaining a low computational cost of 0.14 s per code snippet, on average.
Conclusions:
The proposed tool provides a lightweight and efficient solution for vulnerability detection even on incomplete code.
ER  - 

TY  - JOUR
T1  - EmoSense: A multimodal sentiment-aware framework for music short video AI-generated content detection
AU  - Li, Jiajia
AU  - Pan, Ziyi
AU  - Xiao, Teng
AU  - Wang, Ping
AU  - Hu, Qibiao
AU  - Hou, Jingrui
JO  - Information Processing & Management
VL  - 63
IS  - 2, Part B
SP  - 104473
PY  - 2026
DA  - 2026/03/01/
SN  - 0306-4573
DO  - https://doi.org/10.1016/j.ipm.2025.104473
UR  - https://www.sciencedirect.com/science/article/pii/S0306457325004145
KW  - Multimodal
KW  - AI-generated content detection
KW  - Sentiment analysis
KW  - Music short video
KW  - Feature fusion
AB  - The rapid spread of AI-generated content (AIGC) music short videos on social media has introduced new challenges for information authenticity and public trust. Although existing studies have explored multimodal detection techniques, they often fail to model the nuanced emotional and semantic interplay between modalities—particularly the alignment between musical affect and visual-textual content. Such limitations significantly hinder detection accuracy in complex, sentiment-rich AIGC scenarios. To address these challenges, we propose EmoSense, a sentiment-aware framework tailored for music short video AIGC detection. EmoSense comprises two key modules: a Sentiment Alignment Module that models emotional-semantic coherence across text, audio, and visuals via cross-modal embedding, and a Trace Analysis Module that detects spatial–temporal inconsistencies characteristic of synthetic content. Additionally, A deep fusion strategy further enhances cross-modal complementarity, improving both robustness and generalization. To support evaluation, we introduce MSV-AIGC, a real-world, human-annotated multimodal dataset containing 2912 labeled samples (1562 authentic and 1350 AI-generated), covering aligned those modalities. Experimental results show that EmoSense outperforms state-of-the-art baseline on this dataset, achieving 2.27% gains in accuracy and surpassing GPT-4V by 10.7%, highlighting its robustness in detecting synthetic music short videos.
ER  - 

TY  - JOUR
T1  - CrossCode2Vec: A unified representation across source and binary functions for code similarity detection
AU  - Yu, Gaoqing
AU  - An, Jing
AU  - Lyu, Jiuyang
AU  - Huang, Wei
AU  - Fan, Wenqing
AU  - Cheng, Yixuan
AU  - Sui, Aina
JO  - Neurocomputing
VL  - 620
SP  - 129238
PY  - 2025
DA  - 2025/03/01/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2024.129238
UR  - https://www.sciencedirect.com/science/article/pii/S0925231224020095
KW  - Code Similarity Detection
KW  - Representation learning
KW  - Cross-modal code matching
AB  - Code similarity detection identifies code by analyzing similarities in syntax, semantics, and structure, which includes types of tasks: source-to-source, binary-to-binary, and source-to-binary. Due to encoding and representation disparities between source and binary code, existing methods have mainly focused on individual tasks, without providing a universal solution. Additionally, current source-to-binary tasks only achieve one-to-one matching between source code and binary functions, neglecting the one-to-many relationship inherent between source code and its cross-compiled binaries. In this paper, we propose CrossCode2Vec, a unified framework for representing code in both source and binary functions, which aims to bridge the gap in original coding features and provide a standardized similarity measurement across three code similarity detection tasks. For source code and its corresponding compiled binary, we first design an enhanced Abstract Path Context data preprocessing method, construct an abstract syntax tree (AST) from both source code functions and decompiled binary functions, and implement the function embedding followed by the pre-trained Word2vec model. Then we propose a task-specific data sampling strategy. We establish a one-to-one correspondence between source and binary functions through symbol tables and create a one-to-many relationship between source functions and their cross-compiled binaries based on sampling rules. Finally, we employ a hierarchical LSTM-attention network to facilitate the representation and similarity measurement of functions. We conduct both extrinsic and intrinsic evaluations to confirm the effectiveness of CrossCode2Vec in code representation and code similarity tasks, validating its superiority in model architecture and data processing methods. CrossCode2Vec demonstrates stable and exceptional performance across multiple experiments, reinforcing its ability to bridge the gap between source and binary code representations while effectively measuring their similarities.
ER  - 

TY  - JOUR
T1  - Apply transfer learning to cybersecurity: Predicting exploitability of vulnerabilities by description
AU  - Yin, Jiao
AU  - Tang, MingJian
AU  - Cao, Jinli
AU  - Wang, Hua
JO  - Knowledge-Based Systems
VL  - 210
SP  - 106529
PY  - 2020
DA  - 2020/12/27/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2020.106529
UR  - https://www.sciencedirect.com/science/article/pii/S0950705120306584
KW  - Transfer learning
KW  - Exploitability prediction
KW  - ExBERT
KW  - Software vulnerability
AB  - Thousands of software vulnerabilities are archived and disclosed to the public each year, posing severe cybersecurity threats to the whole society. Predicting the exploitability of vulnerabilities is crucial for decision-makers to prioritize their efforts and patch the most critical vulnerabilities. Software vulnerability descriptions are accessible features in early stage and contain rich semantic information. Therefore, descriptions are wildly used for exploitability prediction in both industry and academia. However, comparing with other corpora, the size of vulnerability description corpus is too small to train a comprehensive Natural Language Processing (NLP) model. To gain a better performance, this paper proposes a framework named ExBERT to accurately predict if a vulnerability will be exploited or not. ExBERT essentially is an improved Bidirectional Encoder Representations from Transformers (BERT) model for exploitability prediction. First, we fine-tune a pre-trained BERT using collected domain-specific corpus. Then, we design a Pooling Layer and a Classification Layer on top of the fine-tuned BERT model to extract sentence-level semantic features and predict the exploitability of vulnerabilities. Results on 46,176 real-word vulnerabilities have demonstrated that the proposed ExBERT framework achieves 91.12% on accuracy and 91.82% on precision, outperforming the state-of-the-art approach with 89.0% on accuracy and 81.8% on precision.
ER  - 

TY  - JOUR
T1  - P3Fed: A personalized and privacy-preserving federated framework for intrusion detection in computing power network
AU  - Wang, Yan
AU  - Wang, Xingwei
AU  - Yi, Bo
AU  - Huang, Min
AU  - Kou, Yue
JO  - Computer Networks
VL  - 275
SP  - 111886
PY  - 2026
DA  - 2026/02/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2025.111886
UR  - https://www.sciencedirect.com/science/article/pii/S1389128625008527
KW  - Personalized federated learning
KW  - Network attack detection
KW  - Computing power network
KW  - Privacy protection
KW  - Knowledge distillation
AB  - With the widespread deployment of Computing Power Network (CPN) in critical industries, the risk of network intrusion is increasing. Traditional centralized intrusion detection methods face severe challenges in data privacy protection and data heterogeneity. To this end, this paper proposes P3Fed, a personalized and privacy-preserving federated intrusion detection framework, aimed at addressing the intertwined problems of non-independent and identically distributed (Non-IID) data and privacy leakage in CPNs. P3Fed constructs a privacy-enhanced federated learning architecture by adopting a sensitivity-adaptive local differential privacy mechanism, ensuring fine-grained protection of model updates and soft labels without exposing raw data. To further improve detection performance, we employ a hybrid feature extraction model that combines a shared CNN-LSTM-Attention module for capturing global attack patterns and client-specific local personalized layers (LP-Layer) for modeling node-level behavioral characteristics. In addition, we introduce a soft-label knowledge distillation based training strategy to alleviate label space heterogeneity, thereby improving the model’s generalization ability and convergence speed in a federated environment. Extensive experiments on three public benchmark datasets, CIC-UNSW-NB15, CIC-IDS2017, and CSE-CIC-IDS2018, demonstrate that P3Fed consistently outperforms representative baseline methods in terms of detection accuracy and robustness. Through knowledge distillation, P3Fed maintains an F1-score of over 98 % when detecting attack types that were not present in local training data, while baseline methods like FedAvg and FedProx achieve only around 50 %. Even under a strict privacy budget (ε=1.0), P3Fed retains over 98 % of its non-private F1-score and effectively handles locally unseen attacks. These results highlight the great potential of P3Fed as an effective and practical solution for enhancing the security and trustworthiness of future CPNs.
ER  - 

TY  - JOUR
T1  - Efficient malware detection using NLP and deep learning model
AU  - Gupta, Umesh
AU  - Kandpal, Shubham
AU  - Alamro, Hayam
AU  - Asiri, Mashael M.
AU  - Alanazi, Meshari H.
AU  - Al-Sharafi, Ali M.
AU  - Sorour, Shaymaa
JO  - Alexandria Engineering Journal
VL  - 124
SP  - 550
EP  - 564
PY  - 2025
DA  - 2025/06/01/
SN  - 1110-0168
DO  - https://doi.org/10.1016/j.aej.2025.03.118
UR  - https://www.sciencedirect.com/science/article/pii/S1110016825004260
KW  - Malware
KW  - Artificial Intelligence
KW  - Natural Language Processing
KW  - Deep Learning
KW  - Classification
AB  - Malware has emerged as a significant challenge in contemporary society, growing in tandem with technological advancements. Consequently, the classification of malware has become a pressing concern for various services. Conventional malware detection techniques, such as signature matching, are constrained by the dynamic evolution of malware, which limits their adaptability and efficacy. To tackle these issues, this study employs natural language processing (NLP) and deep learning approaches to categorize malware entities as either malicious or benign. The model incorporates image processing by transforming code segments into image pixels, applying convolutional operations, and utilizing advanced deep learning methodologies. Following processing, the model generates a normalized value through the sigmoid function, which is then rounded to yield a binary classification. The results were validated using multiple metrics, including precision and accuracy, to evaluate the model's effectiveness and ensure optimal performance throughout the classification process. The proposed model's performance was assessed on datasets of kernel API calls by the malware. The research highlights that using NLP from the function calls and deep learning techniques for malware classification enhances the accuracy and adaptability of detecting malicious software which overcomes the limitations of traditional signature-based methods. The model delivers encouraging results, presenting a viable solution for effective malware classification. This paper aims to experiment with different variables of a malicious code that are often overlooked while analysing a malware.
ER  - 

TY  - JOUR
T1  - Fraud detection at eBay
AU  - Rao, Susie Xi
AU  - Han, Zhichao
AU  - Yin, Hang
AU  - Jiang, Jiawei
AU  - Zhang, Zitao
AU  - Zhao, Yang
AU  - Shan, Yinan
JO  - Emerging Markets Review
VL  - 66
SP  - 101277
PY  - 2025
DA  - 2025/06/01/
SN  - 1566-0141
DO  - https://doi.org/10.1016/j.ememar.2025.101277
UR  - https://www.sciencedirect.com/science/article/pii/S1566014125000263
KW  - Graph neural networks
KW  - Transaction fraud detection
KW  - Explainability
KW  - User behavioral embedding
KW  - Click stream
AB  - Fraud detection is a key research topic for e-commerce, addressing challenges like dynamic heterogeneity and interlinked fraudulent patterns. Existing efforts include rule-based and machine learning systems, but graph-based approaches are increasingly critical. This paper presents the first systematic review of fraud detection in real-world e-commerce environment like eBay, leveraging multi-source data such as transaction logs and user behavior, dealing with challenges of information heterogeneity, scalability, graph dynamics, explainability, and adaptability. We also highlight eBay's efforts in designing explainable fraud detection systems with graph neural networks (GNNs) tailored to deployment needs and offer insights and recommendations for advancing research.
ER  - 

TY  - JOUR
T1  - DaC-GANSAEBF: Divide and Conquer-Generative Adversarial Network—Squeeze and Excitation-Based Framework for Spam Email Identification
AU  - Shawly, Tawfeeq
AU  - Alsheikhy, Ahmed A.
AU  - Said, Yahia
AU  - Shaaban, Shaaban M.
AU  - Lahza, Husam
AU  - AbuEid, Aws I.
AU  - Alzahrani, Abdulrahman
JO  - CMES - Computer Modeling in Engineering and Sciences
VL  - 142
IS  - 3
SP  - 3181
EP  - 3212
PY  - 2025
DA  - 2025/03/03/
SN  - 1526-1492
DO  - https://doi.org/10.32604/cmes.2025.061608
UR  - https://www.sciencedirect.com/science/article/pii/S1526149225000645
KW  - Email
KW  - spam
KW  - fraud
KW  - light dual attention
KW  - squeeze and excitation
KW  - divide and conquer-generative adversarial network—squeeze and excitation-based framework
KW  - security
AB  - Email communication plays a crucial role in both personal and professional contexts; however, it is frequently compromised by the ongoing challenge of spam, which detracts from productivity and introduces considerable security risks. Current spam detection techniques often struggle to keep pace with the evolving tactics employed by spammers, resulting in user dissatisfaction and potential data breaches. To address this issue, we introduce the Divide and Conquer-Generative Adversarial Network Squeeze and Excitation-Based Framework (DaC-GANSAEBF), an innovative deep-learning model designed to identify spam emails. This framework incorporates cutting-edge technologies, such as Generative Adversarial Networks (GAN), Squeeze and Excitation (SAE) modules, and a newly formulated Light Dual Attention (LDA) mechanism, which effectively utilizes both global and local attention to discern intricate patterns within textual data. This approach significantly improves efficiency and accuracy by segmenting scanned email content into smaller, independently evaluated components. The model underwent training and validation using four publicly available benchmark datasets, achieving an impressive average accuracy of 98.87%, outperforming leading methods in the field. These findings underscore the resilience and scalability of DaC-GANSAEBF, positioning it as a viable solution for contemporary spam detection systems. The framework can be easily integrated into existing technologies to enhance user security and reduce the risks associated with spam.
ER  - 

TY  - JOUR
T1  - Double layer blockchain-assisted trusted data flow model for industrial control systems
AU  - Peng, Xiangzhen
AU  - Zheng, Chengliang
AU  - Wang, Yidi
AU  - Cui, Xiaohui
AU  - Shen, Zhidong
JO  - Reliability Engineering & System Safety
VL  - 260
SP  - 111013
PY  - 2025
DA  - 2025/08/01/
SN  - 0951-8320
DO  - https://doi.org/10.1016/j.ress.2025.111013
UR  - https://www.sciencedirect.com/science/article/pii/S0951832025002145
KW  - Industrial control system
KW  - Blockchain
KW  - Zero-trust access control strategy
KW  - Active defense
KW  - Cyber-attack defense
AB  - With the development of information technology (IT), the blurred network boundary between the Operational Technology (OT) network and the IT network poses a higher risk of cyber-attacks on the flow of data in Industrial Control System (ICS). Deep isolation of ICS, enhanced data access control in ICS, and proactive defense against cyber-attacks in ICS can help achieve the secure flow of highly sensitive data in ICS. This article proposes a dual-layer blockchain-assisted data flow protection framework for ICS, driven by blockchain, and conducts simulation and analysis. Firstly, OT-blockchain and IT-blockchain were designed to redefine the network boundary of ICS. Secondly, an identity-assisted authentication mechanism based on Bloom filters and trusted databases was designed to rapidly identify dishonest nodes. Then, an ICS-RBAC zero-trust access control mechanism based on RBAC was designed to ensure the security of the OT blockchain and achieve zero-trust data exchange between the IT-blockchain and ICS physical devices. And, an active defense mechanism for ICS was designed based on the principle of the heartbeat mechanism. Finally, model analysis and simulation verification are conducted. The results indicate that this study can achieve trusted data flow in ICS and fine-grained zero-trust access control, providing security guarantees.
ER  - 

TY  - JOUR
T1  - SABA: Scene-aware bidirectional backdoor attack against multimodal learning
AU  - Xu, Simin
AU  - Li, Guojia
AU  - Cao, Mingyue
AU  - Zhang, Yihong
AU  - Cao, Yan
JO  - Neurocomputing
VL  - 669
SP  - 132366
PY  - 2026
DA  - 2026/03/07/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2025.132366
UR  - https://www.sciencedirect.com/science/article/pii/S0925231225030383
KW  - Backdoor attack
KW  - Multimodal DNN
KW  - Scene-aware
KW  - Visual trigger
KW  - Text trigger
AB  - DNN models have been widely applied to multimodal tasks, including cross-modal retrieval, image captioning, and visual question answering (VQA). While unimodal DNN models face serious security threats from backdoor attacks, backdoor attacks against multimodal DNN models are still underexplored. Current multimodal backdoor attack methods mainly inherit the ideas of unimodal backdoor attacks, making them difficult to adapt to complex multimodal tasks, which results in limited generalization and weak stealthiness of backdoor triggers. We propose a scene-aware multimodal bidirectional backdoor attack method (SABA). For different benign samples, this method first assesses the scene and selects adapted trigger samples based on the semantic understanding of the scene content. It constructs a scene-aware dynamic trigger generation mechanism, generating semantically constrained image and text triggers for different types of scenes, and inserts them into benign image or text samples to achieve a backdoor that is activated in one modality and effective in another modality. We evaluated the effectiveness of this method on two tasks: cross-modal retrieval and visual question answering (VQA). Compared to various SOTA methods for multimodal and unimodal backdoor attacks, SABA demonstrates strong effectiveness. Additionally, SABA can robustly evade existing backdoor defense strategies, posing a potential threat. Furthermore, we evaluate the stealthiness of the bidirectional backdoor attack method, and the comprehensive results are superior to those of three SOTA multimodal backdoor attack methods.
ER  - 

TY  - JOUR
T1  - AIGC-empowered smart manufacturing: Prospects and challenges
AU  - Leng, Jiewu
AU  - Zheng, Keyou
AU  - Li, Rongjie
AU  - Chen, Chong
AU  - Wang, Baicun
AU  - Liu, Qiang
AU  - Chen, Xin
AU  - Shen, Weiming
JO  - Robotics and Computer-Integrated Manufacturing
VL  - 97
SP  - 103076
PY  - 2026
DA  - 2026/02/01/
SN  - 0736-5845
DO  - https://doi.org/10.1016/j.rcim.2025.103076
UR  - https://www.sciencedirect.com/science/article/pii/S0736584525001309
KW  - Artificial intelligence generated content
KW  - Generative artificial intelligence
KW  - Smart manufacturing
KW  - GenAI Agent
KW  - Industry 5.0
AB  - Generative AI (GenAI), the technology behind Artificial Intelligence Generated Content (AIGC), has emerged as a transformative technology in smart manufacturing. However, its full potential and integration within manufacturing processes remain unexplored. This paper presents a comprehensive framework that aligns a GenAI-centered approach with Product Lifecycle Management (PLM), systematically examining the AIGC landscape and its applications across various manufacturing phases. To ensure accuracy and relevance, a human-in-the-loop pipeline is employed to curate and analyze cutting-edge research. Key contributions of this study include: 1) a holistic perspective on AIGC-empowered smart manufacturing, 2) an in-depth analysis of the current technological landscape, and 3) the identification of critical research challenges and future directions. Additionally, the paper considers Industry 5.0 principles, emphasizing human-centricity, sustainability, and resilience. By fostering discussion and collaboration, this review aims to advance innovation and unlock the full potential of AIGC in smart manufacturing.
ER  - 

TY  - JOUR
T1  - MFXSS: An effective XSS vulnerability detection method in JavaScript based on multi-feature model
AU  - Liu, Zhonglin
AU  - Fang, Yong
AU  - Huang, Cheng
AU  - Xu, Yijia
JO  - Computers & Security
VL  - 124
SP  - 103015
PY  - 2023
DA  - 2023/01/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2022.103015
UR  - https://www.sciencedirect.com/science/article/pii/S0167404822004072
KW  - Cross-site scripting
KW  - Multi-feature fusion
KW  - Graph convolutional network
KW  - Weighted aggregation
KW  - Vulnerability detection
AB  - The widespread use of web applications has also made them more vulnerable to hackers, resulting in the leakage of large amounts of application and personal privacy data. Cross-site scripting (XSS) attacks are one of the most significant threats to web applications. Attackers can inject scripts to control the victim’s browser to send data or execute commands, leading to the theft of privacy or the hijacking of login tokens. Therefore, we proposed a multi-feature fusion-based neural network vulnerability detection model for detecting XSS vulnerabilities in the JavaScript source code of websites (We termed our implementation of this approach MFXSS). We combine abstract syntax tree (AST) and code control flow graph (CFG) to convert the generalized sample data into graph structure and code string structure. Then, through the graph convolutional neural network, weighted aggregation, and the bidirectional recurrent neural network, the logical call features and the context execution relationship features of the source code are extracted and fused respectively. Finally, the fused feature vectors are used to detect and predict XSS vulnerabilities in JavaScript. In the experiment, we designed multiple control experiments to verify that the model construction is optimal, and the accuracy rates in the standard and variant datasets are 0.997 and 0.986. Moreover, in comparing similar detection schemes, MFXSS also performs better. Applying the model to an actual web environment, we successfully detected the presence of XSS vulnerabilities in websites.
ER  - 

TY  - JOUR
T1  - Enhanced IoT security: privacy-preserving federated learning model for accurate, real-time intrusion detection across devices
AU  - Puviarasu, A.
AU  - V K, Sudha
JO  - Ain Shams Engineering Journal
VL  - 17
IS  - 1
SP  - 103866
PY  - 2026
DA  - 2026/01/01/
SN  - 2090-4479
DO  - https://doi.org/10.1016/j.asej.2025.103866
UR  - https://www.sciencedirect.com/science/article/pii/S2090447925006070
KW  - Federated learning
KW  - IoT networks
KW  - Intrusion detection
KW  - Privacy preservation
KW  - Differential privacy
KW  - Homomorphic encryption
KW  - Neural networks
KW  - Distributed learning
KW  - Security
AB  - Federated learning (FL) has been proposed as an effective solution in the context of intrusion detection in IoT networks, where models can be trained collaboratively with the security of raw data protection. In this paper we present a privacy-preserving FL framework based on light weight neural network, differential privacy (DP) and homomorphic encryption (HE). With a dataset of 1,191,264 instances and 47 attributes, the proposed model conducted on the IoT Intrusion Detection Dataset available on Kaggle produces overall accuracy (93.5), precision (94.2), recall (93.4), and the F1-score (94.2), with the detection time of 90–130 ms and no distinction between the attacks, where detection latency was considered in this study. At the attack level the model delivered 94.1 %, 92.5 %, and 93.6 % accuracies on DoS, DDoS, and Mirai respectively, and above 85 % accuracy on Malware and Web-based attacks. DP experiments showed that augmenting the privacy budget parameter 0.5 to 20.0 increased the levels of accuracy by 2.6 % to 94.0 %, and decreased the computational time 150 ms to 121 ms, depicting a compromise between privacy and performance. HE experiments likewise exhibited a negligible accuracy reduction (94.1 % to 93.5 %) between no encryption to complete homomorphic encryption, but required more computation time (120 ms to 200 ms). Devices-level testing demonstrated that the model had > 91 % accuracy at the low-end (0.5 GHz CPU, 128 MB memory) and up to 94.5 % accuracy with 110 ms inference time on powerful processors, irrespective of whether or not the sensor was heterogeneous, demonstrating a viable solution to the heterogeneous IT situation. Audit mechanisms further enhanced greater compliance of 0 % to 99 % with minimal reduction in accuracy (< 0.8 %). The results show that privacy-preserving intrusion detection specifically can be performed with real-time intrusion detection, high detection gene, and privacy guarantees in resource-constrained IoT networks.
ER  - 

TY  - JOUR
T1  - DeepFake detection in the AIGC era: A survey, benchmarks, and future perspectives
AU  - Xie, Shichuang
AU  - Qiao, Tong
AU  - Li, Sheng
AU  - Zhang, Xinpeng
AU  - Zhou, Jiantao
AU  - Feng, Guorui
JO  - Information Fusion
VL  - 127
SP  - 103740
PY  - 2026
DA  - 2026/03/01/
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2025.103740
UR  - https://www.sciencedirect.com/science/article/pii/S1566253525008024
KW  - DeepFake survey
KW  - Media forensics
KW  - Face generation and detection
AB  - In recent years, DeepFake has further developed, driven by continuous advances in data, computing power, and deep generative models. This emerging digital media forgery technique can manipulate or generate fake face content, increasingly blurring the boundaries between real and fake media. With the growing misuse of DeepFake, the associated risks are also intensifying. Although some research on DeepFake detection has been conducted, the research on detection is obviously falling behind DeepFake generation, and there is a lack of comprehensive and up-to-date surveys on DeepFake detection. Therefore, to effectively counter the proliferation of DeepFake face and promote the evolution of DeepFake detection, we conduct comprehensive survey and analysis. Specifically, (1) we analyze the key factors driving the proliferation of DeepFake, and we review the four representative types of DeepFake face and introduce a novel cross-modal face manipulation based on foundation models; (2) we reorganize DeepFake detection methods and establish a detection evaluation benchmark, emphasizing the potential of emerging detectors; (3) we focus on the current challenges of DeepFake forensic research and the corresponding development trends, and provide future perspectives, aiming to provide new insights for DeepFake forensic research in the AIGC era.
ER  - 

TY  - JOUR
T1  - An ethical assessment framework for AI security and ethics in smart grid
AU  - Zhang, Yiying
AU  - Zhao, Congcong
AU  - Meng, Ziang
AU  - Lai, Chun Sing
AU  - Chen, Xi
JO  - Global Energy Interconnection
PY  - 2025
DA  - 2025/11/21/
SN  - 2096-5117
DO  - https://doi.org/10.1016/j.gloei.2025.10.006
UR  - https://www.sciencedirect.com/science/article/pii/S2096511725001252
KW  - Smart grid
KW  - Artificial intelligence technology
KW  - Ethics of science and technology
KW  - Assessment framework
AB  - The advancement of smart grid, facilitated by the extensive integration of information communication, automated control, and artificial intelligence (AI) technologies, signifies a significant transformation of the power system towards holistic perception, intelligent management, and secure operation. This article focuses on the security and ethical compliance of smart grid, intending to offer guiding insights for this new technological domain. This study initially delineates the potential applications, technical attributes, and design of smart grid, followed by a thorough examination of the security threats and ethical dilemmas arising from technological advancements. This study examines the pivotal role of AI in smart grid and its intricate interplay with security and ethical concerns. It performs a comprehensive analysis of the possible technical deficiencies and ethical challenges of AI systems in smart grid and assesses the extensive repercussions that these difficulties may entail. This study presents a security ethics evaluation methodology for smart grid, which thoroughly examines the ethical implications of AI technology in power grid applications and identifies existing obstacles and threats. This paper conducts a thorough policy analysis to evaluate the present security and ethical conditions of smart grid, with the objective of offering substantive theoretical support to enhance their security and ethical advancement, thereby fostering their healthy and sustainable development.
ER  - 

TY  - JOUR
T1  - TransURL: Improving malicious URL detection with multi-layer Transformer encoding and multi-scale pyramid features
AU  - Liu, Ruitong
AU  - Wang, Yanbin
AU  - Guo, Zhenhao
AU  - Xu, Haitao
AU  - Qin, Zhan
AU  - Ma, Wenrui
AU  - Zhang, Fan
JO  - Computer Networks
VL  - 253
SP  - 110707
PY  - 2024
DA  - 2024/11/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2024.110707
UR  - https://www.sciencedirect.com/science/article/pii/S1389128624005395
KW  - Malicious URL detection
KW  - Multi-scale learning
KW  - Transformer
KW  - Pyramid attention
AB  - While machine learning progress is advancing the detection of malicious URLs, advanced Transformers applied to URLs face difficulties in extracting local information, character-level information, and structural relationships. To address these challenges, we propose a novel approach for malicious URL detection, named TransURL, that is implemented by co-training the character-aware Transformer with three feature modules—Multi-Layer Encoding, Multi-Scale Feature Learning, and Spatial Pyramid Attention. This special Transformer allows TransURL to extract embeddings that contain character-level information from URL token sequences, with three feature modules contributing to the fusion of multi-layer Transformer encodings and the capture of multi-scale local details and structural relationships. The proposed method is evaluated across several challenging scenarios, including class imbalance learning, multi-classification, cross-dataset testing, and adversarial sample attacks. The experimental results demonstrate a significant improvement compared to the best previous methods. For instance, it achieved a peak F1-score improvement of 40% in class-imbalanced scenarios, and exceeded the best baseline result by 14.13% in accuracy in adversarial attack scenarios. Additionally, we conduct a case study where our method accurately identifies all 30 active malicious web pages, whereas two pior SOTA methods miss 4 and 7 malicious web pages respectively. The codes and data are available at: https://github.com/Vul-det/TransURL/.
ER  - 

TY  - JOUR
T1  - A comprehensive analysis combining structural features for detection of new ransomware families
AU  - Moreira, Caio C.
AU  - Moreira, Davi C.
AU  - Sales, Claudomiro
JO  - Journal of Information Security and Applications
VL  - 81
SP  - 103716
PY  - 2024
DA  - 2024/03/01/
SN  - 2214-2126
DO  - https://doi.org/10.1016/j.jisa.2024.103716
UR  - https://www.sciencedirect.com/science/article/pii/S221421262400019X
KW  - 
KW  - Static analysis
KW  - Structural information
KW  - Portable executable
KW  - Combined features
AB  - This study presents a comprehensive static analysis method that combines multiple structural features extracted from Windows executable files. The method employs an ensemble soft voting model that comprises three machine learning techniques: Logistic Regression (LR), Random Forest (RF), and eXtreme Gradient Boosting (XGB). Our proposed model aims to identify newly emerged ransomware families by analyzing header fields, imported Dynamic-link Libraries (DLLs), function calls, and entropy of sections. To assess the method’s efficacy in detecting zero-day ransomware families, we created a dataset consisting of 2675 binary samples. The training set consisted of 1023 samples from 25 relevant ransomware families and 1134 benign applications (goodware) samples. The testing set comprised 385 samples from 15 recent ransomware families and 133 goodware samples. The results for the Detection of New Ransomware Families (DNRF) demonstrated weighted averages of 97.53% accuracy, 96.36% precision, 97.52% recall, and 96.41% F-measure. In addition, the scanning and prediction showed an average of 0.37 s. These results showed the model’s adaptability to the ever-changing ransomware landscape while maintaining reasonable testing times, making it applicable as an additional security layer in antivirus protection systems on low-resource hardware devices. Furthermore, we used the SHapley Additive exPlanations (SHAP) interpretation method to establish trust and gain insights into the decision-making process of the proposed model. Our method offers significant advantages and can assist developers of ransomware detection systems in creating more resilient, dependable, and real-time solutions.
ER  - 

TY  - JOUR
T1  - A management knowledge graph approach for critical infrastructure protection: Ontology design, information extraction and relation prediction
AU  - Chen, Jiarui
AU  - Lu, Yiqin
AU  - Zhang, Yang
AU  - Huang, Fang
AU  - Qin, Jiancheng
JO  - International Journal of Critical Infrastructure Protection
VL  - 43
SP  - 100634
PY  - 2023
DA  - 2023/12/01/
SN  - 1874-5482
DO  - https://doi.org/10.1016/j.ijcip.2023.100634
UR  - https://www.sciencedirect.com/science/article/pii/S1874548223000471
KW  - Knowledge graph
KW  - Critical infrastructure
KW  - Ontology
KW  - Named entity recognition
KW  - Relation prediction
AB  - Critical Infrastructures (CI) underpin the basic functioning of society and the economy. Proper governance of CI security management remains a crucial challenge. This study aims to construct a knowledge graph for modeling CI protection. While the previous research has focused on threat intelligence modeling and open knowledge bases, they miss considering the defense side. Accordingly, we propose a knowledge graph for critical infrastructure protection, CIPKG, that extends the management ontology to include the defense side. It addresses the cross-industry and cross-time information gaps that occur in the process of CI protection management, making it more comprehensive in structure than the existing knowledge graph. We employ simplified Structured Threat Information Expression as attack ontology and design a new ontology for the defense side, which could combine with the existing threat ontology to form the CI protection knowledge graph. To dynamically extract information from emerging knowledge, we employ a Bi-directional Long Short-Term Memory and Conditional Random Field model with pre-trained cybersecurity domain-specific Bidirectional Encoder Representations from Transformers to recognize the named entities from CI regulations and standards. To associate the threat part with the management portion of the knowledge graph, we adopt the Knowledge Graph Bidirectional Encoder Representations from Transformer model to capture the semantic information and predict the relationship between threat and management. After information extraction and relation prediction, we build a knowledge graph with 529,360 nodes and about 3,335,000 edges.
ER  - 

TY  - JOUR
T1  - Edge-featured multi-hop attention graph neural network for intrusion detection system
AU  - Deng, Ping
AU  - Huang, Yong
JO  - Computers & Security
VL  - 148
SP  - 104132
PY  - 2025
DA  - 2025/01/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104132
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824004371
KW  - Multi-hop attention
KW  - Graph neural networks
KW  - Intrusion detection
KW  - Internet of Things
AB  - With the development of the Internet, the application of computer technology has rapidly become widespread, driving the progress of Internet of Things (IoT) technology. The attacks present on networks have become more complex and stealthy. However, traditional network intrusion detection systems with singular functions are no longer sufficient to meet current demands. While some machine learning-based network intrusion detection systems have emerged, traditional machine learning methods cannot effectively respond to the complex and dynamic nature of network attacks. Intrusion detection systems utilizing deep learning can better enhance detection capabilities through diverse data learning and training. To capture the topological relationships in network data, using graph neural networks (GNNs) is most suitable. Most existing GNNs for intrusion detection use multi-layer network training, which may lead to over-smoothing issues. Additionally, current intrusion detection solutions often lack efficiency. To mitigate the issues mentioned above, this paper proposes an Edge-featured Multi-hop Attention Graph Neural Network for Intrusion Detection System (EMA-IDS), aiming to improve detection performance by capturing more features from data flows. Our method enhances computational efficiency through attention propagation and integrates node and edge features, fully leveraging data characteristics. We carried out experiments on four public datasets, which are NF-CSE-CIC-IDS2018-v2, NF-UNSW-NB15-v2, NF-BoT-IoT, and NF-ToN-IoT. Compared with existing models, our method demonstrated superior performance.
ER  - 

TY  - JOUR
T1  - DDoSBERT: Fine-tuning variant text classification bidirectional encoder representations from transformers for DDoS detection
AU  - Le, Thi-Thu-Huong
AU  - Heo, Shinwook
AU  - Cho, Jaehan
AU  - Kim, Howon
JO  - Computer Networks
VL  - 262
SP  - 111150
PY  - 2025
DA  - 2025/05/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2025.111150
UR  - https://www.sciencedirect.com/science/article/pii/S1389128625001185
KW  - DDoS(distributed denial of service)
KW  - IDS(intrusion detection system)
KW  - Text classification
KW  - Fine-tuning
KW  - BERT(bidirectional encoder representations from transformers)
AB  - The imperative for robust detection mechanisms has grown in the face of increasingly sophisticated Distributed Denial of Service (DDoS) attacks. This paper introduces DDoSBERT, an innovative approach harnessing transformer text classification for DDoS detection. The methodology conducts a detailed exploration of feature selection methods, emphasizing the selection of critical techniques, including Correlation, Mutual Information, and Univariate Feature Selection. Motivated by the dynamic landscape of DDoS attacks, DDoSBERT confronts contemporary challenges such as binary and multi-attack classification and imbalance attack classification. The methodology delves into diverse text transformation techniques for feature selection and employs three transformer classification models: distilbert-base-uncased, prunebert-base-uncased-6-finepruned-w-distil-mnli, and distilbert-base-uncased-finetuned-sst-2-english. Additionally, the paper outlines a comprehensive framework for assessing the importance of features in the context of five DDoS datasets, comprised of APA-DDoS, CRCDDoS2022, DDoS Attack SDN, CIC-DDoS-2019, and BCCC-cPacket-Cloud-DDoS-2024 datasets. The experimental results, rigorously evaluated against relevant benchmarks, affirm the efficacy of DDoSBERT, underscoring its significance in enhancing the resilience of systems against text-based transformation DDoS attacks. The discussion section interprets the results, highlights the implications of the findings, and acknowledges limitations while suggesting avenues for future research.
ER  - 

TY  - JOUR
T1  - Enhancing cyberbullying identification with ELECTRA-BiLSTM: A hybrid approach for improved contextual and sequential understanding
AU  - Agrahari, Shalini
AU  - Tiwari, Arvind Kumar
JO  - Entertainment Computing
VL  - 55
SP  - 101056
PY  - 2025
DA  - 2025/09/01/
SN  - 1875-9521
DO  - https://doi.org/10.1016/j.entcom.2025.101056
UR  - https://www.sciencedirect.com/science/article/pii/S1875952125001363
KW  - Cyberbullying
KW  - Text Classification
KW  - Transformers
KW  - BERT
KW  - ELECTRA
KW  - BiLSTM
KW  - Social Media
AB  - Social media has revolutionized how we connect, fostering communities based on shared interests worldwide. However, it also opens the door to cyberbullying, a serious concern in today’s digital age. Unlike traditional bullying, cyberbullying happens online, making it harder to detect and prevent. In this paper, we combine the Efficiently Learning an Encoder that Classifies Token Replacements Accurately (ELECTRA) model with Bidirectional Long Short-Term Memory (BiLSTM), to better spot cyberbullying, improving the model’s ability to understand context and sequential patterns in text. Preprocessing has included tokenization, normalization and data cleaning to ensure consistent input quality. Using a dataset of approximately 48,000 tweets across six categories, the proposed model achieved 88.38% accuracy, outperforming traditional and existing models, highlighting its potential to enhance online safety.
ER  - 

TY  - JOUR
T1  - A study on ChatGPT for Industry 4.0: Background, potentials, challenges, and eventualities
AU  - Javaid, Mohd
AU  - Haleem, Abid
AU  - Singh, Ravi Pratap
JO  - Journal of Economy and Technology
VL  - 1
SP  - 127
EP  - 143
PY  - 2023
DA  - 2023/11/01/
SN  - 2949-9488
DO  - https://doi.org/10.1016/j.ject.2023.08.001
UR  - https://www.sciencedirect.com/science/article/pii/S2949948823000033
KW  - ChatGPT
KW  - Industry 4.0
KW  - Artificial Intelligence (AI)
KW  - Manufacturing
AB  - ChatGPT is an Artificial Intelligence (AI)-powered Natural Language Processing (NLP) tool that comprehends and produces text in response to given commands. It can be adopted for various requirements, like answering our inquiries, assisting us with content creation, translating languages, and more. The fourth industrial revolution, called "Industry 4.0," denotes a new production age focused on automation, digitalisation, and real-time connectivity of production systems. ChatGPT can help Industry 4.0 in a variety of ways. ChatGPT and AI-driven process optimisation is poised to revolutionise Industry 4.0 by enhancing productivity, quality assurance, and efficiency. For developing this paper, various articles on ChatGPT/ AI for Industry 4.0 were identified through Scopus, ScienceDirect, Google Scholar and ResearchGate. Industry 4.0 progresses due to the incorporation of cutting-edge technology like AI, Machine Learning (ML), and NLP and Manufacturing operations are changing. The ChatGPT language model is becoming well-known for daily use because of its promising applications. In the framework of Industry 4.0, it promises to revolutionise processes to assist advancement in boosting business productivity and efficiency. This paper studies the major need for ChatGPT for Industry 4.0. Various associated features, traits and versatile competencies of ChatGPT for Industry 4.0 are identified and briefed. Finally, it identifies and discusses the significant applications of ChatGPT for Industry 4.0. ChatGPT is a very flexible and efficient method for creating human-machine interfaces and automatically generating text, which provides proper knowledge and guidance to the employee. Applications for ChatGPT include chatbots, virtual assistants, automated customer care, language translation, and content production. In future, it will become an effective tool for enhancing communication and automating processes in Industry 4.0.
ER  - 

TY  - JOUR
T1  - Severity prediction of software vulnerabilities using convolutional neural networks
AU  - Saklani, Santosh
AU  - Kalia, Anshul
JO  - Information and Computer Security
VL  - 33
IS  - 4
SP  - 613
EP  - 630
PY  - 2025
DA  - 2025/02/17/
SN  - 2056-4961
DO  - https://doi.org/10.1108/ICS-10-2024-0265
UR  - https://www.sciencedirect.com/science/article/pii/S2056496125000030
KW  - Machine learning
KW  - Natural language processing
KW  - Convolutional neural network (CNN)
KW  - Software vulnerability
KW  - Common vulnerability scoring system (CVSS)
AB  - Purpose
The continuous influx of software vulnerabilities poses a significant challenge to organizations, necessitating effective resource allocation for threat mitigation. A key factor in this process is assessing the severity of vulnerabilities to prioritize which issues require immediate attention. This paper aims to automate the prediction of common vulnerability scoring system (CVSS) metrics from textual descriptions of vulnerabilities, reducing the reliance on manual expert analysis.
Design/methodology/approach
This study applies machine learning and natural language processing techniques, particularly convolutional neural networks (CNNs), to predict CVSS base metrics such as attack vectors, attack complexity and required privileges. The CNN models are trained on vulnerability descriptions and evaluated for their accuracy in predicting these metrics, which are then used to compute overall severity base scores.
Findings
The CNN models demonstrated high accuracy in predicting CVSS base metrics from textual descriptions. The predicted severity base scores closely align with those provided by human experts, showing the model’s potential to streamline the vulnerability assessment process.
Practical implications
Automating CVSS metric prediction could significantly reduce the time and effort required for vulnerability severity assessment. This would enable security teams to quickly identify and prioritize critical vulnerabilities, improving response times in cybersecurity management.
Originality/value
This research provides an innovative approach to vulnerability management by automating CVSS metric prediction, reducing the need for manual expert analysis and therefore accelerating security assessments.
ER  - 

TY  - JOUR
T1  - Enhancing supply chain resilience and efficiency of HVAC systems in semiconductor manufacturing facilities using graph-based large multimodal models
AU  - Ni, Hsiao-Ping
AU  - Liu, Chi-Yun
AU  - Paul, Fermodelie
AU  - Chong, Wai Oswald
AU  - Chou, Jui-Sheng
JO  - Applied Energy
VL  - 398
SP  - 126420
PY  - 2025
DA  - 2025/11/15/
SN  - 0306-2619
DO  - https://doi.org/10.1016/j.apenergy.2025.126420
UR  - https://www.sciencedirect.com/science/article/pii/S030626192501150X
KW  - Large multimodal model
KW  - Graph neural network
KW  - HVAC systems
KW  - Semiconductor manufacturing facilities
KW  - Supply chain management
KW  - Circular economy
AB  - Semiconductor manufacturing facilities (SMFs) demand ultra-precise environmental conditions maintained by specialized HVAC systems, critical for a resilient and sustainable semiconductor supply chain. While AI-driven solutions have been applied to generic supply chain optimization, they often fail in addressing the unique challenges of SMFs, where HVAC systems must maintain sub-0.1 °C temperature stability, account for 40–60 % of facility energy consumption, and comply with stringent cleanroom standards. This paper proposes an innovative framework that integrates graph-based large multimodal models (G-LMMs), enhanced by graph neural networks (GNNs), to optimize SMF HVAC supply chains across the Design, Construction, Installation, Maintenance, and Operation (DCIMO) phases. GNNs enable the capture and analysis of complex relationships within HVAC systems, facilitating real-time anomaly detection and optimized material flows. Unlike conventional AI models, G-LMMs combine GNNs with multimodal data processing to achieve three key advancements: (1) real-time anomaly detection, (2) automated compliance monitoring, and (3) circular economy integration through resource reuse. G-LMMs enhance supply chain visibility by harmonizing diverse data types while meeting SMFs' precision requirements. As the first framework to unify GNNs and multimodal AI for HVAC optimization, this approach represents a paradigm shift in sustainable semiconductor manufacturing, with broader implications for industries reliant on precision-controlled environments.
ER  - 

TY  - JOUR
T1  - News sentiment, climate conditions, and New Zealand electricity market: A real-time bidding policy perspective
AU  - Wang, Guanghao
AU  - Sbai, Erwann
AU  - Sheng, Mingyue Selena
AU  - Tao, Miaomiao
JO  - Energy
VL  - 318
SP  - 134784
PY  - 2025
DA  - 2025/03/01/
SN  - 0360-5442
DO  - https://doi.org/10.1016/j.energy.2025.134784
UR  - https://www.sciencedirect.com/science/article/pii/S0360544225004268
KW  - Electricity price
KW  - News sentiment
KW  - Climate conditions
KW  - Real-time bidding policy
KW  - New Zealand
AB  - We investigate the short- and long-term dynamics between news sentiment, climate conditions, and New Zealand's wholesale electricity prices. Remarkably, our analysis is mainly grounded in investigating and comparing the determinants of power before and after implementing the real-time bidding policy in New Zealand. We apply the Quantile Autoregressive Distributed Lag (QARDL) approach to address the complex nature of these indicators effectively. Specifically, before implementing the real-time bidding policy, the electricity prices presented salient asymmetry and a non-linear structure in response to climate conditions, news sentiment, and consumer demand, consolidating the market's sensitivity to exogenous conditions in the short and long run. Interestingly, the real-time bidding shock substantially altered these powers, mainly manifested by the stylized fact that the market's response to these factors became noticeably more stable. Further, the market's ability to absorb price fluctuations is also significantly strengthened in the long term due to the insensitive response of the electricity market to climate conditions. Our analysis also confirmed the solid relationship after the relevant policy introduction.
ER  - 

TY  - JOUR
T1  - Epidemic effects in the diffusion of emerging digital technologies: evidence from artificial intelligence adoption
AU  - Dahlke, Johannes
AU  - Beck, Mathias
AU  - Kinne, Jan
AU  - Lenz, David
AU  - Dehghan, Robert
AU  - Wörter, Martin
AU  - Ebersberger, Bernd
JO  - Research Policy
VL  - 53
IS  - 2
SP  - 104917
PY  - 2024
DA  - 2024/03/01/
SN  - 0048-7333
DO  - https://doi.org/10.1016/j.respol.2023.104917
UR  - https://www.sciencedirect.com/science/article/pii/S0048733323002019
KW  - Artificial intelligence
KW  - Inter-firm diffusion
KW  - Epidemic effects
KW  - Web data
KW  - Text mining
KW  - Technology policy
AB  - The properties of emerging, digital, general-purpose technologies make it hard to observe their adoption by firms and identify the salient determinants of adoption. However, these aspects are critical since the patterns related to early-stage diffusion establish path-dependencies which have implications for the distribution of the technological opportunities and socio-economic returns linked to these technologies. We focus on the case of artificial intelligence (AI) and train a transformer language model to identify firm-level AI adoption using textual data from over 1.1 million websites and constructing a hyperlink network that includes >380,000 firms in Germany, Austria, and Switzerland. We use these data to expand and test epidemic models of inter-firm technology diffusion by integrating the concepts of social capital and network embeddedness. We find that AI adoption is related to three epidemic effect mechanisms: 1) Indirect co-location in industrial and regional hot-spots associated to production of AI knowledge; 2) Direct exposure to sources transmitting deep AI knowledge; 3) Relational embeddedness in the AI knowledge network. The pattern of adoption identified is highly clustered and features a rather closed system of AI adopters which is likely to hinder its broader diffusion. This has implications for policy which should facilitate diffusion beyond localized clusters of expertise. Our findings also point to the need to employ a systemic perspective to investigate the relation between AI adoption and firm performance to identify whether appropriation of the benefits of AI depends on network position and social capital.
ER  - 

TY  - JOUR
T1  - The hidden complexities of Android TPL detection: An empirical analysis of techniques, challenges, and effectiveness
AU  - Zhan, Lige
AU  - Ming, Jiang
AU  - Fu, Jianming
AU  - Peng, Guojun
AU  - Sha, Letian
AU  - Lan, Lili
JO  - Computers & Security
VL  - 159
SP  - 104672
PY  - 2025
DA  - 2025/12/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104672
UR  - https://www.sciencedirect.com/science/article/pii/S016740482500361X
KW  - Software supply chain security
KW  - Third-party library detection
KW  - Code obfuscation and optimization
KW  - Vulnerability identification
AB  - Third-party libraries (TPLs) play a crucial role in Android application (app) development and have become an indispensable part of the Android ecosystem. However, TPLs also introduce potential security risks, as they may propagate 1-day vulnerabilities or even malicious code into apps. Moreover, certain downstream tasks, such as app clone detection, license violation identification and patch presence test, require accurate TPL detection as a prerequisite. Consequently, TPL detection has gained increasing importance over the past decade in improving maintainability and enhancing security within the software supply chain. To ensure robustness against external factors and precise vulnerability identification, modern library detection tools, in addition to recognizing TPL variety, must be resilient to code obfuscation and optimization, and must also be capable of accurately identifying library versions. Although recent studies have reported progress in addressing these issues, none have conducted a comprehensive evaluation to determine whether the proposed methods effectively overcome these challenges. Furthermore, critical aspects such as tool performance on real-world apps, as well as the generalizability of existing approaches, are frequently overlooked in current research. To gain deeper insights into TPL detection research, we conducted a comprehensive empirical analysis of state-of-the-art approaches in this domain. This study begins by summarizing the common technologies used at each stage of the TPL detection process, followed by an analysis of the prevalence of code obfuscation and optimization in real-world apps to identify key external factors that hinder effective library detection. Next, we evaluate the performance of cutting-edge tools on multiple ground-truth datasets to validate our findings. Specifically, we systematically analyze the methodologies employed by these tools, assessing their capabilities in TPL variety detection, version identification, resilience to common obfuscation and optimization techniques, and the underlying causes of their failures. Finally, we assessed the generalizability of these tools by comparing their performance across diverse datasets and validating them with real-world data. Our findings confirm that obfuscation and optimization are indeed prevalent in real-world scenarios. However, the code transformations introduced by these techniques often exceed the scope of scenarios considered in prior TPL detection studies. We also observe that even the most advanced detection features struggle to accurately differentiate between library versions. In addition to errors caused by obfuscation and optimization, overly simplistic library features can further contribute to false positives. Moreover, while most tools perform well on their own curated datasets and show reduced performance on external datasets, their effectiveness in real-world scenarios does not exhibit a substantial disparity. Overall, this paper presents a comprehensive analysis and evaluation of current TPL detection techniques, providing a solid foundation for future research in this area.
ER  - 

TY  - JOUR
T1  - MDOB: Enhancing resilient and explainable AI-powered malware detection using feature set optimization and Mutual Deep＋Boosting Ensemble Inference
AU  - Vo, Hoang V.
AU  - Du, Hanh P.
AU  - Nguyen, Hoa N.
JO  - Journal of Information Security and Applications
VL  - 93
SP  - 104175
PY  - 2025
DA  - 2025/09/01/
SN  - 2214-2126
DO  - https://doi.org/10.1016/j.jisa.2025.104175
UR  - https://www.sciencedirect.com/science/article/pii/S2214212625002121
KW  - Feature set optimization
KW  - AI-powered malware detection
KW  - Mutual Deep＋Boosting Learning
KW  - Parallel ensemble inference
AB  - Identifying new malware variants generated through obfuscation and deformation techniques limits the effectiveness of signature-based malware detection methods. It has led to the widespread adoption of AI-powered methods, which use classification models to analyze malware behavior for detection. However, these methods are also vulnerable to adversarial manipulation, where small perturbations can cause misclassifications. Hence, this study introduces MDOB, an innovative AI-powered malware detection framework designed to improve both accuracy and resilience, as well as to provide explainability. Particularly, MDOB incorporates three novel approaches: (i) determining the optimal feature set to enhance efficiency regarding both speed and detection rate for training and identifying malware; (ii) employing an ensemble of mutual deep learning and gradient-boosting inference, initially for voting among multiple AI-based classifiers, followed by stacking individual and voting probability predictions to improve malware detection and reduce vulnerability to model poisoning; and (iii) executing malware detection inference concurrently to diminish inference time. Consequently, extensive experiments on well-known datasets, including EMBER 2018 and BODMAS, demonstrate that MDOB markedly exceeds the current benchmarks in malware detection performance. It achieves the accuracy of 98.14% with merely 1.93% false alarms on EMBER 2018, while significantly diminishing detection time by 37.44%. On BODMAS achieves an accuracy of 99.46% with a false alarm rate of 0.54%, validating its robustness across diverse malware datasets.
ER  - 

TY  - JOUR
T1  - A3D: Attention-based auto-encoder anomaly detector for false data injection attacks
AU  - Kundu, Arnav
AU  - Sahu, Abhijeet
AU  - Serpedin, Erchin
AU  - Davis, Katherine
JO  - Electric Power Systems Research
VL  - 189
SP  - 106795
PY  - 2020
DA  - 2020/12/01/
SN  - 0378-7796
DO  - https://doi.org/10.1016/j.epsr.2020.106795
UR  - https://www.sciencedirect.com/science/article/pii/S0378779620305988
KW  - Anomaly detection
KW  - Auto-Encoders
KW  - Monotonic attention
KW  - False data injection attacks
KW  - Recurrent neural networks
AB  - With the influx of more advanced and more connected computing and control devices, the electric power grid has continuously evolved to rely on communication networks for efficient operation and control. A challenge with these new technologies is that they may introduce new and unforeseen avenues of access, making the grid more susceptible to cyber attacks. False Data Injection Attacks (FDIA) are a particular type of attack that aims to cause disruptions in the operation of the power grid by affecting the feedback mechanism to control the grid. This is carried out by modifying the measurements which enable a state estimator to approximate the state of the system. These attacks are designed in such a way that they preserve the system equations on which the state estimator operates; therefore, they cannot be detected by a simple residual-based detection mechanism. In this paper, we propose monotonic attention based auto-encoders, an unsupervised learning technique to detect FDIAs. The auto-encoder is trained under normal operating conditions, and we hypothesize that it will produce outputs which are close to the true system values at normal operation even if the measurements are modified by an adversary. Based on this hypothesis, that high reconstruction error occurs for the attacked conditions, the intrusion detection is performed by a threshold mechanism using Precision-Recall curve. We validate the efficacy of our proposed attention-based auto-encoder anomaly detector (A3D) over other variants of auto-encoders such as ANN and RNN based auto-encoders, and a few supervised learning techniques, by performing FDIAs on a IEEE 14 bus system.
ER  - 

TY  - JOUR
T1  - SeMalBERT: Semantic-based malware detection with bidirectional encoder representations from transformers
AU  - Liu, Junming
AU  - Zhao, Yuntao
AU  - Feng, Yongxin
AU  - Hu, Yutao
AU  - Ma, Xiangyu
JO  - Journal of Information Security and Applications
VL  - 80
SP  - 103690
PY  - 2024
DA  - 2024/02/01/
SN  - 2214-2126
DO  - https://doi.org/10.1016/j.jisa.2023.103690
UR  - https://www.sciencedirect.com/science/article/pii/S2214212623002740
KW  - Cyber security
KW  - BERT
KW  - Malware
KW  - CNN
KW  - LSTM
AB  - Machine learning models are widely used for identifying malicious software. However, existing models suffer from issues such as imprecise polysemous representations and a lack of contextual semantic representations, leading to the failure to recognize certain types of malicious software. In this paper, we propose a semantic-based intelligent malware detection model called SeMalBERT for identifying malicious software in Windows systems. Specifically, the model utilizes the API function sequences of malicious software as the learned features. Firstly, BERT is applied to accomplish word representation tasks and extract semantic information from the sequences. Secondly, a hybrid discriminator based on Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) is used to explore the chaining relationships between functions. Lastly, an external attention mechanism is added after the LSTM to enable the model to better focus on key information within the text. Experimental results demonstrate that SeMalBERT outperforms existing malware detection techniques in terms of accuracy, F1 score, and loss function value on a general dataset.
ER  - 

TY  - JOUR
T1  - SKT-IDS: Unknown attack detection method based on Sigmoid Kernel Transformation and encoder–decoder architecture
AU  - Zha, Chao
AU  - Wang, Zhiyu
AU  - Fan, Yifei
AU  - Zhang, Xingming
AU  - Bai, Bing
AU  - Zhang, Yinjie
AU  - Shi, Sainan
AU  - Zhang, Ruyun
JO  - Computers & Security
VL  - 146
SP  - 104056
PY  - 2024
DA  - 2024/11/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104056
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824003614
KW  - Intrusion detection
KW  - Sigmoid Kernel Transformation
KW  - Pre-trained encoder
KW  - Encoder–decoder
KW  - Cosine similarity
AB  - Intrusion Detection Systems (IDS) are crucial in cybersecurity for monitoring network traffic and identifying potential attacks. Existing IDS research largely focuses on known attack detection, leaving a significant gap in research regarding unknown attack detection, where achieving a balance between false alarm rate (identifying normal traffic as attack traffic) and recall rate of unknown attack detection remains challenging. To address these gaps, we propose a novel IDS based on Sigmoid Kernel Transformation and Encoder-Decoder architecture, namely SKT-IDS, where SKT stands for Sigmoid Kernel Transformation. We start with pre-training an attention-based encoder for coarse-grained intrusion detection. Then, we use this encoder to build an encoder–decoder model specifically for 0-day attack detection, training it solely on known traffic using the cosine similarity loss function. To enhance detection, we introduce a Sigmoid Kernel Transformation for feature engineering, improving the discriminative ability between normal traffic and 0-day attacks. Finally, we conducted a series of ablation and comparative experiments on the NSL-KDD and CSE-CIC-IDS2018 datasets, confirming the effectiveness of our proposed method. With a false alarm rate of 1%, we achieved recall rates for unknown attack detection of 65% and 69% on the two datasets, respectively, demonstrating significant performance improvements compared to existing state-of-the-art models.
ER  - 

TY  - JOUR
T1  - Dynamic Network Intrusion Detection Model Based on Transformer and Adversarial Autoencoder
AU  - Liu, Weiwei
JO  - International Journal of Intelligent Networks
PY  - 2025
DA  - 2025/11/10/
SN  - 2666-6030
DO  - https://doi.org/10.1016/j.ijin.2025.11.002
UR  - https://www.sciencedirect.com/science/article/pii/S266660302500020X
KW  - Network intrusion detection
KW  - Transformer
KW  - Adversarial autoencoders
KW  - Deep Learning
KW  - Dataset
AB  - With the rapid development of information technology, network security problems have become increasingly severe, and the effectiveness of network intrusion detection systems has become a critical tool in ensuring network security. Traditional intrusion detection methods often suffer from high false positive and false negative rates, particularly when dealing with complex and evolving network attacks that are difficult to manage. To this end, this paper proposes a dynamic network intrusion detection model that integrates Transformer and adversarial autoencoder to improve the accuracy and robustness of network intrusion detection through deep learning technology. First, the Transformer model is used to perform deep learning feature extraction on network traffic data, which can capture time series dependencies in traffic and identify potential patterns of network attacks. Secondly, an adversarial autoencoder is introduced to further optimize the feature representation of the model by generating adversarial training, reduce the risk of overfitting, and improve the detection ability of the model on unknown attack types. An ablation study showed that replacing the AAE with a standard autoencoder reduced performance, with accuracy dropping to 91.6% on KDD99 and 94.2% on CICIDS2017. This demonstrates the AAE's importance in handling complex attacks. Additionally, the false positive rate increased to 6.5% on KDD99, highlighting the AAE's role in reducing overfitting and improving detection. On the KDD99 dataset, the accuracy rate of the model reaches 98.7%, which is 4.5% higher than that of the traditional method; On the CICIDS2017 dataset, the accuracy rate of the model is 97.3%, which is 3.2% higher than the benchmark method. In addition, the proposed model shows good generalization ability when dealing with different attack types, can effectively identify common attack types such as DDoS attacks and SQL injection, and has strong adaptability in dynamic network environments. By comparing the experimental results, the model of this study has excellent performance in reducing false positive rate and false negative rate, with false negative rate as low as 1.5% and false positive rate as low as 2.3%. The dynamic intrusion detection model, combining Transformer and adversarial autoencoders, outperforms traditional IDS methods in terms of accuracy and robustness, offering an effective solution for modern network security challenges.
ER  - 

TY  - JOUR
T1  - KPAMA: A Kubernetes based tool for Mitigating ML system Aging
AU  - Ding, Wenjie
AU  - Liu, Zhihao
AU  - Lu, Xuhui
AU  - Du, Xiaoting
AU  - Zheng, Zheng
JO  - Journal of Systems and Software
VL  - 226
SP  - 112389
PY  - 2025
DA  - 2025/08/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2025.112389
UR  - https://www.sciencedirect.com/science/article/pii/S0164121225000573
KW  - Kubernetes-based machine learning system
KW  - Software aging
KW  - Data prediction
KW  - Autoscaling
AB  - As machine learning (ML) systems continue to evolve and be applied, their user base and system size also expand. This expansion is particularly evident with the widespread adoption of large language models. Currently, the infrastructure supporting ML systems, such as cloud services and computing hardware, which are increasingly becoming foundational to the ML system environment, is increasingly adopted to support continuous training and inference services. Nevertheless, it has been shown that the increased data volume, complexity of computations, and extended run times challenge the stability of ML systems, efficiency, and availability, precipitating system aging. To address this issue, we develop a novel solution, KPAMA, leveraging Kubernetes, the leading container orchestration platform, to enhance the autoscaling of computing workflows and resources, effectively mitigating system aging. KPAMA employs a hybrid model to predict key aging metrics and uses decision and anti-oscillation algorithms to achieve system resource autoscaling. Our experiments indicate that KPAMA markedly mitigates system aging and enhances task reliability compared to the standard Horizontal Pod Autoscaler and systems without scaling capabilities.
ER  - 

TY  - JOUR
T1  - Network intrusion detection based on n-gram frequency and time-aware transformer
AU  - Han, Xueying
AU  - Cui, Susu
AU  - Liu, Song
AU  - Zhang, Chen
AU  - Jiang, Bo
AU  - Lu, Zhigang
JO  - Computers & Security
VL  - 128
SP  - 103171
PY  - 2023
DA  - 2023/05/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2023.103171
UR  - https://www.sciencedirect.com/science/article/pii/S0167404823000810
KW  - Intrusion detection
KW  - Deep learning
KW  - Transformer
KW  - N-Gram
AB  - Network intrusion detection system plays a critical role in protecting the target network from attacks. However, most existing detection methods cannot fully utilize the information contained in raw network traffic, such as information loss in the feature extraction process and incomplete feature dimensions, which lead to performance bottlenecks. In this paper, we propose a novel intrusion detection model based on n-gram frequency and time-aware transformer called GTID. GTID can learn traffic features from packet-level and session-level hierarchically and can minimize information as much as possible. To extract packet-level features effectively, GTID considers the different roles of packet header and payload, and processes them in different ways, where n-gram frequency is used to represent payload contextual information because of its conciseness. Then, GTID uses the proposed time-aware transformer to learn session-level features for intrusion detection. The time-aware transformer considers the time intervals between packets, and learns the temporal features of a session for classification. For evaluation, several solid experiments are conducted on the ISCX2012 dataset and the CICIDS2017 dataset, and the results show the effectiveness and robustness of GTID.
ER  - 

TY  - JOUR
T1  - GenAI in Rule-based Systems for IoMT Security: Testing and Evaluation
AU  - Bughio, Kulsoom S.
AU  - Cook, David M.
AU  - Shah, Syed Afaq A.
JO  - Procedia Computer Science
VL  - 246
SP  - 5330
EP  - 5339
PY  - 2024
DA  - 2024/01/01/
T2  - 28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.09.652
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924027078
KW  - Artificial Intelligence
KW  - IoMT
KW  - Ruled-based Systems
KW  - Vulnerability Detection
KW  - Gen AI
AB  - Generative AI (GenAI) represents a significant advancement in Artificial intelligence research, offering numerous benefits and opening new avenues for innovation across various domains. In healthcare, Generative AI has shown promise in applications such as drug discovery, personalized medicine, and medical imaging. This paper examines the role of Generative AI in rule-based systems, where vulnerabilities are detected with the help of formal logic. In this context, the ruleset is generated and tested to evaluate the performance of rule-based systems with the aid of GenAI. The effectiveness of the GenAI tool was evaluated using a publicly available case study from a laboratory setting. The results show that using generative Artificial intelligence in rule-based systems leads to increased creativity, continuous learning, and robust performance. GenAI responded to each use case and provided the desired results compared to traditional rule-based systems. This integration of advanced AI techniques with traditional rule-based systems ensures that these hybrid systems perform reliably and effectively.
ER  - 

TY  - JOUR
T1  - Sensing the diversity of rumors: Rumor detection with hierarchical prototype contrastive learning
AU  - Zheng, Peng
AU  - Dou, Yong
AU  - Yan, Yeqing
JO  - Information Processing & Management
VL  - 61
IS  - 6
SP  - 103832
PY  - 2024
DA  - 2024/11/01/
SN  - 0306-4573
DO  - https://doi.org/10.1016/j.ipm.2024.103832
UR  - https://www.sciencedirect.com/science/article/pii/S0306457324001912
KW  - Rumor detection
KW  - Social networks
KW  - Hierarchical prototype
KW  - Contrastive learning
AB  - The proliferation of rumors on social networks poses a serious threat to cybersecurity, justice and public trust, increasing the urgent need for rumor detection. Existing detection methods typically treat all rumors as a single homogeneous category, neglecting the diverse semantic hierarchies within rumors. Rumors pervade various domains, each with its distinct characteristics. These methods tend to lag in expressiveness when confronted with real-world scenarios involving multiple semantic levels. Furthermore, the diversity of rumors also complicates the collection of datasets, and inevitably introduces noisy data, which hinders the correctness of the learned representations. To address these challenges, we propose a rumor detection framework with Hierarchical Prototype Contrastive Learning (HPCL). In this framework, we construct a set of dynamically updated hierarchical prototypes through contrastive learning to encourage capturing the hierarchical semantic structure within rumors. Additionally, we design a difficulty metric function based on the distance between instances and prototypes, and introduce curriculum learning to mitigate the adverse effects of noisy data. Experiments on four public datasets demonstrate that our approach achieves state-of-the-art performance. Our code is publicly released at https://github.com/Coder-HenryZa/HPCL.
ER  - 

TY  - JOUR
T1  - Aggression detection through deep neural model on Twitter
AU  - Sadiq, Saima
AU  - Mehmood, Arif
AU  - Ullah, Saleem
AU  - Ahmad, Maqsood
AU  - Choi, Gyu Sang
AU  - On, Byung-Won
JO  - Future Generation Computer Systems
VL  - 114
SP  - 120
EP  - 129
PY  - 2021
DA  - 2021/01/01/
SN  - 0167-739X
DO  - https://doi.org/10.1016/j.future.2020.07.050
UR  - https://www.sciencedirect.com/science/article/pii/S0167739X19330717
KW  - Aggression detection
KW  - Multilayer Perceptron (MLP)
KW  - Convolutional Neural Network (CNN)
KW  - Long short-term memory (LSTM)
KW  - BiLSTM
AB  - Social interaction is being facilitated by every online environment that results in rise of anti-social behavior. Incidents like cyberbullying, trolling and hate speech have been grown significantly across the globe. Hate and aggression detection had become a crucial part of cyberbullying and cyberharassment. Cyberbullying refers to aggressive behavior with rude, offensive, insulting, hateful and teasing comments to harm other individuals on social media. Human moderation is slow and expensive and even not feasible in speedily growing data, only automatic detection can lead to put a stop on trolling. In this paper we address the challenge of automatic identification of aggression detection on tweets of cyber-troll dataset. We deploy Multilayer Perceptron by feeding important manually engineered features and also experimented on state-of-the-art combination of CNN-LSTM and CNN-BiLSTM in deep neural network, both perform well. Statistical results proved that our proposed model performed best and detects aggressive behavior with 92% accuracy.
ER  - 

TY  - JOUR
T1  - Emotion and Phrase-Based Patterns in Smishing: A Feature-Driven Detection Framework
AU  - Krawczyk, Natalia
AU  - Probierz, Barbara
AU  - Kozak, Jan
JO  - Procedia Computer Science
VL  - 270
SP  - 4421
EP  - 4430
PY  - 2025
DA  - 2025/01/01/
T2  - 29th International Conference on Knowledge-Based and Intelligent Information & Engineering Systems (KES 2025)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2025.09.567
UR  - https://www.sciencedirect.com/science/article/pii/S1877050925032405
KW  - smishing detection
KW  - emotional features
KW  - sentiment analysis
KW  - feature engineering
AB  - Smishing, or SMS-based phishing, remains a significant threat to mobile users due to its use of concise and emotionally manipulative language. These messages often rely on psychological cues and high-risk phrases that are not fully captured by traditional feature engineering. This study proposes an improved smishing detection framework that adds emotion-based labels and phrase-level risk indicators to embedding-based models. We used GPT-4.5 to annotate emotional dimensions. We also extracted targeted phrasal indicators based on known smishing patterns. Experiments on a unified dataset of over 22000 SMS messages show that combining emotion-based and phrase-level features consistently improves classification accuracy. For example, in Logistic Regression with TF-IDF, accuracy increased from 0.9186 to 0.9221 after adding both types of features. Gradient Boosting with TF-IDF showed the largest performance gain, while Random Forest achieved the highest absolute accuracy in this setting (0.9432). For Word2Vec embeddings, similar patterns were observed: Logistic Regression improved the most (from 0.8721 to 0.8817), while XGBoost reached the highest overall accuracy (0.9447) with sentiment-enhanced input. However, in some cases, risk-based features led to a slight drop in performance, suggesting potential feature noise in highly optimized or shallow models. These findings indicate that combining emotion-driven and pattern-based features with classical embeddings enhances phishing detection performance, particularly in short messages where traditional methods may lack context awareness.
ER  - 

TY  - JOUR
T1  - One-class classification via generative adversarial and federated distillation
AU  - Yi, Xiaoyang
AU  - Liu, Yang
AU  - Zhang, Jian
AU  - Yang, Binhan
AU  - Bao, Yuru
AU  - Chen, Jing
AU  - Yu, Tong
JO  - Expert Systems with Applications
VL  - 300
SP  - 130165
PY  - 2026
DA  - 2026/03/05/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2025.130165
UR  - https://www.sciencedirect.com/science/article/pii/S0957417425037807
KW  - Federated learning
KW  - One-class classification
KW  - Data-free knowledge distillation
KW  - Adversarial training
AB  - One-class classification (OCC) aims to learn a decision boundary using only in-class samples to determine whether a query sample belongs to the target class. In many OCC applications, the privacy of in-class data is paramount, motivating a federated learning (FL)-based OCC framework, while extreme data heterogeneity hinders model performance. To address these, we propose FedOCC, a novel FL-based OCC framework that combines generative adversarial and federated distillation. Specifically, FedOCC deploys a semantic-aware generator that leverages inherent label-informed semantic and client-specific prototypes to synthesize samples trained against the global model. Additionally, FedOCC integrates data-free knowledge distillation with replay-based contrastive learning to facilitate local knowledge transfer from clients to the global model. Finally, through differential updates, FedOCC mitigates extreme heterogeneity and delivers personalized federated models to clients. Experimental results demonstrate that FedOCC outperforms existing methods, showcasing its effectiveness and robustness.
ER  - 

TY  - JOUR
T1  - Assessing the detection of lateral movement through unsupervised learning techniques
AU  - Smiliotopoulos, Christos
AU  - Kambourakis, Georgios
AU  - Kolias, Constantinos
AU  - Gritzalis, Stefanos
JO  - Computers & Security
VL  - 149
SP  - 104190
PY  - 2025
DA  - 2025/02/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2024.104190
UR  - https://www.sciencedirect.com/science/article/pii/S0167404824004954
KW  - Lateral movement
KW  - Intrusion detection systems
KW  - Cyberattacks
KW  - Machine learning
KW  - Network security
KW  - Sysmon
KW  - Dataset
AB  - Lateral movement (LM) is an umbrella term for techniques through which attackers spread from an entry point to the rest of the network. Typically, LM involves both pivoting through multiple systems and privilege escalation. As LM techniques proliferate and evolve, there is a need for advanced security controls able to detect and possibly nip such attacks in the bud. Based on the published literature, we argue that although LM-focused intrusion detection systems have received considerable attention, a prominent issue remains largely unaddressed. This concerns the detection of LM through unsupervised machine learning (ML) techniques. This work contributes to this field by capitalizing on the LMD-2023 dataset containing traces of 15 diverse LM attack techniques as they were logged by the system monitor (Sysmon) service of the MS Windows platform. We provide a panorama of this sub-field and associated methodologies, exploring the potential of standard ML-based detection. In further detail, in addition to analyzing feature selection and preprocessing, we detail and evaluate a plethora of unsupervised ML techniques, both shallow and deep. The derived scores for the best performer in terms of the AUC and F1 metrics are quite promising, around 94.7%/93% and 95.2%/93.8%, for the best shallow and deep neural network model, respectively. On top of that, in an effort to further improve on those metrics, we devise and evaluate a two-stage ML model, surpassing the previous best score by approximately 3.5%. Overall, to our knowledge, this work provides the first full-blown study on LM detection via unsupervised learning techniques, therefore it is anticipated to serve as a groundwork for anyone working in this timely field.
ER  - 

TY  - JOUR
T1  - N-gram MalGAN: Evading machine learning detection via feature n-gram
AU  - Zhu, Enmin
AU  - Zhang, Jianjie
AU  - Yan, Jijie
AU  - Chen, Kongyang
AU  - Gao, Chongzhi
JO  - Digital Communications and Networks
VL  - 8
IS  - 4
SP  - 485
EP  - 491
PY  - 2022
DA  - 2022/08/01/
SN  - 2352-8648
DO  - https://doi.org/10.1016/j.dcan.2021.11.007
UR  - https://www.sciencedirect.com/science/article/pii/S2352864821000973
KW  - Machine learning
KW  - N-gram
KW  - MalGAN
KW  - Adversarial examples
AB  - In recent years, many adversarial malware examples with different feature strategies, especially GAN and its variants, have been introduced to handle the security threats, e.g., evading the detection of machine learning detectors. However, these solutions still suffer from problems of complicated deployment or long running time. In this paper, we propose an n-gram MalGAN method to solve these problems. We borrow the idea of n-gram from the Natural Language Processing (NLP) area to expand feature sources for adversarial malware examples in MalGAN. Generally, the n-gram MalGAN obtains the feature vector directly from the hexadecimal bytecodes of the executable file. It can be implemented easily and conveniently with a simple program language (e.g., C++), with no need for any prior knowledge of the executable file or any professional feature extraction tools. These features are functionally independent and thus can be added to the non-functional area of the malicious program to maintain its original executability. In this way, the n-gram could make the adversarial attack easier and more convenient. Experimental results show that the evasion rate of the n-gram MalGAN is at least 88.58% to attack different machine learning algorithms under an appropriate group rate, growing to even 100% for the Random Forest algorithm.
ER  - 

TY  - JOUR
T1  - An evaluation framework for network IDS/IPS datasets: Leveraging MITRE ATT&CK and industry relevance metrics
AU  - Tory, Adrita Rahman
AU  - Hasan, Khondokar Fida
JO  - Computers & Security
VL  - 161
SP  - 104777
PY  - 2026
DA  - 2026/02/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2025.104777
UR  - https://www.sciencedirect.com/science/article/pii/S0167404825004663
KW  - Intrusion detection systems
KW  - Intrusion prevention systems
KW  - Dataset evaluation
KW  - MITRE ATT&CK framework
KW  - Industry-specific threat intelligence
AB  - The performance of Machine Learning (ML) and Deep Learning (DL)-based Intrusion Detection and Prevention Systems (IDS/IPS) is critically dependent on the relevance and quality of the datasets used for training and evaluation. However, current AI model evaluation practices for developing IDS/IPS focus predominantly on accuracy metrics, often overlooking whether datasets represent industry-specific threats. To address this gap, we introduce a novel multi-dimensional framework that integrates the MITRE ATT&CK knowledge base for threat intelligence and employs five complementary metrics that together provide a comprehensive assessment of dataset suitability. Methodologically, this framework combines threat intelligence, natural language processing, and quantitative analysis to assess the suitability of datasets for specific industry contexts. Applying this framework to nine publicly available IDS/IPS datasets reveals significant gaps in threat coverage, particularly in the healthcare, energy, and financial sectors. In particular, recent datasets (e.g., CIC-IoMT, CIC-UNSW-NB15) align better with sector-specific threats, whereas others, like CICIoV-24, underperform despite their recency. Our findings provide a standardized, interpretable approach for selecting datasets aligned with sector-specific operational requirements, ultimately enhancing the real-world effectiveness of AI-driven IDS/IPS deployments. The efficiency and practicality of the framework are validated through deployment in a real-world case study, underscoring its capacity to inform dataset selection and enhance the effectiveness of AI-driven IDS/IPS in operational environments.
ER  - 

TY  - JOUR
T1  - Phishing URL detection generalisation using Unsupervised Domain Adaptation
AU  - Rashid, Fariza
AU  - Doyle, Ben
AU  - Han, Soyeon Caren
AU  - Seneviratne, Suranga
JO  - Computer Networks
VL  - 245
SP  - 110398
PY  - 2024
DA  - 2024/05/01/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2024.110398
UR  - https://www.sciencedirect.com/science/article/pii/S1389128624002305
KW  - Phishing detection
KW  - Unsupervised domain adaptation
KW  - URL classification
AB  - Phishing attacks are a prevailing problem in cybersecurity. In many data breaches, the initial entry can be traced back to phishing. URL-based phishing detection is one of the many ways of phishing attempt detection where solely the properties of the URLs are used to decide whether a given URL is phishing or not. While there are multiple existing works that use machine learning and deep learning to detect phishing URLs, in this paper, we show that such methods lack generalisation (i.e., they work effectively only when the test sets are split from the same training dataset). This is a significant issue since the vast majority of phishing attempts are short-lived and use freshly created domain names. Also, many network vantage points and middleboxes record URLs in slightly different formats and as such, URL data collected at various companies may be different. To address this, we propose an Unsupervised Domain Adaptation-based framework to increase the model transferability between datasets. We evaluate our approach using three datasets and show that the increase in cross-dataset F1 score performance is 0.06 on average and in some cases approximately as high as 0.2.
ER  - 

TY  - JOUR
T1  - Leveraging Deep Learning for Precision-Aware Road Accident Detection
AU  - Thakur, Kunal
AU  - Taneja, Ashu
AU  - Alqahtani, Ali
AU  - Alqahtani, Nayef
JO  - Computers, Materials and Continua
VL  - 85
IS  - 3
SP  - 4827
EP  - 4848
PY  - 2025
DA  - 2025/10/23/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2025.067901
UR  - https://www.sciencedirect.com/science/article/pii/S1546221825009841
KW  - Accident detection
KW  - deep learning
KW  - ResNet-50
KW  - traffic safety
KW  - image classification
KW  - optimizer
KW  - real-time monitoring
AB  - Accident detection plays a critical role in improving traffic safety by enabling timely emergency response and reducing the impact of road incidents. The main challenge lies in achieving real-time, reliable and highly accurate detection across diverse Internet-of-vehicles (IoV) environments. To overcome this challenge, this paper leverages deep learning to automatically learn patterns from visual data to detect accidents with high accuracy. A visual classification model based on the ResNet-50 architecture is presented for distinguishing between accident and non-accident images. The model is trained and tested on a labeled dataset and achieves an overall accuracy of 91.84%, with a precision of 94%, recall of 90.38%, and an F1-score of 92.14%. Training behavior is observed over 100 epochs, where the model has shown rapid accuracy gains and loss reduction within the first 30 epochs, followed by gradual stabilization. Accuracy plateaues between 90−93%, and loss values remain consistent between 0.1 and 0.2 in later stages. To understand the effect of training strategy, the model is optimized using three different algorithms, namely, SGD, Adam, and Adadelta with all showing effective performance, though with varied convergence patterns. Further, to test its effectiveness, the proposed model is compared with existing models. In the end, the problems encountered in implementing the model in practical automotive settings and offered solutions are discussed. The results support the reliability of the approach and its suitability for real-time traffic safety applications.
ER  - 

TY  - JOUR
T1  - Towards explainable fake news detection and automated content credibility assessment: Polish internet and digital media use-case
AU  - Kozik, Rafał
AU  - Kątek, Gracjan
AU  - Gackowska, Marta
AU  - Kula, Sebastian
AU  - Komorniczak, Joanna
AU  - Ksieniewicz, Paweł
AU  - Pawlicka, Aleksandra
AU  - Pawlicki, Marek
AU  - Choraś, Michał
JO  - Neurocomputing
VL  - 608
SP  - 128450
PY  - 2024
DA  - 2024/12/01/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2024.128450
UR  - https://www.sciencedirect.com/science/article/pii/S0925231224012219
KW  - Fake news
KW  - Machine learning
KW  - AI
KW  - Explainability
AB  - Detecting fake news and disinformation is a challenging and complex task. With the proliferation of the transformer architectures, researchers and practitioners have started actively using them to combat this phenomenon. In that regard, different approaches have been proposed by the community. Unfortunately, a significant number of solutions have started to treat misinformation in a similar way as other natural language processing challenges (e.g., sentiment classification). However, the reality is more complex, and the fake news detection problem often require additional context that may be essential to provide a complete assessment. Another pitfall in combating fake news is treating it as a binary classification challenge (e.g., fake vs. legitimate news). Combining such a simplified response with a deep black-box neural system effectively impacts the interpretability and eventual trustworthiness of the detection system. In this paper, the phenomenon of fake news is approached from a multi-factor perspective. Therefore, the proposed innovative approach does not limit news content rating to a one-dimensional binary response. In particular, the authors utilize a vast spectrum of processing techniques, including text embedding, machine translation, and various users’ preferences to provide content assessment. The results are presented using a Polish digital media use-case.
ER  - 

TY  - JOUR
T1  - BiT5: A Bidirectional NLP Approach for Advanced Vulnerability Detection in Codebase
AU  - GS, Prabith
AU  - M, Rohit Narayanan
AU  - A, Arya
AU  - R, Aneesh Nadh
AU  - PK, Binu
JO  - Procedia Computer Science
VL  - 233
SP  - 812
EP  - 821
PY  - 2024
DA  - 2024/01/01/
T2  - 5th International Conference on Innovative Data Communication Technologies and Application (ICIDCA 2024)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.03.270
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924006306
KW  - Bidirectional Transformer
KW  - BiT5 Model
KW  - Code Analysis
KW  - Code Vulnerabilities
KW  - Machine Learning
KW  - Natural Language Processing (NLP)
KW  - Software Security
KW  - Vulnerability Detection
AB  - In this research paper, a detailed investigation presents the utilization of the BiT5 Bidirectional NLP model for detecting vulnerabilities within codebases. The study addresses the pressing need for techniques enhancing software security by effectively identifying vulnerabilities. Methodologically, the paper introduces BiT5, specifically designed for code analysis and vulnerability detection, encompassing dataset collection, preprocessing steps, and model fine-tuning. The key findings underscore BiT5’s efficacy in pinpointing vulnerabilities within code snippets, notably reducing both false positives and false negatives. This research contributes by offering a methodology for leveraging BiT5 in vulnerability detection, thus significantly bolstering software security and mitigating risks associated with code vulnerabilities.
ER  - 

TY  - JOUR
T1  - The Impact of AI Foundation models on the future of digital engineering for logistics and supply Chain
AU  - Nicoletti, Bernardo
AU  - Appolloni, Andrea
JO  - Digital Engineering
VL  - 7
SP  - 100058
PY  - 2025
DA  - 2025/12/01/
SN  - 2950-550X
DO  - https://doi.org/10.1016/j.dte.2025.100058
UR  - https://www.sciencedirect.com/science/article/pii/S2950550X2500024X
KW  - Logistics
KW  - Supply chain
KW  - Industry 5.0
KW  - Foundation model
KW  - Artificial intelligence
KW  - Digital twins
KW  - Cyber-physical system
KW  - Digital engineering
KW  - Industrial internet of things. scor
AB  - The organizational environment is subject to constant change, driven by rapid technological progress and the advent of Industry 5.0. This dynamic scenario compels authors and practitioners in the fields of logistics and supply chain management and operations (LSCM) to explore the transformative impact of foundation models (FMs) and artificial intelligence (AI) on these areas. The integration of AI FMs, coupled with digital twins (DT) and cyber-physical systems (CPS), will not only optimize current processes but also fundamentally reshape the future of digital engineering (DE) in LSCM. Understanding the opportunities and challenges with FMs is critical to the strategic positioning in an ever-evolving marketplace where Industry 5.0 technologies drive innovation and efficiency. Organizations can gain a competitive advantage by analyzing the opportunities and risks of integrating FMs into LSCM operations and leveraging their ability to improve decision making and enhance predictive analytics and real-time monitoring through DT and CPS. This paper serves as a comprehensive and informative guide for evaluating the transformative potential of FMs in redesigning LSCM operations in the context of Industry 5.0, highlighting critical applications, exploring potential benefits and challenges, and pointing to upcoming innovations such as AI-driven DT and smart cyber-physical systems that are revolutionizing supply chain (SC) processes. The detailed analysis based on the Supply Chain Operations Reference (SCOR) components shows that FM-based solutions, supported by AI and Industry 5.0 technologies, can significantly improve LSCM business processes. This paper presents an integrated functional framework and technical architecture for implementing FM in LSCM, emphasizing the role of DT and CPS in enabling smart, adaptive, and resilient SC. The paper concludes with an industrial case study that further substantiates these claims and shows the practical application of FM in a shipbuilding organization. The case study describes successful approaches to implementing and effectively utilizing AI and DT. It provides a practical, functional, and technical framework for applying the transformative impact of FMs on LSCM within the Industry 5.0 paradigm. This integration highlights the synergy between FM, AI, DT, and CPS and paves the way. It paves the way for a more innovative, sustainable, and competitive management of supply networks and their operations.
ER  - 

TY  - JOUR
T1  - Collaborative optimization for multirobot manufacturing system reliability through integration of SysML simulation and maintenance knowledge graph
AU  - Zhou, Jian
AU  - Zheng, Lianyu
AU  - Wang, Yiwei
JO  - Journal of Manufacturing Systems
VL  - 80
SP  - 749
EP  - 775
PY  - 2025
DA  - 2025/06/01/
SN  - 0278-6125
DO  - https://doi.org/10.1016/j.jmsy.2025.04.010
UR  - https://www.sciencedirect.com/science/article/pii/S0278612525000998
KW  - Multirobot system
KW  - Reliability optimization
KW  - SysML model simulation
KW  - Maintenance knowledge graph
KW  - Similarity reasoning
AB  - In the rapidly advancing field of industrial automation, the reliability and maintenance of multirobot manufacturing systems are crucial. This paper proposes a collaborative optimization method for the reliability of multirobot system, combining SysML (System Modeling Language) model simulation with an operational and maintenance knowledge graph, aiming to ensure the reliable operation of multirobot manufacturing systems. The SysML model provides a comprehensive framework to represent the system architecture, workflows, and key parameters, identify critical components and potential bottlenecks, and perform detailed reliability analysis. Simultaneously, by embedding intelligent algorithms, the operational and maintenance knowledge graph enables automatic detection of operational anomalies and intelligent generation of maintenance strategies for industrial robots. By integrating the SysML model with the operational and maintenance knowledge graph, a collaborative optimization framework for the reliability of multirobot system is constructed. This framework not only dynamically adjusts key parameters in the simulation model, enhancing the accuracy and real-time performance of system reliability assessments, but also optimizes maintenance strategies based on system simulation indicators to ensure the reliable operation of multirobot system. Case studies validate that the proposed method improves the reliability of multirobot manufacturing systems, demonstrating that the combination of SysML simulation and the operational and maintenance knowledge graph can effectively address the complexity of modern manufacturing systems, offering significant reference value.
ER  - 
